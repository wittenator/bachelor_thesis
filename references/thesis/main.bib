
@article{liptonMythosModelInterpretability2016a,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1606.03490},
  primaryClass = {cs, stat},
  title = {The {{Mythos}} of {{Model Interpretability}}},
  abstract = {Supervised machine learning models boast remarkable predictive capabilities. But can you trust your model? Will it work in deployment? What else can it tell you about the world? We want models to be not only good, but interpretable. And yet the task of interpretation appears underspecified. Papers provide diverse and sometimes non-overlapping motivations for interpretability, and offer myriad notions of what attributes render models interpretable. Despite this ambiguity, many papers proclaim interpretability axiomatically, absent further explanation. In this paper, we seek to refine the discourse on interpretability. First, we examine the motivations underlying interest in interpretability, finding them to be diverse and occasionally discordant. Then, we address model properties and techniques thought to confer interpretability, identifying transparency to humans and post-hoc explanations as competing notions. Throughout, we discuss the feasibility and desirability of different notions, and question the oft-made assertions that linear models are interpretable and that deep neural networks are not.},
  journal = {arXiv:1606.03490 [cs, stat]},
  author = {Lipton, Zachary C.},
  month = jun,
  year = {2016},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing,Statistics - Machine Learning},
  file = {/home/tim/Zotero/storage/K9YF2I9K/Lipton - 2016 - The Mythos of Model Interpretability.pdf;/home/tim/Zotero/storage/2ID6BE7W/1606.html}
}

@article{millerExplainableAIBeware2017,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1712.00547},
  primaryClass = {cs},
  title = {Explainable {{AI}}: {{Beware}} of {{Inmates Running}} the {{Asylum Or}}: {{How I Learnt}} to {{Stop Worrying}} and {{Love}} the {{Social}} and {{Behavioural Sciences}}},
  shorttitle = {Explainable {{AI}}},
  abstract = {In his seminal book `The Inmates are Running the Asylum: Why High-Tech Products Drive Us Crazy And How To Restore The Sanity' [2004, Sams Indianapolis, IN, USA], Alan Cooper argues that a major reason why software is often poorly designed (from a user perspective) is that programmers are in charge of design decisions, rather than interaction designers. As a result, programmers design software for themselves, rather than for their target audience, a phenomenon he refers to as the `inmates running the asylum'. This paper argues that explainable AI risks a similar fate. While the re-emergence of explainable AI is positive, this paper argues most of us as AI researchers are building explanatory agents for ourselves, rather than for the intended users. But explainable AI is more likely to succeed if researchers and practitioners understand, adopt, implement, and improve models from the vast and valuable bodies of research in philosophy, psychology, and cognitive science, and if evaluation of these models is focused more on people than on technology. From a light scan of literature, we demonstrate that there is considerable scope to infuse more results from the social and behavioural sciences into explainable AI, and present some key results from these fields that are relevant to explainable AI.},
  journal = {arXiv:1712.00547 [cs]},
  author = {Miller, Tim and Howe, Piers and Sonenberg, Liz},
  month = dec,
  year = {2017},
  keywords = {Computer Science - Artificial Intelligence},
  file = {/home/tim/Zotero/storage/SGZP2PCV/Miller et al. - 2017 - Explainable AI Beware of Inmates Running the Asyl.pdf;/home/tim/Zotero/storage/JTDVCR2I/1712.html}
}

@article{millerExplanationArtificialIntelligence2017,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1706.07269},
  primaryClass = {cs},
  title = {Explanation in {{Artificial Intelligence}}: {{Insights}} from the {{Social Sciences}}},
  shorttitle = {Explanation in {{Artificial Intelligence}}},
  abstract = {There has been a recent resurgence in the area of explainable artificial intelligence as researchers and practitioners seek to make their algorithms more understandable. Much of this research is focused on explicitly explaining decisions or actions to a human observer, and it should not be controversial to say that looking at how humans explain to each other can serve as a useful starting point for explanation in artificial intelligence. However, it is fair to say that most work in explainable artificial intelligence uses only the researchers' intuition of what constitutes a `good' explanation. There exists vast and valuable bodies of research in philosophy, psychology, and cognitive science of how people define, generate, select, evaluate, and present explanations, which argues that people employ certain cognitive biases and social expectations towards the explanation process. This paper argues that the field of explainable artificial intelligence should build on this existing research, and reviews relevant papers from philosophy, cognitive psychology/science, and social psychology, which study these topics. It draws out some important findings, and discusses ways that these can be infused with work on explainable artificial intelligence.},
  journal = {arXiv:1706.07269 [cs]},
  author = {Miller, Tim},
  month = jun,
  year = {2017},
  keywords = {Computer Science - Artificial Intelligence},
  file = {/home/tim/Zotero/storage/8L9NTSUM/Miller - 2017 - Explanation in Artificial Intelligence Insights f.pdf;/home/tim/Zotero/storage/YFLV9UKK/1706.html}
}

@article{petersenSystematicMappingStudies,
  title = {Systematic {{Mapping Studies}} in {{Software Engineering}}},
  abstract = {BACKGROUND: A software engineering systematic map is a defined method to build a classification scheme and structure a software engineering field of interest. The analysis of results focuses on frequencies of publications for categories within the scheme. Thereby, the coverage of the research field can be determined. Different facets of the scheme can also be combined to answer more specific research questions.
OBJECTIVE: We describe how to conduct a systematic mapping study in software engineering and provide guidelines. We also compare systematic maps and systematic reviews to clarify how to chose between them. This comparison leads to a set of guidelines for systematic maps.
METHOD: We have defined a systematic mapping process and applied it to complete a systematic mapping study. Furthermore, we compare systematic maps with systematic reviews by systematically analyzing existing systematic reviews.
RESULTS: We describe a process for software engineering systematic mapping studies and compare it to systematic reviews. Based on this, guidelines for doing systematic maps are defined.
CONCLUSIONS: Systematic maps and reviews are different in terms of goals, breadth, validity issues and implications. Thus, they should be used complementarily and require different methods (e.g., for analysis).},
  language = {en},
  author = {Petersen, Kai and Feldt, Robert and Mujtaba, Shahid and Mattsson, Michael},
  pages = {10},
  file = {/home/tim/Zotero/storage/VX598A2F/Petersen et al. - Systematic Mapping Studies in Software Engineering.pdf}
}

@misc{IntroducingMuseumFur,
  title = {Introducing the {{Museum}} F{\"u}r {{Naturkunde}} in {{Berlin}}},
  abstract = {An interview with Ulrike Sturm, scientist at the Museum f{\"u}r Naturkunde in Berlin.Tell us about the Museum f{\"u}r Naturkunde.The Museum f{\"u}r Naturkunde \textendash{} \ldots{}},
  language = {en-GB},
  journal = {Europeana Pro},
  howpublished = {https://pro.europeana.eu/post/introducing-the-museum-fur-naturkunde-in-berlin},
  file = {/home/tim/Zotero/storage/H3JQ6NHC/introducing-the-museum-fur-naturkunde-in-berlin.html}
}

@misc{DFGGEPRIS,
  title = {{{DFG}} - {{GEPRIS}}},
  howpublished = {https://gepris.dfg.de/gepris/OCTOPUS?task=showAbout},
  file = {/home/tim/Zotero/storage/3G8PRGJ5/OCTOPUS.html}
}

@misc{dennymatthewpennstateuniversity;spirlingarthurnewyorkuniversityReplicationDataText2017,
  title = {Replication {{Data}} for: {{Text Preprocessing For Unsupervised Learning}}: {{Why It Matters}}, {{When It Misleads}}, {{And What To Do About It}}},
  shorttitle = {Replication {{Data}} For},
  abstract = {Despite the popularity of unsupervised techniques for political science text-as-data research, the importance and implications of preprocessing decisions in this domain have received scant systematic attention. Yet, as we show, such decisions have profound effects on the results of real models for real data. We argue that substantive theory is typically too vague to be of use for feature selection, and that the supervised literature is not necessarily a helpful source of advice. To aid researchers working in unsupervised settings, we introduce a statistical procedure and software that examines the sensitivity of findings under alternate preprocessing regimes. This approach complements a researcher's substantive understanding of a problem by providing a characterization of the variability changes in preprocessing choices may induce when analyzing a particular dataset. In making scholars aware of the degree to which their results are likely to be sensitive to their preprocessing decisions, it aids replication efforts.},
  language = {en},
  publisher = {{Harvard Dataverse}},
  author = {Denny, Matthew (Penn State University); Spirling, Arthur (New York University)},
  year = {2017},
  file = {/home/tim/Zotero/storage/JRGABUXT/Denny, Matthew (Penn State University)\; Spirling, Arthur (New York University) - 2017 - Replication Data for Text Preprocessing For Unsup.pdf},
  doi = {10.7910/dvn/xrr0hm}
}

@article{deerwesterIndexingLatentSemantic,
  title = {Indexing by Latent Semantic Analysis},
  language = {en},
  journal = {JOURNAL OF THE AMERICAN SOCIETY FOR INFORMATION SCIENCE},
  author = {Deerwester, Scott and Dumais, Susan T and Furnas, George W and Landauer, Thomas K and Harshman, Richard},
  pages = {17},
  file = {/home/tim/Zotero/storage/6ZJZKBPF/Deerwester et al. - Indexing by latent semantic analysis.pdf}
}

@article{robertsonUnderstandingInverseDocument2004,
  title = {Understanding Inverse Document Frequency: On Theoretical Arguments for {{IDF}}},
  volume = {60},
  issn = {0022-0418},
  shorttitle = {Understanding Inverse Document Frequency},
  abstract = {The term weighting function known as IDF was proposed in 1972, and has since been extremely widely used, usually as part of a TF*IDF function. It is often described as a heuristic, and many papers have been written (some based on Shannon's Information Theory) seeking to establish some theoretical basis for it. Some of these attempts are reviewed, and it is shown that the Information Theory approaches are problematic, but that there are good theoretical justifications of both IDF and TF*IDF in traditional probabilistic model of information retrieval.},
  language = {en},
  number = {5},
  journal = {Journal of Documentation},
  doi = {10.1108/00220410410560582},
  author = {Robertson, Stephen},
  month = oct,
  year = {2004},
  pages = {503-520},
  file = {/home/tim/Zotero/storage/ZZK4XD5W/Robertson - 2004 - Understanding inverse document frequency on theor.pdf}
}

@inproceedings{li-pingjingImprovedFeatureSelection2002a,
  title = {Improved Feature Selection Approach {{TFIDF}} in Text Mining},
  volume = {2},
  abstract = {This paper describes the feature selection method TFIDF (term frequency, inverse document frequency). With it, we process the data resource and set up the vector space model in order to provide a convenient data structure for text categorization. We calculate the precision of this method with the help of categorization results. According to the empirical results, we analyze its advantages and disadvantages and present a new TFIDF-based feature selection approach to improve its accuracy.},
  booktitle = {Proceedings. {{International Conference}} on {{Machine Learning}} and {{Cybernetics}}},
  doi = {10.1109/ICMLC.2002.1174522},
  author = {{Li-Ping Jing} and {Hou-Kuan Huang} and {Hong-Bo Shi}},
  month = nov,
  year = {2002},
  keywords = {classification,Classification algorithms,data mining,Data mining,Data preprocessing,data structure,data structures,Data structures,evaluation function,feature extraction,feature selection,Frequency,indexing,Indexing,inverse document frequency,Learning systems,Mutual information,term frequency,text categorization,Text categorization,text mining,Text mining,TFIDF method,vector space model},
  pages = {944-946 vol.2},
  file = {/home/tim/Zotero/storage/RZU74A5J/Li-Ping Jing et al. - 2002 - Improved feature selection approach TFIDF in text .pdf;/home/tim/Zotero/storage/6BPY4X38/1174522.html}
}

@article{aizawaInformationtheoreticPerspectiveTf2003,
  title = {An Information-Theoretic Perspective of Tf\textendash{}Idf Measures},
  volume = {39},
  issn = {0306-4573},
  abstract = {This paper presents a mathematical definition of the ``probability-weighted amount of information'' (PWI), a measure of specificity of terms in documents that is based on an information-theoretic view of retrieval events. The proposed PWI is expressed as a product of the occurrence probabilities of terms and their amounts of information, and corresponds well with the conventional term frequency\textendash{}inverse document frequency measures that are commonly used in today's information retrieval systems. The mathematical definition of the PWI is shown, together with some illustrative examples of the calculation.},
  number = {1},
  journal = {Information Processing \& Management},
  doi = {10.1016/S0306-4573(02)00021-3},
  author = {Aizawa, Akiko},
  month = jan,
  year = {2003},
  keywords = {Information theory,Term weighting theories,Text categorization,tf–idf},
  pages = {45-65},
  file = {/home/tim/Zotero/storage/DE62UZ4G/Aizawa - 2003 - An information-theoretic perspective of tf–idf mea.pdf;/home/tim/Zotero/storage/AVANRBHR/S0306457302000213.html}
}

@misc{PivotedDocumentLength,
  title = {Pivoted Document Length Normalisation | {{RARE Technologies}}},
  howpublished = {https://rare-technologies.com/pivoted-document-length-normalisation/},
  file = {/home/tim/Zotero/storage/H2WHRRXR/pivoted-document-length-normalisation.html}
}

@incollection{chenCurseDimensionality2009,
  address = {{Boston, MA}},
  title = {Curse of {{Dimensionality}}},
  isbn = {978-0-387-39940-9},
  language = {en},
  booktitle = {Encyclopedia of {{Database Systems}}},
  publisher = {{Springer US}},
  author = {Chen, Lei},
  editor = {LIU, LING and {\"O}ZSU, M. TAMER},
  year = {2009},
  pages = {545-546},
  doi = {10.1007/978-0-387-39940-9_133}
}

@incollection{aggarwalSurprisingBehaviorDistance2001,
  address = {{Berlin, Heidelberg}},
  title = {On the {{Surprising Behavior}} of {{Distance Metrics}} in {{High Dimensional Space}}},
  volume = {1973},
  isbn = {978-3-540-41456-8 978-3-540-44503-6},
  abstract = {In recent years, the effect of the curse of high dimensionality has been studied in great detail on several problems such as clustering, nearest neighbor search, and indexing. In high dimensional space the data becomes sparse, and traditional indexing and algorithmic techniques fail from a efficiency and/or effectiveness perspective. Recent research results show that in high dimensional space, the concept of proximity, distance or nearest neighbor may not even be qualitatively meaningful. In this paper, we view the dimensionality curse from the point of view of the distance metrics which are used to measure the similarity between objects. We specifically examine the behavior of the commonly used Lk norm and show that the problem of meaningfulness in high dimensionality is sensitive to the value of k. For example, this means that the Manhattan distance metric (L1 norm) is consistently more preferable than the Euclidean distance metric (L2 norm) for high dimensional data mining applications. Using the intuition derived from our analysis, we introduce and examine a natural extension of the Lk norm to fractional distance metrics. We show that the fractional distance metric provides more meaningful results both from the theoretical and empirical perspective. The results show that fractional distance metrics can significantly improve the effectiveness of standard clustering algorithms such as the k-means algorithm.},
  language = {en},
  booktitle = {Database {{Theory}} \textemdash{} {{ICDT}} 2001},
  publisher = {{Springer Berlin Heidelberg}},
  author = {Aggarwal, Charu C. and Hinneburg, Alexander and Keim, Daniel A.},
  editor = {Goos, Gerhard and Hartmanis, Juris and {van Leeuwen}, Jan and {Van den Bussche}, Jan and Vianu, Victor},
  year = {2001},
  pages = {420-434},
  file = {/home/tim/Zotero/storage/B36SJCV8/Aggarwal et al. - 2001 - On the Surprising Behavior of Distance Metrics in .pdf},
  doi = {10.1007/3-540-44503-X_27}
}


