@INPROCEEDINGS{8622073,
author={R. {Chhatwal} and P. {Gronvall} and N. {Huber-Fliflet} and R. {Keeling} and J. {Zhang} and H. {Zhao}},
booktitle={2018 IEEE International Conference on Big Data (Big Data)},
title={Explainable Text Classification in Legal Document Review A Case Study of Explainable Predictive Coding},
year={2018},
volume={},
number={},
pages={1905-1911},
abstract={In today's legal environment, lawsuits and regulatory investigations require companies to embark upon increasingly intensive data-focused engagements to identify, collect and analyze large quantities of data. When documents are staged for review - where they are typically assessed for relevancy or privilege - the process can require companies to dedicate an extraordinary level of resources, both with respect to human resources, but also with respect to the use of technology-based techniques to intelligently sift through data. Companies regularly spend millions of dollars producing `responsive' electronically-stored documents for these types of matters. For several years, attorneys have been using a variety of tools to conduct this exercise, and most recently, they are accepting the use of machine learning techniques like text classification (referred to as predictive coding in the legal industry) to efficiently cull massive volumes of data to identify responsive documents for use in these matters. In recent years, a group of AI and Machine Learning researchers have been actively researching Explainable AI. In an explainable AI system, actions or decisions are human understandable. In typical legal `document review' scenarios, a document can be identified as responsive, as long as one or more of the text snippets (small passages of text) in a document are deemed responsive. In these scenarios, if predictive coding can be used to locate these responsive snippets, then attorneys could easily evaluate the model's document classification decision. When deployed with defined and explainable results, predictive coding can drastically enhance the overall quality and speed of the document review process by reducing the time it takes to review documents. Moreover, explainable predictive coding provides lawyers with greater confidence in the results of that supervised learning task. The authors of this paper propose the concept of explainable predictive coding and simple explainable predictive coding methods to locate responsive snippets within responsive documents. We also report our preliminary experimental results using the data from an actual legal matter that entailed this type of document review. The purpose of this paper is to demonstrate the feasibility of explainable predictive coding in the context of professional services in the legal space.},
keywords={law administration;pattern classification;supervised learning;text analysis;responsive documents;explainable AI system;typical legal document review scenarios;responsive snippets;text classification;explainable predictive coding methods;data-focused engagements;technology-based techniques;machine learning researchers;document classification;supervised learning task;electronically-stored documents;Predictive coding;Law;Predictive models;Text categorization;Machine learning;machine learning;text categorization;explainable AI;predictive coding;explainable predictive coding;legal document review},
doi={10.1109/BigData.2018.8622073},
ISSN={},
month={Dec},}
@INPROCEEDINGS{953860,
author={C. {Nattee} and M. {Numao}},
booktitle={Proceedings of Sixth International Conference on Document Analysis and Recognition},
title={Geometric method for document understanding and classification using online machine learning},
year={2001},
volume={},
number={},
pages={602-606},
abstract={We propose a geometric method for document image processing. This research focuses on document understanding and classification by applying the Winnow algorithm, an online machine learning method. This application makes the document image processing more flexible with various kind of documents since the meaningful knowledge can be extracted from training examples and the model for document type can be updated when there is a new example. This research aims to analyze and classify scientific papers. We conduct the experiments on documents from the proceedings of various conferences to show the performance of the proposed method. The experimental results are compared with the WISDOM++ system and also show the advantages of using the online machine learning method.},
keywords={document image processing;image retrieval;pattern classification;real-time systems;learning systems;document image processing;document understanding;pattern classification;geometric method;Winnow algorithm;machine learning;scientific papers;image retrieval;real time systems;Machine learning;Machine learning algorithms;Learning systems;Document image processing;Text analysis;Information analysis;Logic;Computer science;Electronic mail;Application software},
doi={10.1109/ICDAR.2001.953860},
ISSN={},
month={Sep.},}
@ARTICLE{8466590,
author={A. {Adadi} and M. {Berrada}},
journal={IEEE Access},
title={Peeking Inside the Black-Box: A Survey on Explainable Artificial Intelligence (XAI)},
year={2018},
volume={6},
number={},
pages={52138-52160},
abstract={At the dawn of the fourth industrial revolution, we are witnessing a fast and widespread adoption of artificial intelligence (AI) in our daily life, which contributes to accelerating the shift towards a more algorithmic society. However, even with such unprecedented advancements, a key impediment to the use of AI-based systems is that they often lack transparency. Indeed, the black-box nature of these systems allows powerful predictions, but it cannot be directly explained. This issue has triggered a new debate on explainable AI (XAI). A research field holds substantial promise for improving trust and transparency of AI-based systems. It is recognized as the sine qua non for AI to continue making steady progress without disruption. This survey provides an entry point for interested researchers and practitioners to learn key aspects of the young and rapidly growing body of research related to XAI. Through the lens of the literature, we review the existing approaches regarding the topic, discuss trends surrounding its sphere, and present major research trajectories.},
keywords={artificial intelligence;AI-based systems;black-box nature;explainable AI;XAI;explainable artificial intelligence;fourth industrial revolution;Conferences;Machine learning;Market research;Prediction algorithms;Machine learning algorithms;Biological system modeling;Explainable artificial intelligence;interpretable machine learning;black-box models},
doi={10.1109/ACCESS.2018.2870052},
ISSN={2169-3536},
month={},}
@INPROCEEDINGS{5483913,
author={A. {Pezeshk} and R. L. {Tutwiler}},
booktitle={2010 IEEE Southwest Symposium on Image Analysis Interpretation (SSIAI)},
title={Extended character defect model for recognition of text from maps},
year={2010},
volume={},
number={},
pages={85-88},
abstract={Topographic maps contain a small amount of text compared to other forms of printed documents. Furthermore, the text and graphical components typically intersect with one another thus making the extraction of text a very difficult task. Creating training sets with a suitable size from the actual characters in maps would therefore require the laborious processing of many maps with similar features and the manual extraction of character samples. This paper extends the types of defects represented by Baird's document image degradation model in order to create pseudo randomly generated training sets that closely mimic the various artifacts and defects encountered in characters extracted from maps. Two Hidden Markov Models are then trained and used to recognize the text. Tests performed on extracted street labels show an improvement in performance from 88.4% when only the original Baird's model is used to a character recognition rate of 93.2% when the extended defect model is used for training.},
keywords={cartography;document image processing;hidden Markov models;learning (artificial intelligence);text analysis;extended character defect model;text recognition;topographic maps;document image degradation model;pseudo randomly generated training sets;hidden Markov models;Character recognition;Text recognition;Hidden Markov models;Degradation;Graphics;Image recognition;Optical character recognition software;Artificial neural networks;Feature extraction;Data mining;text recognition;document image degradation model;Hidden Markov Models;feature extraction},
doi={10.1109/SSIAI.2010.5483913},
ISSN={},
month={May},}
@INPROCEEDINGS{8622439,
author={T. {Suzuki} and S. {Oyama} and M. {Kurihara}},
booktitle={2018 IEEE International Conference on Big Data (Big Data)},
title={Toward Explainable Recommendations: Generating Review Text from Multicriteria Evaluation Data},
year={2018},
volume={},
number={},
pages={3549-3551},
abstract={Explaining recommendations helps users to make more accurate and effective decisions and improves system credibility and transparency. Current explainable recommender systems tend to provide fixed statements such as "customers who purchased this item also purchased....". This explanation is generated only on the basis of the purchase history of similar customers, so it does not include the preferences of customers who have purchased the item or a description of the item. Since user-generated reviews generally contain information about the reviewer's preferences and a description of the item, such reviews typically have more effect on purchase decisions. Therefore, using reviews to explain recommendations should be more useful than providing only a fixed statement explanation. Aiming to create a system that provides personalized explanations for recommendations, we have developed a recurrent neural network model that uses multicriteria evaluation data to generate reviews.},
keywords={information filtering;information filters;recommender systems;recurrent neural nets;explainable recommendations;explainable recommender systems;review text;personalized explanations;fixed statement explanation;purchase decisions;reviewer;user-generated reviews;purchase history;fixed statements;transparency;system credibility;multicriteria evaluation data;Decoding;Data models;Recommender systems;Mathematical model;Computational modeling;History;Recurrent neural networks;explainable recommendation;text generation;RNN;recommender systems},
doi={10.1109/BigData.2018.8622439},
ISSN={},
month={Dec},}
@INPROCEEDINGS{8622433,
author={B. {Kovalerchuk} and N. {Neuhaus}},
booktitle={2018 IEEE International Conference on Big Data (Big Data)},
title={Toward Efficient Automation of Interpretable Machine Learning},
year={2018},
volume={},
number={},
pages={4940-4947},
abstract={Developing more efficient automated methods for interpretable machine learning (ML) is an important and longterm machine-learning goal. Recent studies show that unintelligible "black" box models, such as Deep Learning Neural Networks, often outperform more interpretable "grey" or "white" box models such as Decision Trees, Bayesian networks, Logic Relational models and others. Being forced to choose between accuracy and interpretability, however, is a major obstacle in the wider adoption of ML in healthcare and other domains where decisions requires both facets. Due to human perceptual limitations in analyzing complex multidimensional relations in ML, complex ML must be "degraded" to the level of human understanding, thereby also degrading model accuracy. To address this challenge, this paper presents the Dominance Classifier and Predictor (DCP) algorithm, capable of automating the process of discovering human-understandable machine learning models that are simple and visualizable. The success of DCP is shown on the benchmark Wisconsin Breast Cancer dataset with the higher accuracy than the accuracy known for other interpretable methods on these data. Furthermore, the DCP algorithm shortens the accuracy gap between interpretable and non-interpretable models on these data. The DCP explanation includes both interpretable mathematical and visual forms. Such an approach opens a new opportunity for producing more accurate and domain-explainable ML models.},
keywords={learning (artificial intelligence);pattern classification;domain-explainable ML models;dominance classifier and predictor algorithm;DCP algorithm;unintelligible black box models;interpretable machine learning;interpretable mathematical forms;noninterpretable models;interpretable methods;human-understandable machine learning models;complex multidimensional relations;human perceptual limitations;white box models;interpretable grey box models;Classification algorithms;Prediction algorithms;Machine learning;Mathematical model;Machine learning algorithms;Computational modeling;Neural networks;machine learning;explainability;interpretability;accuracy;classifier;visualization;visual model;dominant intervals},
doi={10.1109/BigData.2018.8622433},
ISSN={},
month={Dec},}
@INPROCEEDINGS{7821768,
author={L. {Stephen} and D. {Geert} and K. {Andreas} and P. {Frank}},
booktitle={2016 Future Technologies Conference (FTC)},
title={A non-biological AI approach towards natural language understanding},
year={2016},
volume={},
number={},
pages={1300-1302},
abstract={The problem being addressed in this paper is that using brute force in Natural Language Processing and Machine Learning combined with advanced statistics will only approximate meaning and thus will not deliver in terms of real text understanding. Counting words and tracking word order or parsing by syntax will also result in probability and guesswork at best. Their vendors struggle in delivering accurate quality and this results in ill-functioning applications. The newer generation methodologies like Deep Learning and Cognitive Computing are breaking barriers in the (Big Data) fields of Internet of Things, Robotics and Image/Video Recognition but cannot be successfully deployed for text without huge amounts of training and sample data. In the short term, we believe non-biological Artificial Intelligence will produce the best results for text understanding. Miia applied advanced Linguistic and Semantic Technologies combined with ConceptNet modeling and Machine Learning to successfully cater deep intelligent and cross-language quality to several industries.},
keywords={Big Data;Internet of Things;learning (artificial intelligence);mobile computing;natural language processing;semantic networks;statistics;text analysis;nonbiological AI approach;natural language understanding;natural language processing;machine learning;advanced statistics;meaning approximation;text understanding;word counting;word order tracking;syntax parsing;deep learning;cognitive computing;Big Data;Internet of Things;robotics;image/video recognition;nonbiological artificial intelligence;advanced linguistic technologies;semantic technologies;ConceptNet modeling;cross-language quality;Companies;Natural languages;Artificial intelligence;Semantics;Law;Engines;Natural Language Processing;Natural Language Understanding;Artificial Intelligence;Linguistics;Semantics;Machine Learning;ConceptNet Modelling;Data Mining;Sentiment Analysis;Data Analysis;Big Data;Business Intelligence},
doi={10.1109/FTC.2016.7821768},
ISSN={},
month={Dec},}
@INPROCEEDINGS{8490433,
author={J. {Zhu} and A. {Liapis} and S. {Risi} and R. {Bidarra} and G. M. {Youngblood}},
booktitle={2018 IEEE Conference on Computational Intelligence and Games (CIG)},
title={Explainable AI for Designers: A Human-Centered Perspective on Mixed-Initiative Co-Creation},
year={2018},
volume={},
number={},
pages={1-8},
abstract={Growing interest in eXplainable Artificial Intelligence (XAI) aims to make AI and machine learning more understandable to human users. However, most existing work focuses on new algorithms, and not on usability, practical interpretability and efficacy on real users. In this vision paper, we propose a new research area of eXplainable AI for Designers (XAID), specifically for game designers. By focusing on a specific user group, their needs and tasks, we propose a human-centered approach for facilitating game designers to co-create with AI/ML techniques through XAID. We illustrate our initial XAID framework through three use cases, which require an understanding both of the innate properties of the AI techniques and users' needs, and we identify key open challenges.},
keywords={computer games;human computer interaction;learning (artificial intelligence);game designers;AI/ML techniques;human-centered perspective;AI machine;human-centered approach;explainable artificial intelligence;mixed-initiative co-creation;XAI;machine learning;explainable AI for designers;XAID framework;Games;Task analysis;Machine learning;Neurons;Visualization;Tools;explainable artificial intelligence;mixed-initiative co-creation;human-computer interaction;machine learning;game design},
doi={10.1109/CIG.2018.8490433},
ISSN={2325-4289},
month={Aug},}
@ARTICLE{4492785,
author={S. {Lu} and L. {Li} and C. L. {Tan}},
journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
title={Document Image Retrieval through Word Shape Coding},
year={2008},
volume={30},
number={11},
pages={1913-1918},
abstract={This paper presents a document retrieval technique that is capable of searching document images without optical character recognition (OCR). The proposed technique retrieves document images by a new word shape coding scheme, which captures the document content through annotating each word image by a word shape code. In particular, we annotate word images by using a set of topological shape features including character ascenders/descenders, character holes, and character water reservoirs. With the annotated word shape codes, document images can be retrieved by either query keywords or a query document image. Experimental results show that the proposed document image retrieval technique is fast, efficient, and tolerant to various types of document degradation.},
keywords={document image processing;image coding;image retrieval;document image retrieval;word shape coding;document image searching;document content;word image annotation;topological shape features;character ascenders;character holes;character water reservoirs;annotated word shape codes;query keywords;query document image;document degradation;character descenders;Image retrieval;Shape;Image coding;Optical character recognition software;Content based retrieval;Degradation;Image segmentation;Character recognition;Water resources;Reservoirs;Image/video retrieval;Shape;Text processing;Document analysism;Document Capture;Document and Text Processing;Computing Methodologies;Shape;Vision and Scene Understanding;Artificial Intelligence;Image/video retrieval;Shape;Text processing;Document analysism;Document Capture;Document and Text Processing;Computing Methodologies;Shape;Vision and Scene Understanding;Artificial Intelligence;Artificial Intelligence;Automatic Data Processing;Database Management Systems;Databases, Factual;Documentation;Image Enhancement;Image Interpretation, Computer-Assisted;Information Storage and Retrieval;Language;Pattern Recognition, Automated;Reading},
doi={10.1109/TPAMI.2008.89},
ISSN={0162-8828},
month={Nov},}
@INPROCEEDINGS{8491501,
author={B. {Murray} and M. A. {Islam} and A. J. {Pinar} and T. C. {Havens} and D. T. {Anderson} and G. {Scott}},
booktitle={2018 IEEE International Conference on Fuzzy Systems (FUZZ-IEEE)},
title={Explainable AI for Understanding Decisions and Data-Driven Optimization of the Choquet Integral},
year={2018},
volume={},
number={},
pages={1-8},
abstract={To date, numerous ways have been created to learn a fusion solution from data. However, a gap exists in terms of understanding the quality of what was learned and how trustworthy the fusion is for future-i.e., new-data. In part, the current paper is driven by the demand for so-called explainable AI (XAI). Herein, we discuss methods for XAI of the Choquet integral (ChI), a parametric nonlinear aggregation function. Specifically, we review existing indices, and we introduce new data-centric XAI tools. These various XAI-ChI methods are explored in the context of fusing a set of heterogeneous deep convolutional neural networks for remote sensing.},
keywords={convolution;feedforward neural nets;learning (artificial intelligence);optimisation;remote sensing;sensor fusion;data-driven optimization;Choquet integral;fusion solution;parametric nonlinear aggregation function;data-centric XAI tools;XAI-ChI methods;explainable AI;heterogeneous deep convolutional neural networks;remote sensing;Frequency modulation;Indexes;Remote sensing;Optimization;Artificial intelligence;Electronic mail;Convolutional neural networks;Choquet Integral;Fuzzy Integral;Explainable AI;Machine Learning},
doi={10.1109/FUZZ-IEEE.2018.8491501},
ISSN={},
month={July},}
@INPROCEEDINGS{1224095,
author={ and C. {Hinde} and D. {Gillingwater}},
booktitle={Proceedings of the International Joint Conference on Neural Networks, 2003.},
title={A new method for explaining neural network reasoning},
year={2003},
volume={4},
number={},
pages={3256-3260 vol.4},
abstract={This paper presents a new method for explaining the reasoning results of a trained neural network. The method considers the most significant attribute first under the guidance of a relative strength of effect analysis and eliminates irrelevant points. Following the adaptive search in the dynamic state space, a set of relevant points are extracted and form the basis of the explanation of the neural network reasoning. Combining a relative strength of effect analysis with the relevant points, a case based explanation approach is put forward. As an illustration, an experiment with a small data set on the relationship between weather conditions and play decisions is presented to demonstrate the utility of the proposed approach.},
keywords={neural nets;learning (artificial intelligence);explanation;inference mechanisms;neural network reasoning;trained neural network;relative strength of effect analysis;adaptive search;dynamic state space;relevant point extraction;case based explanation approach;weather conditions;play decisions;Neural networks;Data mining;Knowledge representation;Computational intelligence;Intelligent structures;Computer science;State-space methods;Information analysis;Training data;Artificial neural networks},
doi={10.1109/IJCNN.2003.1224095},
ISSN={1098-7576},
month={July},}
@ARTICLE{8440091,
author={J. {Zhang} and Y. {Wang} and P. {Molino} and L. {Li} and D. S. {Ebert}},
journal={IEEE Transactions on Visualization and Computer Graphics},
title={Manifold: A Model-Agnostic Framework for Interpretation and Diagnosis of Machine Learning Models},
year={2019},
volume={25},
number={1},
pages={364-373},
abstract={Interpretation and diagnosis of machine learning models have gained renewed interest in recent years with breakthroughs in new approaches. We present Manifold, a framework that utilizes visual analysis techniques to support interpretation, debugging, and comparison of machine learning models in a more transparent and interactive manner. Conventional techniques usually focus on visualizing the internal logic of a specific model type (i.e., deep neural networks), lacking the ability to extend to a more complex scenario where different model types are integrated. To this end, Manifold is designed as a generic framework that does not rely on or access the internal logic of the model and solely observes the input (i.e., instances or features) and the output (i.e., the predicted result and probability distribution). We describe the workflow of Manifold as an iterative process consisting of three major phases that are commonly involved in the model development and diagnosis process: inspection (hypothesis), explanation (reasoning), and refinement (verification). The visual components supporting these tasks include a scatterplot-based visual summary that overviews the models' outcome and a customizable tabular view that reveals feature discrimination. We demonstrate current applications of the framework on the classification and regression tasks and discuss other potential machine learning use scenarios where Manifold can be applied.},
keywords={data analysis;data visualisation;iterative methods;learning (artificial intelligence);neural nets;regression analysis;model-agnostic framework;machine learning models;visual analysis techniques;internal logic;specific model type;model development;diagnosis process;potential machine learning;regression tasks;classification tasks;feature discrimination;customizable tabular view;models outcome;scatterplot-based visual summary;refinement;explanation;inspection;generic framework;deep neural networks;debugging;interpretation;manifold;Visualization;Analytical models;Task analysis;Machine learning;Manifolds;Data models;Computational modeling;Interactive machine learning;performance analysis;model comparison;model debugging},
doi={10.1109/TVCG.2018.2864499},
ISSN={1077-2626},
month={Jan},}
@ARTICLE{8440842,
author={B. C. {Kwon} and M. {Choi} and J. T. {Kim} and E. {Choi} and Y. B. {Kim} and S. {Kwon} and J. {Sun} and J. {Choo}},
journal={IEEE Transactions on Visualization and Computer Graphics},
title={RetainVis: Visual Analytics with Interpretable and Interactive Recurrent Neural Networks on Electronic Medical Records},
year={2019},
volume={25},
number={1},
pages={299-309},
abstract={We have recently seen many successful applications of recurrent neural networks (RNNs) on electronic medical records (EMRs), which contain histories of patients' diagnoses, medications, and other various events, in order to predict the current and future states of patients. Despite the strong performance of RNNs, it is often challenging for users to understand why the model makes a particular prediction. Such black-box nature of RNNs can impede its wide adoption in clinical practice. Furthermore, we have no established methods to interactively leverage users' domain expertise and prior knowledge as inputs for steering the model. Therefore, our design study aims to provide a visual analytics solution to increase interpretability and interactivity of RNNs via a joint effort of medical experts, artificial intelligence scientists, and visual analytics researchers. Following the iterative design process between the experts, we design, implement, and evaluate a visual analytics tool called RetainVis, which couples a newly improved, interpretable, and interactive RNN-based model called RetainEX and visualizations for users' exploration of EMR data in the context of prediction tasks. Our study shows the effective use of RetainVis for gaining insights into how individual medical codes contribute to making risk predictions, using EMRs of patients with heart failure and cataract symptoms. Our study also demonstrates how we made substantial changes to the state-of-the-art RNN model called RETAIN in order to make use of temporal information and increase interactivity. This study will provide a useful guideline for researchers that aim to design an interpretable and interactive visual analytics tool for RNNs.},
keywords={artificial intelligence;data analysis;data visualisation;interactive systems;medical information systems;recurrent neural nets;interactive RNN-based model;EMR data;prediction tasks;RetainVis;individual medical codes;risk predictions;temporal information;increase interactivity;interpretable analytics tool;interpretable networks;interactive recurrent neural networks;electronic medical records;black-box nature;interactively leverage users;design study;visual analytics solution;medical experts;artificial intelligence scientists;iterative design process;newly improved RNN-based model;RNN-based model;visual analytic researchers;interactive visual analytic tool;Machine learning;Medical diagnostic imaging;Task analysis;Predictive models;Computational modeling;Visual analytics;Data models;Interactive Artificial Intelligence;XAI (Explainable Artificial Intelligence);Interpretable Deep Learning;Healthcare},
doi={10.1109/TVCG.2018.2865027},
ISSN={1077-2626},
month={Jan},}
@INPROCEEDINGS{8047390,
author={Y. {Hayashida} and T. {Uetsuji} and Y. {Ebara} and K. {Koyamada}},
booktitle={2017 Nicograph International (NicoInt)},
title={Category Classification of Text Data with Machine Learning Technique for Visualizing Flow of Conversation in Counseling},
year={2017},
volume={},
number={},
pages={37-40},
abstract={The beginner counselors have more likely to continue counseling in their own interest, they have a high tendency to make great use of the closed-ended question in order to confirm the interpretation with the client. While expert counselors are instructing the counseling skill to beginner counselors, we consider that the reaction of a client for a beginner counselor's question is important to visualize in an appropriate method. To respond the request, we have developed a system for visualizing the flow of conversation in counseling. However, the expert counselor as the system user requires to correct the initial classification result manually, and the work burden is large, because the accuracy of the category classification of conversation data is very low in the current system. To improve this problem, we have implemented on the category classification method of text data with SVM (Support Vector Machine) as machine learning technique to visualize the flow of conversation in counseling. In addition, we have compared and evaluated with results of the initial classification method of the current system. As these results, we have shown that the accuracy rate of the classification method with SVM become higher than the results in the current system.},
keywords={data visualisation;learning (artificial intelligence);pattern classification;psychology;support vector machines;text analysis;category classification;text data;machine learning;conversation flow visualization;counseling;support vector machine;SVM;Employee welfare;Support vector machines;Data visualization;Psychology;Dictionaries;Data models;Employment;Counseling;Visualization;Machine Learning;Text Classification},
doi={10.1109/NICOInt.2017.35},
ISSN={},
month={June},}
@ARTICLE{6875959,
author={S. {Koch} and M. {John} and M. {Wörner} and A. {Müller} and T. {Ertl}},
journal={IEEE Transactions on Visualization and Computer Graphics},
title={VarifocalReader — In-Depth Visual Analysis of Large Text Documents},
year={2014},
volume={20},
number={12},
pages={1723-1732},
abstract={Interactive visualization provides valuable support for exploring, analyzing, and understanding textual documents. Certain tasks, however, require that insights derived from visual abstractions are verified by a human expert perusing the source text. So far, this problem is typically solved by offering overview-detail techniques, which present different views with different levels of abstractions. This often leads to problems with visual continuity. Focus-context techniques, on the other hand, succeed in accentuating interesting subsections of large text documents but are normally not suited for integrating visual abstractions. With VarifocalReader we present a technique that helps to solve some of these approaches' problems by combining characteristics from both. In particular, our method simplifies working with large and potentially complex text documents by simultaneously offering abstract representations of varying detail, based on the inherent structure of the document, and access to the text itself. In addition, VarifocalReader supports intra-document exploration through advanced navigation concepts and facilitates visual analysis tasks. The approach enables users to apply machine learning techniques and search mechanisms as well as to assess and adapt these techniques. This helps to extract entities, concepts and other artifacts from texts. In combination with the automatic generation of intermediate text levels through topic segmentation for thematic orientation, users can test hypotheses or develop interesting new research questions. To illustrate the advantages of our approach, we provide usage examples from literature studies.},
keywords={data visualisation;learning (artificial intelligence);text analysis;varifocalreader;in-depth visual analysis;focus-context techniques;text documents;machine learning techniques;intermediate text levels;document analysis;literary analysis;natural language processing;text mining;visual abstraction;Data visualization;Interactive systems;Navigation;Tag clouds;Natural language processing;Text mining;Document handling;Data mining;visual analytics;document analysis;literary analysis;natural language processing;text mining;machine learning;distant reading},
doi={10.1109/TVCG.2014.2346677},
ISSN={1077-2626},
month={Dec},}
@INPROCEEDINGS{8679150,
author={D. {Kim} and W. {Lim} and M. {Hong} and H. {Kim}},
booktitle={2019 IEEE International Conference on Big Data and Smart Computing (BigComp)},
title={The Structure of Deep Neural Network for Interpretable Transfer Learning},
year={2019},
volume={},
number={},
pages={1-4},
abstract={Training a deep neural network requires a large amount of high-quality data and time. However, most of the real tasks don't have enough labeled data to train each complex model. To solve this problem, transfer learning reuses the pretrained model on a new task. However, one weakness of transfer learning is that it applies a pretrained model to a new task without understanding the output of an existing model. This may cause a lack of interpretability in training deep neural network. In this paper, we propose a technique to improve the interpretability in transfer learning tasks. We define the interpretable features and use it to train model to a new task. Thus, we will be able to explain the relationship between the source and target domain in a transfer learning task. Feature Network (FN) consists of Feature Extraction Layer and a single mapping layer that connects the features extracted from the source domain to the target domain. We examined the interpretability of the transfer learning by applying pretrained model with defined features to Korean characters classification.},
keywords={feature extraction;image classification;learning (artificial intelligence);natural language processing;neural nets;deep neural network;interpretable transfer learning;high-quality data;complex model;pretrained model;interpretability;transfer learning task;interpretable features;feature extraction layer;Korean characters classification;Feature extraction;Task analysis;Training;Data models;Convolution;Computational modeling;Neural networks;Interpretability;Transfer Learning;Machine Learning},
doi={10.1109/BIGCOMP.2019.8679150},
ISSN={2375-9356},
month={Feb},}
@INPROCEEDINGS{395650,
author={R. K. {Srihari}},
booktitle={Proceedings of 2nd International Conference on Document Analysis and Recognition (ICDAR '93)},
title={Intelligent document understanding: Understanding photographs with captions},
year={1993},
volume={},
number={},
pages={664-667},
abstract={The interaction of textual and photographic information in document understanding is explored. Specifically, a computational model whereby textual captions are used as collateral information in the interpretation of the corresponding photographs is presented. The final understanding of the picture and caption reflects a consolidation of the information obtained from each of the two sources and can thus be used in intelligent information retrieval tasks. The problem of performing general-purpose vision without apriori knowledge is very difficult at best. The concept of using collateral information in scene understanding has been explored in systems that use general scene context in the task of object identification. The work described extends this notion by incorporating picture specific information. Finally, as a test of the model, a multi-stage system PICTION which uses captions to identify humans in an accompanying photograph is described. This provides a computationally less expensive alternative to traditional methods of face recognition since it does not require a pre-stored database of face models for all people to be identified.<<ETX>>},
keywords={knowledge based systems;document image processing;face recognition;image recognition;computational complexity;optical character recognition;textual information;intelligent document understanding;photographic information;document understanding;computational model;textual captions;intelligent information retrieval;scene understanding;object identification;picture specific information;multi-stage system;PICTION;captions;face recognition;database;face models;Layout;Information retrieval;Image retrieval;Computer vision;Computational modeling;System testing;Machine vision;Content based retrieval;Text analysis;Information analysis},
doi={10.1109/ICDAR.1993.395650},
ISSN={},
month={Oct},}
@INPROCEEDINGS{4761259,
author={S. {Ferilli} and M. {Biba} and T. M. A. {Basile} and F. {Esposito}},
booktitle={2008 19th International Conference on Pattern Recognition},
title={Incremental machine learning techniques for document layout understanding},
year={2008},
volume={},
number={},
pages={1-4},
abstract={In real-world digital libraries, artificial intelligence techniques are essential for tackling the automatic document processing task with sufficient flexibility. The great variability in document kind, content and shape requires powerful representation formalisms to catch all the domain complexity. The continuous flow of new documents requires adaptable techniques that can progressively adjust the acquired knowledge on documents as long as new evidence becomes available, even extending if needed the set of recognized document types. Both these issues have not yet been thoroughly studied. This paper presents an incremental first-order logic learning framework for automatically dealing with various kinds of evolution in digital repositories content: evolution in the definition of class definitions, evolution in the set of known classes and evolution by addition of new unknown classes. Experiments show that the approach can be applied to real-world.},
keywords={digital libraries;document image processing;learning (artificial intelligence);incremental machine learning;first-order logic learning;document layout understanding;digital libraries;artificial intelligence;representation formalisms;domain complexity;Machine learning;Software libraries;Artificial intelligence;Shape;Data mining;Learning systems;Automatic logic units;Production systems;Digital systems;Technology management},
doi={10.1109/ICPR.2008.4761259},
ISSN={1051-4651},
month={Dec},}
@INPROCEEDINGS{619849,
author={H. {Walischewski}},
booktitle={Proceedings of the Fourth International Conference on Document Analysis and Recognition},
title={Automatic knowledge acquisition for spatial document interpretation},
year={1997},
volume={1},
number={},
pages={243-247 vol.1},
abstract={In this paper, a qualitative representation for the layout of structured documents as well as classes of documents is presented, which is established by means of supervised learning from a labeled training set of documents. For this formal representation, an inference algorithm has been developed, adopted from error-tolerant subgraph isomorphism, which assigns logic labels to the layout objects of a test document.},
keywords={knowledge acquisition;document image processing;learning (artificial intelligence);knowledge representation;inference mechanisms;fault tolerant computing;graph theory;automatic knowledge acquisition;spatial document interpretation;qualitative representation;structured document layout;document classes;supervised learning;labeled training set;formal representation;inference algorithm;error-tolerant subgraph isomorphism;logic labels;layout objects;Knowledge acquisition;Logic testing;Data mining;Inference mechanisms;Inference algorithms;Humans;Information analysis;Writing;Training data;Computer science education},
doi={10.1109/ICDAR.1997.619849},
ISSN={},
month={Aug},}
@INPROCEEDINGS{8489172,
author={X. {Liu} and X. {Wang} and S. {Matwin}},
booktitle={2018 International Joint Conference on Neural Networks (IJCNN)},
title={Interpretable Deep Convolutional Neural Networks via Meta-learning},
year={2018},
volume={},
number={},
pages={1-9},
abstract={Model interpretability is a requirement in many applications in which crucial decisions are made by users relying on a model's outputs. The recent movement for “algorithmic fairness” also stipulates explainability, and therefore interpretability of learning models. And yet the most successful contemporary Machine Learning approaches, the Deep Neural Networks, produce models that are highly non-interpretable. We attempt to address this challenge by proposing a technique called CNN-INTE to interpret deep Convolutional Neural Networks (CNN) via meta-learning. In this work, we interpret a specific hidden layer of the deep CNN model on the MNIST image dataset. We use a clustering algorithm in a two-level structure to find the meta-level training data and Random Forest as base learning algorithms to generate the meta-level test data. The interpretation results are displayed visually via diagrams, which clearly indicates how a specific test instance is classified. Our method achieves global interpretation for all the test instances on the hidden layers without sacrificing the accuracy obtained by the original deep CNN model. This means our model is faithful to the original deep CNN model, which leads to reliable interpretations.},
keywords={convolution;feedforward neural nets;learning (artificial intelligence);pattern classification;pattern clustering;random processes;meta-learning;model interpretability;CNN-INTE;clustering algorithm;meta-level training data;base learning algorithms;meta-level test data;machine learning approaches;interpretable deep convolutional neural networks;MNIST image dataset;random forest;deep CNN model;Prediction algorithms;Machine learning;Machine learning algorithms;Predictive models;Computational modeling;Training data;Visualization;interpretability;Meta-learning;deep learning;Convolutional Neural Network;TensorFlow;big data},
doi={10.1109/IJCNN.2018.8489172},
ISSN={2161-4407},
month={July},}
@INPROCEEDINGS{7311974,
author={S. {Denisleam Molomer} and S. {Trausan-Matu} and P. {Dessus} and M. {Bianco}},
booktitle={2015 14th RoEduNet International Conference - Networking in Education and Research (RoEduNet NER)},
title={Analyzing students pauses during reading and explaining a story},
year={2015},
volume={},
number={},
pages={90-93},
abstract={In this paper we present a semi-automated analysis of student reading performance from the perspective of her text reading level and text understanding. Silences (pauses) between uttered words or read sentences as well as silences between verbalizations given by students are the key points in the analysis of their learning activities. Pause is an essential element in the analysis of a text, which also gives good control over interactions during the processes of text reading and explanation of understanding. This study presents the results specific to pauses in the reading and verbalization using Praat, a tool to analyze spoken productions. Correlations between students' fluency, story understanding, and mean pause duration of reading and explanation phases show consistent results across texts for reading. Results about pauses during explaining yielded low correlations, showing that other variables may influence the pausing behaviors during explaining.},
keywords={computer aided instruction;linguistics;speech processing;text analysis;students pauses;semiautomated analysis;student reading performance;text reading level;text understanding;uttered words;read sentences;silences;verbalizations;learning activities;text analysis;Praat tool;spoken productions;students fluency;story understanding;mean pause duration;reading phases;explanation phases;pausing behaviors;explaining;Decision support systems;Pause;Reading;Explanation},
doi={10.1109/RoEduNet.2015.7311974},
ISSN={2068-1038},
month={Sep.},}
@INPROCEEDINGS{5158992,
author={M. {Xue} and C. {Zhu}},
booktitle={2009 International Joint Conference on Artificial Intelligence},
title={A Study and Application on Machine Learning of Artificial Intellligence},
year={2009},
volume={},
number={},
pages={272-274},
abstract={This thesis elaborated the concept, significance and main strategy of machine learning as well as the basic structure of machine learning system. By combining several basic ideas of main strategies, great effort are laid on introducing several machine learning methods, such as Rote learning, Explanation-based learning, Learning from instruction, Learning by deduction, Learning by analogy and Inductive learning, etc. Meanwhile, comparison and analysis are made upon their respective advantages and limitations. At the end of the article, it proposes the research objective of machine learning and points out its development trend.Machine learning is a fundamental way that enable the computer to have the intelligence ; Its application which had been used mainly the method of induction and the synthesis, rather than the deduction has already reached many fields of Artificial Intelligence.},
keywords={learning (artificial intelligence);artificial intelligence;machine learning system;rote learning;explanation-based learning;learning from instruction;learning by deduction;learning by analogy;Inductive learning;Machine learning;Artificial intelligence;Learning systems;Application software;Humans;Computational modeling;Machine learning algorithms;Intelligent systems;Intelligent robots;Physiology;machine learning;AI;system structure;learning strategy;algorithm},
doi={10.1109/JCAI.2009.55},
ISSN={},
month={April},}
@INPROCEEDINGS{8320258,
author={A. {Jain} and D. {Bhatia} and M. K. {Thakur}},
booktitle={2017 International Conference on Machine Learning and Data Science (MLDS)},
title={Extractive Text Summarization Using Word Vector Embedding},
year={2017},
volume={},
number={},
pages={51-55},
abstract={These days, text summarization is an active research field to identify the relevant information from large documents produced in various domains such as finance, news media, academics, politics, etc. Text summarization is the process of shortening the documents by preserving the important contents of the text. This can be achieved through extractive and abstractive summarization. In this paper, we have proposed an approach to extract a good set of features followed by neural network for supervised extractive summarization. Our experimental results on Document Understanding Conferences 2002 dataset show the effectiveness of the proposed method against various online extractive text summarizers.},
keywords={text analysis;news media;abstractive summarization;supervised extractive summarization;Document Understanding Conferences 2002 dataset;online extractive text summarizers;word vector;active research field;Feature extraction;Neural networks;Data mining;Training;Mathematical model;Computational modeling;Testing;Extractive Text Summarization;Neural Network;Machine Learning;Word Vector Embedding},
doi={10.1109/MLDS.2017.12},
ISSN={},
month={Dec},}
@ARTICLE{1359749,
author={S. {Marinai} and M. {Gori} and G. {Soda}},
journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
title={Artificial neural networks for document analysis and recognition},
year={2005},
volume={27},
number={1},
pages={23-35},
abstract={Artificial neural networks have been extensively applied to document analysis and recognition. Most efforts have been devoted to the recognition of isolated handwritten and printed characters with widely recognized successful results. However, many other document processing tasks, like preprocessing, layout analysis, character segmentation, word recognition, and signature verification, have been effectively faced with very promising results. This paper surveys the most significant problems in the area of offline document image processing, where connectionist-based approaches have been applied. Similarities and differences between approaches belonging to different categories are discussed. A particular emphasis is given on the crucial role of prior knowledge for the conception of both appropriate architectures and learning algorithms. Finally, the paper provides a critical analysts on the reviewed approaches and depicts the most promising research guidelines in the field. In particular, a second generation of connectionist-based models are foreseen which are based on appropriate graphical representations of the learning environment.},
keywords={document image processing;recurrent neural nets;handwritten character recognition;image segmentation;handwriting recognition;learning (artificial intelligence);artificial neural networks;document image analysis;document image recognition;handwritten recognition;character recognition;layout analysis;character segmentation;word recognition;signature verification;offline document image processing;connectionist based approach;learning algorithms;document preprocessing;recurrent neural nets;graphical representations;Artificial neural networks;Text analysis;Character recognition;Handwriting recognition;Image analysis;Image recognition;Neural networks;Optical character recognition software;Image segmentation;Face recognition;Index Terms- Character segmentation;document image analysis and recognition;layout analysis;neural networks;preprocessing;recursive neural networks;word recognition.;Algorithms;Artificial Intelligence;Automatic Data Processing;Computer Graphics;Documentation;Handwriting;Image Enhancement;Image Interpretation, Computer-Assisted;Information Storage and Retrieval;Neural Networks (Computer);Numerical Analysis, Computer-Assisted;Pattern Recognition, Automated;Reading;Reproducibility of Results;Sensitivity and Specificity;Signal Processing, Computer-Assisted;User-Computer Interface},
doi={10.1109/TPAMI.2005.4},
ISSN={0162-8828},
month={Jan},}
@ARTICLE{4359385,
author={Y. {Li} and Y. {Zheng} and D. {Doermann} and S. {Jaeger}},
journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
title={Script-Independent Text Line Segmentation in Freestyle Handwritten Documents},
year={2008},
volume={30},
number={8},
pages={1313-1329},
abstract={Text line segmentation in freestyle handwritten documents remains an open document analysis problem. Curvilinear text lines and small gaps between neighboring text lines present a challenge to algorithms developed for machine printed or hand-printed documents. In this paper, we propose a novel approach based on density estimation and a state-of-the-art image segmentation technique, the level set method. From an input document image, we estimate a probability map, where each element represents the probability that the underlying pixel belongs to a text line. The level set method is then exploited to determine the boundary of neighboring text lines by evolving an initial estimate. Unlike connected component based methods ( [1], [2] for example), the proposed algorithm does not use any script-specific knowledge. Extensive quantitative experiments on freestyle handwritten documents with diverse scripts, such as Arabic, Chinese, Korean, and Hindi, demonstrate that our algorithm consistently outperforms previous methods. Further experiments show the proposed algorithm is robust to scale change, rotation, and noise.},
keywords={document image processing;estimation theory;handwritten character recognition;image segmentation;probability;set theory;text analysis;script-independent curvilinear text line segmentation;freestyle handwritten document image segmentation;document analysis problem;machine printed document;hand-printed document;level set method;probability map estimation;connected component based method;Image segmentation;Text analysis;Level set;Image analysis;Piecewise linear approximation;State estimation;Pixel;Noise robustness;Character recognition;Algorithm design and analysis;Document analysis;Handwriting analysis;Document and Text Processing;Document analysis;Handwriting analysis;Document and Text Processing;Algorithms;Artificial Intelligence;Automatic Data Processing;Documentation;Handwriting;Image Enhancement;Image Interpretation, Computer-Assisted;Information Storage and Retrieval;Pattern Recognition, Automated;Reproducibility of Results;Sensitivity and Specificity},
doi={10.1109/TPAMI.2007.70792},
ISSN={0162-8828},
month={Aug},}
@INPROCEEDINGS{7333750,
author={L. {Wang} and W. {Fan} and J. {Sun} and S. {Naoi} and T. {Hiroshi}},
booktitle={2015 13th International Conference on Document Analysis and Recognition (ICDAR)},
title={Text line extraction in document images},
year={2015},
volume={},
number={},
pages={191-195},
abstract={Text line extraction in document images is an important prerequisite for many content based image understanding applications. In this paper, we propose an accurate and robust method for generic text line extraction, which can be applied on large categories of document images, diverse languages, and text lines with different orientations. Firstly, the candidate connected components are extracted from document image using Maximal Stable Extremal Region (MSER) with the noises filtered by Adaboost and Convolution Neural Network (CNN). Then, the coarse text lines are generated from hierarchical edges reconstruction and cut by local linearity of text lines in the document spanning tree. Finally, for accurate text line extraction, the cut multi-components are re-connected based on text line energy minimization in terms of text line consistency and the fitting error. Experimental results on multilingual test dataset demonstrate the effectiveness and robust of the proposed method, which yields higher performance compared with state-of-the-art methods.},
keywords={document image processing;edge detection;feature extraction;image reconstruction;learning (artificial intelligence);natural language processing;neural nets;text analysis;trees (mathematics);text line extraction;document images;content based image understanding applications;generic text line extraction;candidate connected components;maximal stable extremal region;noise filtering;Adaboost;convolution neural network;CNN;hierarchical edge reconstruction;document spanning tree;text line energy minimization;text line consistency;fitting error;multilingual test dataset;Robustness;Benchmark testing;Image segmentation;Surveillance;Image recognition;Integrated optics;Optical imaging;generic text line extraction;MSER;hierarchical edge reconstruction and cut;text line energy minimization},
doi={10.1109/ICDAR.2015.7333750},
ISSN={},
month={Aug},}
@INPROCEEDINGS{8276047,
author={K. {Saranya} and S. {Jayanthy}},
booktitle={2017 International Conference on Innovations in Information, Embedded and Communication Systems (ICIIECS)},
title={Onto-based sentiment classification using machine learning techniques},
year={2017},
volume={},
number={},
pages={1-5},
abstract={Sentiment analysis is a methodology used to analyse the emotion or view of an individual to a situation or topic. In present scenario, Social media is the source for the collection of individual's feedbacks, user's emotions, reviews and personal experiences which lead to a need for efficient mining of the text to derive knowledge. An optimal classification of text based on emotion is an unsolved problem in text mining. To extract knowledge from text many machine learning tools and techniques were proposed. An onto-based process is proposed to analyse the customer's emotion in this paper. The input emotional text that needs to be classified is given as input to the NLP and processed and an emotional ontology is created for better understanding of the semantics and relationships. When adding new instances, Ontology can be automatically classify them based on emotional relationship. The Emowords from ontology can be further classified using any of the standard machine learning techniques which definitively gives a better performance. This paper is a review of all the machine learning techniques that can be applied on the semantic analysis of sentiments.},
keywords={data mining;emotion recognition;knowledge based systems;learning (artificial intelligence);natural language processing;ontologies (artificial intelligence);pattern classification;sentiment analysis;social networking (online);text analysis;text mining;machine learning tools;customer;input emotional text;emotional ontology;emotional relationship;standard machine learning techniques;sentiment analysis;Social media;feedbacks;optimal classification;Emowords;Onto-based sentiment classification;NLP;Ontologies;Sentiment analysis;Social network services;Text mining;Semantics;Support vector machines;sentimental analysis;ontology;machine learning;NLP;semantics},
doi={10.1109/ICIIECS.2017.8276047},
ISSN={},
month={March},}
@INPROCEEDINGS{8591457,
author={D. L. {Marino} and C. S. {Wickramasinghe} and M. {Manic}},
booktitle={IECON 2018 - 44th Annual Conference of the IEEE Industrial Electronics Society},
title={An Adversarial Approach for Explainable AI in Intrusion Detection Systems},
year={2018},
volume={},
number={},
pages={3237-3243},
abstract={Despite the growing popularity of modern machine learning techniques (e.g, Deep Neural Networks) in cyber-security applications, most of these models are perceived as a black-box for the user. Adversarial machine learning offers an approach to increase our understanding of these models. In this paper we present an approach to generate explanations for incorrect classifications made by data-driven Intrusion Detection Systems (IDSs) An adversarial approach is used to find the minimum modifications (of the input features) required to correctly classify a given set of misclassified samples. The magnitude of such modifications is used to visualize the most relevant features that explain the reason for the misclassification. The presented methodology generated satisfactory explanations that describe the reasoning behind the mis-classifications, with descriptions that match expert knowledge. The advantages of the presented methodology are: 1) applicable to any classifier with defined gradients. 2) does not require any modification of the classifier model. 3) can be extended to perform further diagnosis (e.g. vulnerability assessment) and gain further understanding of the system. Experimental evaluation was conducted on the NSL-KDD99 benchmark dataset using Linear and Multilayer perceptron classifiers. The results are shown using intuitive visualizations in order to improve the interpretability of the results.},
keywords={learning (artificial intelligence);multilayer perceptrons;neural nets;pattern classification;security of data;adversarial approach;explainable AI;cyber-security applications;adversarial machine learning;multilayer perceptron classifiers;machine learning techniques;deep neural networks;data-driven intrusion detection systems;IDSs;Machine learning;Intrusion detection;Mathematical model;Visualization;Estimation;Adversarial Machine Learning;Adversarial samples;Explainable AI;cyber-security},
doi={10.1109/IECON.2018.8591457},
ISSN={2577-1647},
month={Oct},}
@INPROCEEDINGS{953778,
author={D. {Malerba} and F. {Esposito} and F. A. {Lisi} and O. {Altamura}},
booktitle={Proceedings of Sixth International Conference on Document Analysis and Recognition},
title={Automated discovery of dependencies between logical components in document image understanding},
year={2001},
volume={},
number={},
pages={174-178},
abstract={Document image understanding denotes the recognition of semantically relevant components in the layout extracted from a document image. This recognition process is based on some visual models, whose manual specification can be a highly demanding task. In order to automatically acquire these models, we propose the application of machine learning techniques. Problems raised by possible dependencies between concepts to be learned are illustrated and solved with a computational strategy based on the separate-and-parallel-conquer search. The approach is tested on a set of real multi-page documents processed by the system WISDOM++. New results confirm the validity of the proposed strategy and show some limits of the learning system used in this work.},
keywords={document image processing;optical character recognition;learning (artificial intelligence);divide and conquer methods;search problems;document image understanding;logical component dependence discovery;document image recognition;visual models;machine learning;computational strategy;separate-and-parallel-conquer search;multi-page documents;WISDOM system;OCR;Image recognition;Text analysis;Image analysis;Optical character recognition software;XML;System testing;Publishing;Image databases;Digital images;Optical devices},
doi={10.1109/ICDAR.2001.953778},
ISSN={},
month={Sep.},}
@ARTICLE{774103,
author={I. A. {Taha} and J. {Ghosh}},
journal={IEEE Transactions on Knowledge and Data Engineering},
title={Symbolic interpretation of artificial neural networks},
year={1999},
volume={11},
number={3},
pages={448-463},
abstract={Hybrid intelligent systems that combine knowledge-based and artificial neural network systems typically have four phases, involving domain knowledge representation, mapping of this knowledge into an initial connectionist architecture, network training and rule extraction, respectively. The final phase is important because it can provide a trained connectionist architecture with explanation power and validate its output decisions. Moreover, it can be used to refine and maintain the initial knowledge acquired from domain experts. In this paper, we present three rule extraction techniques. The first technique extracts a set of binary rules from any type of neural network. The other two techniques are specific to feedforward networks, with a single hidden layer of sigmoidal units. Technique 2 extracts partial rules that represent the most important embedded knowledge with an adjustable level of detail, while the third technique provides a more comprehensive and universal approach. A rule-evaluation technique, which orders extracted rules based on three performance measures, is then proposed. The three techniques area applied to the iris and breast cancer data sets. The extracted rules are evaluated qualitatively and quantitatively, and are compared with those obtained by other approaches.},
keywords={symbol manipulation;knowledge representation;explanation;truth maintenance;feedforward neural nets;neural net architecture;knowledge based systems;learning (artificial intelligence);symbolic interpretation;hybrid intelligent systems;knowledge-based systems;artificial neural networks;domain knowledge representation;domain knowledge mapping;connectionist architecture;network training;rule extraction;explanation power;output decision validation;knowledge refinement;binary rules;feedforward networks;hidden layer;sigmoidal units;partial rules;embedded knowledge;adjustable detail level;rule evaluation technique;rule ordering;performance measures;iris data set;breast cancer data set;Artificial neural networks;Neural networks;Data mining;Military computing;Knowledge representation;Knowledge based systems;Fuzzy neural networks;Fuzzy sets;Computer networks;Intelligent systems},
doi={10.1109/69.774103},
ISSN={1041-4347},
month={May},}
@INPROCEEDINGS{346487,
author={P. S. {Jacobs}},
booktitle={Proceedings Sixth International Conference on Tools with Artificial Intelligence. TAI 94},
title={Text-based systems and information management: artificial intelligence confronts matters of scale},
year={1994},
volume={},
number={},
pages={235-236},
abstract={Many of the more ambitious goals of artificial intelligence have proved unattainable because of the failure of the many small, successful systems to scale up. The general use of technologies such as natural language interfaces and expert systems has done little to alleviate the basic difficulties and overwhelming cost of knowledge engineering. At the same time, emerging text processing techniques, including data extraction from text and new text retrieval methods, offer a means of accessing stores of information many times larger than any organized knowledge base or database. Although knowledge acquisition from text is at the heart of the information management problem, interpreting text, paradoxically, requires large amounts of knowledge, mainly about the way words are used in context. In other words, before intelligent text processing systems can be trained to mine for useful knowledge, they must already have enough knowledge to interpret what they read. The point at which there is "enough", is still a matter of debate, as no real program seems close to having enough knowledge to achieve general human-like understanding. Current research in large-scale natural language processing has come, rightly, to focus on lexical acquisition as the key to future progress. Unfortunately, the current state of the art is quite far from the recipe for acquiring knowledge about words, because it leans too heavily on resources that are available, without consideration for what is needed.<<ETX>>},
keywords={word processing;natural language interfaces;knowledge acquisition;information retrieval;text-based systems;information management;artificial intelligence;natural language interfaces;expert systems;knowledge engineering;text processing techniques;data extraction;text retrieval methods;knowledge acquisition;intelligent text processing systems;human-like understanding;large-scale natural language processing;lexical acquisition;word processing;Information management;Text processing;Data mining;Artificial intelligence;Natural languages;Expert systems;Costs;Knowledge engineering;Information retrieval;Databases},
doi={10.1109/TAI.1994.346487},
ISSN={},
month={Nov},}
@INPROCEEDINGS{6460845,
author={B. {Su} and S. {Lu} and C. L. {Tan}},
booktitle={Proceedings of the 21st International Conference on Pattern Recognition (ICPR2012)},
title={A learning framework for degraded document image binarization using Markov Random Field},
year={2012},
volume={},
number={},
pages={3200-3203},
abstract={Document image binarization is an important preprocessing technique for document image analysis that segments the text from the document image backgrounds. Many techniques have been proposed and successfully applied in different applications, such as document image retrieval. However, these techniques may perform poorly on degraded document images. In this paper, we propose a learning framework that makes use of the Markov Random Field to improve the performance of the existing document image binarization methods for those degraded document images. Extensive experiments on the recent Document Image Bina-rization Contest datasets demonstrate that significant improvements of the existing binarization methods when applying our proposed framework.},
keywords={document image processing;image retrieval;image segmentation;learning (artificial intelligence);Markov processes;random processes;text analysis;learning framework;degraded document image binarization methods;Markov random field;document image analysis;text segmentation;document image backgrounds;document image retrieval;document image binarization contest datasets;Image edge detection;Markov random fields;Vectors;Equations;Mathematical model;Text analysis},
doi={},
ISSN={1051-4651},
month={Nov},}
@INPROCEEDINGS{7960721,
author={İ. Ü. {Oğul} and C. {Özcan} and Ö. {Hakdağlı}},
booktitle={2017 25th Signal Processing and Communications Applications Conference (SIU)},
title={Fast text classification with Naive Bayes method on Apache Spark},
year={2017},
volume={},
number={},
pages={1-4},
abstract={The increase in the number of devices and users online with the transition of Internet of Things (IoT), increases the amount of large data exponentially. Classification of ascending data, deletion of irrelevant data, and meaning extraction have reached vital importance in today's standards. Analysis can be done in various variations such as Classification of text on text data, analysis of spam, personality analysis. In this study, fast text classification was performed with machine learning on Apache Spark using the Naive Bayes method. Spark architecture uses a distributed in-memory data collection instead of a distributed data structure presented in Hadoop architecture to provide fast storage and analysis of data. Analyzes were made on the interpretation data of the Reddit which is open source social news site by using the Naive Bayes method. The results are presented in tables and graphs.},
keywords={Bayes methods;data analysis;distributed processing;Internet of Things;learning (artificial intelligence);pattern classification;public domain software;social networking (online);text analysis;IoT;open source social news site;Reddit;interpretation data;data analysis;fast data storage;Hadoop architecture;distributed data structure;distributed in-memory data collection;Apache Spark architecture;Naive Bayes method;machine learning;meaning extraction;irrelevant data deletion;Internet of Things;fast text classification;Sparks;Java;Internet of Things;Standards;Text categorization;Art;Machine learning;Text mining;Big data;Apache Spark;Classification;Naive Bayes},
doi={10.1109/SIU.2017.7960721},
ISSN={},
month={May},}
@INPROCEEDINGS{7801719,
author={D. {Kim} and J. {Lee}},
booktitle={2016 Joint 8th International Conference on Soft Computing and Intelligent Systems (SCIS) and 17th International Symposium on Advanced Intelligent Systems (ISIS)},
title={Multi-document Summarization by Creating Synthetic Document Vector Based on Language Model},
year={2016},
volume={},
number={},
pages={605-609},
abstract={Multi-document summarization is to create summaries covering the major information that multiple documents tell in common. For this point, the existing methods are based on hand-crafted features for word and sentence. However, it is difficult to figure out the core contents of each document with the hand-crafted features because they have the limited information presented the given documents. Moreover, there exists a limit to figure out the major information because documents with the same meaning used to be paraphrased depending on their writers. Therefore, it is necessary to represent the semantic meanings of documents as well as sentences through understanding natural language. In this paper, we propose a new multi-document summarization system by creating a synthetic document vector covering the whole documents based on Language Model, whose is well-known for learning the semantic features in text. We experimented with DUC 2004 dataset provided by Document Understanding Conference (DUC) and the results show that our method summarizes multiple documents effectively based on their core contents.},
keywords={document handling;natural language processing;word processing;multidocument summarization system;semantic text feature learning;DUC 2004 dataset;document understanding conference;natural language model;semantic document meanings;hand-crafted features;synthetic document vector;Semantics;Context;Hidden Markov models;Computational modeling;Redundancy;Intelligent systems;Natural languages;Multi-document summarization;Core content;Major Information;Synthetic document vector;Language model},
doi={10.1109/SCIS-ISIS.2016.0132},
ISSN={},
month={Aug},}
@INPROCEEDINGS{8551093,
author={S. G. {Kanakaraddi} and S. S. {Nandval}},
booktitle={2018 International Conference on Current Trends towards Converging Technologies (ICCTCT)},
title={Dynamic Fuzzy Parser to Parse English Sentence Using POS Tagger and Fuzzy Max-Min Technique},
year={2018},
volume={},
number={},
pages={1-5},
abstract={Natural Language (NL) is an essential part of ourlife. Humans use language for communication. NL is a prevailing tool used by the humans to convey the information. Natural Language Understanding (NLU) is a major challenge in Natural Language Processing (NLP). NLP is a part of Artificial Intelligence (AI). NLP provides a significant tool for communication. It attempts to produces noise free data and conversion of noise to text. NLU is having different levels. This paper presents the issue with respect to one of the level such as syntax analysis. To provide a solution for syntax analysis, dynamic fuzzy parser is designed and implemented to parse the English input sentences. Traditional approach of parsing is enhanced by applying fuzzy logic. This helps to know the syntactic correctness of the sentence. Penns tree bank parts of speech tags are used for the Parts of Speech Tagger (POS). POS tagger assigns the parts of speech tags for the input English sentence. Then these tags of the words are parsed using the grammar rules. Finally the result is displayed to represent the number of words parsed in a sentence with its associated fuzzy membership value. This parser produces Precision value of 1(100%), Recall value of 0.92 (92%) and F-measure value of 0.9583 for the sample of 50 correct and 50 incorrect sentences.},
keywords={artificial intelligence;computational linguistics;context-free grammars;fuzzy logic;natural language processing;text analysis;syntax analysis;dynamic fuzzy parser;natural language;recall value;precision value;F-measure value;grammar rules;parts of speech tagger;Penns tree bank parts of speech tags;parse English input sentences;artificial intelligence;natural language processing;natural language understanding;fuzzy membership value;POS tagger;NLP;NLU;fuzzy max-min technique;fuzzy logic;Grammar;Syntactics;Natural language processing;Conferences;Market research;Artificial intelligence;POS;FCFG;NL;NLU;NLP;POS;AI;CFG},
doi={10.1109/ICCTCT.2018.8551093},
ISSN={},
month={March},}
@INPROCEEDINGS{8468758,
author={W. {Sun} and X. {Gao}},
booktitle={2018 13th International Conference on Computer Science Education (ICCSE)},
title={The Construction of Undergraduate Machine Learning Course in the Artificial Intelligence Era},
year={2018},
volume={},
number={},
pages={1-5},
abstract={Machine learning technology has been greatly developed in the last decade, which makes artificial intelligence reach a revolutionary breakthrough and lets us really perceive the potential of artificial intelligence in changing human life. In order to improve the understanding and application ability of artificial intelligence, carrying out the corresponding machine learning course is of significance for the students during the undergraduate period. This paper probes into the teaching content, teaching form and other aspects of the undergraduate machine learning course based on this issue and proposes a teaching method driven by application scenarios to guide the undergraduate students to understand the development, current situation and frontier technology of machine learning. In the experimental design, the students' theoretical knowledge is fully considered, the practical questions are simplified, and the students' ability to think and solve problems is also raised, so as to lay a theoretical and practical basis for further study of machine learning.},
keywords={artificial intelligence;computer aided instruction;computer science education;educational courses;further education;learning (artificial intelligence);teaching;artificial intelligence era;machine learning technology;undergraduate period;undergraduate students;undergraduate machine learning course;machine learning course;teaching content;teaching form;Machine learning;Machine learning algorithms;Classification algorithms;Prediction algorithms;Education;Decision trees;artificial intelligence;machine learning;undergraduate},
doi={10.1109/ICCSE.2018.8468758},
ISSN={2473-9464},
month={Aug},}
@INPROCEEDINGS{5580484,
author={X. {Ma} and W. W. Y. {Ng} and P. P. K. {Chan} and D. S. {Yeung}},
booktitle={2010 International Conference on Machine Learning and Cybernetics},
title={Video text detection and localization based on localized generalization error model},
year={2010},
volume={4},
number={},
pages={2161-2166},
abstract={Texts in videos provide plenteous information for video analysis such as video indexing, understanding and retrieval. We propose a neural network based method detecting text in the video frames in this work. The proposed method consists of three major steps: feature extraction, text region detection and candidate region refinement. Firstly, we extract texture features from four edge maps yielded from the target video frame. Secondly, a Radial Basis Function Neural Network (RBFNN) optimized by the Localized Generalization Error Model (L-GEM) is applied to detect text candidates. Finally, a false detection of text is applied to fine tune the result. Experimental results demonstrate that the proposed method is efficient for different font-colors, font-sizes and language in complex background.},
keywords={edge detection;feature extraction;radial basis function networks;text analysis;video signal processing;video text detection;localized generalization error model;video indexing;video understanding;video retrieval;texture features extraction;edge maps;radial basis function neural network;Image edge detection;Feature extraction;Training;Computer architecture;Neurons;Classification algorithms;Machine learning;Text detection;Localized generalization error model (LGEM);Radial basis function neural network (RBFNN)},
doi={10.1109/ICMLC.2010.5580484},
ISSN={2160-133X},
month={July},}
@INPROCEEDINGS{236591,
author={J. {Genest}},
booktitle={Proceedings First International Conference on Artificial Intelligence Applications on Wall Street},
title={Building a banking system specification using machine learning},
year={1991},
volume={},
number={},
pages={263-268},
abstract={Transforming user requirements into software specification is a complex and demanding task. Artificial intelligence methods such as machine learning (ML) can assist in the software specification process by providing support to system designers. This paper presents an approach based on explanation-based learning (EBL), a ML technique in which a concept is learned by building an explanation. The approach is presented in the context of the system LISE (Learning in Software Engineering). LISE converts a user requirement for a software module into an operational module definition using EBL with an incomplete theory. An example where LISE is used to build the specification of a banking system is illustrated.<<ETX>>},
keywords={bank data processing;case-based reasoning;explanation;formal specification;learning (artificial intelligence);case-based reasoning;banking system specification;user requirements;machine learning;explanation-based learning;LISE;Learning in Software Engineering;Banking;Machine learning;Buildings;Software engineering;Mathematics;Artificial intelligence;Programming;Software design;Multilevel systems;Software libraries},
doi={10.1109/AIAWS.1991.236591},
ISSN={},
month={Oct},}
@INPROCEEDINGS{5383110,
author={S. F. {Rashid} and S. S. {Bukhari} and F. {Shafait} and T. M. {Breuel}},
booktitle={2009 IEEE 13th International Multitopic Conference},
title={A discriminative learning approach for orientation detection of Urdu document images},
year={2009},
volume={},
number={},
pages={1-5},
abstract={Orientation detection is an important preprocessing step for accurate recognition of text from document images. Many existing orientation detection techniques are based on the fact that in Roman script text ascenders occur more likely than descenders, but this approach is not applicable to document of other scripts like Urdu, Arabic, etc. In this paper, we propose a discriminative learning approach for orientation detection of Urdu documents with varying layouts and fonts. The main advantage of our approach is that it can be applied to documents of other scripts easily and accurately. Our approach is based on classification of individual connected component orientation in the document image, and then the orientation of the page image is determined via majority count. A convolutional neural network is trained as discriminative learning model for the labeled Urdu books dataset with four target orientations: 0, 90, 180 and 270 degrees. We demonstrate the effectiveness of our method on dataset of Urdu documents categorized into the layouts of book, novel and poetry. We achieved 100% orientation detection accuracy on a test set of 328 document images.},
keywords={classification;document image processing;learning (artificial intelligence);natural language processing;neural nets;text analysis;discriminative learning approach;orientation detection;Urdu document images;text recognition;Roman script;text ascenders;classification;convolutional neural network;Urdu books dataset;Neural networks;Optical character recognition software;Shape;Pattern recognition;Image recognition;Books;Cellular neural networks;Learning;Artificial intelligence;Text recognition},
doi={10.1109/INMIC.2009.5383110},
ISSN={},
month={Dec},}
@INPROCEEDINGS{8679370,
author={S. {Kim} and H. {Kim}},
booktitle={2019 IEEE International Conference on Big Data and Smart Computing (BigComp)},
title={Deep Explanation Model for Facial Expression Recognition Through Facial Action Coding Unit},
year={2019},
volume={},
number={},
pages={1-4},
abstract={Facial expression is the most powerful and natural non-verbal emotional communication method. Facial Expression Recognition(FER) has significance in machine learning tasks. Deep Learning models perform well in FER tasks, but it doesn't provide any justification for its decisions. Based on the hypothesis that facial expression is a combination of facial muscle movements, we find that Facial Action Coding Units(AUs) and Emotion label have a relationship in CK+ Dataset. In this paper, we propose a model which utilises AUs to explain Convolutional Neural Network(CNN) model's classification results. The CNN model is trained with CK+ Dataset and classifies emotion based on extracted features. Explanation model classifies the multiple AUs with the extracted features and emotion classes from the CNN model. Our experiment shows that with only features and emotion classes obtained from the CNN model, Explanation model generates AUs very well.},
keywords={convolutional neural nets;emotion recognition;face recognition;feature extraction;learning (artificial intelligence);nonverbal emotional communication method;machine learning tasks;Deep Learning models;FER tasks;facial muscle movements;CK+ Dataset;CNN model;emotion classes;facial expression recognition;convolutional neural network model;facial action coding units;deep explanation model;facial action coding unit;Hidden Markov models;Gold;Feature extraction;Face recognition;Deep learning;Computational modeling;Task analysis;Explanation Model;Facial Expression Recognition;Deep learning;Justification;Facial Action Coding System},
doi={10.1109/BIGCOMP.2019.8679370},
ISSN={2375-9356},
month={Feb},}
@INPROCEEDINGS{8258557,
author={S. {Shirataki} and S. {Yamaguchi}},
booktitle={2017 IEEE International Conference on Big Data (Big Data)},
title={A study on interpretability of decision of machine learning},
year={2017},
volume={},
number={},
pages={4830-4831},
abstract={Machine learning is one of the most important fields in recent improvement in big data analysis. Many people apply machine learning for a variety of domains for various purposes, such as classification of opinions. However, the constructed models of machine learning are black boxes. They cannot understand the background reason for their decisions. In many cases, understanding the reasons important. In this paper, we focus on interpretation of models and understanding of decision reasons. First, we introduce the results of an opinions classification of the reviews with Support Vector Machine (SVM). Second, we interpret the model by analyzing weights of the model. Third, we introduce a method for helping to understand the reasons for a decision by SVM by providing a simplified information of the highly weighted words.},
keywords={Big Data;data analysis;learning (artificial intelligence);pattern classification;support vector machines;text analysis;machine learning;decision reasons;Support Vector Machine;big data analysis;SVM;highly weighted words;black boxes;opinions classification;Support vector machines;DVD;Analytical models;Predictive models;Training;Big Data;Tools;SVM;machine learning;interpretability},
doi={10.1109/BigData.2017.8258557},
ISSN={},
month={Dec},}
@INPROCEEDINGS{6102474,
author={I. {Icke} and A. {Rosenberg}},
booktitle={2011 IEEE Conference on Visual Analytics Science and Technology (VAST)},
title={Automated measures for interpretable dimensionality reduction for visual classification: A user study},
year={2011},
volume={},
number={},
pages={281-282},
abstract={This paper studies the interpretability of transformations of labeled higher dimensional data into a 2D representation (scatterplots) for visual classification.<sup>1</sup>In this context, the term interpretability has two components: the interpretability of the visualization (the image itself) and the interpretability of the visualization axes (the data transformation functions). We define a data transformation function as any linear or non-linear function of the original variables mapping the data into 1D. Even for a small dataset, the space of possible data transformations is beyond the limit of manual exploration, therefore it is important to develop automated techniques that capture both aspects of interpretability so that they can be used to guide the search process without human intervention. The goal of the search process is to find a smaller number of interpretable data transformations for the users to explore. We briefly discuss how we used such automated measures in an evolutionary computing based data dimensionality reduction application for visual analytics. In this paper, we present a two-part user study in which we separately investigated how humans rated the visualizations of labeled data and comprehensibility of mathematical expressions that could be used as data transformation functions. In the first part, we compared human perception with a number of automated measures from the machine learning and visual analytics literature. In the second part, we studied how various structural properties of an expression related to its interpretability.},
keywords={data analysis;data visualisation;learning (artificial intelligence);pattern classification;interpretable dimensionality reduction;visual classification;transformation interpretability;labeled higher dimensional data;2D representation;visualization axis interpretability;data transformation functions;evolutionary computing;visual analytics;labeled data visualization;mathematical expression comprehensibility;human perception;machine learning;expression structural properties;Indexes;Humans;Visualization;Data visualization;Support vector machines;Particle measurements;Atmospheric measurements;data transformation;visualization;user study},
doi={10.1109/VAST.2011.6102474},
ISSN={},
month={Oct},}
@INPROCEEDINGS{7557899,
author={R. {Goebel}},
booktitle={2016 20th International Conference Information Visualisation (IV)},
title={Why Visualization is an AI-complete Problem (and Why That Matters)},
year={2016},
volume={},
number={},
pages={27-32},
abstract={Artificial Intelligence (AI) has infiltrated almost every scientific and social endeavour, including everything from medical research to the sociology of crowd control. But the foundation of AI continues to be based on digital representations of knowledge, and computational reasoning therewith. Because so much of modern knowledge infrastructure and social behaviour is connected to AI, understanding the role of AI in each such endeavour not only helps accelerate progress in those fields in which it applies, but also creates the challenges to extend the foundation for modern AI methods. The simple hypothesis herein is that so-called AI-complete problems have a role in helping to articulate the appropriate integration of AI within other disciplines. With the current growth of interest in "big data" and visualization, we argue that relatively simple formal structures provide a basis for the claim that visualization is an AI-complete problem. The value of confirming this claim is largely to encourage stronger formalizations of the visualization process in terms of the AI foundations of representation and reasoning. This connection will help ensure that relevant components of AI are appropriately applied and integrated, to provide value for a basis of a theory of visualization. The sketch of this claim here is based on the simple idea that visualization is an abstraction process, and that abstractions from partial information, however voluminous, directly confronts the non monotonic reasoning challenge, thus the need for caution in engineering visualization systems without carefully considering the consequences of visual abstraction. This is particularly important with interactive visualization, which has recently formed the basis for such fields as visual analytics.},
keywords={artificial intelligence;Big Data;data analysis;data structures;data visualisation;AI-complete problem;artificial intelligence;digital knowledge representations;computational reasoning;modern knowledge infrastructure;social behaviour;AI methods;AI integration;Big Data;formal structures;visualization process formalization;partial information abstraction process;monotonic reasoning challenge;engineering visualization systems;visual abstraction;interactive visualization;visual analytics;Data visualization;Visualization;Artificial intelligence;Context;Complexity theory;Cognition;Semantics;AI-complete visualization incomplete knowledge},
doi={10.1109/IV.2016.53},
ISSN={2375-0138},
month={July},}
@INPROCEEDINGS{395697,
author={T. A. {Bayer}},
booktitle={Proceedings of 2nd International Conference on Document Analysis and Recognition (ICDAR '93)},
title={Understanding structured text documents by a model based document analysis system},
year={1993},
volume={},
number={},
pages={448-453},
abstract={A document analysis system which is capable of extracting the semantics of specific text portions of structured documents is presented. The architecture of the analysis system is based on a knowledge representation scheme, a semantic network, called Resco-Frame Representation of Structured Documents. It allows the definition of knowledge about document components as well as knowledge about analysis algorithms in a uniform, simple, but powerful representation formalism. Hence, this architecture enables the analysis system to exploit the specific power of both the algorithmic knowledge describing the properties of algorithms and the declarative knowledge about properties of text objects in documents. The inference engine and the control algorithm show how these two knowledge sources are combined and utilized. The flexibility of the representation formalism Fresco, the recognition results and the computational complexity of the inference algorithm are presented in two different applications.<<ETX>>},
keywords={document handling;semantic networks;model-based reasoning;structured text documents;model based document analysis system;knowledge representation scheme;semantic network;representation formalism;declarative knowledge;text objects;inference engine;control algorithm;Text analysis;Inference algorithms;Image recognition;Optical character recognition software;Data mining;Algorithm design and analysis;Engines;Computational complexity;Document image processing;Electronics packaging},
doi={10.1109/ICDAR.1993.395697},
ISSN={},
month={Oct},}
@ARTICLE{8540793,
author={X. I. {Quan} and J. {Sanderson}},
journal={IEEE Engineering Management Review},
title={Understanding the Artificial Intelligence Business Ecosystem},
year={2018},
volume={46},
number={4},
pages={22-25},
abstract={This technology manager's note piece identifies the major components in the artificial intelligence (AI) business ecosystem and discusses several implications for managers. Specifically, it emphasizes on the designing of AI user scenarios, data acquisition for AI, and building the AI ecosystem.},
keywords={artificial intelligence;business data processing;competitive intelligence;data acquisition;technology management;artificial intelligence business ecosystem;technology manager;AI user scenarios;AI ecosystem;data acquisition;Business;Ecosystems;Machine learning;Medical services;Buildings;Artificial intelligence;business ecosystem;technology management},
doi={10.1109/EMR.2018.2882430},
ISSN={0360-8581},
month={Fourthquarter},}
@INPROCEEDINGS{716778,
author={C. {Chiu} and T. {Oki} and P. {Paolellia}},
booktitle={Proceedings of 1993 International Conference on Neural Networks (IJCNN-93-Nagoya, Japan)},
title={A novel pattern searching method using neural networks and correlation},
year={1993},
volume={2},
number={},
pages={1277-1280 vol.2},
abstract={A novel pattern searching method using neural networks and correlation is presented. This method combines the quickness and adaptiveness of neural networks with the accuracy of the mathematical correlation approach. Images are divided into small sub-images which are presented to the trained neural network. Sub-images that may contain the pattern or partial pattern are selected by the neural network. The neural network also provides the approximate location of the pattern, therefore the selected sub-images can be adjusted to contain the complete pattern. Desired patterns can be located by measuring the new sub-images' correlation values against the reference models in a small area. Experiments show that this superior method is able to find the desired patterns. Moreover, this method is much faster and more adaptable than traditional pattern searching methods.},
keywords={image recognition;neural nets;correlation methods;pattern searching method;neural networks;adaptiveness;mathematical correlation;sub-images;Neural networks;Pattern recognition;Brightness;Character recognition;Image recognition;Pixel;Manufacturing automation;Inspection;Printed circuits;Correlation},
doi={10.1109/IJCNN.1993.716778},
ISSN={},
month={Oct},}
@ARTICLE{8494828,
author={H. {Strobelt} and S. {Gehrmann} and M. {Behrisch} and A. {Perer} and H. {Pfister} and A. M. {Rush}},
journal={IEEE Transactions on Visualization and Computer Graphics},
title={Seq2seq-Vis: A Visual Debugging Tool for Sequence-to-Sequence Models},
year={2019},
volume={25},
number={1},
pages={353-363},
abstract={Neural sequence-to-sequence models have proven to be accurate and robust for many sequence prediction tasks, and have become the standard approach for automatic translation of text. The models work with a five-stage blackbox pipeline that begins with encoding a source sequence to a vector space and then decoding out to a new target sequence. This process is now standard, but like many deep learning methods remains quite difficult to understand or debug. In this work, we present a visual analysis tool that allows interaction and “what if”-style exploration of trained sequence-to-sequence models through each stage of the translation process. The aim is to identify which patterns have been learned, to detect model errors, and to probe the model with counterfactual scenario. We demonstrate the utility of our tool through several real-world sequence-to-sequence use cases on large-scale models.},
keywords={data visualisation;learning (artificial intelligence);neural nets;program debugging;sequences;seq2seq-Vis;source sequence;target sequence;visual debugging tool;neural sequence-to-sequence models;blackbox pipeline;vector space;deep learning methods;visual analysis tool;Analytical models;Visualization;Tools;Predictive models;Machine learning;Data models;Atmosphere;Explainable AI;Visual Debugging;Visual Analytics;Machine Learning;Deep Learning;NLP},
doi={10.1109/TVCG.2018.2865044},
ISSN={1077-2626},
month={Jan},}
@INPROCEEDINGS{5590681,
author={Z. {Chen} and H. {Dong}},
booktitle={2010 Second International Conference on Intelligent Human-Machine Systems and Cybernetics},
title={The Effects of Documents Lineage on Use of Explanation in Document-Driven DSS},
year={2010},
volume={1},
number={},
pages={243-248},
abstract={In document-driven DSS, the decisions are both based on the inheritance among the documents and the acceptance of advices for users. Research in the field of DSS has shown that providing explanations may improve acceptance of decision makers. The most important part of explanations in document-driven DSS lies in tracing the contents and the classification of interrelated documents. But current document-driven DSS is lack of a mechanism to record the citation and cluster the related documents. This paper tries to find out the trace routes among documents to improve the explanations. First, a document lineage model is established to present the citation and delivery mechanism in documents. Second, the document DNA is used to build the routes of documents transferences. Third, the whole lineage in documents is integrated by routes. Finally, a system frame for explanations mechanism in document-driven DSS was described.},
keywords={data mining;decision making;decision support systems;information retrieval;pattern clustering;text analysis;document driven DSS;decision support system;decision making;document lineage model;document transference;Decision support systems;DNA;Decision making;Blood;Face;Computers;Document-driven DSS;Explanation;Document lineage},
doi={10.1109/IHMSC.2010.67},
ISSN={},
month={Aug},}
@INPROCEEDINGS{8365991,
author={S. {Nie} and C. {Healey} and K. {Padia} and S. {Leeman-Munk} and J. {Benson} and D. {Caira} and S. {Sethi} and R. {Devarajan}},
booktitle={2018 IEEE Pacific Visualization Symposium (PacificVis)},
title={Visualizing Deep Neural Networks for Text Analytics},
year={2018},
volume={},
number={},
pages={180-189},
abstract={Deep neural networks (DNNs) have made tremendous progress in many different areas in recent years. How these networks function internally, however, is often not well understood. Advances in under-standing DNNs will benefit and accelerate the development of the field. We present TNNVis, a visualization system that supports un-derstanding of deep neural networks specifically designed to analyze text. TNNVis focuses on DNNs composed of fully connected and convolutional layers. It integrates visual encodings and interaction techniques chosen specifically for our tasks. The tool allows users to: (1) visually explore DNN models with arbitrary input using a combination of node-link diagrams and matrix representation; (2) quickly identify activation values, weights, and feature map patterns within a network; (3) flexibly focus on visual information of interest with threshold, inspection, insight query, and tooltip operations; (4) discover network activation and training patterns through animation; and (5) compare differences between internal activation patterns for different inputs to the DNN. These functions allow neural network researchers to examine their DNN models from new perspectives, producing insights on how these models function. Clustering and summarization techniques are employed to support large convolutional and fully connected layers. Based on several part of speech models with different structure and size, we present multiple use cases where visualization facilitates an understanding of the models.},
keywords={data visualisation;feedforward neural nets;learning (artificial intelligence);natural language processing;text analysis;interaction techniques;DNN models;network activation;training patterns;internal activation patterns;neural network researchers;convolutional connected layers;fully connected layers;deep neural networks;DNNs;visualization system;convolutional layers;visual encodings;text analytics;TNNVis;clustering techniques;summarization techniques;speech models;Visualization;Neurons;Computational modeling;Task analysis;Convolutional neural networks;Biological neural networks;information visualization;deep learning;machine learning;visualization design;human centered computing},
doi={10.1109/PacificVis.2018.00031},
ISSN={2165-8773},
month={April},}
@ARTICLE{5993545,
author={S. {Razavi} and B. A. {Tolson}},
journal={IEEE Transactions on Neural Networks},
title={A New Formulation for Feedforward Neural Networks},
year={2011},
volume={22},
number={10},
pages={1588-1598},
abstract={Feedforward neural network is one of the most commonly used function approximation techniques and has been applied to a wide variety of problems arising from various disciplines. However, neural networks are black-box models having multiple challenges/difficulties associated with training and generalization. This paper initially looks into the internal behavior of neural networks and develops a detailed interpretation of the neural network functional geometry. Based on this geometrical interpretation, a new set of variables describing neural networks is proposed as a more effective and geometrically interpretable alternative to the traditional set of network weights and biases. Then, this paper develops a new formulation for neural networks with respect to the newly defined variables; this reformulated neural network (ReNN) is equivalent to the common feedforward neural network but has a less complex error response surface. To demonstrate the learning ability of ReNN, in this paper, two training methods involving a derivative-based (a variation of backpropagation) and a derivative-free optimization algorithms are employed. Moreover, a new measure of regularization on the basis of the developed geometrical interpretation is proposed to evaluate and improve the generalization ability of neural networks. The value of the proposed geometrical interpretation, the ReNN approach, and the new regularization measure are demonstrated across multiple test problems. Results show that ReNN can be trained more effectively and efficiently compared to the common neural networks and the proposed regularization measure is an effective indicator of how a network would perform in terms of generalization.},
keywords={feedforward neural nets;function approximation;generalisation (artificial intelligence);learning (artificial intelligence);optimisation;function approximation techniques;black box model;neural network functional geometry;geometrical interpretation;reformulated neural network;feedforward neural network;error response surface;learning ability;training method;derivative free optimization algorithm;generalization ability;ReNN approach;Biological neural networks;Training;Nickel;Optimization;Function approximation;Neurons;Feedforward neural networks;generalization;geometrical interpretation;internal behavior;measure of regularization;reformulated neural network;training;Algorithms;Artificial Intelligence;Feedback;Models, Neurological;Neural Networks (Computer);Software Design},
doi={10.1109/TNN.2011.2163169},
ISSN={1045-9227},
month={Oct},}
@INPROCEEDINGS{6486324,
author={S. {Rustamov}},
booktitle={2012 IV International Conference "Problems of Cybernetics and Informatics" (PCI)},
title={Application of Neuro-Fuzzy model for text and speech understanding systems},
year={2012},
volume={},
number={},
pages={1-4},
abstract={The problem of speech and text understanding and its application to the spoken dialogue systems is investigated in the paper. The Neuro-Fuzzy model has been applied for solution this problem and received satisfactory results. Mathematical model and software developed for building human-computer dialogue system.},
keywords={fuzzy set theory;human computer interaction;interactive systems;neural nets;speech synthesis;text analysis;neuro-fuzzy model;text understanding systems;speech understanding systems;spoken dialogue systems;mathematical model;human-computer dialogue system;dialogue systems;speech understanding;neuro-fuzzy model;learning user intention},
doi={10.1109/ICPCI.2012.6486324},
ISSN={},
month={Sep.},}
@INPROCEEDINGS{5579790,
author={ and S. {Manickam}},
booktitle={2010 3rd International Conference on Advanced Computer Theory and Engineering(ICACTE)},
title={Intelligent Expertise Classification approach: An innovative artificial intelligence approach to accelerate network data visualization},
year={2010},
volume={6},
number={},
pages={V6-437-V6-440},
abstract={In order to visualize huge network traffic, data visualization applications are being developed and used to complement network data visualization. With today's network data visualization tools, it is only possible to view small portions of data and consuming lots of time to process the data. The network data process time can be reduced with the innovative artificial intelligence approach, which can effectively accelerate the network data visualization and consequently classify network data into different level of details according diverse computer users' expertise level on network. In the last few years, many visualization tools have been developed; either suffers from time to process the network data or the low understanding from the network data visualization efficiency. In this paper, we proposed an innovative intelligence approach, namely Intelligent Expertise Classification Algorithm (IECA) based on diverse computer users' expertise level in order to improve the network data process time as well as the understanding level among computer users. The approach architecture details and its requirements such as expertise level from diverse computer users and processed data from data mining classification will be discussed. Numbers of experiments have been carried out on 100 computer users from different fields and different level of computer expertise to evaluate the approach effectiveness. It features fast intelligent expertise classification and support network data understanding performance.},
keywords={artificial intelligence;computer network security;data mining;data visualisation;pattern classification;telecommunication traffic;intelligent expertise classification approach;innovative artificial intelligence approach;network data visualization;network traffic visualization;network data process;network data classification;data mining classification;Data visualization;Lead;Data mining;Visualization;artificial intelligence approach;intelligent expertise classification algorithm;network data visualization},
doi={10.1109/ICACTE.2010.5579790},
ISSN={2154-7505},
month={Aug},}
@INPROCEEDINGS{7982151,
author={C. {Subroto} and and and G. {Zhang}},
booktitle={2017 1st International Conference on Electrical Materials and Power Equipment (ICEMPE)},
title={Artificial intelligence for DGA interpretation methods using weighting factor},
year={2017},
volume={},
number={},
pages={85-88},
abstract={The accuracy of conventional DGA interpretation methods can be different when each of these methods are used in different places or different circumstances. Rogers Ratio Method (RRM), IEC Ratio Method (IRM) (Basic Gas Ratios Method), GB/T 7252 (National Standard of the People's Republic of China) are popular conventional methods for interpreting the possible faults indicator of transformer in Indonesia and China. This research proposes artificial intelligence to interpret DGA by combining conventional method and artificial intelligence method using weighting factor. The artificial intelligence method which are used in this research is fuzzy logic. DGA practical data which used as refer data for data mining in this research were taken from China and Indonesia. This research also uses Thompson tau method to filter the data from outlier and fuzzy c means clustering to cluster the data to make sure the data are used is valid and good enough to be used to build artificial intelligence through data mining. The output of this research is to create an artificial intelligence and the combination between artificial intelligence which have been built with conventional method to interpret DGA whether there is any fault in transformer or not.},
keywords={artificial intelligence;fuzzy logic;fuzzy set theory;power engineering computing;power transformers;artificial intelligence;DGA interpretation methods;weighting factor;Rogers ratio method;RRM;IEC Ratio Method;IRM;basic gas ratios method;transformer faults indicator;fuzzy logic;Thompson tau method;fuzzy c means clustering;data mining;Artificial intelligence;Fuzzy logic;Partial discharges;Data mining;Discharges (electric);Power transformer insulation;DGA;Fuzzy Logic;Weighting factor;Thompson tau method;Fuzzy C Means},
doi={10.1109/ICEMPE.2017.7982151},
ISSN={},
month={May},}
@ARTICLE{8399509,
author={X. {Zhang} and Y. {Sun} and K. {Jiang} and C. {Li} and L. {Jiao} and H. {Zhou}},
journal={IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing},
title={Spatial Sequential Recurrent Neural Network for Hyperspectral Image Classification},
year={2018},
volume={11},
number={11},
pages={4141-4155},
abstract={In hyperspectral image processing, classification is one of the most popular research topics. In recent years, research progress made in deep-learning-based hierarchical feature extraction and classification has shown a great power in many applications. In this paper, we propose a novel local spatial sequential (LSS) method, which is used in a recurrent neural network (RNN). Using this model, we can extract local and semantic information for hyperspectral image classification. First, we extract low-level features from hyperspectral images, including texture and differential morphological profiles. Second, we combine the low-level features together and propose a method to construct the LSS features. Afterwards, we build an RNN and use the LSS features as the input to train the network for optimizing the system parameters. Finally, the high-level semantic features generated by the RNN is fed into a softmax layer for the final classification. In addition, a nonlocal spatial sequential method is presented for the recurrent neural network model (NLSS-RNN) to further enhance the classification performance. NLSS-RNN finds nonlocal similar structures to a given pixel and extracts corresponding LSS features, which not only preserve the local spatial information, but also integrate the information of nonlocal similar samples. The experimental results on three publicly accessible datasets show that our proposed method can obtain competitive performance compared with several state-of-the-art classifiers.},
keywords={feature extraction;image classification;learning (artificial intelligence);recurrent neural nets;local spatial information;spatial sequential recurrent neural network;hyperspectral image classification;hyperspectral image processing;popular research topics;deep-learning-based hierarchical feature extraction;local spatial sequential method;local information;semantic information;low-level features;hyperspectral images;high-level semantic features;nonlocal spatial sequential method;recurrent neural network model;NLSS-RNN;LSS feature extraction;Feature extraction;Recurrent neural networks;Machine learning;Hyperspectral imaging;Computer architecture;Feedforward neural networks;Deep learning;high-level semantic feature;hyperspectral image (HSI) classification;low-level feature;recurrent neural network (RNN)},
doi={10.1109/JSTARS.2018.2844873},
ISSN={1939-1404},
month={Nov},}
@INPROCEEDINGS{413883,
author={A. {Miyauchi} and A. {Watanabe} and M. {Miyauchi}},
booktitle={Proceedings of 1st International Conference on Image Processing},
title={A method to interpret 3D motion using neural networks},
year={1994},
volume={3},
number={},
pages={83-87 vol.3},
abstract={This study proposes a 3D motion interpretation method which uses a neural network system consisting of three kinds of neural networks. This system estimates the solutions of 3D motion of an object by interpreting three optical flow (OF - motion vector field calculated from images) patterns of the same object obtained from three different view points. Though the interpretation system is trained using only basic 3D motions consisting of a single motion component, the system can interpret unknown multiple 3D motions consisting of several motion components. The generalization capacity of the proposed system is confirmed using diverse test patterns. Also the robustness of the system to noise is proved experimentally. The experimental results show that this method has suitable features for applying to real images.<<ETX>>},
keywords={motion estimation;image sequences;neural nets;learning (artificial intelligence);3D motion interpretation method;neural network system;optical flow normalisation network;motion components;test patterns;noise robustness;experimental results;real images;motion vector field;2D motion interpretation network;3D motion interpretation network;Neural networks;Cameras;Motion estimation;Noise robustness;Parameter estimation;Helium;Optical computing;Image motion analysis;System testing;Computer vision},
doi={10.1109/ICIP.1994.413883},
ISSN={},
month={Nov},}
@INPROCEEDINGS{777686,
author={B. {Klein} and A. {Abecker}},
booktitle={Proceedings IEEE Forum on Research and Technology Advances in Digital Libraries},
title={Distributed knowledge-based parsing for document analysis and understanding},
year={1999},
volume={},
number={},
pages={6-15},
abstract={Document Analysis and Understanding (DAU) is a complex AI application with high industrial impact. For the increasing demands upon the bandwidth and quality of the analysis it is crucial to enable different analysis modules to collaborate. For making collaboration possible, we first examine the question of whether there exists a common ontological basis which can serve as a platform for communication of different DAU modules. Once communication is enabled, we investigate the second question, how DAU modules originally designed as stand-alone systems must be modified in order to benefit from collaboration with others.},
keywords={document handling;knowledge based systems;grammars;groupware;distributed knowledge based parsing;document analysis and understanding;DAU;complex AI application;industrial impact;analysis modules;collaboration;common ontological basis;DAU modules;Text analysis;Information analysis;Data mining;Collaboration;Text recognition;SGML;Automata;Artificial intelligence;Bandwidth;Ontologies},
doi={10.1109/ADL.1999.777686},
ISSN={1092-9959},
month={May},}
@INPROCEEDINGS{8538416,
author={S. A. {Fahad} and A. E. {Yahya}},
booktitle={2018 International Conference on Smart Computing and Electronic Enterprise (ICSCEE)},
title={Inflectional Review of Deep Learning on Natural Language Processing},
year={2018},
volume={},
number={},
pages={1-4},
abstract={In the age of knowledge, Natural Language Processing (NLP) express its demand by a huge range of utilization. Previously NLP was dealing with statically data. Contemporary time NLP is doing considerably with the corpus, lexicon database, pattern reorganization. Considering Deep Learning (DL) method recognize artificial Neural Network (NN) to nonlinear process, NLP tools become increasingly accurate and efficient that begin a debacle. Multi-Layer Neural Network obtaining the importance of the NLP for its capability including standard speed and resolute output. Hierarchical designs of data operate recurring processing layers to learn and with this arrangement of DL methods manage several practices. In this paper, this resumed striving to reach a review of the tools and the necessary methodology to present a clear understanding of the association of NLP and DL for truly understand in the training. Efficiency and execution both are improved in NLP by Part of speech tagging (POST), Morphological Analysis, Named Entity Recognition (NER), Semantic Role Labeling (SRL), Syntactic Parsing, and Coreference resolution. Artificial Neural Networks (ANN), Time Delay Neural Networks (TDNN), Recurrent Neural Network (RNN), Convolution Neural Networks (CNN), and Long-Short-Term-Memory (LSTM) dealings among Dense Vector (DV), Windows Approach (WA), and Multitask learning (MTL) as a characteristic of Deep Learning. After statically methods, when DL communicate the influence of NLP, the individual form of the NLP process and DL rule collaboration was started a fundamental connection.},
keywords={learning (artificial intelligence);natural language processing;recurrent neural nets;text analysis;natural language processing;contemporary time NLP;Considering Deep;(DL) method;artificial Neural Network;nonlinear process;NLP tools;MultiLayer Neural Network;processing layers;DL methods;Artificial Neural Networks;Time Delay Neural Networks;Recurrent Neural Network;Convolution Neural Networks;deep learning;NLP process;Natural language processing;Artificial neural networks;Tagging;Semantics;Task analysis;-Deep Learning;Natural language processing;Deep nural Network;Multitask Learning},
doi={10.1109/ICSCEE.2018.8538416},
ISSN={},
month={July},}
@INPROCEEDINGS{7333799,
author={L. {Chen} and S. {Wang} and W. {Fan} and J. {Sun} and N. {Satoshi}},
booktitle={2015 13th International Conference on Document Analysis and Recognition (ICDAR)},
title={Deep learning based language and orientation recognition in document analysis},
year={2015},
volume={},
number={},
pages={436-440},
abstract={In practical applications of document understanding, if the documents have multiple languages and orientations, the conventional OCR systems can not be directly applied. This is because those OCR systems are usually designed for texts of single language and normal orientation. To solve this problem, many non-character based recognition approaches were proposed. However, the performance of those methods were not comparable with the mature OCR systems. Consequently, a better idea is to recognize the language type and orientation before the OCR is applied. Besides, the characters of different languages have very ambiguous shape, so it is very difficult to extract stable feature for the recognition. Recently, the convolutional neural networks (CNN) have achieved great success in pattern recognition tasks. Therefore, for such difficult tasks, the CNN is one of the best choice. In this paper, we first applied CNN to the recognition of the document properties. A novel sliding window voting process is proposed to reduce the network scale and fully use the information of the text line. In the experiments, our method had very high recognition rate. The results proved the advantage of the proposed method and which also can be applied to create a document understanding system with OCR systems.},
keywords={document image processing;image recognition;neural nets;text detection;deep learning;orientation recognition;language recognition;document analysis;convolutional neural networks;CNN;document properties recognition;sliding window voting process;text line information;recognition rate;document understanding system;Kernel;Optical character recognition software},
doi={10.1109/ICDAR.2015.7333799},
ISSN={},
month={Aug},}
@ARTICLE{8440085,
author={Y. {Ming} and H. {Qu} and E. {Bertini}},
journal={IEEE Transactions on Visualization and Computer Graphics},
title={RuleMatrix: Visualizing and Understanding Classifiers with Rules},
year={2019},
volume={25},
number={1},
pages={342-352},
abstract={With the growing adoption of machine learning techniques, there is a surge of research interest towards making machine learning systems more transparent and interpretable. Various visualizations have been developed to help model developers understand, diagnose, and refine machine learning models. However, a large number of potential but neglected users are the domain experts with little knowledge of machine learning but are expected to work with machine learning systems. In this paper, we present an interactive visualization technique to help users with little expertise in machine learning to understand, explore and validate predictive models. By viewing the model as a black box, we extract a standardized rule-based knowledge representation from its input-output behavior. Then, we design RuleMatrix, a matrix-based visualization of rules to help users navigate and verify the rules and the black-box model. We evaluate the effectiveness of RuleMatrix via two use cases and a usability study.},
keywords={data visualisation;interactive systems;knowledge representation;learning (artificial intelligence);matrix algebra;pattern classification;rule matrix;black-box model;matrix-based visualization;standardized rule-based knowledge representation;predictive models;interactive visualization technique;machine learning systems;Machine learning;Data visualization;Visualization;Neural networks;Decision trees;Data models;Support vector machines;explainable machine learning;rule visualization;visual analytics},
doi={10.1109/TVCG.2018.2864812},
ISSN={1077-2626},
month={Jan},}
@ARTICLE{8653995,
author={X. {Cui} and D. {Wang} and Z. J. {Wang}},
journal={IEEE Transactions on Multimedia},
title={Multi-scale Interpretation Model for Convolutional Neural Networks: Building Trust based on Hierarchical Interpretation},
year={2019},
volume={},
number={},
pages={1-1},
abstract={With the rapid development of deep learning models, their performances in various tasks are improved, while meanwhile their increasingly intricate architectures make them difficult to interpret. To tackle this challenge, model interpretability is essential and has been investigated in a wide range of applications. For end users, model interpretability can be used to build trust in the deployed machine learning models. For practitioners, interpretability plays a critical role in model explanation, model validation, and model improvement to develop a faithful model. In the paper, we propose a novel Multi-scale INTerpretation (MINT) model for convolutional neural networks using both the perturbation-based and the gradient-based interpretation approaches. It learns the class-discriminative interpretable knowledge from the multi-scale perturbation of feature information in different layers of deep networks. The proposed MINT model provides the coarse-scale and the fine-scale interpretations for the attention in the deep layer and specific features in the shallow layer, respectively. Experimental results show that the MINT model presents the class-discriminative interpretation of the network decision and explains the significance of the hierarchical network structure.},
keywords={Visualization;Computational modeling;Analytical models;Feature extraction;Perturbation methods;Image segmentation;Heating systems;Model interpretability;multi-scale interpretation;convolutional neural networks;model-agnostic},
doi={10.1109/TMM.2019.2902099},
ISSN={1520-9210},
month={},}
@ARTICLE{6634123,
author={L. {Gosink} and K. {Bensema} and T. {Pulsipher} and H. {Obermaier} and M. {Henry} and H. {Childs} and K. I. {Joy}},
journal={IEEE Transactions on Visualization and Computer Graphics},
title={Characterizing and Visualizing Predictive Uncertainty in Numerical Ensembles Through Bayesian Model Averaging},
year={2013},
volume={19},
number={12},
pages={2703-2712},
abstract={Numerical ensemble forecasting is a powerful tool that drives many risk analysis efforts and decision making tasks. These ensembles are composed of individual simulations that each uniquely model a possible outcome for a common event of interest: e.g., the direction and force of a hurricane, or the path of travel and mortality rate of a pandemic. This paper presents a new visual strategy to help quantify and characterize a numerical ensemble's predictive uncertainty: i.e., the ability for ensemble constituents to accurately and consistently predict an event of interest based on ground truth observations. Our strategy employs a Bayesian framework to first construct a statistical aggregate from the ensemble. We extend the information obtained from the aggregate with a visualization strategy that characterizes predictive uncertainty at two levels: at a global level, which assesses the ensemble as a whole, as well as a local level, which examines each of the ensemble's constituents. Through this approach, modelers are able to better assess the predictive strengths and weaknesses of the ensemble as a whole, as well as individual models. We apply our method to two datasets to demonstrate its broad applicability.},
keywords={Bayes methods;data visualisation;learning (artificial intelligence);statistical analysis;uncertainty handling;predictive uncertainty characterization;predictive uncertainty visualization;numerical ensemble forecasting;Bayesian model averaging framework;visual strategy;ensemble constituents;event-of-interest prediction;ground truth observations;statistical aggregate;visualization strategy;Bayes methods;Mathematical model;Predictive models;Numerical models;Data visualization;Bayes methods;Mathematical model;Predictive models;Numerical models;Data visualization;statistical visualization;Uncertainty visualization;numerical ensembles;Algorithms;Bayes Theorem;Computer Graphics;Computer Simulation;Data Interpretation, Statistical;Models, Statistical;Pattern Recognition, Automated;Reproducibility of Results;Sensitivity and Specificity;User-Computer Interface},
doi={10.1109/TVCG.2013.138},
ISSN={1077-2626},
month={Dec},}
@INPROCEEDINGS{598997,
author={G. S. D. {Farrow} and C. S. {Xydeas} and J. P. {Oakley}},
booktitle={Proceedings of 3rd International Conference on Document Analysis and Recognition},
title={Model matching in intelligent document understanding},
year={1995},
volume={1},
number={},
pages={293-296 vol.1},
abstract={Intelligent Document Understanding (IDU) is the process of converting scanned document pages into an electronic, processable form. We have previously presented a IDU system architecture suitable for this task which uses a hybrid bottom-up/top-down control strategy. In this paper we focus on a specific subproblem that arises within the chosen framework, concerned with selecting an appropriate page layout structure. A detailed analysis of the problem using an error propagation model, allows computationally simple search strategies to be developed. A multistage layout formation algorithm is proposed and its performance is critically assessed when implemented using two different Layout Object selection criterion. The first selection criterion is based on a maximal column area coverage; the second is based on a probabilistic Layout Object selection. Both techniques have been incorporated into the hybrid IDU system and the results presented indicate its superiority over previously reported systems.},
keywords={document image processing;optical character recognition;search problems;intelligent document understanding;model matching;hybrid bottom-up/top-down control strategy;appropriate page layout structure;error propagation model;computationally simple search strategies;maximal column area coverage;probabilistic layout object selection;Control systems;Computer vision;Computer architecture;Performance analysis;Process control;Image databases;Object detection;Computational modeling;Intelligent structures;Degradation},
doi={10.1109/ICDAR.1995.598997},
ISSN={},
month={Aug},}
@INPROCEEDINGS{8614130,
author={S. {Ghanta} and S. {Subramanian} and S. {Sundararaman} and L. {Khermosh} and V. {Sridhar} and D. {Arteaga} and Q. {Luo} and D. {Das} and N. {Talagala}},
booktitle={2018 17th IEEE International Conference on Machine Learning and Applications (ICMLA)},
title={Interpretability and Reproducability in Production Machine Learning Applications},
year={2018},
volume={},
number={},
pages={658-664},
abstract={Explainability/Interpretability in machine learning applications is becoming critical, with legal and industry requirements demanding human understandable machine learning results. We describe the additional complexities that occur when a known interpretability technique (canary models) is applied to a real production scenario. We furthermore argue that reproducibility is a key feature in practical usages of such interpretability techniques in production scenarios. With this motivation, we present a production ML reproducibility solution, namely a comprehensive time ordered event sequence for machine learning applications. We demonstrate how our approach can bring this known common interpretability technique into production viability. We further present the system design and early performance characteristics of our reproducibility solution.},
keywords={learning (artificial intelligence);production engineering computing;production scenario;interpretability techniques;production ML reproducibility solution;production viability;reproducability;production machine learning applications;legal industry requirements;human understandable machine learning;Production;Pipelines;Predictive models;Machine learning;Training;Data models;Load modeling;reproducability;explainability;interpretability;systems;tracking},
doi={10.1109/ICMLA.2018.00105},
ISSN={},
month={Dec},}
@INPROCEEDINGS{5212590,
author={ and M. {Liao} and and and and and },
booktitle={2009 International Conference on Machine Learning and Cybernetics},
title={Constructing financial distress prediction model using group method of data handling technique},
year={2009},
volume={5},
number={},
pages={2897-2902},
abstract={Companies in financial distress make the creditors, shareholders, employees, investors and other participants of the related firms suffer great losses. In order to prevent the companies run into bankruptcy, financial distress prediction has been a useful tool for distinguishing companies in financial distress from those healthy. Statistical methods and artificial intelligence techniques have been widely used to deal with this issue. Many studies indicated that artificial neural networks outperform many statistical methods. However, artificial neural networks have the drawback of failing to interpret the classification results. This paper uses an artificial intelligence technique-group method of data handling technique to overcome this drawback. The sample data are collected from Taiwan listed companies in the Taiwan Stock Exchange Corporation. The result illustrates that the accuracy rates of classification of group method of data handling models are larger than 90% and the models of the group method of data handling obtain better accuracy than the models of discriminant analysis and logistic regression.},
keywords={data handling;financial data processing;investment;neural nets;pattern classification;statistical analysis;stock markets;financial distress prediction model;group method;data handling technique;creditor;investor;statistical method;artificial intelligence technique;artificial neural network;Taiwan stock exchange corporation;data classification;Predictive models;Data handling;Artificial neural networks;Logistics;Companies;Statistical analysis;Artificial intelligence;Investments;Neural networks;Machine learning;Financial distress prediction;Group method of data handling;Artificial neural network},
doi={10.1109/ICMLC.2009.5212590},
ISSN={2160-133X},
month={July},}
@INPROCEEDINGS{7193210,
author={P. M. {Manwatkar} and S. H. {Yadav}},
booktitle={2015 International Conference on Innovations in Information, Embedded and Communication Systems (ICIIECS)},
title={Text recognition from images},
year={2015},
volume={},
number={},
pages={1-6},
abstract={Text recognition in images is a research area which attempts to develop a computer system with the ability to automatically read the text from images. These days there is a huge demand in storing the information available in paper documents format in to a computer storage disk and then later reusing this information by searching process. One simple way to store information from these paper documents in to computer system is to first scan the documents and then store them as images. But to reuse this information it is very difficult to read the individual contents and searching the contents form these documents line-by-line and word-by-word. The challenges involved in this the font characteristics of the characters in paper documents and quality of images. Due to these challenges, computer is unable to recognize the characters while reading them. Thus there is a need of character recognition mechanisms to perform Document Image Analysis (DIA) which transforms documents in paper format to electronic format. In this paper we have discuss method for text recognition from images. The objective of this paper is to recognition of text from image for better understanding of the reader by using particular sequence of different processing module.},
keywords={character recognition;document image processing;image resolution;image texture;text detection;image text recognition;computer storage disk;computer system;image quality;character recognition;document image analysis;DIA;Text recognition;Biological neural networks;Computers;Image segmentation;Character recognition;Neurons;Feature extraction;Document Image Analysis (DIA);electronic format;text recognition;font characteristics},
doi={10.1109/ICIIECS.2015.7193210},
ISSN={},
month={March},}
@INPROCEEDINGS{6991412,
author={P. {Thitisathienkul} and N. {Prompoon}},
booktitle={Ninth International Conference on Digital Information Management (ICDIM 2014)},
title={Quality assessment method for software development process document based on software document characteristics metric},
year={2014},
volume={},
number={},
pages={182-188},
abstract={To deliver the software product which conforms to customer's actual needs has become an important issue of software development companies. The appropriate Software Development Life Cycle (SDLC) which is the process consists of a sequence of activities performed for developing that software product is selected. During those activities, there are various information related to software product development and are used to communicate among parties involved. This information is often specified in SDLC documents using natural language. Unfortunately, the problems of interpretation and difficulty of understanding are arisen and often caused by characteristic of natural language itself, which is ambiguous, and the inappropriateness of document structure. These problems which are some of the interested open questions in software requirements specifications area may influence on software product discrepancy from customer's actual needs. To mitigate these problems, this paper proposes a method for assessing quality of SDLC documents characteristics focusing on document contents and structure. The measurement process model is used as a guideline for proposing the method and the measurement information model is applied to define metrics which are used to assess SDLC documents characteristics directly. A Software Requirements Specifications (SRS) document was used to illustrate our proposed method as a case study. The result of the proposed method can be used to indicate the quality level of SDLC documents and appeared flaws, which leads to the improvement of SDLC document quality. The improved SDLC documents can enhance the quality of communication among stakeholders and support the software product development to meet customer's actual needs. These results can also be stored as a lesson learned and be applied for the future similar situation.},
keywords={document handling;formal specification;software metrics;software product lines;software quality;quality assessment method;software development process document;software document characteristics metric;software product deliver;customer needs;software development companies;software development life cycle;software product development;SDLC documents;natural language characteristic;document structure;software requirement specifications;software product discrepancy;document contents;document structure;measurement process model;measurement information model;SDLC document characteristics assessment;software requirement specification document;SRS document;SDLC document quality level;communication quality enhancement;Software;Natural languages;Databases;Quality assessment;Software measurement;Standards;Quality Assessment Method;Software Metric;SDLC Document;Characteristics;Document Structure},
doi={10.1109/ICDIM.2014.6991412},
ISSN={},
month={Sep.},}
@INPROCEEDINGS{8621470,
author={S. {Starikov} and E. {Khrameeva} and M. {Gelfand}},
booktitle={2018 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)},
title={Prediction of chromatin spatial structure characteristics using machine learning methods},
year={2018},
volume={},
number={},
pages={2489-2489},
abstract={Development of chromosome conformation capture methods boosted progress in the study of the spatial organization of chromatin. Accumulation of large amounts of experimental data provides an opportunity to apply machine learning methods to examine the connection between epigenetics and the three-dimensional structure of chromatin. The aim of this study was to predict the characteristics of the chromatin structure, namely the transitional gamma, from ChIP-Seq experimental data by means of machine learning methods, and also to reveal the properties of epigenetic data influencing prediction. The neural network and the loss function designed for the prediction task are shown to perform with a sufficiently high accuracy. In addition, the genomic size of the chromatin context required for improving the quality of the prediction was assessed. Several neural network visualization techniques were tested as a means for improving interpretability of network, showing the possibility for using visualization to study interrelations in epigenetic data relevant for three-dimensional chromatin structure. To sum up, a close relationship between epigenetic factors and the structure of chromatin has been confirmed.},
keywords={biology computing;data visualisation;genetics;genomics;learning (artificial intelligence);neural nets;chromosome conformation capture methods;ChIP-Seq experimental data;machine learning methods;epigenetic data influencing prediction;neural network visualization techniques;three-dimensional chromatin structure;chromatin spatial structure characteristics;Machine learning;Bioinformatics;Neural networks;Data visualization;Conferences;Biomedical engineering;Life sciences;Hi-C;machine learning;neural networks;ChIP-Seq},
doi={10.1109/BIBM.2018.8621470},
ISSN={},
month={Dec},}
@ARTICLE{750572,
author={M. M. {Kantardzic} and A. A. {Aly} and A. S. {Elmaghraby}},
journal={IEEE Transactions on Neural Networks},
title={Visualization of neural-network gaps based on error analysis},
year={1999},
volume={10},
number={2},
pages={419-426},
abstract={Presents a methodology for detection of neural-network gaps (NNGs) based on error analysis and the visualization that is applicable to the n-dimensional I/O domain. The generalization problem in artificial neural networks (ANN) training is analyzed and the concept of NNGs is introduced. The NNGs are highly undesirable in ANN generalization and methods for detecting, analyzing, and eliminating them are necessary. Previous methods for NNG detection, based on two-dimensional (2-D) and three dimensional (3-D) visualization, were not applicable for ANNs with more than three inputs. Experiments demonstrate advantages of this new methodology, which allows better understanding of the NNG phenomena using a quantitative approach.},
keywords={neural nets;generalisation (artificial intelligence);learning (artificial intelligence);error analysis;neural-network gaps;error analysis;visualization;n-dimensional I/O domain;generalization problem;quantitative approach;Visualization;Error analysis;Artificial neural networks;Testing;Neural networks;Two dimensional displays;Particle measurements;Computer networks;Performance evaluation;Supervised learning},
doi={10.1109/72.750572},
ISSN={1045-9227},
month={March},}
@INPROCEEDINGS{7846312,
author={T. {Ushio} and H. {Shi} and M. {Endo} and K. {Yamagami} and N. {Horii}},
booktitle={2016 IEEE Spoken Language Technology Workshop (SLT)},
title={Recurrent convolutional neural networks for structured speech act tagging},
year={2016},
volume={},
number={},
pages={518-524},
abstract={Spoken language understanding (SLU) is one of the important problem in natural language processing, and especially in dialog system. Fifth Dialog State Tracking Challenge (DSTC5) introduced a SLU challenge task, which is automatic tagging to speech utterances by two speaker roles with speech acts tag and semantic slots tag. In this paper, we focus on speech acts tagging. We propose local coactivate multi-task learning model for capturing structured speech acts, based on sentence features by recurrent convolutional neural networks. An experiment result, shows that our model outperformed all other submitted entries, and were able to capture coactivated local features of category and attribute, which are parts of speech act.},
keywords={feedforward neural nets;learning (artificial intelligence);natural language processing;pattern classification;recurrent neural nets;speech processing;text analysis;attribute feature;category feature;sentence feature;local coactivate multitask learning model;semantic-slot tag;speech-act tag;speech utterances;automatic tagging;SLU challenge task;DSTC5;Fifth-Dialog State Tracking Challenge;dialog system;natural language processing;spoken language understanding;structured speech act tagging;recurrent convolutional neural networks;Speech;Tagging;Neural networks;Hidden Markov models;Training;Text categorization;Neurons;spoken language understanding;speech act tagging;text classification;multi-task learning;neural networks},
doi={10.1109/SLT.2016.7846312},
ISSN={},
month={Dec},}
@INPROCEEDINGS{8215791,
author={T. {Ito} and H. {Sakaji} and K. {Izumi} and K. {Tsubouchi} and T. {Yamashita}},
booktitle={2017 IEEE International Conference on Data Mining Workshops (ICDMW)},
title={Development of an Interpretable Neural Network Model for Creation of Polarity Concept Dictionaries},
year={2017},
volume={},
number={},
pages={1122-1131},
abstract={Automatic creation of polarity dictionaries is an important issue, as explanations of prediction models are often required in the financial industry. This paper proposes a novel method of developing an interpretable and predictable neural network model. The neural network model we built can extract polarity scores of concepts from documents. Furthermore, we can detect pairwise interactions between concepts, and create polarity concept dictionaries using our neural network model. The model was built using vector representations of words and polarity scores for about 100 words provided by financial professionals, and we obtained about a hundred times more polarity scores for unknown words through backpropagation. First, we analyze the properties of our method from a theoretical point of view. We then confirm its capabilities by conducting simulations of assigning polarity scores to unknown words and detecting interactions using artificial data. We subsequently estimate sentiment tags using real financial textual datasets. Compared with other conventional methods, the proposed approach can forecast sentiments with higher F1 scores. Finally, we develop a polarity concept dictionary based on Yahoo! Finance board textual data.},
keywords={backpropagation;data mining;dictionaries;financial data processing;natural language processing;neural nets;text analysis;interpretable neural network model;polarity concept dictionaries;automatic creation;polarity dictionaries;prediction models;interpretable network model;predictable neural network model;polarity scores;unknown words;detecting interactions;financial industry;vector representations;Yahoo! Finance board textual data;Dictionaries;Artificial neural networks;Predictive models;Data mining;Industries;Analytical models;Neural Network Model;Text-mining;Sentiment analysis},
doi={10.1109/ICDMW.2017.159},
ISSN={2375-9259},
month={Nov},}
@INPROCEEDINGS{8256457,
author={R. {Khummongkol} and M. {Yokota}},
booktitle={2017 IEEE 8th International Conference on Awareness Science and Technology (iCAST)},
title={An approach to mental image based understanding of natural language: Focused on static and dynamic spatial relations},
year={2017},
volume={},
number={},
pages={254-259},
abstract={It must be rather difficult for ordinary people to communicate with robots using special technical languages. Therefore, it must be more desirable for them to use natural language (NL) for such a purpose because it is the most conventional among them. This work proposes a methodology for natural language understanding through an AI system named Conversation Management System (CMS) based on Mental Image Directed Semantic Theory proposed by M. Yokota. CMS is intended to enable a robot to understand NL in the same way as people do, and actually can reach the most plausible semantic interpretation of an input text and return desirable outcomes by employing word concepts, postulates, and inference rules. Recently, the authors have applied several spatial terms in English language, for example verbs, prepositions (e.g. between, along, left, right, and so on). We found that the methodology is outstanding from conventional approaches with the attempt to provide robots understand NL based on mental image model. This paper focuses on how CMS understands static spatial (3D) relations expressed in NL.},
keywords={artificial intelligence;human-robot interaction;natural language processing;mental image based understanding;static relations;dynamic spatial relations;special technical languages;NL;natural language understanding;AI system;Conversation Management System;CMS;Mental Image Directed Semantic Theory;spatial terms;English language;mental image model;robot communication;semantic interpretation;static spatial 3D relations;Robots;Semantics;Natural languages;Rivers;Conferences;Artificial intelligence;Cognition;natural language understanding;human — robot interaction;semantic interpretation},
doi={10.1109/ICAwST.2017.8256457},
ISSN={2325-5994},
month={Nov},}
@ARTICLE{8432512,
author={X. {Zhang} and Y. {Sun} and J. {Zhang} and P. {Wu} and L. {Jiao}},
journal={IEEE Geoscience and Remote Sensing Letters},
title={Hyperspectral Unmixing via Deep Convolutional Neural Networks},
year={2018},
volume={15},
number={11},
pages={1755-1759},
abstract={Hyperspectral unmixing (HU) is a method used to estimate the fractional abundances corresponding to endmembers in each of the mixed pixels in the hyperspectral remote sensing image. In recent times, deep learning has been recognized as an effective technique for hyperspectral image classification. In this letter, an end-to-end HU method is proposed based on the convolutional neural network (CNN). The proposed method uses a CNN architecture that consists of two stages: the first stage extracts features and the second stage performs the mapping from the extracted features to obtain the abundance percentages. Furthermore, a pixel-based CNN and cube-based CNN, which can improve the accuracy of HU, are presented in this letter. More importantly, we also use dropout to avoid overfitting. The evaluation of the complete performance is carried out on two hyperspectral data sets: Jasper Ridge and Urban. Compared with that of the existing method, our results show significantly higher accuracy.},
keywords={feature extraction;hyperspectral imaging;image classification;learning (artificial intelligence);recurrent neural nets;hyperspectral unmixing;deep convolutional neural networks;hyperspectral remote sensing image;deep learning;hyperspectral image classification;end-to-end HU method;convolutional neural network;CNN architecture;pixel-based CNN;hyperspectral data sets;Jasper Ridge dataset;Urban dataset;Feature extraction;Hyperspectral imaging;Convolution;Artificial neural networks;Indexes;Kernel;Convolutional neural networks (CNNs);end-to-end model;spectral unmixing;spectral–spatial information},
doi={10.1109/LGRS.2018.2857804},
ISSN={1545-598X},
month={Nov},}
@ARTICLE{7552539,
author={W. {Samek} and A. {Binder} and G. {Montavon} and S. {Lapuschkin} and K. {Müller}},
journal={IEEE Transactions on Neural Networks and Learning Systems},
title={Evaluating the Visualization of What a Deep Neural Network Has Learned},
year={2017},
volume={28},
number={11},
pages={2660-2673},
abstract={Deep neural networks (DNNs) have demonstrated impressive performance in complex machine learning tasks such as image classification or speech recognition. However, due to their multilayer nonlinear structure, they are not transparent, i.e., it is hard to grasp what makes them arrive at a particular classification or recognition decision, given a new unseen data sample. Recently, several approaches have been proposed enabling one to understand and interpret the reasoning embodied in a DNN for a single test image. These methods quantify the “importance” of individual pixels with respect to the classification decision and allow a visualization in terms of a heatmap in pixel/input space. While the usefulness of heatmaps can be judged subjectively by a human, an objective quality measure is missing. In this paper, we present a general methodology based on region perturbation for evaluating ordered collections of pixels such as heatmaps. We compare heatmaps computed by three different methods on the SUN397, ILSVRC2012, and MIT Places data sets. Our main result is that the recently proposed layer-wise relevance propagation algorithm qualitatively and quantitatively provides a better explanation of what made a DNN arrive at a particular classification decision than the sensitivity-based approach or the deconvolution method. We provide theoretical arguments to explain this result and discuss its practical implications. Finally, we investigate the use of heatmaps for unsupervised assessment of the neural network performance.},
keywords={data visualisation;image classification;learning (artificial intelligence);neural nets;sensitivity-based approach;deconvolution method;heatmap;deep neural network;complex machine learning tasks;multilayer nonlinear structure;DNN;MIT Places data sets;SUN397;ILSVRC2012;relevance propagation algorithm;data visualization;Heating;Neurons;Biological neural networks;Deconvolution;Sensitivity;Learning systems;Algorithm design and analysis;Convolutional neural networks;explaining classification;image classification;interpretable machine learning;relevance models},
doi={10.1109/TNNLS.2016.2599820},
ISSN={2162-237X},
month={Nov},}
@INPROCEEDINGS{791799,
author={C. {Cracknell} and A. C. {Downton}},
booktitle={Proceedings of the Fifth International Conference on Document Analysis and Recognition. ICDAR '99 (Cat. No.PR00318)},
title={A Handwriting Understanding Environment (HUE) for rapid prototyping in handwriting and document analysis research},
year={1999},
volume={},
number={},
pages={362-365},
abstract={HUE (the Handwriting Understanding Environment) is a software framework for handwriting and document analysis built around a two-level programming model in which components are implemented in a system programming language (typically C++) and are connected together into prototype systems using the scripting language Tcl Tk. HUE is an extended version of TABS (a previous handwriting analysis framework), and incorporates the authors' experience of using TABS for around 2 years in data-intensive handwriting and document analysis research and evaluation. HUE currently contains 94 C++ components, 7 native data types, 11 custom-built Tcl Tk packages, a novel dynamic user interface, and several demonstration systems implemented as Tcl scripts.},
keywords={document image processing;object-oriented programming;handwritten character recognition;user interfaces;software prototyping;Handwriting Understanding Environment;rapid prototyping;document analysis;handwriting analysis;software framework;two-level programming model;system programming language;Tcl Tk scripting language;TABS;C++ components;native data types;custom-built Tcl Tk packages;dynamic user interface;demonstration systems;Prototypes;Computer languages;Text analysis;Handwriting recognition;Image processing;Computer vision;Libraries;Programming profession;Design engineering;Systems engineering and theory},
doi={10.1109/ICDAR.1999.791799},
ISSN={},
month={Sep.},}
@INPROCEEDINGS{6154802,
author={M. K. {Dalal} and M. A. {Zaveri}},
booktitle={2012 Computing, Communications and Applications Conference},
title={Automatic Text Classification of sports blog data},
year={2012},
volume={},
number={},
pages={219-222},
abstract={Automatic Text Classification is a semi-supervised machine learning task that automatically assigns a given text document to a set of pre-defined categories based on the features extracted from its textual content. This paper attempts to automatically classify the textual entries made by bloggers on various sports blogs, to the appropriate category of sport by following steps like pre-processing, feature extraction and naïve Bayesian classification. Empirical evaluation of this technique has resulted in a classification accuracy of approximately 87% over the test set. In addition to classifying the textual entries of sports blogs, it is proposed that the extracted features themselves be further classified under more meaningful heads which results in generation of a semantic resource that lends greater understanding to the classification task. This semantic resource can be used for data mining requirements that arise in the future.},
keywords={Bayes methods;data mining;feature extraction;learning (artificial intelligence);pattern classification;semantic Web;sport;text analysis;Web sites;automatic text classification;sports blog data;semi-supervised machine learning task;text document;feature extraction;naïve Bayesian classification;semantic resource;data mining requirements;Blogs;Feature extraction;Text categorization;Bayesian methods;Training;Semantics;Accuracy;automatic text classification;feature extraction;heuristics;intelligent data mining;machine learning;naïve Bayes classification},
doi={10.1109/ComComAp.2012.6154802},
ISSN={},
month={Jan},}
@INPROCEEDINGS{8614007,
author={H. {Yanagimto} and K. {Hashimoto} and M. {Okada}},
booktitle={2018 International Conference on Machine Learning and Data Engineering (iCMLDE)},
title={Attention Visualization of Gated Convolutional Neural Networks with Self Attention in Sentiment Analysis},
year={2018},
volume={},
number={},
pages={77-82},
abstract={Deep learning is applied to many research topics; Natural Language Processing, Image Processing, and Acoustic Recognition. In deep learning, neural networks have a very complex and deep structure and it is difficult to discuss why they work well or not. So you have to take a trial-and-error to improve their performances. We develop a mechanism to show how neural networks predict final results and help you to design a new neural network architecture based on its prediction criteria. Speaking concrete, we visualize important features to predict the final results with an attentional mechanism. In this paper, we take up sentient analysis, which is one of natural language processing tasks. In image processing visualizing weights of a neural network is a major approach and you can obtain intuitive results; object outlines and object components. However, in natural language processing, the approach is not interpretable because a discriminate function constructed by a neural network is a complex and nonlinear one and it is very difficult to correlate weights and words in a text. We employ Gated Convolutional Neural Network (GCNN) and introduce a self-attention mechanism to understand how GCNN determines sentiment polarities from raw reviews. GCNN can simulate an n-gram model and the self-attention mechanism can make correspondence between weights of a neural network and words clear. In experiments, we used Amazon reviews and evaluated the performance of the proposed method. Especially, the proposed method was able to emphasize some words in the review to determine sentiment polarity. Moreover, when the prediction was wrong, we were able to understand why the proposed method made mistakes because we found what words the proposed method emphasized.},
keywords={convolutional neural nets;learning (artificial intelligence);neural net architecture;sentiment analysis;neural network architecture;self-attention mechanism;Amazon reviews;GCNN;sentient analysis;attention visualization;natural language processing;gated convolutional neural networks;deep learning;Logic gates;Convolutional neural networks;Kernel;Sentiment analysis;Task analysis;Deep learning;Natural language processing;Gated CNN;Sentiment analysis;the self-attention mechanism},
doi={10.1109/iCMLDE.2018.00024},
ISSN={},
month={Dec},}
@INPROCEEDINGS{8332874,
author={T. {Shancheng} and B. {Yunyue} and M. {Fuyu}},
booktitle={2018 International Conference on Intelligent Transportation, Big Data Smart City (ICITBS)},
title={A Semantic Text Similarity Model for Double Short Chinese Sequences},
year={2018},
volume={},
number={},
pages={736-739},
abstract={Semantic Text Similarity plays a major role in natural language processing. In recent years, researchers have paid considerable attention to Semantic Text Similarity. Some breakthroughs have been made in English, but there are two disadvantages when these models are applied to Chinese: Single sequence models don't consider semantic ambiguity such as polysemy, synonym; these models don't consider that Chinese stop words are important for Chinese word segmentation, voice analysis, semantic understanding. Firstly, in order to overcome the first problem, we proposed the double short text sequences model that has two identical LSTM (Long Short-Term Memory) processing two text sequences at the same time. Secondly, in order to overcome the second problem, according to the characteristics of Chinese, we used the Chinese semantic similarity data sets designed by experts to train and test the model, and retained the stop words in the model training process. Finally, the proposed model was compared with the Semantic Text Similarity model based on CNN (Convolution Neural Network) and the Baidu Semantic Text Similarity model. The results show that the model is greater than the previous two in terms of accuracy, recall rate and so on, and the generalization ability is improved also.},
keywords={feedforward neural nets;learning (artificial intelligence);natural language processing;text analysis;natural language processing;semantic ambiguity;Chinese stop words;Chinese word segmentation;semantic understanding;double short text sequences model;Long Short-Term Memory;Chinese semantic similarity data sets;single sequence models;double short Chinese sequences;Baidu semantic text similarity model;CNN;convolution neural network;Semantics;Training;Computational modeling;Data models;Analytical models;Training data;Encyclopedias;Semantic similarity;Chinese short text;double sequence;deep learning},
doi={10.1109/ICITBS.2018.00190},
ISSN={},
month={Jan},}
@ARTICLE{6634108,
author={T. {Isenberg} and P. {Isenberg} and J. {Chen} and M. {Sedlmair} and T. {Möller}},
journal={IEEE Transactions on Visualization and Computer Graphics},
title={A Systematic Review on the Practice of Evaluating Visualization},
year={2013},
volume={19},
number={12},
pages={2818-2827},
abstract={We present an assessment of the state and historic development of evaluation practices as reported in papers published at the IEEE Visualization conference. Our goal is to reflect on a meta-level about evaluation in our community through a systematic understanding of the characteristics and goals of presented evaluations. For this purpose we conducted a systematic review of ten years of evaluations in the published papers using and extending a coding scheme previously established by Lam et al. [2012]. The results of our review include an overview of the most common evaluation goals in the community, how they evolved over time, and how they contrast or align to those of the IEEE Information Visualization conference. In particular, we found that evaluations specific to assessing resulting images and algorithm performance are the most prevalent (with consistently 80-90% of all papers since 1997). However, especially over the last six years there is a steady increase in evaluation methods that include participants, either by evaluating their performances and subjective feedback or by evaluating their work practices and their improved analysis and reasoning capabilities using visual tools. Up to 2010, this trend in the IEEE Visualization conference was much more pronounced than in the IEEE Information Visualization conference which only showed an increasing percentage of evaluation through user performance and experience testing. Since 2011, however, also papers in IEEE Information Visualization show such an increase of evaluations of work practices and analysis as well as reasoning using visual tools. Further, we found that generally the studies reporting requirements analyses and domain-specific work practices are too informally reported which hinders cross-comparison and lowers external validity.},
keywords={data visualisation;encoding;visualization evaluation;meta-level;coding scheme;IEEE visualization conference;IEEE information visualization;visual tools;requirements analyses;domain-specific work practices;Encoding;Data visualization;History;Systematics;Mathematical model;Encoding;Data visualization;History;Systematics;Mathematical model;information visualization;Evaluation;validation;systematic review;visualization;scientific visualization;Algorithms;Computer Graphics;Humans;Image Enhancement;Image Interpretation, Computer-Assisted;Imaging, Three-Dimensional;Information Storage and Retrieval;Pattern Recognition, Automated;Reproducibility of Results;Sensitivity and Specificity;User-Computer Interface},
doi={10.1109/TVCG.2013.126},
ISSN={1077-2626},
month={Dec},}
@INPROCEEDINGS{8260658,
author={K. {Kowsari} and D. E. {Brown} and M. {Heidarysafa} and K. {Jafari Meimandi} and M. S. {Gerber} and L. E. {Barnes}},
booktitle={2017 16th IEEE International Conference on Machine Learning and Applications (ICMLA)},
title={HDLTex: Hierarchical Deep Learning for Text Classification},
year={2017},
volume={},
number={},
pages={364-371},
abstract={Increasingly large document collections require improved information processing methods for searching, retrieving, and organizing text. Central to these information processing methods is document classification, which has become an important application for supervised learning. Recently the performance of traditional supervised classifiers has degraded as the number of documents has increased. This is because along with growth in the number of documents has come an increase in the number of categories. This paper approaches this problem differently from current document classification methods that view the problem as multi-class classification. Instead we perform hierarchical classification using an approach we call Hierarchical Deep Learning for Text classification (HDLTex). HDLTex employs stacks of deep learning architectures to provide specialized understanding at each level of the document hierarchy.},
keywords={data mining;learning (artificial intelligence);neural nets;pattern classification;text analysis;document hierarchy;HDLTex;Hierarchical Deep;Text classification;document collections;information processing methods;supervised learning;multiclass classification;hierarchical classification;deep learning architectures;supervised classifiers;text organization;document classification methods;Machine learning;Support vector machines;Computer architecture;Kernel;Mathematical model;Recurrent neural networks;Text Mining;Document Classification;Deep Neural Networks;Hierarchical Learning;Deep Learning},
doi={10.1109/ICMLA.2017.0-134},
ISSN={},
month={Dec},}
@INPROCEEDINGS{5333385,
author={ and and and },
booktitle={2009 ICCAS-SICE},
title={Study on interpretable fuzzy classification system based on neural networks},
year={2009},
volume={},
number={},
pages={5318-5321},
abstract={This paper describes a comprehensive method to construct fuzzy classification system considering both precision and interpretability. Fuzzy classification system, initialized by modified Gath-Geva fuzzy clustering algorithm, is transformed into neural network. After training the neural network, fuzzy sets similarity measure is adopt to merge redundant fuzzy sets to improve interpretability, and a constraint genetic algorithm is applied to improve precision. The simulation result on Iris data problem demonstrates the effectiveness of the proposed method.},
keywords={fuzzy set theory;genetic algorithms;neural nets;interpretable fuzzy classification system;neural networks;modified Gath-Geva fuzzy clustering algorithm;constraint genetic algorithm;Iris data problem;fuzzy set theory;Fuzzy neural networks;Fuzzy systems;Neural networks;Fuzzy sets;Genetic algorithms;Electronic mail;Clustering algorithms;Iris;Telecommunication traffic;Transportation;Fuzzy classification system;neural network;interpretability},
doi={},
ISSN={},
month={Aug},}
@INPROCEEDINGS{8490530,
author={A. {Holzinger}},
booktitle={2018 World Symposium on Digital Intelligence for Systems and Machines (DISA)},
title={From Machine Learning to Explainable AI},
year={2018},
volume={},
number={},
pages={55-66},
abstract={The success of statistical machine learning (ML) methods made the field of Artificial Intelligence (AI) so popular again, after the last AI winter. Meanwhile deep learning approaches even exceed human performance in particular tasks. However, such approaches have some disadvantages besides of needing big quality data, much computational power and engineering effort; those approaches are becoming increasingly opaque, and even if we understand the underlying mathematical principles of such models they still lack explicit declarative knowledge. For example, words are mapped to high-dimensional vectors, making them unintelligible to humans. What we need in the future are context-adaptive procedures, i.e. systems that construct contextual explanatory models for classes of real-world phenomena. This is the goal of explainable AI, which is not a new field; rather, the problem of explainability is as old as AI itself. While rule-based approaches of early AI were comprehensible “glass-box” approaches at least in narrow domains, their weakness was in dealing with uncertainties of the real world. Maybe one step further is in linking probabilistic learning methods with large knowledge representations (ontologies) and logical approaches, thus making results re-traceable, explainable and comprehensible on demand.},
keywords={learning (artificial intelligence);ontologies (artificial intelligence);probability;statistical machine learning methods;AI winter;deep learning approaches;big quality data;computational power;engineering effort;ontologies;knowledge representations;glass-box approaches;mathematical principles;artificial intelligence;logical approaches;probabilistic learning methods;rule-based approaches;contextual explanatory models;context-adaptive procedures;high-dimensional vectors;Machine learning;Data mining;Data visualization;Uncertainty;Games;Cognitive science},
doi={10.1109/DISA.2018.8490530},
ISSN={},
month={Aug},}
@INPROCEEDINGS{7066257,
author={J. {Jameson} and S. N. H. S. {Abdullah}},
booktitle={2014 14th International Conference on Intelligent Systems Design and Applications},
title={Extraction of arbitrary text in natural scene image based on stroke width transform},
year={2014},
volume={},
number={},
pages={124-128},
abstract={Text extraction plays an important role in numerous applications. Research on its method still need to be improved in order to achieve better performance, to increase the reliability of text extraction system and to deal with complex cases of text extraction. The majority of the text extraction methods are focusing on horizontal and near horizontal text lines; however, text in natural scene might be in arbitrary line in real time. Thus, this paper aims to solve the issue of extracting the arbitrary oriented text by suggesting a method for text detection and localization based on the Stroke Width Transform. The proposed method is tested on an arbitrary text dataset and ICDAR dataset. The result of the experiment shows that the proposed method adapts well to the arbitrary text.},
keywords={text detection;transforms;arbitrary text extraction;natural scene image;stroke width transform;text detection;text localization;ICDAR dataset;Image edge detection;Text analysis;Transforms;Optical character recognition software;Licenses;Integrated circuits;Text extraction;Text detection and localization;Stroke Width Transform;Scene understanding},
doi={10.1109/ISDA.2014.7066257},
ISSN={2164-7143},
month={Nov},}
@INPROCEEDINGS{8308186,
author={S. {Albawi} and T. A. {Mohammed} and S. {Al-Zawi}},
booktitle={2017 International Conference on Engineering and Technology (ICET)},
title={Understanding of a convolutional neural network},
year={2017},
volume={},
number={},
pages={1-6},
abstract={The term Deep Learning or Deep Neural Network refers to Artificial Neural Networks (ANN) with multi layers. Over the last few decades, it has been considered to be one of the most powerful tools, and has become very popular in the literature as it is able to handle a huge amount of data. The interest in having deeper hidden layers has recently begun to surpass classical methods performance in different fields; especially in pattern recognition. One of the most popular deep neural networks is the Convolutional Neural Network (CNN). It take this name from mathematical linear operation between matrixes called convolution. CNN have multiple layers; including convolutional layer, non-linearity layer, pooling layer and fully-connected layer. The convolutional and fully-connected layers have parameters but pooling and non-linearity layers don't have parameters. The CNN has an excellent performance in machine learning problems. Specially the applications that deal with image data, such as largest image classification data set (Image Net), computer vision, and in natural language processing (NLP) and the results achieved were very amazing. In this paper we will explain and define all the elements and important issues related to CNN, and how these elements work. In addition, we will also state the parameters that effect CNN efficiency. This paper assumes that the readers have adequate knowledge about both machine learning and artificial neural network.},
keywords={computer vision;feedforward neural nets;image classification;learning (artificial intelligence);natural language processing;fully-connected layers;convolutional connected layers;nonlinearity layer;multiple layers;matrixes called convolution;mathematical linear operation;classical methods performance;deeper hidden layers;multilayers;Artificial Neural Networks;Deep Neural Network;term Deep Learning;convolutional neural network;artificial neural network;largest image classification data;image data;CNN;pooling;Convolution;Neurons;Convolutional neural networks;Feature extraction;Image edge detection;machine learning;artificial neural networks;deep learning;convolutional neural networks;computer vision;Image recognition},
doi={10.1109/ICEngTechnol.2017.8308186},
ISSN={},
month={Aug},}
@INPROCEEDINGS{5267552,
author={X. {Ma} and J. {Zhang} and H. {Zhao}},
booktitle={2009 ISECS International Colloquium on Computing, Communication, Control, and Management},
title={Application of artificial neural networks in lithofacies interpretation used for 3D geological modelling},
year={2009},
volume={4},
number={},
pages={451-454},
abstract={This paper represents a study using Artificial Neural Networks (ANN) to perform automatic interpretation of lithofacies in a reservoir scale. This technique having been used successfully to interpret lithofacies automatically in the Sha20 Block, Shanian oilfield. Description and interpretation from a cored section in the key well was used to train the Supervised neural network. Having trained the network, it was then used to recognise and interpret the units vertically and laterally in the studied reservoir. The unsupervised neural network was run to classify the cored interval into 2 and 6 classes respectively and the results were then compared with the supervised network output. The results were observed to be over 87% accurate. Then a 3D geological model was built using the sequential indicator simulation method, the excellent results obtained from the developed model shows that the method is quite effective and gets satisfying prediction precision for the lithofacies in reservoir modeling.},
keywords={geology;hydrocarbon reservoirs;neural nets;artificial neural networks;lithofacies interpretation;3D geological modelling;Shanian oilfield;Sha20 Block;supervised neural network;unsupervised neural network;sequential indicator simulation method;Artificial neural networks;Geology;Reservoirs;Predictive models;Petroleum;Neural networks;Computer networks;Costs;Permeability;Cellular neural networks;Artificial Neural Networks;Lithofacies;modelling;training},
doi={10.1109/CCCM.2009.5267552},
ISSN={2154-9613},
month={Aug},}
@ARTICLE{1262324,
author={ and and D. {Doermann}},
journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
title={Machine printed text and handwriting identification in noisy document images},
year={2004},
volume={26},
number={3},
pages={337-353},
abstract={In this paper, we address the problem of the identification of text in noisy document images. We are especially focused on segmenting and identifying between handwriting and machine printed text because: 1) Handwriting in a document often indicates corrections, additions, or other supplemental information that should be treated differently from the main content and 2) the segmentation and recognition techniques requested for machine printed and handwritten text are significantly different. A novel aspect of our approach is that we treat noise as a separate class and model noise based on selected features. Trained Fisher classifiers are used to identify machine printed text and handwriting from noise and we further exploit context to refine the classification. A Markov Random Field-based (MRF) approach is used to model the geometrical structure of the printed text, handwriting, and noise to rectify misclassifications. Experimental results show that our approach is robust and can significantly improve page segmentation in noisy document collections.},
keywords={handwriting recognition;image segmentation;document image processing;text analysis;image enhancement;feature extraction;Markov processes;text identification;handwriting identification;noisy document images;machine printed text;recognition techniques;fisher classifiers;Markov random field;page segmentation;Image segmentation;Text recognition;Text analysis;Handwriting recognition;Markov random fields;Image analysis;Context modeling;Solid modeling;Noise robustness;Image enhancement;Algorithms;Artificial Intelligence;Automatic Data Processing;Computer Graphics;Documentation;Image Enhancement;Image Interpretation, Computer-Assisted;Information Storage and Retrieval;Models, Statistical;Numerical Analysis, Computer-Assisted;Pattern Recognition, Automated;Reading;Reproducibility of Results;Sensitivity and Specificity;Signal Processing, Computer-Assisted;Stochastic Processes;Subtraction Technique;User-Computer Interface;Writing},
doi={10.1109/TPAMI.2004.1262324},
ISSN={0162-8828},
month={March},}
@INPROCEEDINGS{8588744,
author={S. {Khademi} and X. {Shi} and T. {Mager} and R. {Siebes} and C. {Hein} and V. {de Boer} and J. {van Gemert}},
booktitle={2018 IEEE 14th International Conference on e-Science (e-Science)},
title={Sight-Seeing in the Eyes of Deep Neural Networks},
year={2018},
volume={},
number={},
pages={407-408},
abstract={We address the interpretability of convolutional neural networks (CNNs) for predicting a geo-location from an image. In a pilot experiment we classify images of Pittsburgh vs Tokyo and visualize the learned CNN filters. We found that varying the CNN architecture leads to variating in the visualized filters. This calls for further investigation of the effective parameters on the interpretability of CNNs.},
keywords={feedforward neural nets;learning (artificial intelligence);neural net architecture;sight-seeing;eyes;deep neural networks;interpretability;convolutional neural networks;CNNs;geo-location;Tokyo;learned CNN filters;CNN architecture;visualized filters;Visualization;Computer architecture;Neural networks;Image recognition;Conferences;Computer science;Intelligent systems;convolutional neural network (CNN);interpretability;place recognition;visualization;classification},
doi={10.1109/eScience.2018.00125},
ISSN={},
month={Oct},}
@INPROCEEDINGS{8275810,
author={W. {Zheng} and Y. {Liu} and H. {Lu} and H. {Tang}},
booktitle={2017 10th International Symposium on Computational Intelligence and Design (ISCID)},
title={Discriminative Topic Sparse Representation for Text Categorization},
year={2017},
volume={1},
number={},
pages={454-457},
abstract={In text categorization, feature representation for dimensionality reduction is a key step. Usually, some commonly used methods, e.g., latent semantic analysis (LSA), yield a dense representation or a dense transformation matrix, which is difficult to precisely characterize the document-topic or the topic-word relationship. This paper proposes a novel discriminative topic sparse representation (DTSR) approach for text categorization, in which two stages are included: the topic dictionary construction and sparse representation. Firstly, a discriminative and interpretable dictionary is constructed to characterize the topic-word relationship. The dictionary contains all category center vectors as well as some semantic topic vectors generated by a latent Dirichlet allocation (LDA) model. Furthermore, each document can be represented with a sparse form to obtain a good document-topic relationship. Experimental results on well-known benchmark datasets indicate that the proposed method not only achieves a satisfactory classification performance but also provides a reasonable sparse semantic meaningful.},
keywords={learning (artificial intelligence);pattern classification;text analysis;vectors;semantic topic vectors;latent Dirichlet allocation model;text categorization;feature representation;dimensionality reduction;latent semantic analysis;dense transformation matrix;topic-word relationship;topic dictionary construction;discriminative dictionary;interpretable dictionary;document-topic relationship;discriminative topic sparse representation approach;Semantics;Dictionaries;Text categorization;Training;Sparse matrices;Large scale integration;Resource management;Text Categorization;Sparse Representation;Topic;Discriminative;Semantic},
doi={10.1109/ISCID.2017.54},
ISSN={2473-3547},
month={Dec},}
@INPROCEEDINGS{1575741,
author={V. {Long} and R. {Dale} and S. {Cassidy}},
booktitle={Eighth International Conference on Document Analysis and Recognition (ICDAR'05)},
title={A model for detecting and merging vertically spanned table cells in plain text documents},
year={2005},
volume={},
number={},
pages={1242-1246 Vol. 2},
abstract={A spanned cell in a table is a single, complete unit that physically occupies multiple columns and/or multiple rows. Spanned cells are common in tables, and they are a significant cause of error in the extraction of tables from free text documents. In this paper, we present a model for the detection and merging of vertically spanned cells for tables presented in plain text documents. Our model and algorithm are based purely on the layout features of the tables, and they require no semantic understanding of the documents. When tested on the 98 tables appearing in 40 randomly selected documents from a corpus of company announcements from the Australian Stock Exchange (ASX), our algorithm achieves an accuracy of 86.79% in detecting and merging vertically spanned cells.},
keywords={text analysis;vertically spanned table cell merging;vertically spanned table cell detection;plain text documents;free text documents;document semantic understanding;Merging;IEEE news;Australia;Stock markets;Data mining;Terminology;Testing;Robustness;Text analysis},
doi={10.1109/ICDAR.2005.21},
ISSN={1520-5363},
month={Aug},}
@INPROCEEDINGS{1562962,
author={ and },
booktitle={17th IEEE International Conference on Tools with Artificial Intelligence (ICTAI'05)},
title={Customized explanation in expert system for earthquake prediction},
year={2005},
volume={},
number={},
pages={5 pp.-371},
abstract={A main line of research for introducing explanation capabilities in knowledge-based system supposes that explanations are used to transmit knowledge from the machine to a user and to improve learning ability of the latter. A reasonable explanation should be adapted to different level of users because different users have different knowledge. To describe the difference and then generate a personalized explanation is the main problem. In this paper, a novel method called FUM-CE (fuzzy user model based customized explanation) is proposed, in which a fuzzy user model called FUM is defined, and then several new algorithms are proposed to initialize FUM, update FUM, and extract correlative knowledge for explanation based on the FUM. FUM-CE can provide different and suitable explanation for the different users with different domain knowledge, by which the understandability and acceptability of the expert system for earthquake prediction are improved},
keywords={earthquakes;expert systems;explanation;fuzzy set theory;geophysics computing;expert system;earthquake prediction;knowledge-based system;fuzzy user model based customized explanation;Expert systems;Earthquake engineering;Knowledge engineering;Machine learning;Artificial intelligence;Humans;Hybrid intelligent systems;Fuzzy systems;Knowledge based systems;Problem-solving},
doi={10.1109/ICTAI.2005.54},
ISSN={1082-3409},
month={Nov},}
@INPROCEEDINGS{8519384,
author={J. {Pei} and Y. {Huang} and W. {Huo} and Y. {Zhang} and J. {Yang}},
booktitle={IGARSS 2018 - 2018 IEEE International Geoscience and Remote Sensing Symposium},
title={Target Aspect Identification in SAR Image: A Machine Learning Approach},
year={2018},
volume={},
number={},
pages={2310-2313},
abstract={Identifying the aspect for a given target is an important issue in synthetic aperture radar (SAR) image interpretation. A new SAR target aspect identification method based on machine learning theory is proposed in this paper. First, the aspect angles of the SAR target are discretized, and the spatial relationships of the neighborhoods of the SAR target samples are established. Then an optimal linear mapping is solved based on the proposed subspace aspect discriminant analysis. The samples will be projected into a low-dimensional space and be of a better aspect identifiability than in their original space. Finally, the projected samples are fed into a multilayer neural network, and the aspects of the SAR targets will be indicated. Experimental results have shown the superiority of the proposed method based on the moving and stationary target acquisition and recognition (MSTAR) data set.},
keywords={image sampling;learning (artificial intelligence);multilayer perceptrons;radar computing;radar imaging;radar target recognition;synthetic aperture radar;optimal linear mapping;low-dimensional space;moving-and-stationary target acquisition-and-recognition data set;MSTAR data set;multilayer neural network;aspect angles;machine learning theory;SAR target aspect identification method;synthetic aperture radar image interpretation;SAR image;stationary target acquisition;projected samples;aspect identifiability;subspace aspect discriminant analysis;SAR target samples;Synthetic aperture radar;Multi-layer neural network;Estimation;Training;Neurons;Machine learning;Synthetic aperture radar;target aspect identification;machine learning;multi-layer neural network},
doi={10.1109/IGARSS.2018.8519384},
ISSN={2153-7003},
month={July},}
@INPROCEEDINGS{618903,
author={C. {Ornes} and J. {Sklansky}},
booktitle={Proceedings of the IEEE/IAFE 1997 Computational Intelligence for Financial Engineering (CIFEr)},
title={A neural network that explains as well as predicts financial market behavior},
year={1997},
volume={},
number={},
pages={43-49},
abstract={When a neural network makes a financial prediction, the user may benefit from knowing which previous time periods are illustrative of the current time period. The authors describe a high-performance neural network that in addition to predicting stock market direction, allows the user to visualize the relationship between current conditions and previous conditions that led to similar predictions. Visualization is accomplished by forming a gated multi-expert network using funnel-shaped multilayer dimensionality reduction networks. The neck of the funnel is a two-neuron layer that displays the training data and the decision boundaries in a two-dimensional space. This architecture facilitates a) interactive design of the decision functions and b) explanation of the relevance of past decisions from the training set to the current decision. They describe a stock market prediction system whose design incorporates a visual neural network for prediction, wavelet transforms and tapped delay lines for feature extraction, and a genetic algorithm for feature selection. This system shows that the visual neural network provides the low error rates (i.e., accurate predictions) of multi-expert networks along with the visual explanatory power of nonlinear dimensionality reduction.},
keywords={explanation;prediction theory;neural net architecture;financial data processing;stock markets;multilayer perceptrons;feedforward neural nets;decision support systems;data visualisation;genetic algorithms;feature extraction;financial market behavior explanation;financial market behavior prediction;time periods;high-performance neural network;visualization;current conditions;previous conditions;gated multi-expert network;funnel-shaped multilayer dimensionality reduction networks;two-neuron layer;training data;decision boundaries;2D space;architecture;interactive decision function design;past decision relevance;visual neural network;wavelet transforms;tapped delay lines;feature extraction;genetic algorithm;Neural networks;Stock markets;Data visualization;Multi-layer neural network;Neck;Two dimensional displays;Training data;Algorithm design and analysis;Wavelet transforms;Delay lines},
doi={10.1109/CIFER.1997.618903},
ISSN={},
month={March},}
@ARTICLE{5290725,
author={Y. {Chen} and L. {Wang} and M. {Dong} and J. {Hua}},
journal={IEEE Transactions on Visualization and Computer Graphics},
title={Exemplar-based Visualization of Large Document Corpus (InfoVis2009-1115)},
year={2009},
volume={15},
number={6},
pages={1161-1168},
abstract={With the rapid growth of the World Wide Web and electronic information services, text corpus is becoming available online at an incredible rate. By displaying text data in a logical layout (e.g., color graphs), text visualization presents a direct way to observe the documents as well as understand the relationship between them. In this paper, we propose a novel technique, Exemplar-based visualization (EV), to visualize an extremely large text corpus. Capitalizing on recent advances in matrix approximation and decomposition, EV presents a probabilistic multidimensional projection model in the low-rank text subspace with a sound objective function. The probability of each document proportion to the topics is obtained through iterative optimization and embedded to a low dimensional space using parameter embedding. By selecting the representative exemplars, we obtain a compact approximation of the data. This makes the visualization highly efficient and flexible. In addition, the selected exemplars neatly summarize the entire data set and greatly reduce the cognitive overload in the visualization, leading to an easier interpretation of large text corpus. Empirically, we demonstrate the superior performance of EV through extensive experiments performed on the publicly available text data sets.},
keywords={biology computing;data visualisation;iterative methods;optimisation;exemplar-based visualization;large document corpus;text corpus;text visualization;matrix approximation;iterative optimization;parameter embedding;Data visualization;Web sites;Multidimensional systems;Drugs;Text mining;Principal component analysis;Computer science;Matrix decomposition;Large-scale systems;Indexing;Exemplar;large-scale document visualization;multidimensional projection.},
doi={10.1109/TVCG.2009.140},
ISSN={1077-2626},
month={Nov},}
@INPROCEEDINGS{8268978,
author={T. {Parcollet} and M. {Morchid} and G. {Linarès}},
booktitle={2017 IEEE Automatic Speech Recognition and Understanding Workshop (ASRU)},
title={Deep quaternion neural networks for spoken language understanding},
year={2017},
volume={},
number={},
pages={504-511},
abstract={Deep Neural Networks (DNN) received a great interest from researchers due to their capability to construct robust abstract representations of heterogeneous documents in a latent subspace. Nonetheless, mere real-valued deep neural networks require an appropriate adaptation, such as the convolution process, to capture latent relations between input features. Moreover, real-valued deep neural networks reveal little in way of document internal dependencies, by only considering words or topics contained in the document as an isolate basic element. Quaternion-valued multi-layer perceptrons (QMLP), and autoencoders (QAE) have been introduced to capture such latent dependencies, alongside to represent multidimensional data. Nonetheless, a three-layered neural network does not benefit from the high abstraction capability of DNNs. The paper proposes first to extend the hyper-complex algebra to deep neural networks (QDNN) and, then, introduces pre-trained deep quaternion neural networks (QDNN-AE) with dedicated quaternion encoder-decoders (QAE). The experiments conduced on a theme identification task of spoken dialogues from the DECODA data set show, inter alia, that the QDNN-AE reaches a promising gain of 2.2% compared to the standard real-valued DNN-AE.},
keywords={learning (artificial intelligence);multilayer perceptrons;natural language processing;speech recognition;real-valued deep neural networks;document internal dependencies;neural network;deep quaternion neural networks;spoken language understanding;quaternion-valued multilayer perceptrons;QMLP;autoencoders;QAE;spoken dialogues;Quaternions;Speech;Task analysis;Telephone sets;Algebra;Biological neural networks;Quaternions;deep neural networks;spoken language understanding;autoencoders;machine learning},
doi={10.1109/ASRU.2017.8268978},
ISSN={},
month={Dec},}
@INPROCEEDINGS{8128175,
author={L. {Gonzaga} and M. R. {Veronez} and D. N. {Alves} and F. {Bordin} and G. L. {Kannenberg} and F. P. {Marson} and F. M. W. {Tognoli} and L. C. {Inocencio}},
booktitle={2017 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)},
title={MOSIS — Multi-outcrop sharing interpretation system},
year={2017},
volume={},
number={},
pages={5209-5212},
abstract={The use of LiDAR and multiples digital images jointly with 3-D reconstruction techniques for creating 3-D models of natural outcrops and surfaces studies have increased dramatically in the last few years. These techniques have provided an enormous amount of data for interpretation by geoscientists. However, these researchers have no available software capable of offering a user experience comparable to the fieldwork. The majority of solutions have considered desktop systems, which presents inherent limitations due to the 2-D characteristics of displays and loss of immersion into the 3-D model, or up until expensive and complex stereoscopic based approaches to improve the 3-D user experience do not offer well suitable solutions. To address these limitations, this paper presents a low-cost completely disruptive solution for processing, visualizing, sharing and directly handling Digital Outcrop Models with the support of a full interpretation toolset, the MOSIS System. The proposed system provides a fully immersive computational environment, capable of teleporting virtually geoscientists to the fieldwork, giving an awareness of being there physically with an extensible toolset for the DOM's interpretation. Besides, desktop, web and mobile versions of MOSIS have been under development and fulfill the lack of tools for digital outcrop modeling.},
keywords={data visualisation;geophysical techniques;image reconstruction;optical radar;radar imaging;stereo image processing;MOSIS;multioutcrop sharing multiples digital images;digital outcrop models;DOM interpretation;digital outcrop modeling;fully immersive computational environment;MOSIS System;interpretation toolset;complex stereoscopic based approaches;natural outcrops;3-D model;3-D reconstruction techniques;Three-dimensional displays;Geology;Data visualization;Solid modeling;Tools;Visualization;Standards;immersive visualization;digital outcop model (DOM);virtual outcrop;interpretation;3-D visualization;GPU Computing},
doi={10.1109/IGARSS.2017.8128175},
ISSN={2153-7003},
month={July},}
@INPROCEEDINGS{7846290,
author={T. {Parcollet} and M. {Morchid} and P. {Bousquet} and R. {Dufour} and G. {Linarès} and R. {De Mori}},
booktitle={2016 IEEE Spoken Language Technology Workshop (SLT)},
title={Quaternion Neural Networks for Spoken Language Understanding},
year={2016},
volume={},
number={},
pages={362-368},
abstract={Machine Learning (ML) techniques have allowed a great performance improvement of different challenging Spoken Language Understanding (SLU) tasks. Among these methods, Neural Networks (NN), or Multilayer Perceptron (MLP), recently received a great interest from researchers due to their representation capability of complex internal structures in a low dimensional subspace. However, MLPs employ document representations based on basic word level or topic-based features. Therefore, these basic representations reveal little in way of document statistical structure by only considering words or topics contained in the document as a “bag-of-words”, ignoring relations between them. We propose to remedy this weakness by extending the complex features based on Quaternion algebra presented in [1] to neural networks called QMLP. This original QMLP approach is based on hyper-complex algebra to take into consideration features dependencies in documents. New document features, based on the document structure itself, used as input of the QMLP, are also investigated in this paper, in comparison to those initially proposed in [1]. Experiments made on a SLU task from a real framework of human spoken dialogues showed that our QMLP approach associated with the proposed document features outperforms other approaches, with an accuracy gain of 2% with respect to the MLP based on real numbers and more than 3% with respect to the first Quaternion-based features proposed in [1]. We finally demonstrated that less iterations are needed by our QMLP architecture to be efficient and to reach promising accuracies.},
keywords={algebra;document handling;learning (artificial intelligence);multilayer perceptrons;natural language processing;quaternion neural networks;machine learning;spoken language understanding;SLU;multilayer perceptron;MLP;document representations;document statistical structure;quaternion algebra;Quaternions;Computational modeling;Neurons;Artificial neural networks;Algebra;Natural language processing;Quaternion;Neural Network;Spoken Language Understanding;Machine Learning},
doi={10.1109/SLT.2016.7846290},
ISSN={},
month={Dec},}
@INPROCEEDINGS{8310088,
author={R. {Raoui-Outach} and C. {Million-Rousseau} and A. {Benoit} and P. {Lambert}},
booktitle={2017 Seventh International Conference on Image Processing Theory, Tools and Applications (IPTA)},
title={Deep learning for automatic sale receipt understanding},
year={2017},
volume={},
number={},
pages={1-6},
abstract={As a general rule, data analytics are now mandatory for companies. Scanned document analysis brings additional challenges introduced by paper damages and scanning quality. In an industrial context, this work focuses on the automatic understanding of sale receipts which enable access to essential and accurate consumption statistics. Given an image acquired with a smart-phone, the proposed work mainly focuses on the first steps of the full tool chain which aims at providing essential information such as the store brand, purchased products and related prices with the highest possible confidence. To get this high confidence level, even if scanning is not perfectly controlled, we propose a double check processing tool-chain using Deep Convolutional Neural Networks (DCNNs) on one hand and more classical image and text processings on another hand. The originality of this work relates in this double check processing and in the joint use of DCNNs for different applications and text analysis.},
keywords={data analysis;document image processing;feedforward neural nets;learning (artificial intelligence);sales management;text analysis;Deep learning;automatic sale receipt understanding;data analytics;scanned document analysis;paper damages;scanning quality;industrial context;automatic understanding;essential consumption statistics;accurate consumption statistics;smart-phone;tool chain;essential information;store brand;purchased products;related prices;highest possible confidence;high confidence level;tool-chain;Deep Convolutional Neural Networks;classical image;text processings;double check processing;text analysis;Optical character recognition software;Character recognition;Semantics;Text analysis;Task analysis;Object detection;Machine learning;Receipt image understanding;Deep Convolutional Neural Networks;Object Detection;Semantic Analysis},
doi={10.1109/IPTA.2017.8310088},
ISSN={2154-512X},
month={Nov},}
@INPROCEEDINGS{8613997,
author={F. {Ahamed} and F. {Farid}},
booktitle={2018 International Conference on Machine Learning and Data Engineering (iCMLDE)},
title={Applying Internet of Things and Machine-Learning for Personalized Healthcare: Issues and Challenges},
year={2018},
volume={},
number={},
pages={19-21},
abstract={Personalized Healthcare (PH) is a new patientoriented healthcare approach which expects to improve the traditional healthcare system. The focus of this new advancement is the patient data collected from patient Electronic health records (EHR), Internet of Things (IoT) sensor devices, wearables and mobile devices, web-based information and social media. PH applies Artificial Intelligence (AI) techniques to the collected dataset to improve disease progression technique, disease prediction, patient selfmanagement and clinical intervention. Machine learning techniques are widely used in this regard to develop analytic models. These models are integrated into different healthcare service applications and clinical decision support systems. These models mainly analyse the collected data from sensor devices and other sources to identify behavioral patterns and clinical conditions of the patient. For example, these models analyse the collected data to identify the patient's improvements, habits and anomaly in daily routine, changes in sleeping and mobility, eating, drinking and digestive pattern. Based on those patterns the healthcare applications and the clinical decision support systems recommend lifestyle advice, special treatment and care plans for the patient. The doctors and caregivers can also be engaged in the care plan process to validate lifestyle advice. However, there are many uncertainties and a grey area when it comes to applying machine learning in this context. Clinical, behaviour and lifestyle data in nature are very sensitive. There could be different types of biased involved in the process of data collection and interpretation. The training data model could have an older version of the dataset. All these could lead to an incorrect decision from the system without the user's knowledge. In this paper, some of the standards of the ML models reported in the recent research trends, identify the reliability issues and propose improvements.},
keywords={data acquisition;decision support systems;diseases;electronic health records;health care;Internet of Things;learning (artificial intelligence);patient treatment;healthcare service applications;patient self-management;artificial intelligence techniques;Web-based information;Internet of Things sensor devices;electronic health records;healthcare system;electronic health records;ML models;training data model;data collection;lifestyle data;healthcare applications;clinical conditions;behavioral patterns;clinical decision support systems;machine learning techniques;clinical intervention;disease prediction;disease progression technique;social media;mobile devices;patient data;personalized healthcare;Machine learning;Internet of Things;Hospitals;Monitoring;Sleep apnea;Personalized Healthcare;Internet of Things;Machine Learning},
doi={10.1109/iCMLDE.2018.00014},
ISSN={},
month={Dec},}
@INPROCEEDINGS{1259707,
author={ and and and and },
booktitle={Proceedings of the 2003 International Conference on Machine Learning and Cybernetics (IEEE Cat. No.03EX693)},
title={Information geometry on extendable hierarchical large scale neural network model},
year={2003},
volume={3},
number={},
pages={1380-1384 Vol.3},
abstract={In this paper, an extendable hierarchical large scale neural network model is developed based on the theoretical analysis of information geometry. In a hierarchical set of systems, a lower order system is included in the parameter space of a larger one as a subset. Such a parameter space has rich geometrical structures that are responsible for the dynamic behaviors of learning. Extendable hierarchical large scale neural network divides a task into small tasks, and each task is fulfilled by a small network under the principle of divide and conquer to improve the performance of a single network. By studying the dual manifold architecture for a family of neural networks and analyzing the hierarchical expansion of this model based on information geometry, the paper proposes a new method to construct the extendable hierarchical large scale neural network model that has knowledge-increasable and structure-extendible ability. The method helps to provide explanation of the transformation mechanism of human recognition system and understand the theory of global architecture of neural network.},
keywords={neural nets;learning (artificial intelligence);large-scale systems;hierarchical systems;statistical distributions;geometry;cognition;extendable hierarchical large scale neural network model;information geometry;lower order system;parameter space;learning behaviors;human recognition system;dual flat manifold architecture;Information geometry;Large-scale systems;Neural networks;Solid modeling;Probability distribution;Information analysis;Computer science;Electronic mail;Humans;Information theory},
doi={10.1109/ICMLC.2003.1259707},
ISSN={},
month={Nov},}
@INPROCEEDINGS{8356909,
author={Y. {Pang} and T. {Ito}},
booktitle={2017 Conference on Technologies and Applications of Artificial Intelligence (TAAI)},
title={A Proposal of Visualization Method for Critical Area in Computer Go},
year={2017},
volume={},
number={},
pages={62-65},
abstract={Deep Learning for the game of Go recently had a tremendous success with the victory of AlphaGo against Ke Jie in May 2017. However, there is no clear understanding of why they perform so well. In this paper, we introduce a visualization technique that performs a sensitivity analysis of the classifier output by occluding portions of the input Go board, revealing which parts of the board are important for predicting the next move. Using this tool, we start with the experiment about the accuracy of the critical area revealed. We also suppose that by showing the critical area, it will allow Go beginners to understand the board visually that they may have been confused about.},
keywords={computer games;data visualisation;learning (artificial intelligence);pattern classification;sensitivity analysis;sensitivity analysis;classifier output;critical area;visualization method;Ke Jie;deep learning;computer go;Go game;AlphaGo;input Go board;Machine learning;Data visualization;Training;Deep Learning;Computer Go;Visualization},
doi={10.1109/TAAI.2017.42},
ISSN={2376-6824},
month={Dec},}
@INPROCEEDINGS{8371950,
author={N. {Bourbakis}},
booktitle={2017 IEEE 29th International Conference on Tools with Artificial Intelligence (ICTAI)},
title={Converting Diagrams, Formulas, Tables, Graphics and Pictures into SPN and NL-text Sentences for Automatic Deep Understanding of Technical Documents},
year={2017},
volume={},
number={},
pages={247-254},
abstract={Most of the technical documents are composed by several modalities, like diagrams, tables, formulas, graphics, pictures and natural language text. Each of these modalities and their associations significantly contribute to the overall deep understanding of the technical document and the knowledge represented in it. Here for us all these modalities, except NL text, are considered as "images". Thus, each technical document mainly is composed by NL text sentences and "images". Thus, in this paper we present a methodology where all these modalities can be expressed into the same two modalities (natural languages text sentences and SPN graphs) for better associations and deeper understanding of a technical document. This deeper understanding will come from two different contributions. The first unique contribution will be an enrichment of the NL text part with additional NL text sentences extracted from the "images" of the technical document. The second unique contribution will come from the SPM models of these images that enrich the main diagram by generating a simulator for the system that technical document describes.},
keywords={document image processing;graph theory;natural language processing;Petri nets;stochastic processes;text analysis;technical document;natural languages text sentences;stochastic Petri-net forms;SPN graphs;knowledge representation;Pictures;Graphics;Tables;Formulas;Diagrams;NL text sentences;Databases;Text recognition;Shape;Image recognition;Natural languages;Visualization;SPN;Technical Documents;NL text Sentences},
doi={10.1109/ICTAI.2017.00047},
ISSN={2375-0197},
month={Nov},}

