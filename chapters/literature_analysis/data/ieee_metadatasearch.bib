@INPROCEEDINGS{8614020,
author={D. {Howard} and M. A. {Edwards}},
booktitle={2018 International Conference on Machine Learning and Data Engineering (iCMLDE)},
title={Explainable A.I.: The Promise of Genetic Programming Multi-run Subtree Encapsulation},
year={2018},
volume={},
number={},
pages={158-159},
abstract={Deep Learning and other Artificial Neural Network based solutions are rarely transparent, and white-box solutions are often called for. This paper explains how Multirun Subtree Encapsulation can provide equivalent white box solutions to facilitate Explainable Artificial Intelligence.},
keywords={data encapsulation;genetic algorithms;learning (artificial intelligence);neural nets;trees (mathematics);white-box solutions;artificial neural network;explainable artificial intelligence;genetic programming;deep learning;multirun subtree encapsulation;explainable AI;Encapsulation;Databases;Genetic programming;Standards;Deep learning;Artificial neural networks;Explainable Artificial Intelligence;A.I.;Genetic Programming;Evolutionary Computation;modularization;Subtree Encapsulation;Automatically Defined Functions;Software Evolution;white box;black box;expression simplification;Deep Learning;Artificial Neural Networks;Multirun Subtree Encapsulation;subtree database},
doi={10.1109/iCMLDE.2018.00037},
ISSN={},
month={Dec},}
@INPROCEEDINGS{5158992,
author={M. {Xue} and C. {Zhu}},
booktitle={2009 International Joint Conference on Artificial Intelligence},
title={A Study and Application on Machine Learning of Artificial Intellligence},
year={2009},
volume={},
number={},
pages={272-274},
abstract={This thesis elaborated the concept, significance and main strategy of machine learning as well as the basic structure of machine learning system. By combining several basic ideas of main strategies, great effort are laid on introducing several machine learning methods, such as Rote learning, Explanation-based learning, Learning from instruction, Learning by deduction, Learning by analogy and Inductive learning, etc. Meanwhile, comparison and analysis are made upon their respective advantages and limitations. At the end of the article, it proposes the research objective of machine learning and points out its development trend.Machine learning is a fundamental way that enable the computer to have the intelligence ; Its application which had been used mainly the method of induction and the synthesis, rather than the deduction has already reached many fields of Artificial Intelligence.},
keywords={learning (artificial intelligence);artificial intelligence;machine learning system;rote learning;explanation-based learning;learning from instruction;learning by deduction;learning by analogy;Inductive learning;Machine learning;Artificial intelligence;Learning systems;Application software;Humans;Computational modeling;Machine learning algorithms;Intelligent systems;Intelligent robots;Physiology;machine learning;AI;system structure;learning strategy;algorithm},
doi={10.1109/JCAI.2009.55},
ISSN={},
month={April},}
@INPROCEEDINGS{8419428,
author={M. A. {Ahmad} and A. {Teredesai} and C. {Eckert}},
booktitle={2018 IEEE International Conference on Healthcare Informatics (ICHI)},
title={Interpretable Machine Learning in Healthcare},
year={2018},
volume={},
number={},
pages={447-447},
abstract={This tutorial extensively covers the definitions, nuances, challenges, and requirements for the design of interpretable and explainable machine learning models and systems in healthcare. We discuss many uses in which interpretable machine learning models are needed in healthcare and how they should be deployed. Additionally, we explore the landscape of recent advances to address the challenges model interpretability in healthcare and also describe how one would go about choosing the right interpretable machine learnig algorithm for a given problem in healthcare.},
keywords={health care;learning (artificial intelligence);interpretable machine learning models;healthcare;interpretable machine learning algorithm;Machine learning;Machine learning algorithms;Prediction algorithms;Tutorials;Predictive models;Cancer;interpretable machine learning;explainable artificial intelligence},
doi={10.1109/ICHI.2018.00095},
ISSN={2575-2634},
month={June},}
@ARTICLE{4359216,
author={K. {Huang} and H. {Yang} and I. {King} and M. R. {Lyu}},
journal={IEEE Transactions on Neural Networks},
title={Maxi–Min Margin Machine: Learning Large Margin Classifiers Locally and Globally},
year={2008},
volume={19},
number={2},
pages={260-272},
abstract={In this paper, we propose a novel large margin classifier, called the maxi-min margin machine (M4). This model learns the decision boundary both locally and globally. In comparison, other large margin classifiers construct separating hyperplanes only either locally or globally. For example, a state-of-the-art large margin classifier, the support vector machine (SVM), considers data only locally, while another significant model, the minimax probability machine (MPM), focuses on building the decision hyperplane exclusively based on the global information. As a major contribution, we show that SVM yields the same solution as M4when data satisfy certain conditions, and MPM can be regarded as a relaxation model of M4. Moreover, based on our proposed local and global view of data, another popular model, the linear discriminant analysis, can easily be interpreted and extended as well. We describe the M4model definition, provide a geometrical interpretation, present theoretical justifications, and propose a practical sequential conic programming method to solve the optimization problem. We also show how to exploit Mercer kernels to extend M4for nonlinear classifications. Furthermore, we perform a series of evaluations on both synthetic data sets and real-world benchmark data sets. Comparison with SVM and MPM demonstrates the advantages of our new model.},
keywords={boundary-value problems;computational geometry;learning (artificial intelligence);minimax techniques;nonlinear programming;pattern classification;probability;relaxation theory;support vector machines;maxi-min margin machine;large margin classifier learning;decision boundaries;minimax probability machine;relaxation model;linear discriminant analysis;geometrical interpretation;sequential conic programming method;optimization problem;Mercer kernels;nonlinear classification;support vector machines;Machine learning;Support vector machines;Support vector machine classification;Minimax techniques;Buildings;Linear discriminant analysis;Solid modeling;Optimization methods;Kernel;Performance evaluation;Classification;kernel methods;large margin;learning locally and globally;second-order cone programming;Classification;kernel methods;large margin;learning locally and globally;second-order cone programming;Algorithms;Artificial Intelligence;Cluster Analysis;Neural Networks (Computer);Pattern Recognition, Automated},
doi={10.1109/TNN.2007.905855},
ISSN={1045-9227},
month={Feb},}
@INPROCEEDINGS{8679150,
author={D. {Kim} and W. {Lim} and M. {Hong} and H. {Kim}},
booktitle={2019 IEEE International Conference on Big Data and Smart Computing (BigComp)},
title={The Structure of Deep Neural Network for Interpretable Transfer Learning},
year={2019},
volume={},
number={},
pages={1-4},
abstract={Training a deep neural network requires a large amount of high-quality data and time. However, most of the real tasks don't have enough labeled data to train each complex model. To solve this problem, transfer learning reuses the pretrained model on a new task. However, one weakness of transfer learning is that it applies a pretrained model to a new task without understanding the output of an existing model. This may cause a lack of interpretability in training deep neural network. In this paper, we propose a technique to improve the interpretability in transfer learning tasks. We define the interpretable features and use it to train model to a new task. Thus, we will be able to explain the relationship between the source and target domain in a transfer learning task. Feature Network (FN) consists of Feature Extraction Layer and a single mapping layer that connects the features extracted from the source domain to the target domain. We examined the interpretability of the transfer learning by applying pretrained model with defined features to Korean characters classification.},
keywords={feature extraction;image classification;learning (artificial intelligence);natural language processing;neural nets;deep neural network;interpretable transfer learning;high-quality data;complex model;pretrained model;interpretability;transfer learning task;interpretable features;feature extraction layer;Korean characters classification;Feature extraction;Task analysis;Training;Data models;Convolution;Computational modeling;Neural networks;Interpretability;Transfer Learning;Machine Learning},
doi={10.1109/BIGCOMP.2019.8679150},
ISSN={2375-9356},
month={Feb},}
@ARTICLE{774103,
author={I. A. {Taha} and J. {Ghosh}},
journal={IEEE Transactions on Knowledge and Data Engineering},
title={Symbolic interpretation of artificial neural networks},
year={1999},
volume={11},
number={3},
pages={448-463},
abstract={Hybrid intelligent systems that combine knowledge-based and artificial neural network systems typically have four phases, involving domain knowledge representation, mapping of this knowledge into an initial connectionist architecture, network training and rule extraction, respectively. The final phase is important because it can provide a trained connectionist architecture with explanation power and validate its output decisions. Moreover, it can be used to refine and maintain the initial knowledge acquired from domain experts. In this paper, we present three rule extraction techniques. The first technique extracts a set of binary rules from any type of neural network. The other two techniques are specific to feedforward networks, with a single hidden layer of sigmoidal units. Technique 2 extracts partial rules that represent the most important embedded knowledge with an adjustable level of detail, while the third technique provides a more comprehensive and universal approach. A rule-evaluation technique, which orders extracted rules based on three performance measures, is then proposed. The three techniques area applied to the iris and breast cancer data sets. The extracted rules are evaluated qualitatively and quantitatively, and are compared with those obtained by other approaches.},
keywords={symbol manipulation;knowledge representation;explanation;truth maintenance;feedforward neural nets;neural net architecture;knowledge based systems;learning (artificial intelligence);symbolic interpretation;hybrid intelligent systems;knowledge-based systems;artificial neural networks;domain knowledge representation;domain knowledge mapping;connectionist architecture;network training;rule extraction;explanation power;output decision validation;knowledge refinement;binary rules;feedforward networks;hidden layer;sigmoidal units;partial rules;embedded knowledge;adjustable detail level;rule evaluation technique;rule ordering;performance measures;iris data set;breast cancer data set;Artificial neural networks;Neural networks;Data mining;Military computing;Knowledge representation;Knowledge based systems;Fuzzy neural networks;Fuzzy sets;Computer networks;Intelligent systems},
doi={10.1109/69.774103},
ISSN={1041-4347},
month={May},}
@INPROCEEDINGS{8389957,
author={A. {Lasod} and D. {Soni}},
booktitle={2017 International Conference on Energy, Communication, Data Analytics and Soft Computing (ICECDS)},
title={Efficiency enhancement of food recognition using artificial neural network},
year={2017},
volume={},
number={},
pages={2758-2762},
abstract={In this paper, we have a tendency to apply a artificial neural network (ANN) to the tasks of detective work and recognizing food pictures. Be- explanation for the wide diversity of styles of food, image recognition of food things is usually terribly difficulties. Be that as it may, deep learning has been indicated as of late to be a truly intense image recognition system, and ANN could be a dynamic way to deal with deep learning. We tend to connected ANN to the errands of food location and recognition through parameter change. We tend to made a dataset of the preeminent incessant food things in a publically available food-logging framework, and utilized it to recognition execution. ANN demonstrated fundamentally higher accuracy than did antiquated support-vector-machine-based routes with handmade choices. Furthermore, we tend to establish that the convolution bits demonstrate that shading commands the component extraction strategy. For food image discovery, ANN also indicated fundamentally higher accuracy than a customary procedure. Fundamentally higher accuracy than a customary strategy.},
keywords={image recognition;learning (artificial intelligence);neural nets;support vector machines;efficiency enhancement;food recognition;artificial neural network;deep learning;food location;publically available food-logging framework;food image discovery;image recognition system;ANN;support-vector-machine;food pictures recognization;handmade choices;convolution bits;Image recognition;Artificial neural networks;Biological neural networks;Feature extraction;Machine learning;Neurons;Artificial neural network;SVM;Food image recognition},
doi={10.1109/ICECDS.2017.8389957},
ISSN={},
month={Aug},}
@INPROCEEDINGS{1279325,
author={ and and and },
booktitle={International Conference on Neural Networks and Signal Processing, 2003. Proceedings of the 2003},
title={A multiple objective optimization based GA for designing interpretable and comprehensible neural network trees},
year={2003},
volume={1},
number={},
pages={518-521 Vol.1},
abstract={Neural network tree (NNTree) is a hybrid model for machine learning. The overall structure is a decision tree (DT), and each non-terminal node is an expert neural network (ENN). Generally speaking, NNTrees can achieve better performance than conventional DTs with fewer nodes, and the performance of the tree can be improved through incremental learning. In addition, the NNTrees can be interpreted in polynomial time if the number of inputs for each ENN is limited. In this paper, we propose a multiple objective optimization based genetic algorithm (MOO-GA) for designing interpretable and comprehensible NNTrees. The efficiency of the proposed algorithm is validated by experimental results.},
keywords={decision trees;neural nets;learning (artificial intelligence);genetic algorithms;multiple objective optimization;neural network trees;machine learning;decision tree;expert neural network;incremental learning;genetic algorithm;Design optimization;Neural networks;Algorithm design and analysis;Polynomials;Machine learning;Decision trees;Genetic algorithms;Machine learning algorithms;Helium;Humans},
doi={10.1109/ICNNSP.2003.1279325},
ISSN={},
month={Dec},}
@INPROCEEDINGS{8489172,
author={X. {Liu} and X. {Wang} and S. {Matwin}},
booktitle={2018 International Joint Conference on Neural Networks (IJCNN)},
title={Interpretable Deep Convolutional Neural Networks via Meta-learning},
year={2018},
volume={},
number={},
pages={1-9},
abstract={Model interpretability is a requirement in many applications in which crucial decisions are made by users relying on a model's outputs. The recent movement for “algorithmic fairness” also stipulates explainability, and therefore interpretability of learning models. And yet the most successful contemporary Machine Learning approaches, the Deep Neural Networks, produce models that are highly non-interpretable. We attempt to address this challenge by proposing a technique called CNN-INTE to interpret deep Convolutional Neural Networks (CNN) via meta-learning. In this work, we interpret a specific hidden layer of the deep CNN model on the MNIST image dataset. We use a clustering algorithm in a two-level structure to find the meta-level training data and Random Forest as base learning algorithms to generate the meta-level test data. The interpretation results are displayed visually via diagrams, which clearly indicates how a specific test instance is classified. Our method achieves global interpretation for all the test instances on the hidden layers without sacrificing the accuracy obtained by the original deep CNN model. This means our model is faithful to the original deep CNN model, which leads to reliable interpretations.},
keywords={convolution;feedforward neural nets;learning (artificial intelligence);pattern classification;pattern clustering;random processes;meta-learning;model interpretability;CNN-INTE;clustering algorithm;meta-level training data;base learning algorithms;meta-level test data;machine learning approaches;interpretable deep convolutional neural networks;MNIST image dataset;random forest;deep CNN model;Prediction algorithms;Machine learning;Machine learning algorithms;Predictive models;Computational modeling;Training data;Visualization;interpretability;Meta-learning;deep learning;Convolutional Neural Network;TensorFlow;big data},
doi={10.1109/IJCNN.2018.8489172},
ISSN={2161-4407},
month={July},}
@ARTICLE{728352,
author={A. B. {Tickle} and R. {Andrews} and M. {Golea} and J. {Diederich}},
journal={IEEE Transactions on Neural Networks},
title={The truth will come to light: directions and challenges in extracting the knowledge embedded within trained artificial neural networks},
year={1998},
volume={9},
number={6},
pages={1057-1068},
abstract={To date, the preponderance of techniques for eliciting the knowledge embedded in trained artificial neural networks (ANN's) has focused primarily on extracting rule-based explanations from feedforward ANN's. The ADT taxonomy for categorizing such techniques was proposed in 1995 to provide a basis for the systematic comparison of the different approaches. This paper shows that not only is this taxonomy applicable to a cross section of current techniques for extracting rules from trained feedforward ANN's but also how the taxonomy can be adapted and extended to embrace a broader range of ANN types (e,g., recurrent neural networks) and explanation structures. In addition we identify some of the key research questions in extracting the knowledge embedded within ANN's including the need for the formulation of a consistent theoretical basis for what has been, until recently, a disparate collection of empirical results.},
keywords={feedforward neural nets;recurrent neural nets;knowledge acquisition;finite automata;explanation;feedforward neural networks;ADT taxonomy;rule extraction;knowledge acquisition;explanation structures;finite state automata;fuzzy neural networks;knowledge insertion;recurrent neural networks;rule refinement;Artificial neural networks;Taxonomy;Recurrent neural networks;Intelligent networks;Neural networks;Feedforward neural networks;Automata;Fuzzy neural networks;Pattern recognition;Function approximation},
doi={10.1109/72.728352},
ISSN={1045-9227},
month={Nov},}
@INPROCEEDINGS{8400040,
author={F. K. {Došilović} and M. {Brčić} and N. {Hlupić}},
booktitle={2018 41st International Convention on Information and Communication Technology, Electronics and Microelectronics (MIPRO)},
title={Explainable artificial intelligence: A survey},
year={2018},
volume={},
number={},
pages={0210-0215},
abstract={In the last decade, with availability of large datasets and more computing power, machine learning systems have achieved (super)human performance in a wide variety of tasks. Examples of this rapid development can be seen in image recognition, speech analysis, strategic game planning and many more. The problem with many state-of-the-art models is a lack of transparency and interpretability. The lack of thereof is a major drawback in many applications, e.g. healthcare and finance, where rationale for model's decision is a requirement for trust. In the light of these issues, explainable artificial intelligence (XAI) has become an area of interest in research community. This paper summarizes recent developments in XAI in supervised learning, starts a discussion on its connection with artificial general intelligence, and gives proposals for further research directions.},
keywords={learning (artificial intelligence);interpretability;healthcare;finance;explainable artificial intelligence;XAI;recent developments;supervised learning;artificial general intelligence;datasets;computing power;machine learning systems;(super)human performance;image recognition;speech analysis;strategic game planning;state-of-the-art models;transparency;Predictive models;Machine learning;Support vector machines;Decision trees;Supervised learning;Optimization;explainable artificial intelligence;interpretability;explainability;comprehensibility},
doi={10.23919/MIPRO.2018.8400040},
ISSN={},
month={May},}
@ARTICLE{5337957,
author={H. {Chen} and X. {Yao}},
journal={IEEE Transactions on Neural Networks},
title={Regularized Negative Correlation Learning for Neural Network Ensembles},
year={2009},
volume={20},
number={12},
pages={1962-1979},
abstract={Negative correlation learning (NCL) is a neural network ensemble learning algorithm that introduces a correlation penalty term to the cost function of each individual network so that each neural network minimizes its mean square error (MSE) together with the correlation of the ensemble. This paper analyzes NCL and reveals that the training of NCL (when ¿ = 1) corresponds to training the entire ensemble as a single learning machine that only minimizes the MSE without regularization. This analysis explains the reason why NCL is prone to overfitting the noise in the training set. This paper also demonstrates that tuning the correlation parameter ¿ in NCL by cross validation cannot overcome the overfitting problem. The paper analyzes this problem and proposes the regularized negative correlation learning (RNCL) algorithm which incorporates an additional regularization term for the whole ensemble. RNCL decomposes the ensemble's training objectives, including MSE and regularization, into a set of sub-objectives, and each sub-objective is implemented by an individual neural network. In this paper, we also provide a Bayesian interpretation for RNCL and provide an automatic algorithm to optimize regularization parameters based on Bayesian inference. The RNCL formulation is applicable to any nonlinear estimator minimizing the MSE. The experiments on synthetic as well as real-world data sets demonstrate that RNCL achieves better performance than NCL, especially when the noise level is nontrivial in the data set.},
keywords={belief networks;inference mechanisms;learning (artificial intelligence);mean square error methods;neural nets;regularized negative correlation learning;neural network ensemble learning algorithm;mean square error;learning machine;Bayesian interpretation;Bayesian inference;Neural networks;Machine learning;Cost function;Mean square error methods;Bayesian methods;Algorithm design and analysis;Inference algorithms;Noise level;Computational intelligence;Application software;Ensembles;negative correlation learning (NCL);neural network ensembles;neural networks;probabilistic model;regularization;Algorithms;Automatic Data Processing;Bayes Theorem;Humans;Learning;Neural Networks (Computer);Nonlinear Dynamics;Signal Processing, Computer-Assisted},
doi={10.1109/TNN.2009.2034144},
ISSN={1045-9227},
month={Dec},}
@INPROCEEDINGS{8646474,
author={A. {Shahroudnejad} and P. {Afshar} and K. N. {Plataniotis} and A. {Mohammadi}},
booktitle={2018 IEEE Global Conference on Signal and Information Processing (GlobalSIP)},
title={IMPROVED EXPLAINABILITY OF CAPSULE NETWORKS: RELEVANCE PATH BY AGREEMENT},
year={2018},
volume={},
number={},
pages={549-553},
abstract={Recent advancements in signal processing domain have resulted in a surge of interest in deep neural networks (DNNs) due to their unprecedented performance and high accuracy for challenging problems of significant engineering importance. However, when such deep learning architectures are utilized for making critical decisions such as the ones that involve human lives (e.g., in medical applications), it is of paramount importance to understand, trust, and in one word "explain" the rational behind deep models' decisions. Generally, DNNs are considered as black-box systems, which do not provide any clue on their internal processing actions. Although some recent efforts have been initiated to explain behavior/decisions of deep networks, explainable artificial intelligence (XAI) domain is still in its infancy. In this regard, we consider capsule networks (referred to as CapsNets), which are novel deep structures; recently proposed as an alternative counterpart to convolutional neural networks (CNNs), and posed to change the future of machine intelligence. In this paper, we investigate and analyze structure and behavior of CapsNets and illustrate potential explainability properties of such networks. Furthermore, we show possibility of transforming deep architectures in to transparent networks via incorporation of capsules in different layers instead of convolution layers of the CNNs.},
keywords={convolutional neural nets;learning (artificial intelligence);signal processing;capsule networks;relevance path;signal processing domain;deep neural networks;unprecedented performance;significant engineering importance;deep learning architectures;critical decisions;human lives;medical applications;deep models;black-box systems;internal processing actions;deep networks;explainable artificial intelligence domain;CapsNets;deep structures;convolutional neural networks;potential explainability properties;deep architectures;transparent networks;DNN;XAI;CNN;Feature extraction;Predictive models;Neural networks;Machine learning;Training;Couplings;Computer architecture;Explainable Machine Learning;Capsule Networks;Deep Neural Networks;Convolutional Neural Networks},
doi={10.1109/GlobalSIP.2018.8646474},
ISSN={},
month={Nov},}
@INPROCEEDINGS{8622433,
author={B. {Kovalerchuk} and N. {Neuhaus}},
booktitle={2018 IEEE International Conference on Big Data (Big Data)},
title={Toward Efficient Automation of Interpretable Machine Learning},
year={2018},
volume={},
number={},
pages={4940-4947},
abstract={Developing more efficient automated methods for interpretable machine learning (ML) is an important and longterm machine-learning goal. Recent studies show that unintelligible "black" box models, such as Deep Learning Neural Networks, often outperform more interpretable "grey" or "white" box models such as Decision Trees, Bayesian networks, Logic Relational models and others. Being forced to choose between accuracy and interpretability, however, is a major obstacle in the wider adoption of ML in healthcare and other domains where decisions requires both facets. Due to human perceptual limitations in analyzing complex multidimensional relations in ML, complex ML must be "degraded" to the level of human understanding, thereby also degrading model accuracy. To address this challenge, this paper presents the Dominance Classifier and Predictor (DCP) algorithm, capable of automating the process of discovering human-understandable machine learning models that are simple and visualizable. The success of DCP is shown on the benchmark Wisconsin Breast Cancer dataset with the higher accuracy than the accuracy known for other interpretable methods on these data. Furthermore, the DCP algorithm shortens the accuracy gap between interpretable and non-interpretable models on these data. The DCP explanation includes both interpretable mathematical and visual forms. Such an approach opens a new opportunity for producing more accurate and domain-explainable ML models.},
keywords={learning (artificial intelligence);pattern classification;domain-explainable ML models;dominance classifier and predictor algorithm;DCP algorithm;unintelligible black box models;interpretable machine learning;interpretable mathematical forms;noninterpretable models;interpretable methods;human-understandable machine learning models;complex multidimensional relations;human perceptual limitations;white box models;interpretable grey box models;Classification algorithms;Prediction algorithms;Machine learning;Mathematical model;Machine learning algorithms;Computational modeling;Neural networks;machine learning;explainability;interpretability;accuracy;classifier;visualization;visual model;dominant intervals},
doi={10.1109/BigData.2018.8622433},
ISSN={},
month={Dec},}
@INPROCEEDINGS{236591,
author={J. {Genest}},
booktitle={Proceedings First International Conference on Artificial Intelligence Applications on Wall Street},
title={Building a banking system specification using machine learning},
year={1991},
volume={},
number={},
pages={263-268},
abstract={Transforming user requirements into software specification is a complex and demanding task. Artificial intelligence methods such as machine learning (ML) can assist in the software specification process by providing support to system designers. This paper presents an approach based on explanation-based learning (EBL), a ML technique in which a concept is learned by building an explanation. The approach is presented in the context of the system LISE (Learning in Software Engineering). LISE converts a user requirement for a software module into an operational module definition using EBL with an incomplete theory. An example where LISE is used to build the specification of a banking system is illustrated.<<ETX>>},
keywords={bank data processing;case-based reasoning;explanation;formal specification;learning (artificial intelligence);case-based reasoning;banking system specification;user requirements;machine learning;explanation-based learning;LISE;Learning in Software Engineering;Banking;Machine learning;Buildings;Software engineering;Mathematics;Artificial intelligence;Programming;Software design;Multilevel systems;Software libraries},
doi={10.1109/AIAWS.1991.236591},
ISSN={},
month={Oct},}
@ARTICLE{1603636,
author={G. {Costantini} and D. {Casali} and R. {Perfetti}},
journal={IEEE Transactions on Neural Networks},
title={Associative memory design for 256 gray-level images using a multilayer neural network},
year={2006},
volume={17},
number={2},
pages={519-522},
abstract={A design procedure is presented for neural associative memories storing gray-scale images. It is an evolution of a previous work based on the decomposition of the image with 2/sup L/ gray levels into L binary patterns, stored in L uncoupled neural networks. In this letter, an L-layer neural network is proposed with both intralayer and interlayer connections. The connections between different layers introduce interactions among all the neurons, increasing the recall performance with respect to the uncoupled case. In particular, the proposed network can store images with the commonly used number of 256 gray levels instead of 16, as in the previous approach.},
keywords={neural nets;content-addressable storage;neural associative memory design;gray-level images;multilayer neural network;2/sup L/ gray levels;L binary patterns;L uncoupled neural networks;Multi-layer neural network;Associative memory;Neural networks;Neurons;Biological neural networks;Image storage;Gray-scale;Pixel;Cellular neural networks;Quantization;Associative memories;brain-state-in-a-box (BSB) neural networks;gray-scale images;multilayer architectures;Algorithms;Artificial Intelligence;Colorimetry;Computer Graphics;Computer Simulation;Image Interpretation, Computer-Assisted;Information Storage and Retrieval;Models, Theoretical;Neural Networks (Computer);Numerical Analysis, Computer-Assisted;Pattern Recognition, Automated;Signal Processing, Computer-Assisted},
doi={10.1109/TNN.2005.863465},
ISSN={1045-9227},
month={March},}
@ARTICLE{7369936,
author={J. G. {Wolff}},
journal={IEEE Access},
title={The SP Theory of Intelligence: Distinctive Features and Advantages},
year={2016},
volume={4},
number={},
pages={216-246},
abstract={This paper aims to highlight distinctive features of the SP theory of intelligence, realized in the SP computer model, and its apparent advantages compared with some AI-related alternatives. Perhaps most importantly, the theory simplifies and integrates observations and concepts in AI-related areas, and has potential to simplify and integrate of structures and processes in computing systems. Unlike most other AI-related theories, the SP theory is itself a theory of computing, which can be the basis for new architectures for computers. Fundamental in the theory is information compression via the matching and unification of patterns and, more specifically, via a concept of multiple alignment. The theory promotes transparency in the representation and processing of knowledge, and unsupervised learning of natural structures via information compression. It provides an interpretation of aspects of mathematics and an interpretation of phenomena in human perception and cognition. concepts in the theory may be realized in terms of neurons and their inter-connections (SP-neural). These features and advantages of the SP system are discussed in relation to AI-related alternatives: the concept of minimum length encoding and related concepts, how computational and energy efficiency in computing may be achieved, deep learning in neural networks, unified theories of cognition and related research, universal search, Bayesian networks and some other models for AI, IBM's Watson, solving problems associated with big data and in the development of intelligence in autonomous robots, pattern recognition and vision, the learning and processing of natural language, exact and inexact forms of reasoning, representation and processing of diverse forms of knowledge, and software engineering. In conclusion, the SP system can provide a firm foundation for the long-term development of AI and related areas, and at the same time, it may deliver useful results on relatively short timescales.},
keywords={knowledge representation;learning (artificial intelligence);neural nets;pattern matching;deep-learning;energy efficiency;computational efficiency;minimum length encoding;SP-neural;neuron interconnections;cognition;human perception;information compression;unsupervised learning;knowledge representation;knowledge processing;pattern unification;pattern matching;information compression;AI;SP computer model;SP intelligence theory;Artificial intelligence;Computational modeling;Information compression;Computer architecture;Unsupervised learning;Turing machines;Neural networks;Mathematics;Unsupervised learning;artificial intelligence;information compression;multiple alignment;perception;cognition;neural networks;deep learning;unsupervised learning;reasoning;mathematics;Artificial intelligence;information compression;multiple alignment;perception;cognition;neural networks;deep learning;unsupervised learning;reasoning;mathematics},
doi={10.1109/ACCESS.2015.2513822},
ISSN={2169-3536},
month={},}
@INPROCEEDINGS{8491679,
author={R. {Chimatapu} and H. {Hagras} and A. {Starkey} and G. {Owusu}},
booktitle={2018 IEEE International Conference on Fuzzy Systems (FUZZ-IEEE)},
title={Interval Type-2 Fuzzy Logic Based Stacked Autoencoder Deep Neural Network For Generating Explainable AI Models in Workforce Optimization},
year={2018},
volume={},
number={},
pages={1-8},
abstract={In Utility based industries that employ a large mobile workforce, efficient utilization of field engineers is key to optimal service delivery. The utilization of the engineers can be improved by predicting the future performance of work areas by using machine learning tools such as Deep Neural Networks (DNNs).The dramatic success of DNNs has led to an explosion of its applications. However, the effectiveness of DNNs can be limited by the inability to explain how the models arrived at their predictions.In this paper, we present a novel Type-2 Fuzzy Logic System (FLS) whose inputs are preprocessed by a Stacked Autoencoder Neural Network to add some interpretability to a Deep Neural Network model. The proposed type-2 FLS will contain a small rule set with a small number of antecedents per rule to maximize the model's interpretability. We also present an algorithm which can be used to efficiently train the proposed model.We will compare the proposed model with a Standard Stacked Autoencoder Deep Neural Network, a Multi-Layer Perceptron (MLP) neural network and an Interval Type-2 Fuzzy Logic System.The results show that even though the Standard Stacked Autoencoder and MLP Neural Networks have better performance, they do not provide any insight into the reasoning behind the predictions. The Proposed model, on the other hand, provides better result than the standalone type-2 FLS and a comparable performance to the neural networks and provides a little bit of insight into the decision-making process. Without this insight, we cannot be sure why there is a drop in the performance and we need to further analyze the WA before we can take any decision. This leads to quicker decision making and potentially improving the efficiency of the engineers.},
keywords={decision making;fuzzy logic;fuzzy set theory;learning (artificial intelligence);multilayer perceptrons;optimisation;workforce optimization;mobile workforce;field engineers;optimal service delivery;machine learning tools;DNNs;standalone type-2 FLS;multilayer perceptron neural network;interval type-2 fuzzy logic system;MLP neural networks;utility based industries;explainable AI models;standard stacked autoencoder deep neural network;decision-making process;Fuzzy logic;Neural networks;Fuzzy sets;Optimization;Task analysis;Predictive models;Type-2 fuzzy logic;Big Bang - Big Crunch;Deep Neural Networks;Explainable Artificial Intelligence},
doi={10.1109/FUZZ-IEEE.2018.8491679},
ISSN={},
month={July},}
@ARTICLE{1356017,
author={H. K. {Lam} and F. H. F. {Leung}},
journal={IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)},
title={Digit and command interpretation for electronic book using neural network and genetic algorithm},
year={2004},
volume={34},
number={6},
pages={2273-2283},
abstract={This work presents the interpretation of digits and commands using a modified neural network and the genetic algorithm. The modified neural network exhibits a node-to-node relationship which enhances its learning and generalization abilities. A digit-and-command interpreter constructed by the modified neural networks is proposed to recognize handwritten digits and commands. A genetic algorithm is employed to train the parameters of the modified neural networks of the digit-and-command interpreter. The proposed digit-and-command interpreter is successfully realized in an electronic book. Simulation and experimental results will be presented to show the applicability and merits of the proposed approach.},
keywords={genetic algorithms;neural nets;learning (artificial intelligence);generalisation (artificial intelligence);electronic publishing;handwritten character recognition;digit interpretation;command interpretation;neural network;genetic algorithm;artificial intelligence learning;artificial intelligence generalization;electronic book;Electronic publishing;Neural networks;Genetic algorithms;Biological neural networks;Signal processing algorithms;Backpropagation algorithms;Error correction;Neurons;Books;Handwriting recognition;Digit and command interpretation;electronic book;genetic algorithm;neural networks;Algorithms;Artificial Intelligence;Automatic Data Processing;Books;Computer Graphics;Handwriting;Image Enhancement;Image Interpretation, Computer-Assisted;Information Storage and Retrieval;Models, Statistical;Neural Networks (Computer);Numerical Analysis, Computer-Assisted;Pattern Recognition, Automated;Publishing;Reading;Reproducibility of Results;Sensitivity and Specificity;Signal Processing, Computer-Assisted;User-Computer Interface;Word Processing},
doi={10.1109/TSMCB.2004.834432},
ISSN={1083-4419},
month={Dec},}
@INPROCEEDINGS{7966169,
author={R. {Kamimura}},
booktitle={2017 International Joint Conference on Neural Networks (IJCNN)},
title={Potential layer-wise supervised learning for training multi-layered neural networks},
year={2017},
volume={},
number={},
pages={2568-2575},
abstract={The present paper tries to show that the greedy layer-wise supervised learning becomes effective enough to improve generalization and interpretation by the help of potential learning. It has been observed that unsupervised pre-training has a shortcoming of vanishing information as is the case of simple multi-layered network training. When the layer becomes higher, valuable information becomes smaller. Information through many different layers tends to diminish considerably and naturally from the information-theoretic point of view. For this, we use the layer-wise supervised training to prevent information from diminishing. The supervised learning has been said to be not good for pre-training for multi-layered neural networks. However, we have found that the new potential learning can be effectively used to extract valuable information through supervised pre-training. With the help of important components extracted by the potential learning, the supervised pre-training becomes effective for training multi-layered neural networks. We applied the method to two data sets, namely, an artificial and banknote data sets. In both cases, the potential learning proved to be effective in increasing generalization performance. In addition, we could show a possibility that final representation by this method could be clearly understood.},
keywords={generalisation (artificial intelligence);greedy algorithms;information theory;learning (artificial intelligence);neural nets;potential layerwise supervised learning;multilayered neural networks training;greedy layerwise supervised learning;generalization;interpretation;information theory;Neurons;Biological neural networks;Training;Machine learning;Supervised learning;Minimization},
doi={10.1109/IJCNN.2017.7966169},
ISSN={2161-4407},
month={May},}
@INPROCEEDINGS{8490433,
author={J. {Zhu} and A. {Liapis} and S. {Risi} and R. {Bidarra} and G. M. {Youngblood}},
booktitle={2018 IEEE Conference on Computational Intelligence and Games (CIG)},
title={Explainable AI for Designers: A Human-Centered Perspective on Mixed-Initiative Co-Creation},
year={2018},
volume={},
number={},
pages={1-8},
abstract={Growing interest in eXplainable Artificial Intelligence (XAI) aims to make AI and machine learning more understandable to human users. However, most existing work focuses on new algorithms, and not on usability, practical interpretability and efficacy on real users. In this vision paper, we propose a new research area of eXplainable AI for Designers (XAID), specifically for game designers. By focusing on a specific user group, their needs and tasks, we propose a human-centered approach for facilitating game designers to co-create with AI/ML techniques through XAID. We illustrate our initial XAID framework through three use cases, which require an understanding both of the innate properties of the AI techniques and users' needs, and we identify key open challenges.},
keywords={computer games;human computer interaction;learning (artificial intelligence);game designers;AI/ML techniques;human-centered perspective;AI machine;human-centered approach;explainable artificial intelligence;mixed-initiative co-creation;XAI;machine learning;explainable AI for designers;XAID framework;Games;Task analysis;Machine learning;Neurons;Visualization;Tools;explainable artificial intelligence;mixed-initiative co-creation;human-computer interaction;machine learning;game design},
doi={10.1109/CIG.2018.8490433},
ISSN={2325-4289},
month={Aug},}
@INPROCEEDINGS{1224095,
author={ and C. {Hinde} and D. {Gillingwater}},
booktitle={Proceedings of the International Joint Conference on Neural Networks, 2003.},
title={A new method for explaining neural network reasoning},
year={2003},
volume={4},
number={},
pages={3256-3260 vol.4},
abstract={This paper presents a new method for explaining the reasoning results of a trained neural network. The method considers the most significant attribute first under the guidance of a relative strength of effect analysis and eliminates irrelevant points. Following the adaptive search in the dynamic state space, a set of relevant points are extracted and form the basis of the explanation of the neural network reasoning. Combining a relative strength of effect analysis with the relevant points, a case based explanation approach is put forward. As an illustration, an experiment with a small data set on the relationship between weather conditions and play decisions is presented to demonstrate the utility of the proposed approach.},
keywords={neural nets;learning (artificial intelligence);explanation;inference mechanisms;neural network reasoning;trained neural network;relative strength of effect analysis;adaptive search;dynamic state space;relevant point extraction;case based explanation approach;weather conditions;play decisions;Neural networks;Data mining;Knowledge representation;Computational intelligence;Intelligent structures;Computer science;State-space methods;Information analysis;Training data;Artificial neural networks},
doi={10.1109/IJCNN.2003.1224095},
ISSN={1098-7576},
month={July},}
@ARTICLE{1359749,
author={S. {Marinai} and M. {Gori} and G. {Soda}},
journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
title={Artificial neural networks for document analysis and recognition},
year={2005},
volume={27},
number={1},
pages={23-35},
abstract={Artificial neural networks have been extensively applied to document analysis and recognition. Most efforts have been devoted to the recognition of isolated handwritten and printed characters with widely recognized successful results. However, many other document processing tasks, like preprocessing, layout analysis, character segmentation, word recognition, and signature verification, have been effectively faced with very promising results. This paper surveys the most significant problems in the area of offline document image processing, where connectionist-based approaches have been applied. Similarities and differences between approaches belonging to different categories are discussed. A particular emphasis is given on the crucial role of prior knowledge for the conception of both appropriate architectures and learning algorithms. Finally, the paper provides a critical analysts on the reviewed approaches and depicts the most promising research guidelines in the field. In particular, a second generation of connectionist-based models are foreseen which are based on appropriate graphical representations of the learning environment.},
keywords={document image processing;recurrent neural nets;handwritten character recognition;image segmentation;handwriting recognition;learning (artificial intelligence);artificial neural networks;document image analysis;document image recognition;handwritten recognition;character recognition;layout analysis;character segmentation;word recognition;signature verification;offline document image processing;connectionist based approach;learning algorithms;document preprocessing;recurrent neural nets;graphical representations;Artificial neural networks;Text analysis;Character recognition;Handwriting recognition;Image analysis;Image recognition;Neural networks;Optical character recognition software;Image segmentation;Face recognition;Index Terms- Character segmentation;document image analysis and recognition;layout analysis;neural networks;preprocessing;recursive neural networks;word recognition.;Algorithms;Artificial Intelligence;Automatic Data Processing;Computer Graphics;Documentation;Handwriting;Image Enhancement;Image Interpretation, Computer-Assisted;Information Storage and Retrieval;Neural Networks (Computer);Numerical Analysis, Computer-Assisted;Pattern Recognition, Automated;Reading;Reproducibility of Results;Sensitivity and Specificity;Signal Processing, Computer-Assisted;User-Computer Interface},
doi={10.1109/TPAMI.2005.4},
ISSN={0162-8828},
month={Jan},}
@ARTICLE{8466590,
author={A. {Adadi} and M. {Berrada}},
journal={IEEE Access},
title={Peeking Inside the Black-Box: A Survey on Explainable Artificial Intelligence (XAI)},
year={2018},
volume={6},
number={},
pages={52138-52160},
abstract={At the dawn of the fourth industrial revolution, we are witnessing a fast and widespread adoption of artificial intelligence (AI) in our daily life, which contributes to accelerating the shift towards a more algorithmic society. However, even with such unprecedented advancements, a key impediment to the use of AI-based systems is that they often lack transparency. Indeed, the black-box nature of these systems allows powerful predictions, but it cannot be directly explained. This issue has triggered a new debate on explainable AI (XAI). A research field holds substantial promise for improving trust and transparency of AI-based systems. It is recognized as the sine qua non for AI to continue making steady progress without disruption. This survey provides an entry point for interested researchers and practitioners to learn key aspects of the young and rapidly growing body of research related to XAI. Through the lens of the literature, we review the existing approaches regarding the topic, discuss trends surrounding its sphere, and present major research trajectories.},
keywords={artificial intelligence;AI-based systems;black-box nature;explainable AI;XAI;explainable artificial intelligence;fourth industrial revolution;Conferences;Machine learning;Market research;Prediction algorithms;Machine learning algorithms;Biological system modeling;Explainable artificial intelligence;interpretable machine learning;black-box models},
doi={10.1109/ACCESS.2018.2870052},
ISSN={2169-3536},
month={},}
@ARTICLE{5993545,
author={S. {Razavi} and B. A. {Tolson}},
journal={IEEE Transactions on Neural Networks},
title={A New Formulation for Feedforward Neural Networks},
year={2011},
volume={22},
number={10},
pages={1588-1598},
abstract={Feedforward neural network is one of the most commonly used function approximation techniques and has been applied to a wide variety of problems arising from various disciplines. However, neural networks are black-box models having multiple challenges/difficulties associated with training and generalization. This paper initially looks into the internal behavior of neural networks and develops a detailed interpretation of the neural network functional geometry. Based on this geometrical interpretation, a new set of variables describing neural networks is proposed as a more effective and geometrically interpretable alternative to the traditional set of network weights and biases. Then, this paper develops a new formulation for neural networks with respect to the newly defined variables; this reformulated neural network (ReNN) is equivalent to the common feedforward neural network but has a less complex error response surface. To demonstrate the learning ability of ReNN, in this paper, two training methods involving a derivative-based (a variation of backpropagation) and a derivative-free optimization algorithms are employed. Moreover, a new measure of regularization on the basis of the developed geometrical interpretation is proposed to evaluate and improve the generalization ability of neural networks. The value of the proposed geometrical interpretation, the ReNN approach, and the new regularization measure are demonstrated across multiple test problems. Results show that ReNN can be trained more effectively and efficiently compared to the common neural networks and the proposed regularization measure is an effective indicator of how a network would perform in terms of generalization.},
keywords={feedforward neural nets;function approximation;generalisation (artificial intelligence);learning (artificial intelligence);optimisation;function approximation techniques;black box model;neural network functional geometry;geometrical interpretation;reformulated neural network;feedforward neural network;error response surface;learning ability;training method;derivative free optimization algorithm;generalization ability;ReNN approach;Biological neural networks;Training;Nickel;Optimization;Function approximation;Neurons;Feedforward neural networks;generalization;geometrical interpretation;internal behavior;measure of regularization;reformulated neural network;training;Algorithms;Artificial Intelligence;Feedback;Models, Neurological;Neural Networks (Computer);Software Design},
doi={10.1109/TNN.2011.2163169},
ISSN={1045-9227},
month={Oct},}
@INPROCEEDINGS{8511831,
author={T. W. {Kim} and B. R. {Routledge}},
booktitle={2018 IEEE Symposium on Privacy-Aware Computing (PAC)},
title={Informational Privacy, A Right to Explanation, and Interpretable AI},
year={2018},
volume={},
number={},
pages={64-74},
abstract={Businesses increasingly utilize secret algorithms and infringe users' informational privacy. We argue that to best protect users' online privacy, the use of an algorithm that assists with decisions or autonomously makes decisions that impact people requires a right to explanation.},
keywords={artificial intelligence;business data processing;data protection;informational privacy;interpretable AI;online privacy protection;Companies;Mathematical model;Privacy;Decision making;Loans and mortgages;Artificial intelligence;Law;GDPR;A right to explanation;Trust;Privacy;Explainable AI},
doi={10.1109/PAC.2018.00013},
ISSN={},
month={Sep.},}
@INPROCEEDINGS{118383,
author={ and },
booktitle={International 1989 Joint Conference on Neural Networks},
title={A general explanation and interrogation system for neural networks},
year={1989},
volume={},
number={},
pages={594 vol.2-},
abstract={Summary form only given, as follows. The information in a trained neural network is stored as numerical weights in the neural elements and the connectivity pattern of the network. For many applications, it is desirable to have this neural network information converted into symbolic knowledge form for communication with human or machine experts. Techniques are presented for converting the information in a trained network into symbolic form as a set of rules and for obtaining explanations from the network for specific inputs. These two techniques provide the neurocomputer with one advantage of expert systems while retaining the learning and generalization capability of the neural network.<<ETX>>},
keywords={expert systems;explanation;neural nets;explanation;interrogation system;neural networks;numerical weights;connectivity pattern;symbolic knowledge form;neurocomputer;expert systems;learning;generalization capability;Expert systems;Explanation;Neural networks},
doi={10.1109/IJCNN.1989.118383},
ISSN={},
month={},}
@INPROCEEDINGS{170480,
author={B. -. {Zhang} and G. {Veenker}},
booktitle={[Proceedings] 1991 IEEE International Joint Conference on Neural Networks},
title={Neural networks that teach themselves through genetic discovery of novel examples},
year={1991},
volume={},
number={},
pages={690-695 vol.1},
abstract={The authors introduce an active learning paradigm for neural networks. In contrast to the passive paradigm, the learning in the active paradigm is initiated by the machine learner instead of its environment or teacher. The authors present a learning algorithm that uses a genetic algorithm for creating novel examples to teach multilayer feedforward networks. The creative learning networks, based on their own knowledge, discover new examples, criticize and select useful ones, train themselves, and thereby extend their existing knowledge. Experiments on function extrapolation show that the self-teaching neural networks not only reduce the teaching efforts of the human, but the genetically created examples also contribute robustly to the improvement of generalization performance and the interpretation of the connectionist knowledge.<<ETX>>},
keywords={extrapolation;learning systems;neural nets;genetic discovery;active learning paradigm;neural networks;machine learner;multilayer feedforward networks;function extrapolation;teaching efforts;generalization performance;connectionist knowledge;Neural networks;Artificial neural networks;Learning systems;Genetic algorithms;Unsupervised learning;Artificial intelligence;Supervised learning;Computer science;Multi-layer neural network;Extrapolation},
doi={10.1109/IJCNN.1991.170480},
ISSN={},
month={Nov},}
@INPROCEEDINGS{200004,
author={X. {Guan} and R. J. {Mural} and J. R. {Einstein} and R. C. {Mann} and E. C. {Uberbacher}},
booktitle={Proceedings Eighth Conference on Artificial Intelligence for Applications},
title={GRAIL: an integrated artificial intelligence system for gene recognition and interpretation},
year={1992},
volume={},
number={},
pages={9-13},
abstract={The development of an integrated artificial intelligence system, GRAIL (gene recognition and analysis Internet link) is described. This system uses a combination of a multi-sensor/neural network, expert system, and parallel search tools to recognize and interpret genes in DNA sequences. A simple electronic mail (E-mail) interface makes the system accessible through Internet. The strength of the system in recognizing and interpreting genes in DNA sequences and the simple E-mail interface have already attracted more than 150 users. The success of the system is largely due to the multi-sensor/neural network approach and the integration of several AI tools. The modular development and flexible framework have made it easier to incorporate new knowledge and tools into the existing system.<<ETX>>},
keywords={biology computing;cellular biophysics;DNA;expert systems;neural nets;parallel processing;integrated artificial intelligence system;GRAIL;gene recognition;Internet link;multi-sensor/neural network;expert system;parallel search tools;DNA sequences;electronic mail;E-mail interface;AI tools;modular development;flexible framework;Artificial intelligence;Sequences;DNA;Neural networks;Expert systems;Humans;Genomics;Bioinformatics;Proteins;Data mining},
doi={10.1109/CAIA.1992.200004},
ISSN={},
month={March},}
@ARTICLE{4523947,
author={X. {Geng} and Z. {Zhou} and K. {Smith-Miles}},
journal={IEEE Transactions on Neural Networks},
title={Individual Stable Space: An Approach to Face Recognition Under Uncontrolled Conditions},
year={2008},
volume={19},
number={8},
pages={1354-1368},
abstract={There usually exist many kinds of variations in face images taken under uncontrolled conditions, such as changes of pose, illumination, expression, etc. Most previous works on face recognition (FR) focus on particular variations and usually assume the absence of others. Instead of such a ldquodivide and conquerrdquo strategy, this paper attempts to directly address <i>face</i> <i>recognition</i> <i>under</i> <i>uncontrolled</i> <i>conditions</i>. The key is the individual stable space (ISS), which only expresses personal characteristics. A neural network named ISNN is proposed to map a raw face image into the ISS. After that, three ISS-based algorithms are designed for FR under uncontrolled conditions. There are no restrictions for the images fed into these algorithms. Moreover, unlike many other FR techniques, they do not require any extra training information, such as the view angle. These advantages make them practical to implement under uncontrolled conditions. The proposed algorithms are tested on three large face databases with vast variations and achieve superior performance compared with other 12 existing FR techniques.},
keywords={face recognition;neural nets;face recognition;individual stable space;neural network;ISNN;face databases;Face recognition;Image recognition;Lighting;Neural networks;Image databases;Pattern recognition;Humans;Algorithm design and analysis;Machine learning algorithms;Testing;Face recognition (FR);individual stable space (ISS);machine learning;neural networks;pattern recognition;Algorithms;Artificial Intelligence;Face;Humans;Image Enhancement;Image Interpretation, Computer-Assisted;Neural Networks (Computer);Pattern Recognition, Automated;Sensitivity and Specificity},
doi={10.1109/TNN.2008.2000275},
ISSN={1045-9227},
month={Aug},}
@ARTICLE{4267862,
author={D. {Dancey} and Z. A. {Bandar} and D. {McLean}},
journal={IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)},
title={Logistic Model Tree Extraction From Artificial Neural Networks},
year={2007},
volume={37},
number={4},
pages={794-802},
abstract={Artificial neural networks (ANNs) are a powerful and widely used pattern recognition technique. However, they remain "black boxes" giving no explanation for the decisions they make. This paper presents a new algorithm for extracting a logistic model tree (LMT) from a neural network, which gives a symbolic representation of the knowledge hidden within the ANN. Landwehr's LMTs are based on standard decision trees, but the terminal nodes are replaced with logistic regression functions. This paper reports the results of an empirical evaluation that compares the new decision tree extraction algorithm with Quinlan's C4.5 and ExTree. The evaluation used 12 standard benchmark datasets from the university of California, Irvine machine-learning repository. The results of this evaluation demonstrate that the new algorithm produces decision trees that have higher accuracy and higher fidelity than decision trees created by both C4.5 and ExTree.},
keywords={decision making;decision trees;learning (artificial intelligence);neural nets;pattern recognition;regression analysis;logistic model tree extraction;artificial neural networks;pattern recognition;black boxes;decision making;decision trees;logistic regression;machine-learning repository;C4.5;ExTree;Logistics;Artificial neural networks;Neural networks;Decision trees;Data mining;Pattern recognition;Regression tree analysis;Multi-layer neural network;Feedforward neural networks;Intelligent networks;Artificial intelligence;feedforward neural networks;multilayer perceptrons (MPLs);neural networks;Algorithms;Computer Simulation;Decision Support Techniques;Logistic Models;Neural Networks (Computer);Pattern Recognition, Automated},
doi={10.1109/TSMCB.2007.895334},
ISSN={1083-4419},
month={Aug},}
@INPROCEEDINGS{191443,
author={J. H. {Johnson} and N. J. {Hallam} and P. D. {Picton}},
booktitle={IEE Colloquium on Neural Nets in Human-Computer Interaction},
title={Safety critical neural computing: explanation and verification in knowledge augmented neural networks},
year={1990},
volume={},
number={},
pages={1/1-1/8},
abstract={Conventional neural networks cannot contain a priori knowledge and cannot explain their output. A mathematical theory of black box classifiers is developed which covers most of the best known neural architectures. The limitations of the non-model based computational paradigm are discussed; these include inability to predict the behaviour of systems with multiple-valued, discontinuous, catastrophic and chaotic state spaces. Worse, they include the inability to detect the presence of such systems, when they are working: outside their 'range of competence', and with data of quality outside their range of experience. Neural networks themselves cannot communicate with human decisionmakers in human terms; often the choice is 'take it or leave it'. Knowledge-based computation does not necessarily have these drawbacks, and can therefore augment the powerful neural computing paradigm where it is weakest. The authors consider three fundamental ways of combining the two computational paradigms and show how the explanation facility of knowledge based systems can be used to induce explanation on the output of neural subsystems. They conclude with an architecture which is generic for safety critical neural computation.<<ETX>>},
keywords={explanation;knowledge based systems;neural nets;safety;knowledge augmented neural networks;mathematical theory;black box classifiers;best known neural architectures;non-model based computational paradigm;predict;multiple-valued;catastrophic;chaotic state spaces;human decisionmakers;human terms;neural computing paradigm;computational paradigms;explanation facility;knowledge based systems;neural subsystems;architecture;safety critical neural computation;Explanation;Knowledge based systems;Neural networks;Safety},
doi={},
ISSN={},
month={Dec},}
@INPROCEEDINGS{5209797,
author={H. {Shi}},
booktitle={2009 Second International Symposium on Electronic Commerce and Security},
title={Application of Unascertained Neural Networks to Financial Early Warning},
year={2009},
volume={2},
number={},
pages={365-368},
abstract={Artificial neural network (ANN) has outstanding characteristics in machine learning, fault, tolerant, parallel reasoning and processing nonlinear problem abilities. Unascertained system that imitates the human brain's thinking logical is a kind of mathematical tools used to deal with imprecise and uncertain knowledge. Integrating unascertained method with neural network technology, the reasoning process of network coding can be tracked, and the output of the network can be given a physical explanation. A unascertained neural network was set up. It can be compared with the fuzzy network, so that their own advantages and shortcomings can be found and further study can be made on the uncertainty network to improve the uncertainty network more complete.},
keywords={financial data processing;learning (artificial intelligence);neural nets;unascertained neural network;financial early warning;artificial neural network;machine learning;parallel reasoning;processing nonlinear problem;unascertained system;uncertain knowledge;unascertained method;neural network technology;network coding;fuzzy network;uncertainty network;Neural networks;Artificial neural networks;Uncertainty;Biological neural networks;Humans;Machine learning;Network coding;Electronic commerce;Civil engineering;Electronic mail},
doi={10.1109/ISECS.2009.133},
ISSN={},
month={May},}
@ARTICLE{6222007,
author={Y. {Yang} and Y. {Wang} and X. {Yuan}},
journal={IEEE Transactions on Neural Networks and Learning Systems},
title={Bidirectional Extreme Learning Machine for Regression Problem and Its Learning Effectiveness},
year={2012},
volume={23},
number={9},
pages={1498-1505},
abstract={It is clear that the learning effectiveness and learning speed of neural networks are in general far slower than required, which has been a major bottleneck for many applications. Recently, a simple and efficient learning method, referred to as extreme learning machine (ELM), was proposed by Huang , which has shown that, compared to some conventional methods, the training time of neural networks can be reduced by a thousand times. However, one of the open problems in ELM research is whether the number of hidden nodes can be further reduced without affecting learning effectiveness. This brief proposes a new learning algorithm, called bidirectional extreme learning machine (B-ELM), in which some hidden nodes are not randomly selected. In theory, this algorithm tends to reduce network output error to 0 at an extremely early learning stage. Furthermore, we find a relationship between the network output error and the network output weights in the proposed B-ELM. Simulation results demonstrate that the proposed method can be tens to hundreds of times faster than other incremental ELM algorithms.},
keywords={learning (artificial intelligence);neural nets;regression analysis;bidirectional extreme learning machine;regression problem;learning effectiveness;neural networks;B-ELM;Machine learning;Training;Testing;Learning systems;Helium;Equations;Computer architecture;Feedforward neural network;learning effectiveness;number of hidden nodes;universal approximation;Algorithms;Computer Simulation;Data Interpretation, Statistical;Models, Statistical;Neural Networks (Computer);Pattern Recognition, Automated;Regression Analysis},
doi={10.1109/TNNLS.2012.2202289},
ISSN={2162-237X},
month={Sep.},}
@ARTICLE{1353291,
author={K. C. {Tan} and H. J. {Tang}},
journal={IEEE Transactions on Neural Networks},
title={New dynamical optimal learning for linear multilayer FNN},
year={2004},
volume={15},
number={6},
pages={1562-1570},
abstract={This letter presents a new dynamical optimal learning (DOL) algorithm for three-layer linear neural networks and investigates its generalization ability. The optimal learning rates can be fully determined during the training process. The mean squared error (mse) is guaranteed to be stably decreased and the learning is less sensitive to initial parameter settings. The simulation results illustrate that the proposed DOL algorithm gives better generalization performance and faster convergence as compared to standard error back propagation algorithm.},
keywords={learning (artificial intelligence);feedforward neural nets;mean square error methods;stability;dynamical optimal learning algorithm;linear multilayer FNN;three-layer linear neural network;mean squared error;Nonhomogeneous media;Neural networks;Multi-layer neural network;Feedforward neural networks;Stability;Pattern recognition;Chaos;Transfer functions;Convergence;Function approximation;Back propagation;dynamical optimal learning (DOL);feedforward neural networks (FNN);stability;Algorithms;Artificial Intelligence;Computer Simulation;Decision Support Techniques;Feedback;Image Interpretation, Computer-Assisted;Information Storage and Retrieval;Linear Models;Neural Networks (Computer);Numerical Analysis, Computer-Assisted;Pattern Recognition, Automated},
doi={10.1109/TNN.2004.830801},
ISSN={1045-9227},
month={Nov},}
@INPROCEEDINGS{1380384,
author={ and },
booktitle={Proceedings of 2004 International Conference on Machine Learning and Cybernetics (IEEE Cat. No.04EX826)},
title={Explanation based generalized /spl epsi/-SVM and its application in intelligent project management},
year={2004},
volume={6},
number={},
pages={3454-3459 vol.6},
abstract={Support vector machine works well in classifying populations characterized by abrupt decreases in density functions. Its generalization accuracy, however, is not always optimal in dealing with real world problems with neither Gaussian distributions nor sharp boundaries. Incorporating domain theory about problems and excellent intelligent techniques in machine learning into SVM becomes one of promising alternatives. A novel approach, explanation based generalized /spl epsi/-SVM, which synthesizes SVM, prior knowledge, fuzzy logic and neural network, is proposed. Prior knowledge is expressed as a trained fuzzy neural network. An optimal subset of features is obtained by dynamically reducing feature space dimensionality according to the training derivatives extracted from network. By examining a subset of the practical data sampled from Guangdong Natural Science Foundation and testing the remaining set of data, application shows that explanation based generalized /spl epsi/-SVM performs better than that pure SVM and other traditional classifiers.},
keywords={support vector machines;pattern classification;explanation;generalisation (artificial intelligence);project management;learning (artificial intelligence);fuzzy logic;fuzzy neural nets;generalized /spl epsi/-SVM;intelligent project management;support vector machine;domain theory;machine learning;prior knowledge;fuzzy logic;neural network;trained fuzzy neural network;Project management;Support vector machines;Support vector machine classification;Learning systems;Density functional theory;Gaussian distribution;Machine learning;Network synthesis;Fuzzy logic;Neural networks},
doi={10.1109/ICMLC.2004.1380384},
ISSN={},
month={Aug},}
@INPROCEEDINGS{8621470,
author={S. {Starikov} and E. {Khrameeva} and M. {Gelfand}},
booktitle={2018 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)},
title={Prediction of chromatin spatial structure characteristics using machine learning methods},
year={2018},
volume={},
number={},
pages={2489-2489},
abstract={Development of chromosome conformation capture methods boosted progress in the study of the spatial organization of chromatin. Accumulation of large amounts of experimental data provides an opportunity to apply machine learning methods to examine the connection between epigenetics and the three-dimensional structure of chromatin. The aim of this study was to predict the characteristics of the chromatin structure, namely the transitional gamma, from ChIP-Seq experimental data by means of machine learning methods, and also to reveal the properties of epigenetic data influencing prediction. The neural network and the loss function designed for the prediction task are shown to perform with a sufficiently high accuracy. In addition, the genomic size of the chromatin context required for improving the quality of the prediction was assessed. Several neural network visualization techniques were tested as a means for improving interpretability of network, showing the possibility for using visualization to study interrelations in epigenetic data relevant for three-dimensional chromatin structure. To sum up, a close relationship between epigenetic factors and the structure of chromatin has been confirmed.},
keywords={biology computing;data visualisation;genetics;genomics;learning (artificial intelligence);neural nets;chromosome conformation capture methods;ChIP-Seq experimental data;machine learning methods;epigenetic data influencing prediction;neural network visualization techniques;three-dimensional chromatin structure;chromatin spatial structure characteristics;Machine learning;Bioinformatics;Neural networks;Data visualization;Conferences;Biomedical engineering;Life sciences;Hi-C;machine learning;neural networks;ChIP-Seq},
doi={10.1109/BIBM.2018.8621470},
ISSN={},
month={Dec},}
@INPROCEEDINGS{685683,
author={R. J. P. {de Figueiredo}},
booktitle={1998 IEEE Symposium on Advances in Digital Filtering and Signal Processing. Symposium Proceedings (Cat. No.98EX185)},
title={D-FANNS (dynamical functional artificial neural networks)-a new avenue for intelligent analog signal processing},
year={1998},
volume={},
number={},
pages={6-},
abstract={Summary form only given. Intelligent signal processing may be defined as the process of mapping a signal x into a binary vector or matrix y, so that y enables the detection, classification, or interpretation of an event present in x. (In the case of an interpretation in an appropriate language, y would represent a digitally coded relational structure.) We denote by f the input-output map of such an intelligent signal processing filter. In a number of applications, it is possible to naturally implement the nonlinear filter map f by an artificial neural network (ANN). We consider the case in which x is an analog signal (waveform) belonging to L2(I), where I is an appropriate interval of the real line R1 (i.e., L2(I) is the space of square integrable functions on I), and propose the realization of f by an artificial neural network in which the synaptic weight actions of the first layer are implemented by a filter bank. We call such a network a dynamical functional artificial neural network (D-FANN) to distinguish it from a conventional functional artificial neural network (FANN), where a synaptic weight action is implemented by a scalar product (integration) in L2(I), between the incoming waveform x and a "distributed" functional weight. Compared with conventional FANNs, D-FANNs permit simple and meaningful causal realizations of intelligent analog signal processors. A novel element in the present paper is the introduction of a "D-FANN gain equation", in a way analogous to that in Kalman filtering. Applications of D-FANNs to real and simulated data are now in progress and these results are discussed.},
keywords={neural nets;signal processing;band-pass filters;filtering theory;nonlinear filters;dynamical functional artificial neural networks;D-FANNS;intelligent analog signal processing;binary vector;matrix;detection;classification;interpretation;digitally coded relational structure;input-output map;intelligent signal processing filter;nonlinear filter map;waveform;synaptic weight;functional artificial neural network;FANN;scalar product;integration;distributed functional weight;D-FANN gain equation;Kalman filtering;simulated data;real data;Artificial neural networks;Artificial intelligence;Signal processing;Signal mapping;Event detection;Intelligent structures;Digital filters;Nonlinear filters;Filter bank;Equations},
doi={10.1109/ADFSP.1998.685683},
ISSN={},
month={June},}
@INPROCEEDINGS{1174403,
author={ and and },
booktitle={Proceedings. International Conference on Machine Learning and Cybernetics},
title={Knowledge-increasable learning behaviors research of neural field},
year={2002},
volume={2},
number={},
pages={586-590 vol.2},
abstract={In a hierarchical set of systems, a lower order system is included in the parameter space of a large one as a subset. Such a parameter space has rich geometrical structures that are responsible for the dynamic behaviors of learning. Based on the theoretical analysis of information geometry and differential manifold, this paper studies knowledge-increasable learning behaviors of the neural field, and presents a layered knowledge-increasable artificial neural network model which has the knowledge-increasable and structure-extendible ability. The method helps to provide an explanation of the transformation mechanism of human's recognition system and understand the theory of global architecture of neural networks.},
keywords={neural nets;learning (artificial intelligence);parallel processing;information theory;probability;neural network;knowledge-increasable learning;parameter space;geometrical structures;information geometry;differential manifold;structure-extendible ability;parallel processing;probability distribution;Artificial neural networks;Information geometry;Neural networks;Solid modeling;Humans;Probability distribution;Information analysis;Large-scale systems;Machine learning;Computer science},
doi={10.1109/ICMLC.2002.1174403},
ISSN={},
month={Nov},}
@INPROCEEDINGS{713958,
author={G. {Deco} and L. {Parra}},
booktitle={Proceedings of 1993 International Conference on Neural Networks (IJCNN-93-Nagoya, Japan)},
title={Self-organization in stochastic neural networks},
year={1993},
volume={1},
number={},
pages={479-482 vol.1},
abstract={The maximization of the mutual information between the stochastic outputs neurons and the clamped inputs is used as an unsupervised criterion for training a Boltzmann machine. The resulting learning rule contains two terms corresponding to the Hebbian and anti-Hebbian learning. The two terms are weighted by the amount of transmitted information in the learning synapse, giving an information-theoretic interpretation to the proportionality constant given in the biological rule of Hebb. The anti-Hebbian term causes the convergence of weights. Simulation for the encoder problem demonstrates optimal performance of this method.},
keywords={Boltzmann machines;neural nets;Hebbian learning;unsupervised learning;information theory;self-organization;stochastic neural networks;unsupervised learning;Boltzmann machine;anti-Hebbian learning;Hebbian learning;information-theory;proportionality constant;Intelligent networks;Stochastic processes;Neural networks;Neurons;Mutual information;Information theory;Unsupervised learning;Equations;Research and development;Tin},
doi={10.1109/IJCNN.1993.713958},
ISSN={},
month={Oct},}
@ARTICLE{8440842,
author={B. C. {Kwon} and M. {Choi} and J. T. {Kim} and E. {Choi} and Y. B. {Kim} and S. {Kwon} and J. {Sun} and J. {Choo}},
journal={IEEE Transactions on Visualization and Computer Graphics},
title={RetainVis: Visual Analytics with Interpretable and Interactive Recurrent Neural Networks on Electronic Medical Records},
year={2019},
volume={25},
number={1},
pages={299-309},
abstract={We have recently seen many successful applications of recurrent neural networks (RNNs) on electronic medical records (EMRs), which contain histories of patients' diagnoses, medications, and other various events, in order to predict the current and future states of patients. Despite the strong performance of RNNs, it is often challenging for users to understand why the model makes a particular prediction. Such black-box nature of RNNs can impede its wide adoption in clinical practice. Furthermore, we have no established methods to interactively leverage users' domain expertise and prior knowledge as inputs for steering the model. Therefore, our design study aims to provide a visual analytics solution to increase interpretability and interactivity of RNNs via a joint effort of medical experts, artificial intelligence scientists, and visual analytics researchers. Following the iterative design process between the experts, we design, implement, and evaluate a visual analytics tool called RetainVis, which couples a newly improved, interpretable, and interactive RNN-based model called RetainEX and visualizations for users' exploration of EMR data in the context of prediction tasks. Our study shows the effective use of RetainVis for gaining insights into how individual medical codes contribute to making risk predictions, using EMRs of patients with heart failure and cataract symptoms. Our study also demonstrates how we made substantial changes to the state-of-the-art RNN model called RETAIN in order to make use of temporal information and increase interactivity. This study will provide a useful guideline for researchers that aim to design an interpretable and interactive visual analytics tool for RNNs.},
keywords={artificial intelligence;data analysis;data visualisation;interactive systems;medical information systems;recurrent neural nets;interactive RNN-based model;EMR data;prediction tasks;RetainVis;individual medical codes;risk predictions;temporal information;increase interactivity;interpretable analytics tool;interpretable networks;interactive recurrent neural networks;electronic medical records;black-box nature;interactively leverage users;design study;visual analytics solution;medical experts;artificial intelligence scientists;iterative design process;newly improved RNN-based model;RNN-based model;visual analytic researchers;interactive visual analytic tool;Machine learning;Medical diagnostic imaging;Task analysis;Predictive models;Computational modeling;Visual analytics;Data models;Interactive Artificial Intelligence;XAI (Explainable Artificial Intelligence);Interpretable Deep Learning;Healthcare},
doi={10.1109/TVCG.2018.2865027},
ISSN={1077-2626},
month={Jan},}
@ARTICLE{8481251,
author={H. {Hagras}},
journal={Computer},
title={Toward Human-Understandable, Explainable AI},
year={2018},
volume={51},
number={9},
pages={28-36},
abstract={Recent increases in computing power, coupled with rapid growth in the availability and quantity of data have rekindled our interest in the theory and applications of artificial intelligence (AI). However, for AI to be confidently rolled out by industries and governments, users want greater transparency through explainable AI (XAI) systems. The author introduces XAI concepts, and gives an overview of areas in need of further exploration-such as type-2 fuzzy logic systems-to ensure such systems can be fully understood and analyzed by the lay user.},
keywords={artificial intelligence;fuzzy logic;computing power;artificial intelligence;XAI;type-2 fuzzy logic systems;AI systems;human-understandable;Artificial intelligence;Machine learning;Learning systems;Fuzzy logic;Intelligent systems;Future of AI;artificial intelligence;AI;intelligent systems;explainable artificial intelligence;machine leaning;Type-2 Fuzzy Logic Systems},
doi={10.1109/MC.2018.3620965},
ISSN={0018-9162},
month={Sep.},}
@INPROCEEDINGS{8455710,
author={R. {Tomsett} and A. {Widdicombe} and T. {Xing} and S. {Chakraborty} and S. {Julier} and P. {Gurram} and R. {Rao} and M. {Srivastava}},
booktitle={2018 21st International Conference on Information Fusion (FUSION)},
title={Why the Failure? How Adversarial Examples Can Provide Insights for Interpretable Machine Learning},
year={2018},
volume={},
number={},
pages={838-845},
abstract={Recent advances in Machine Learning (ML) have profoundly changed many detection, classification, recognition and inference tasks. Given the complexity of the battlespace, ML has the potential to revolutionise how Coalition Situation Understanding is synthesised and revised. However, many issues must be overcome before its widespread adoption. In this paper we consider two - interpretability and adversarial attacks. Interpretability is needed because military decision-makers must be able to justify their decisions. Adversarial attacks arise because many ML algorithms are very sensitive to certain kinds of input perturbations. In this paper, we argue that these two issues are conceptually linked, and insights in one can provide insights in the other. We illustrate these ideas with relevant examples from the literature and our own experiments.},
keywords={decision making;inference mechanisms;learning (artificial intelligence);military computing;interpretable machine learning;ML algorithms;military decision-makers;adversarial attacks;Coalition Situation Understanding;inference tasks;Task analysis;Machine learning;Measurement;Data models;Taxonomy;Internet;Sensors;interpretability;interpretable machine learning;deep learning;adversarial machine learning;adversarial examples;explainable AI;AI alignment;internet of battlefield things},
doi={10.23919/ICIF.2018.8455710},
ISSN={},
month={July},}
@INPROCEEDINGS{8389340,
author={Y. {Hasija} and N. {Garg} and S. {Sourav}},
booktitle={2017 International Conference on Intelligent Sustainable Systems (ICISS)},
title={Automated detection of dermatological disorders through image-processing and machine learning},
year={2017},
volume={},
number={},
pages={1047-1051},
abstract={Dermatological Diseases are one of the biggest medical issues in 21stcentury due to it's highly complex and expensive diagnosis with difficulties and subjectivity of human interpretation. In cases of fatal diseases like Melanoma diagnosis in early stages play a vital role in determining the probability of getting cured. We believe that the application of automated methods will help in early diagnosis especially with the set of images with variety of diagnosis. Hence, in this article we present a completely automated system of dermatological disease recognition through lesion images, a machine intervention in contrast to conventional medical personnel based detection. Our model is designed into three phases compromising of data collection and augmentation, designing model and finally prediction. We have used multiple AI algorithms like Convolutional Neural Network and Support Vector Machine and amalgamated it with image processing tools to form a better structure, leading to higher accuracy of 95.3%.},
keywords={biomedical optical imaging;diseases;image classification;learning (artificial intelligence);medical image processing;neural nets;skin;support vector machines;image processing tools;automated detection;dermatological disorders;Dermatological Diseases;expensive diagnosis;fatal diseases;Melanoma diagnosis;automated methods;early diagnosis;completely automated system;dermatological disease recognition;lesion images;machine intervention;conventional medical personnel;data collection;Support Vector Machine;multiple AI algorithms;convolutional neural network;Diseases;Support vector machines;Feature extraction;Training;Data models;Predictive models;Machine learning;Dermatological Disorders;Machine Learning;Image Processing;Automated Disease Diagnosis;AI algorithm;Computer Vision Techniques},
doi={10.1109/ISS1.2017.8389340},
ISSN={},
month={Dec},}
@INPROCEEDINGS{8490530,
author={A. {Holzinger}},
booktitle={2018 World Symposium on Digital Intelligence for Systems and Machines (DISA)},
title={From Machine Learning to Explainable AI},
year={2018},
volume={},
number={},
pages={55-66},
abstract={The success of statistical machine learning (ML) methods made the field of Artificial Intelligence (AI) so popular again, after the last AI winter. Meanwhile deep learning approaches even exceed human performance in particular tasks. However, such approaches have some disadvantages besides of needing big quality data, much computational power and engineering effort; those approaches are becoming increasingly opaque, and even if we understand the underlying mathematical principles of such models they still lack explicit declarative knowledge. For example, words are mapped to high-dimensional vectors, making them unintelligible to humans. What we need in the future are context-adaptive procedures, i.e. systems that construct contextual explanatory models for classes of real-world phenomena. This is the goal of explainable AI, which is not a new field; rather, the problem of explainability is as old as AI itself. While rule-based approaches of early AI were comprehensible “glass-box” approaches at least in narrow domains, their weakness was in dealing with uncertainties of the real world. Maybe one step further is in linking probabilistic learning methods with large knowledge representations (ontologies) and logical approaches, thus making results re-traceable, explainable and comprehensible on demand.},
keywords={learning (artificial intelligence);ontologies (artificial intelligence);probability;statistical machine learning methods;AI winter;deep learning approaches;big quality data;computational power;engineering effort;ontologies;knowledge representations;glass-box approaches;mathematical principles;artificial intelligence;logical approaches;probabilistic learning methods;rule-based approaches;contextual explanatory models;context-adaptive procedures;high-dimensional vectors;Machine learning;Data mining;Data visualization;Uncertainty;Games;Cognitive science},
doi={10.1109/DISA.2018.8490530},
ISSN={},
month={Aug},}
@INPROCEEDINGS{8599838,
author={A. {Preece} and D. {Harborne} and R. {Raghavendra} and R. {Tomsett} and D. {Braines}},
booktitle={MILCOM 2018 - 2018 IEEE Military Communications Conference (MILCOM)},
title={Provisioning Robust and Interpretable AI/ML-Based Service Bundles},
year={2018},
volume={},
number={},
pages={1-9},
abstract={Coalition operations environments are characterised by the need to share intelligence, surveillance and reconnaissance services. Increasingly, such services are based on artificial intelligence (AI)and machine learning (ML)technologies. Two key issues in the exploitation of AI/ML services are robustness and interpretability. Employing a diverse portfolio of services can make a system robust to `unknown unknowns'. Interpretability - the need for services to offer explanation facilities to engender user trust - can be addressed by a variety of methods to generate either transparent or post hoc explanations according to users' requirements. This paper shows how a service-provisioning framework for coalition operations can be extended to address specific requirements for robustness and interpretability, allowing automatic selection of service bundles for intelligence, surveillance and reconnaissance tasks. The approach is demonstrated in a case study on traffic monitoring featuring a diverse set of AI/ML services based on deep neural networks and heuristic reasoning approaches.},
keywords={artificial intelligence;Internet;learning (artificial intelligence);neural nets;trusted computing;coalition operations environments;reconnaissance services;service-provisioning framework;reconnaissance tasks;artificial intelligence;interpretable AI-ML-based service;machine learning technologies;Task analysis;Robustness;Surveillance;Reconnaissance;Cognition;Machine learning;intelligence;surveillance and reconnaissance;robustness;interpretability;reasoning;machine learning},
doi={10.1109/MILCOM.2018.8599838},
ISSN={2155-7586},
month={Oct},}
@ARTICLE{1687932,
author={N. B. {Karayiannis} and Y. {Xiong}},
journal={IEEE Transactions on Neural Networks},
title={Training Reformulated Radial Basis Function Neural Networks Capable of Identifying Uncertainty in Data Classification},
year={2006},
volume={17},
number={5},
pages={1222-1234},
abstract={This paper introduces a learning algorithm that can be used for training reformulated radial basis function neural networks (RBFNNs) capable of identifying uncertainty in data classification. This learning algorithm trains a special class of reformulated RBFNNs, known as cosine RBFNNs, by updating selected adjustable parameters to minimize the class-conditional variances at the outputs of their radial basis functions (RBFs). The experiments verify that quantum neural networks (QNNs) and cosine RBFNNs trained by the proposed learning algorithm are capable of identifying uncertainty in data classification, a property that is not shared by cosine RBFNNs trained by the original learning algorithm and conventional feed-forward neural networks (FFNNs). Finally, this study leads to a simple classification strategy that can be used to improve the classification accuracy of QNNs and cosine RBFNNs by rejecting ambiguous feature vectors based on their responses},
keywords={learning (artificial intelligence);radial basis function networks;uncertain systems;radial basis function neural networks;data classification;learning algorithm;uncertainty identification;class-conditional variances;quantum neural networks;feedforward neural networks;Radial basis function networks;Uncertainty;Intelligent networks;Neural networks;Feedforward neural networks;Feedforward systems;Function approximation;Training data;Classification algorithms;Cosine radial basis function (RBF);feed-forward neural network (FFNN);gradient descent learning;quantum neural network (QNN);radial basis function neural network (RBFNN);uncertainty;Algorithms;Artificial Intelligence;Cluster Analysis;Computer Simulation;Computing Methodologies;Data Interpretation, Statistical;Models, Statistical;Neural Networks (Computer);Pattern Recognition, Automated},
doi={10.1109/TNN.2006.877538},
ISSN={1045-9227},
month={Sep.},}
@INPROCEEDINGS{1380390,
author={ and and and },
booktitle={Proceedings of 2004 International Conference on Machine Learning and Cybernetics (IEEE Cat. No.04EX826)},
title={Information geometry on pruning of neural network},
year={2004},
volume={6},
number={},
pages={3479-3483 vol.6},
abstract={The problem of determining the proper size of an artificial neural network is recognized to be crucial. One popular approach is pruning which means training a larger than necessary network and removing unnecessary weights/nodes. Though pruning is commonly used in architecture learning of neural network, there is still no theoretical framework about it. We give an information geometric explanation of pruning. In information geometric framework, most kinds of neural networks form exponential or mixture manifold which has a natural hierarchical structure. In a hierarchical set of systems, a lower order system is included in the parameter space of a large one as a submanifold. Such a parameter space has rich geometrical structures that are responsible for the dynamic behaviors of learning. The pruning problem is formulated in iterative m-projections from the current manifold to its submanifold in which the divergence between the two manifolds is minimized, and it means meaning the network performance does not worsen over the entire pruning process. The result gives a geometric understanding and an information geometric guideline of pruning, which has more authentic theoretic foundation.},
keywords={information theory;artificial intelligence;iterative methods;neural net architecture;information geometry;artificial neural network;pruning;architecture learning;iterative m-projections;mixture manifold;exponential manifold;Information geometry;Neural networks;Artificial neural networks;Probability distribution;Computer science;Electronic mail;Guidelines;Information theory;Mathematical programming;Solid modeling},
doi={10.1109/ICMLC.2004.1380390},
ISSN={},
month={Aug},}
@INPROCEEDINGS{170682,
author={R. C. {Eberhart} and R. W. {Dobbins}},
booktitle={[Proceedings] 1991 IEEE International Joint Conference on Neural Networks},
title={Designing neural network explanation facilities using genetic algorithms},
year={1991},
volume={},
number={},
pages={1758-1763 vol.2},
abstract={The authors describe the use of genetic algorithms to provide components of explanation facilities for neural network applications. The genetic algorithm implementation, Genesis, uses a trained backpropagation neural network weight matrix as the genetic algorithm fitness function. Using different combinations of Genesis' run-time options, codebook vectors and decision surfaces are defined for the trained neural network. These vectors and surfaces can then be used as components of a facility that explains how the network is trained, and how it differentiates between classes. Two examples of this methodology are presented and briefly discussed. The first is a network trained to solve the XOR problem. The second is a network trained to diagnose appendicitis.<<ETX>>},
keywords={explanation;genetic algorithms;neural nets;diagnosis;neural network explanation facilities;genetic algorithms;Genesis;trained backpropagation neural network weight matrix;fitness function;run-time options;codebook vectors;decision surfaces;XOR problem;appendicitis;Algorithm design and analysis;Neural networks;Genetic algorithms;Physics;Laboratories;Runtime;Diagnostic expert systems;Abdomen;Pain;Genetic mutations},
doi={10.1109/IJCNN.1991.170682},
ISSN={},
month={Nov},}
@INPROCEEDINGS{218477,
author={R. {Bergmann}},
booktitle={CompEuro 1992 Proceedings Computer Systems and Software Engineering},
title={Explanation-based learning for the automated reuse of programs},
year={1992},
volume={},
number={},
pages={109-110},
abstract={A new approach for software reuse is presented which allows for the efficient preparation of already available programs, so that they can be automatically reused for novel programming tasks. Explanation-based learning from programs, guided by a domain theory of the semantics of the programming language, was used to acquire skeletal programs. For that purpose, a symbolic trace is constructed as an explanation of the functioning of a program, which may contain different types of control constructs such as sequential execution, conditional execution, and recursion. Explanation-based generalization was extended to explicitly handle these different kinds of execution control which are most essential for computer programs.<<ETX>>},
keywords={explanation;generalisation (artificial intelligence);high level languages;learning (artificial intelligence);software reusability;automated reuse;software reuse;novel programming tasks;domain theory;semantics;programming language;skeletal programs;symbolic trace;control constructs;sequential execution;conditional execution;recursion;execution control;computer programs;Automatic programming;Computer languages;Machine learning;Concrete;Artificial intelligence;Software reusability;Software engineering;Productivity;Software design;Software systems},
doi={10.1109/CMPEUR.1992.218477},
ISSN={},
month={May},}
@INPROCEEDINGS{1181456,
author={H. {Nunez} and C. {Angulo} and A. {Catala}},
booktitle={VII Brazilian Symposium on Neural Networks, 2002. SBRN 2002. Proceedings.},
title={Support vector machines with symbolic interpretation},
year={2002},
volume={},
number={},
pages={142-147},
abstract={In this work, a procedure for rule extraction from support vector machines (SVMs) is proposed. Our method first determines the prototype vectors by using k-means. Then, these vectors are combined with the support vectors using geometric methods to define ellipsoids in the input space, which are later translated to if-then rules. In this way, it is possible to give an interpretation to the knowledge acquired by the SVM. On the other hand, the extracted rules render possible the integration of SVMs with symbolic AI systems.},
keywords={neural nets;pattern classification;knowledge acquisition;symbol manipulation;learning (artificial intelligence);rule extraction;support vector machines;geometric methods;ellipsoids;pattern recognition;symbolic interpretation;knowledge acquisition;Support vector machines;Data mining;Neural networks;Prototypes;Artificial intelligence;Predictive models;Clustering algorithms;Support vector machine classification;Systems engineering and theory;Intelligent systems},
doi={10.1109/SBRN.2002.1181456},
ISSN={},
month={Nov},}
@INPROCEEDINGS{7099955,
author={L. {Travé-Massuyès} and S. {Gentil}},
booktitle={1999 European Control Conference (ECC)},
title={Artificial intelligence approaches for supervision and alarm interpretation in industrial environments},
year={1999},
volume={},
number={},
pages={3989-3994},
abstract={This paper discusses the potential benefits of artificial intelligence techniques. First, the role of alarm interpretation in complex process monitoring is examined followed by an analysis of the alarm interpretation task. The techniques used in several industrial applications are described. They are compared and the common features are highlighted. This paper has been written so as to provide the adequate introductory material to the ECC'99 invited session on Artificial Intelligence for Industrial Process Supervision.},
keywords={alarm systems;artificial intelligence;process monitoring;artificial intelligence approach;supervision interpretation;industrial environments;complex process monitoring;alarm interpretation task;artificial intelligence for industrial process supervision;Monitoring;Cognition;Expert systems;Numerical models;Sensors;Automata;Artificial intelligence techniques;process monitoring;alarm interpretation;diagnosis;industrial applications},
doi={10.23919/ECC.1999.7099955},
ISSN={},
month={Aug},}
@INPROCEEDINGS{8613997,
author={F. {Ahamed} and F. {Farid}},
booktitle={2018 International Conference on Machine Learning and Data Engineering (iCMLDE)},
title={Applying Internet of Things and Machine-Learning for Personalized Healthcare: Issues and Challenges},
year={2018},
volume={},
number={},
pages={19-21},
abstract={Personalized Healthcare (PH) is a new patientoriented healthcare approach which expects to improve the traditional healthcare system. The focus of this new advancement is the patient data collected from patient Electronic health records (EHR), Internet of Things (IoT) sensor devices, wearables and mobile devices, web-based information and social media. PH applies Artificial Intelligence (AI) techniques to the collected dataset to improve disease progression technique, disease prediction, patient selfmanagement and clinical intervention. Machine learning techniques are widely used in this regard to develop analytic models. These models are integrated into different healthcare service applications and clinical decision support systems. These models mainly analyse the collected data from sensor devices and other sources to identify behavioral patterns and clinical conditions of the patient. For example, these models analyse the collected data to identify the patient's improvements, habits and anomaly in daily routine, changes in sleeping and mobility, eating, drinking and digestive pattern. Based on those patterns the healthcare applications and the clinical decision support systems recommend lifestyle advice, special treatment and care plans for the patient. The doctors and caregivers can also be engaged in the care plan process to validate lifestyle advice. However, there are many uncertainties and a grey area when it comes to applying machine learning in this context. Clinical, behaviour and lifestyle data in nature are very sensitive. There could be different types of biased involved in the process of data collection and interpretation. The training data model could have an older version of the dataset. All these could lead to an incorrect decision from the system without the user's knowledge. In this paper, some of the standards of the ML models reported in the recent research trends, identify the reliability issues and propose improvements.},
keywords={data acquisition;decision support systems;diseases;electronic health records;health care;Internet of Things;learning (artificial intelligence);patient treatment;healthcare service applications;patient self-management;artificial intelligence techniques;Web-based information;Internet of Things sensor devices;electronic health records;healthcare system;electronic health records;ML models;training data model;data collection;lifestyle data;healthcare applications;clinical conditions;behavioral patterns;clinical decision support systems;machine learning techniques;clinical intervention;disease prediction;disease progression technique;social media;mobile devices;patient data;personalized healthcare;Machine learning;Internet of Things;Hospitals;Monitoring;Sleep apnea;Personalized Healthcare;Internet of Things;Machine Learning},
doi={10.1109/iCMLDE.2018.00014},
ISSN={},
month={Dec},}
@INPROCEEDINGS{8519384,
author={J. {Pei} and Y. {Huang} and W. {Huo} and Y. {Zhang} and J. {Yang}},
booktitle={IGARSS 2018 - 2018 IEEE International Geoscience and Remote Sensing Symposium},
title={Target Aspect Identification in SAR Image: A Machine Learning Approach},
year={2018},
volume={},
number={},
pages={2310-2313},
abstract={Identifying the aspect for a given target is an important issue in synthetic aperture radar (SAR) image interpretation. A new SAR target aspect identification method based on machine learning theory is proposed in this paper. First, the aspect angles of the SAR target are discretized, and the spatial relationships of the neighborhoods of the SAR target samples are established. Then an optimal linear mapping is solved based on the proposed subspace aspect discriminant analysis. The samples will be projected into a low-dimensional space and be of a better aspect identifiability than in their original space. Finally, the projected samples are fed into a multilayer neural network, and the aspects of the SAR targets will be indicated. Experimental results have shown the superiority of the proposed method based on the moving and stationary target acquisition and recognition (MSTAR) data set.},
keywords={image sampling;learning (artificial intelligence);multilayer perceptrons;radar computing;radar imaging;radar target recognition;synthetic aperture radar;optimal linear mapping;low-dimensional space;moving-and-stationary target acquisition-and-recognition data set;MSTAR data set;multilayer neural network;aspect angles;machine learning theory;SAR target aspect identification method;synthetic aperture radar image interpretation;SAR image;stationary target acquisition;projected samples;aspect identifiability;subspace aspect discriminant analysis;SAR target samples;Synthetic aperture radar;Multi-layer neural network;Estimation;Training;Neurons;Machine learning;Synthetic aperture radar;target aspect identification;machine learning;multi-layer neural network},
doi={10.1109/IGARSS.2018.8519384},
ISSN={2153-7003},
month={July},}
@INPROCEEDINGS{5621722,
author={H. Y. {Pan} and H. {He}},
booktitle={2010 Third International Conference on Business Intelligence and Financial Engineering},
title={Evaluation Techniques for Oil Gas Reservoir Based on Artificial Neural Networks Techniques},
year={2010},
volume={},
number={},
pages={28-31},
abstract={By using BP artificial nerve network's error reversion transmission. Summing up various data of comprehensive logging can solve the problem of low accurate rate for identifying oil, gas, water zones. The software provides nerve network reservoir interpretation model by studying and training the initial data of tested oil. Practice proves the overall coincidence rate of interpretation reaches 97%. It can more efficiently reflects logging technique's advantage of wellsite quick evaluation oil, gas, water zones. The application in this technique improves the level of logging data interpretation and evaluation.},
keywords={backpropagation;hydrocarbon reservoirs;neural nets;petroleum industry;evaluation technique;oil gas reservoir;artificial neural network technique;BP artificial nerve network;error reversion transmission;water zone;network nerve reservoir interpretation;tested oil;logging data interpretation;Hydrocarbon reservoirs;Artificial neural networks;Reservoirs;Data models;Training;Biological neural networks;artificial neural Networks;Oil;Gas and Water Layer;Mud Logging;Identification},
doi={10.1109/BIFE.2010.17},
ISSN={},
month={Aug},}
@ARTICLE{6877713,
author={S. Y. {Wong} and K. S. {Yap} and H. J. {Yap} and S. C. {Tan} and S. W. {Chang}},
journal={IEEE Transactions on Neural Networks and Learning Systems},
title={On Equivalence of FIS and ELM for Interpretable Rule-Based Knowledge Representation},
year={2015},
volume={26},
number={7},
pages={1417-1430},
abstract={This paper presents a fuzzy extreme learning machine (F-ELM) that embeds fuzzy membership functions and rules into the hidden layer of extreme learning machine (ELM). Similar to the concept of ELM that employed the random initialization technique, three parameters of F-ELM are randomly assigned. They are the standard deviation of the membership functions, matrix-C (rule-combination matrix), and matrix-D [don't care (DC) matrix]. Fuzzy if-then rules are formulated by the rule-combination Matrix of F-ELM, and a DC approach is adopted to minimize the number of input attributes in the rules. Furthermore, F-ELM utilizes the output weights of the ELM to form the target class and confidence factor for each of the rules. This is to indicate that the corresponding consequent parameters are determined analytically. The operations of F-ELM are equivalent to a fuzzy inference system. Several benchmark data sets and a real world fault detection and diagnosis problem have been used to empirically evaluate the efficacy of the proposed F-ELM in handling pattern classification tasks. The results show that the accuracy rates of F-ELM are comparable (if not superior) to ELM with distinctive ability of providing explicit knowledge in the form of interpretable rule base.},
keywords={fault diagnosis;fuzzy logic;fuzzy reasoning;knowledge representation;matrix algebra;pattern classification;FIS;interpretable rule-based knowledge representation;fuzzy extreme learning machine;F-ELM;fuzzy membership functions;random initialization technique;standard deviation;matrix-C;rule-combination matrix;matrix-D;don't care matrix;fuzzy if-then rules;fuzzy inference system;fault detection;fault diagnosis problem;pattern classification tasks;interpretable rule base;Artificial neural networks;Neurons;Fuzzy logic;Pragmatics;Training;Accuracy;Computational modeling;Extreme learning machine (ELM);fuzzy inference system (FIS);pattern classification;rule based;Extreme learning machine (ELM);fuzzy inference system (FIS);pattern classification;rule based;Algorithms;Artificial Intelligence;Benchmarking;Classification;Databases, Factual;Feedback;Fuzzy Logic;Machine Learning;Models, Statistical;Neural Networks (Computer);Neurons;Power Plants;Reproducibility of Results},
doi={10.1109/TNNLS.2014.2341655},
ISSN={2162-237X},
month={July},}
@INPROCEEDINGS{8258557,
author={S. {Shirataki} and S. {Yamaguchi}},
booktitle={2017 IEEE International Conference on Big Data (Big Data)},
title={A study on interpretability of decision of machine learning},
year={2017},
volume={},
number={},
pages={4830-4831},
abstract={Machine learning is one of the most important fields in recent improvement in big data analysis. Many people apply machine learning for a variety of domains for various purposes, such as classification of opinions. However, the constructed models of machine learning are black boxes. They cannot understand the background reason for their decisions. In many cases, understanding the reasons important. In this paper, we focus on interpretation of models and understanding of decision reasons. First, we introduce the results of an opinions classification of the reviews with Support Vector Machine (SVM). Second, we interpret the model by analyzing weights of the model. Third, we introduce a method for helping to understand the reasons for a decision by SVM by providing a simplified information of the highly weighted words.},
keywords={Big Data;data analysis;learning (artificial intelligence);pattern classification;support vector machines;text analysis;machine learning;decision reasons;Support Vector Machine;big data analysis;SVM;highly weighted words;black boxes;opinions classification;Support vector machines;DVD;Analytical models;Predictive models;Training;Big Data;Tools;SVM;machine learning;interpretability},
doi={10.1109/BigData.2017.8258557},
ISSN={},
month={Dec},}
@INPROCEEDINGS{190514,
author={T. L. {McCluskey}},
booktitle={IEE Colloquium on Machine Learning},
title={Empirical results from applying machine learning techniques to planning},
year={1990},
volume={},
number={},
pages={6/1-6/3},
abstract={Outlines an experimental machine learning implementation, called 'FM', that applies both explanation based learning and similarity-based learning to AI planners. The system shell of FM contains techniques for learning application-dependent heuristics, through the experience of using a performance component (a planner) in that application. An application domain is supplied by specifying a set of action schemas, and environmental facts and rules. FM is then fed an initial state, and a sequence of tasks within this application, roughly in ascending order of complexity, which it is expected to solve. After each task has been solved, the system analyses the planning trace, allowing it to learn from experience.<<ETX>>},
keywords={artificial intelligence;learning systems;explanation based learning;machine learning;planning;similarity-based learning;AI planners;application-dependent heuristics;Artificial intelligence;Learning systems},
doi={},
ISSN={},
month={June},}
@INPROCEEDINGS{287210,
author={ and and },
booktitle={[Proceedings 1992] IJCNN International Joint Conference on Neural Networks},
title={A conceptual interpretation of spurious memories in the Hopfield-type neural network},
year={1992},
volume={1},
number={},
pages={21-26 vol.1},
abstract={It is shown that the spurious memories are represented as logical combinations of the learned memories. By assigning a conceptual interpretation to each learned memory, the spurious memories can be interpreted as novel conceptual knowledge created by the network. It is proposed that the generation of spurious memories be considered a primitive creativity that the simple network exhibits in high-level information processing.<<ETX>>},
keywords={Hebbian learning;Hopfield neural nets;knowledge representation;Hopfield-type neural network;spurious memories;learned memories;conceptual interpretation;conceptual knowledge;creativity;Intelligent networks;Neural networks;Hopfield neural networks;Neurons;Information processing;Samarium;Cities and towns;Artificial intelligence;Artificial neural networks;Art},
doi={10.1109/IJCNN.1992.287210},
ISSN={},
month={June},}
@INPROCEEDINGS{118339,
author={},
booktitle={International 1989 Joint Conference on Neural Networks},
title={Handling knowledge in high order neural networks: the combinatorial neural model},
year={1989},
volume={},
number={},
pages={582 vol.2-},
abstract={Summary form only given, as follows. A description is given of the combinatorial neural model, a high-order neural network suitable for classification tasks. The model is based on fuzzy set theory, neural sciences studies, and expert knowledge analysis results. It presents interesting properties such as modularity, explanation capacity, knowledge and data representation, high speed of training, incremental learning, generalization capacity, processing of uncertain and incomplete data, and ability to reason nonmonotonically when representing only relevant evidence, and graceful decay.<<ETX>>},
keywords={explanation;fuzzy set theory;knowledge representation;neural nets;knowledge representation;neural nets;uncertain data;nonmonotonic reasoning;high order neural networks;combinatorial neural model;classification;fuzzy set theory;neural sciences;expert knowledge analysis;modularity;explanation capacity;data representation;training;incremental learning;generalization capacity;incomplete data;Explanation;Fuzzy sets;Knowledge representation;Neural networks},
doi={10.1109/IJCNN.1989.118339},
ISSN={},
month={},}
@INPROCEEDINGS{7334730,
author={C. {Song} and F. {Li} and L. {Xiao} and L. {Feng}},
booktitle={2015 7th International Conference on Intelligent Human-Machine Systems and Cybernetics},
title={Soft Sensor Modeling Based on Extreme Learning Machine and Case-Based Reasoning},
year={2015},
volume={1},
number={},
pages={391-394},
abstract={Neural network (NN) and Case-based reasoning (CBR) have common advantages over other learning strategies. NN and CBR can be directly applied to the classification and regression problem without additional transform mechanisms. However, they all have disadvantages. The knowledge representation of NN is unreadable and this black box property restricts the application of NN to areas which needs proper explanations. Meanwhile CBR suffers from the feature-weighting problem, when CBR measures the distance between cases, some input features should be treated more importantly than others. This paper, we propose a hybrid prediction system of extreme learning machine (ELM) and Case-based reasoning (ELM-CBR). In our hybrid system, the feature weight set calculated from the trained ELM network plays the core role in connecting both the learning strategies, and the explanation on prediction can be given by presenting the most similar cases from the case base. Moreover, the prediction value of the Online Sequential Extreme Learning Machine also utilized in conjunction with the neighborhood information. This provides extended information for the query with most similar cases in the database. Finally, we present an application in the sugarcane juice clarification, experiments show that the hybrid system has a better recognition rate compared the k-NN and GA-CBR method.},
keywords={beverages;case-based reasoning;learning (artificial intelligence);neural nets;soft sensor modeling;case-based reasoning;neural network;NN;CBR;regression problem;knowledge representation;black box property;feature-weighting problem;trained ELM network;learning strategies;online sequential extreme learning machine;sugarcane juice clarification;hybrid system;recognition rate;Artificial neural networks;Cognition;Training;Image color analysis;Sugar industry;Classification algorithms;extreme learning machine;case-based reasoning;feature weighting;juice clarification},
doi={10.1109/IHMSC.2015.39},
ISSN={},
month={Aug},}
@INPROCEEDINGS{343689,
author={R. {Kamimura} and R. R. {Yager} and S. {Nakanishi}},
booktitle={Proceedings of 1994 IEEE 3rd International Fuzzy Systems Conference},
title={Representing acquired knowledge of neural networks by fuzzy sets: control of internal information of neural networks by entropy minimization},
year={1994},
volume={},
number={},
pages={58-63 vol.1},
abstract={The authors propose an entropy algorithm to extract the internal information of the neural networks, and show that the extracted information is expressed by fuzzy sets. Fuzzy sets representing internal information of neural networks after learning are composed of the competitive hidden unit activities which can be controlled by the entropy method. We apply this method to meaning interpretation of alphabet.<<ETX>>},
keywords={fuzzy neural nets;fuzzy set theory;knowledge representation;learning (artificial intelligence);entropy;knowledge representation;neural networks;fuzzy set theory;internal information;entropy minimization;learning;competitive hidden unit;alphabet interpretation;Neural networks;Fuzzy sets;Entropy;Data mining;Minimization methods;Shape;Information science;Machine intelligence;Machine learning;Knowledge acquisition},
doi={10.1109/FUZZY.1994.343689},
ISSN={},
month={June},}
@INPROCEEDINGS{8529552,
author={A. {Karnewar}},
booktitle={2018 3rd International Conference for Convergence in Technology (I2CT)},
title={AANN: Absolute Artificial Neural Network},
year={2018},
volume={},
number={},
pages={1-6},
abstract={This research paper describes a simplistic architecture named as AANN: Absolute Artificial Neural Network, which can be used to create highly interpretable representations of the input data. These representations are generated by penalizing the learning of the network in such a way that those learned representations correspond to the respective labels present in the labeled dataset used for supervised training; thereby, simultaneously giving the network the ability to classify the input data. The network can be used in the reverse direction to generate data that closely resembles the input by feeding in representation vectors as required. This research paper also explores the use of mathematical abs (absolute valued) functions as activation functions which constitutes the core part of this neural network architecture. Finally the results obtained on the MNIST dataset by using this technique are presented and discussed in brief.},
keywords={data structures;learning (artificial intelligence);neural net architecture;neural nets;pattern classification;transfer functions;representation vectors;neural network architecture;AANN;input data representations;absolute artificial neural network;input data classification;mathematical abs functions;absolute valued functions;activation functions;Training;Neurons;Generative adversarial networks;Artificial neural networks;Backpropagation;Task analysis;artificial neural networks;supervised learning;knowledge representation;Backpropagation},
doi={10.1109/I2CT.2018.8529552},
ISSN={},
month={April},}
@INPROCEEDINGS{8666524,
author={B. {Czejdo} and S. {Bhattacharya} and C. {Spooner}},
booktitle={2019 IEEE 9th Annual Computing and Communication Workshop and Conference (CCWC)},
title={Improvement of Protein Model Scoring Using Grouping and Interpreter for Machine Learning},
year={2019},
volume={},
number={},
pages={0349-0353},
abstract={In this paper, we describe our protein folding research with the goal of improving protein model scoring by grouping of protein models and using an interpreter for machine learning (ML). The traditional approach is to use a handful of popular ML algorithms, such as Support Vector Machines (SVM), Random Forest and Neural Networks that are trained on a whole set of models. Our approach is to group the protein models and train the ML algorithms on each group separately. Our framework can be generalized to other application of ML where there is a strong diversification of data set. In this paper, we describe results of comparison of traditional vs. our grouping approach showing that some improvement in the scoring of protein models can be achieved. To further improve the scoring, an interpreter for machine learning is used. The interpreter is based on Local Interpretable Model-Agnostic Explanations (LIME) tool. In this paper it is used to determine feature vector for each group of protein models. Different feature vectors are then used for ML training on different groups of protein models allowing us to improve the ML algorithms. In addition, interpreter of ML can be used in the future to provide feedback for the process of protein models generation.},
keywords={bioinformatics;feature extraction;learning (artificial intelligence);proteins;protein model scoring;machine learning;grouping approach;ML algorithms;support vector machines;SVM;random forest;neural networks;LIME;local interpretable model-agnostic explanations tool;feature vector;Proteins;Training;Machine learning;Machine learning algorithms;Computational modeling;Solid modeling;Predictive models;Bioinformatics;Machine Learning;Protein Models;Model Scoring;Interpretation-Generating Algorithms},
doi={10.1109/CCWC.2019.8666524},
ISSN={},
month={Jan},}
@INPROCEEDINGS{128603,
author={J. P. E. {Hodgson} and R. B. {Banerji}},
booktitle={Proceedings. 5th IEEE International Symposium on Intelligent Control 1990},
title={AI research activities at Saint Joseph's University},
year={1990},
volume={},
number={},
pages={1178-1179 vol.2},
abstract={Research activities in artificial intelligence at Saint Joseph's University are described. There has been significant progress in both basic research and system implementation in the last few years. The software developed pertains to search pruning for problem solving, learning from examples (similarity-based learning as it is often called), and explanation-based generalization and self-improving game-playing programs. The work on similarity-based learning can support the automatic formation of expert rules. All of this work is based on the basic research. Activities in the areas of the theory of problem solving, learning algorithms, and software development are described.<<ETX>>},
keywords={artificial intelligence;learning systems;software engineering;AI research activities;Saint Joseph's University;system implementation;search pruning;problem solving;explanation-based generalization;self-improving game-playing programs;automatic formation;expert rules;learning algorithms;software development;Artificial intelligence;Problem-solving;Machine learning;Calculus;Computer science;Mathematics;Personnel;Laboratories;Pattern recognition;Learning systems},
doi={10.1109/ISIC.1990.128603},
ISSN={2158-9860},
month={Sep.},}
@ARTICLE{4359988,
author={H. {Lin}},
journal={IEEE Transactions on Biomedical Engineering},
title={Identification of Spinal Deformity Classification With Total Curvature Analysis and Artificial Neural Network},
year={2008},
volume={55},
number={1},
pages={376-382},
abstract={In this paper, a multilayer feed-forward, back-propagation (MLFF/BP) artificial neural network (ANN) was implemented to identify the classification patterns of the scoliosis spinal deformity. At the first step, the simplified 3D spine model was constructed based on the coronal and sagittal X-ray images. The features of the central axis curve of the spinal deformity patterns in 3D space were extracted by the total curvature analysis. The discrete form of the total curvature, including the curvature and the torsion of the central axis of the simplified 3D spine model was derived from the difference quotients. The total curvature values of 17 vertebrae from the first thoracic to the fifth lumbar spine formed a Euclidean space of 17 dimensions. The King classification model was tested on this MLFF/BP ANN identification system. The 17 total curvature values were presented to the input layer of MLFF/BP ANN. In the output layer there were five neurons representing five King classification types. A total of 37 spinal deformity patterns from scoliosis patients were selected. These 37 patterns were divided into two groups. The training group had 25 patterns and testing group had 12 patterns. The 25-pattern training group was further divided into five subsets. Based on the definition of King classification system, each subset contained all five King types. The network training was conducted on these five subsets by the hold-out method, one of cross-validation variants, and the early stop method. In each one of the five cross-validation sessions, four subsets were alternatively used for estimation learning and one subset left was used for validation learning. Final network testing was conducted with remaining 12 patterns in testing group after the MLFF/BP ANN was trained by all five subsets in training group. The performance of the neural network was evaluated by comparing between two network topologies, one with one hidden layer and another with two hidden layers. The results are shown in three tables. The first table shows network errors in estimation learning and the second table shows identification rates in validation learning. The network errors and identification rates in the last round of network training and testing are shown in the third table. Each table has a comparison for both one hidden layer and two hidden layer networks.},
keywords={backpropagation;biomechanics;bone;diagnostic radiography;feature extraction;image classification;medical computing;medical image processing;multilayer perceptrons;scoliosis spinal deformity classification patterns;total curvature analysis;artificial neural network;multilayer feed-forward back-propagation;MLFF-BP ANN identification system;3-D spine model;coronal X-ray images;sagittal X-ray images;feature extraction;difference quotients;Euclidean space;King classification model;hold-out method;cross-validation variants;hidden layer networks;estimation learning;validation learning;Artificial neural networks;Spine;Multi-layer neural network;Feedforward systems;X-ray imaging;Pattern analysis;System testing;Neurons;Neural networks;Network topology;Artificial neural network (ANN);difference quotients;scoliosis;space curve;spinal deformity classification;torsion;total curvature analysis;Spinal deformity;classification;scoliosis;total curvature analysis;space curve;torsion;difference quotients;artificial neural network;Algorithms;Artificial Intelligence;Humans;Imaging, Three-Dimensional;Neural Networks (Computer);Pattern Recognition, Automated;Radiographic Image Enhancement;Radiographic Image Interpretation, Computer-Assisted;Reproducibility of Results;Scoliosis;Sensitivity and Specificity},
doi={10.1109/TBME.2007.894831},
ISSN={0018-9294},
month={Jan},}
@INPROCEEDINGS{8622073,
author={R. {Chhatwal} and P. {Gronvall} and N. {Huber-Fliflet} and R. {Keeling} and J. {Zhang} and H. {Zhao}},
booktitle={2018 IEEE International Conference on Big Data (Big Data)},
title={Explainable Text Classification in Legal Document Review A Case Study of Explainable Predictive Coding},
year={2018},
volume={},
number={},
pages={1905-1911},
abstract={In today's legal environment, lawsuits and regulatory investigations require companies to embark upon increasingly intensive data-focused engagements to identify, collect and analyze large quantities of data. When documents are staged for review - where they are typically assessed for relevancy or privilege - the process can require companies to dedicate an extraordinary level of resources, both with respect to human resources, but also with respect to the use of technology-based techniques to intelligently sift through data. Companies regularly spend millions of dollars producing `responsive' electronically-stored documents for these types of matters. For several years, attorneys have been using a variety of tools to conduct this exercise, and most recently, they are accepting the use of machine learning techniques like text classification (referred to as predictive coding in the legal industry) to efficiently cull massive volumes of data to identify responsive documents for use in these matters. In recent years, a group of AI and Machine Learning researchers have been actively researching Explainable AI. In an explainable AI system, actions or decisions are human understandable. In typical legal `document review' scenarios, a document can be identified as responsive, as long as one or more of the text snippets (small passages of text) in a document are deemed responsive. In these scenarios, if predictive coding can be used to locate these responsive snippets, then attorneys could easily evaluate the model's document classification decision. When deployed with defined and explainable results, predictive coding can drastically enhance the overall quality and speed of the document review process by reducing the time it takes to review documents. Moreover, explainable predictive coding provides lawyers with greater confidence in the results of that supervised learning task. The authors of this paper propose the concept of explainable predictive coding and simple explainable predictive coding methods to locate responsive snippets within responsive documents. We also report our preliminary experimental results using the data from an actual legal matter that entailed this type of document review. The purpose of this paper is to demonstrate the feasibility of explainable predictive coding in the context of professional services in the legal space.},
keywords={law administration;pattern classification;supervised learning;text analysis;responsive documents;explainable AI system;typical legal document review scenarios;responsive snippets;text classification;explainable predictive coding methods;data-focused engagements;technology-based techniques;machine learning researchers;document classification;supervised learning task;electronically-stored documents;Predictive coding;Law;Predictive models;Text categorization;Machine learning;machine learning;text categorization;explainable AI;predictive coding;explainable predictive coding;legal document review},
doi={10.1109/BigData.2018.8622073},
ISSN={},
month={Dec},}
@INPROCEEDINGS{614209,
author={M. {Georgiopoulos} and I. {Dagher} and G. L. {Heileman} and G. {Bebis}},
booktitle={Proceedings of International Conference on Neural Networks (ICNN'97)},
title={Properties of learning of a fuzzy ART variant},
year={1997},
volume={3},
number={},
pages={2012-2016 vol.3},
abstract={This paper discusses one variation of the fuzzy ART architecture, referred to as fuzzy ART variant. The fuzzy ART variant is a fuzzy ART algorithm, with a very large value for the choice parameter. Based on the geometrical interpretation of templates in fuzzy ART we present and prove useful properties of learning pertaining to the fuzzy ART variant. One of these properties of learning establishes an upper bound on the number of list presentations required by the fuzzy ART variant to learn an arbitrary list of input patterns presented to it. In previously published work, it was shown that the fuzzy ART variant performs as well as a fuzzy ART algorithm with more typical values for the choice parameter. Hence, the fuzzy ART variant is as good a clustering machine as the fuzzy ART algorithm using more typical values of the choice parameter.},
keywords={ART neural nets;fuzzy neural nets;learning (artificial intelligence);neural net architecture;geometry;learning properties;fuzzy ART variant neural net architecture;geometrical interpretation;templates;clustering machine;Subspace constraints;Fuzzy neural networks;Clustering algorithms;Supervised learning;Neural networks;Data preprocessing;Pattern clustering;Fuzzy logic;Computer architecture;Upper bound},
doi={10.1109/ICNN.1997.614209},
ISSN={},
month={June},}
@ARTICLE{7063914,
author={N. {Chang} and K. {Bai} and C. {Chen}},
journal={IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing},
title={Smart Information Reconstruction via Time-Space-Spectrum Continuum for Cloud Removal in Satellite Images},
year={2015},
volume={8},
number={5},
pages={1898-1912},
abstract={Cloud contamination is a big obstacle when processing satellite images retrieved from visible and infrared spectral ranges for application. Although computational techniques including interpolation and substitution have been applied to recover missing information caused by cloud contamination, these algorithms are subject to many limitations. In this paper, a novel smart information reconstruction (SMIR) method is proposed, in order to reconstruct cloud contaminated pixel values from the time-space-spectrum continuum with the aid of a machine learning tool, namely extreme learning machine (ELM). For the purpose of demonstration, the performance of SMIR is evaluated by reconstructing the missing remote sensing reflectance values derived from the Moderate Resolution Imaging Spectroradiometer (MODIS) on board the Terra satellite over Lake Nicaragua, where is a very cloudy area year round. For comparison, the traditional backpropagation neural network algorithms will also be implemented to reconstruct the missing values. Experimental results show that the ELM outperforms the BP algorithms by an enhanced machine learning capacity with simulated memory effect embedded in MODIS due to linking the complex time-space-spectrum continuum between cloud-free and cloudy pixels. The ELM-based SMIR practice presents a correlation coefficient of 0.88 with root mean squared error of 7.4E - 04sr<sup>-1</sup> between simulated and observed reflectance values. Finding suggests that the SMIR method is effective to reconstruct all the missing information providing visually logical and quantitatively assured images for further image processing and interpretation in environmental applications.},
keywords={clouds;geophysical image processing;image reconstruction;lakes;learning (artificial intelligence);neural nets;reflectivity;remote sensing;smart information reconstruction;time-space-spectrum continuum;cloud removal;cloud contamination;satellite image processing;visible spectral range;infrared spectral range;computational technique;missing information recovery;SMIR method;cloud contaminated pixel reconstruction;machine learning tool;extreme learning machine;missing remote sensing reflectance value;moderate resolution imaging spectroradiometer;Terra satellite;Lake Nicaragua;cloudy area;backpropagation neural network algorithm;enhanced machine learning capacity;cloud-free;cloudy pixel;ELM-based SMIR practice;root mean squared error;environmental application;Clouds;Training;Image reconstruction;Remote sensing;Satellites;Neural networks;Contamination;Artificial neural network;cloud removal;computational intelligence;extreme learning machine;machine learning;satellite images;Artificial neural network;cloud removal;computational intelligence;extreme learning machine;machine learning;satellite images},
doi={10.1109/JSTARS.2015.2400636},
ISSN={1939-1404},
month={May},}
@INPROCEEDINGS{1295633,
author={C. G. {Fernando} and R. {Munasinghe}},
booktitle={Thirty-Sixth Southeastern Symposium on System Theory, 2004. Proceedings of the},
title={Hybrid AI system for geometric pattern recognition},
year={2004},
volume={},
number={},
pages={128-131},
abstract={The research area of hybrid and neural processing has been actively developing. Hybrid neural systems are computational systems which are based mainly on artificial neural networks but also allow a symbolic interpretation or interaction with symbolic classical artificial intelligence. In this paper we describe a hybrid AI system developed for 2D object recognition. The 2D object recognition system was developed as the initial step for developing a 3D object recognition system for an unmanned aerial vehicle (UAV).},
keywords={artificial intelligence;neural nets;object recognition;remotely operated vehicles;computer vision;hybrid AI system;geometric pattern recognition;hybrid neural systems;computational systems;artificial neural networks;symbolic interpretation;artificial intelligence;2D object recognition;unmanned aerial vehicle;Pattern recognition;Artificial intelligence;Object recognition;Biological neural networks;Neurons;Artificial neural networks;Expert systems;Robustness;Humans;Computer networks},
doi={10.1109/SSST.2004.1295633},
ISSN={0094-2898},
month={March},}
@INPROCEEDINGS{8489490,
author={K. E. {Smith} and P. {Williams} and K. J. {Bryan} and M. {Solomon} and M. {Ble} and R. {Haber}},
booktitle={2018 International Joint Conference on Neural Networks (IJCNN)},
title={Shepard Interpolation Neural Networks with K-Means: A Shallow Learning Method for Time Series Classification},
year={2018},
volume={},
number={},
pages={1-6},
abstract={Deep neural network architectures have redefined benchmark machine learning challenges, from classification to anomaly detection, and have become popular in the time series domain. However, deep learning techniques fall short in time series classification (TSC) because the explainability of deep learning is still abstract, and the training requires vast amounts of data, which utilizes computational power. These obstacles are not the case with Shepard Interpolation Neural Networks (SINN), a shallow learning architecture approach for deep learning tasks. Based on a statistical interpolation technique rather than a biological brain, SINN require little data to achieve high accuracy in its training. Additionally, its explainability can be equated to feature mapping onto hyper surfaces in the feature space. Our proposed algorithm outperforms the other state-of-the-art algorithms on the popular UCR time series classification benchmark data set and outperforms LSTMs on data sets which have significantly smaller training data than testing.},
keywords={interpolation;learning (artificial intelligence);neural nets;pattern classification;time series;Shepard interpolation neural networks;shallow learning method;neural network architectures;benchmark machine learning challenges;time series domain;deep learning techniques;Shepard Interpolation Neural Networks;SINN;deep learning tasks;statistical interpolation technique;K-means;UCR time series classification benchmark data;Interpolation;Neurons;Time series analysis;Measurement;Machine learning;Neural networks;Task analysis;Time Series Classification;Neural Networks;Shallow and Deep Learning;Shepard Interpolation;Unsupervised Clustering},
doi={10.1109/IJCNN.2018.8489490},
ISSN={2161-4407},
month={July},}
@INPROCEEDINGS{1259707,
author={ and and and and },
booktitle={Proceedings of the 2003 International Conference on Machine Learning and Cybernetics (IEEE Cat. No.03EX693)},
title={Information geometry on extendable hierarchical large scale neural network model},
year={2003},
volume={3},
number={},
pages={1380-1384 Vol.3},
abstract={In this paper, an extendable hierarchical large scale neural network model is developed based on the theoretical analysis of information geometry. In a hierarchical set of systems, a lower order system is included in the parameter space of a larger one as a subset. Such a parameter space has rich geometrical structures that are responsible for the dynamic behaviors of learning. Extendable hierarchical large scale neural network divides a task into small tasks, and each task is fulfilled by a small network under the principle of divide and conquer to improve the performance of a single network. By studying the dual manifold architecture for a family of neural networks and analyzing the hierarchical expansion of this model based on information geometry, the paper proposes a new method to construct the extendable hierarchical large scale neural network model that has knowledge-increasable and structure-extendible ability. The method helps to provide explanation of the transformation mechanism of human recognition system and understand the theory of global architecture of neural network.},
keywords={neural nets;learning (artificial intelligence);large-scale systems;hierarchical systems;statistical distributions;geometry;cognition;extendable hierarchical large scale neural network model;information geometry;lower order system;parameter space;learning behaviors;human recognition system;dual flat manifold architecture;Information geometry;Large-scale systems;Neural networks;Solid modeling;Probability distribution;Information analysis;Computer science;Electronic mail;Humans;Information theory},
doi={10.1109/ICMLC.2003.1259707},
ISSN={},
month={Nov},}
@ARTICLE{737497,
author={ and V. {Honavar}},
journal={IEEE Transactions on Neural Networks},
title={A neural-network architecture for syntax analysis},
year={1999},
volume={10},
number={1},
pages={94-114},
abstract={Artificial neural networks (ANNs), due to their inherent parallelism, offer an attractive paradigm for implementation of symbol processing systems for applications in computer science and artificial intelligence. The paper explores systematic synthesis of modular neural-network architectures for syntax analysis using a prespecified grammar-a prototypical symbol processing task which finds applications in programming language interpretation, syntax analysis of symbolic expressions, and high-performance compilers. The proposed architecture is assembled from ANN components for lexical analysis, stack, parsing and parse tree construction. Each of these modules takes advantage of parallel content-based pattern matching using a neural associative memory. The proposed neural-network architecture for syntax analysis provides a relatively efficient and high performance alternative to current computer systems for applications that involve parsing of LR grammars which constitute a widely used subset of deterministic context-free grammars. Comparison of quantitatively estimated performance of such a system (implemented using current CMOS VLSI technology) with that of conventional computers demonstrates the benefits of massively parallel neural-network architectures for symbol processing applications.},
keywords={context-free grammars;program compilers;pattern matching;content-addressable storage;symbol manipulation;neural net architecture;syntax analysis;inherent parallelism;symbol processing systems;computer science;artificial intelligence;modular neural-network architectures;programming language interpretation;symbolic expressions;high-performance compilers;lexical analysis;parsing;parse tree construction;parallel content-based pattern matching;neural associative memory;LR grammars;deterministic context-free grammars;Computer architecture;Application software;Artificial neural networks;CMOS technology;Parallel processing;Computer science;Artificial intelligence;Network synthesis;Prototypes;Computer languages},
doi={10.1109/72.737497},
ISSN={1045-9227},
month={Jan},}
@INPROCEEDINGS{6016793,
author={T. {Wang} and T. {Yu}},
booktitle={2011 International Conference on Machine Learning and Cybernetics},
title={Application of neural network to identify the remote sensing data of hillslide},
year={2011},
volume={2},
number={},
pages={661-665},
abstract={This study presents the results of neural network simulation of hillside area prediction from remote sensing data. Five neural network methods were compared, which were Back Propagation Network (BPN), Extend Neuron Networks (ENN), Fuzzy Neural Network (FNN), Analysis Adjustment Synthesis Network (AASN), and Genetic Algorithm Neural Network (GANN). Three factors were used as the predictor in this study, which were NDVI value, shape factor, and color difference. The result reveals that the BPN is the best choice, because the error is the lowest among the five schemes in this study.},
keywords={genetic algorithms;geophysics computing;image processing;neural nets;remote sensing;remote sensing data;hillslide;neural network simulation;hillside area prediction;back propagation network;BPN;extend neuron networks;ENN;fuzzy neural network;FNN;analysis adjustment synthesis network;AASN;genetic algorithm neural network;GANN;Biological neural networks;Remote sensing;Shape;Image color analysis;Machine learning;Cybernetics;Data models;Neural network;Image identification;Image interpretation;Image variation},
doi={10.1109/ICMLC.2011.6016793},
ISSN={2160-1348},
month={July},}
@INPROCEEDINGS{714304,
author={ and },
booktitle={Proceedings of 1993 International Conference on Neural Networks (IJCNN-93-Nagoya, Japan)},
title={A decision support system using neural networks in a glass furnace process},
year={1993},
volume={3},
number={},
pages={2795-2798 vol.3},
abstract={A decision support system using artificial neural networks is implemented with real world data of a glass furnace process at Samsung. It provides the functions such as process model identification, set-point control and interpreting input factors. Since a glass furnace process is highly complex, a traditional attempt to develop a model from first principles often proves to be a difficult and costly procedure. However, the decision support system using artificial neural networks does not require a priori knowledge of a glass furnace process and proves to be useful in identifying the model directly by input/output data collected from the plant. This paper shows the method of finding the partial derivative value at some point from trained weights, the conversion method of a 3-layered perceptron network into a 2-layered one, and the interpretation method of neural networks solutions.},
keywords={multilayer perceptrons;furnaces;glass industry;decision support systems;process control;decision support system;glass furnace;artificial neural networks;Samsung;process model identification;set-point control;partial derivative value;3-layered perceptron network;2-layered network;Decision support systems;Neural networks;Intelligent networks;Glass manufacturing;Artificial neural networks;Thermal variables control;Chemical processes;Petroleum;Furnaces;Artificial intelligence},
doi={10.1109/IJCNN.1993.714304},
ISSN={},
month={Oct},}
@INPROCEEDINGS{8614007,
author={H. {Yanagimto} and K. {Hashimoto} and M. {Okada}},
booktitle={2018 International Conference on Machine Learning and Data Engineering (iCMLDE)},
title={Attention Visualization of Gated Convolutional Neural Networks with Self Attention in Sentiment Analysis},
year={2018},
volume={},
number={},
pages={77-82},
abstract={Deep learning is applied to many research topics; Natural Language Processing, Image Processing, and Acoustic Recognition. In deep learning, neural networks have a very complex and deep structure and it is difficult to discuss why they work well or not. So you have to take a trial-and-error to improve their performances. We develop a mechanism to show how neural networks predict final results and help you to design a new neural network architecture based on its prediction criteria. Speaking concrete, we visualize important features to predict the final results with an attentional mechanism. In this paper, we take up sentient analysis, which is one of natural language processing tasks. In image processing visualizing weights of a neural network is a major approach and you can obtain intuitive results; object outlines and object components. However, in natural language processing, the approach is not interpretable because a discriminate function constructed by a neural network is a complex and nonlinear one and it is very difficult to correlate weights and words in a text. We employ Gated Convolutional Neural Network (GCNN) and introduce a self-attention mechanism to understand how GCNN determines sentiment polarities from raw reviews. GCNN can simulate an n-gram model and the self-attention mechanism can make correspondence between weights of a neural network and words clear. In experiments, we used Amazon reviews and evaluated the performance of the proposed method. Especially, the proposed method was able to emphasize some words in the review to determine sentiment polarity. Moreover, when the prediction was wrong, we were able to understand why the proposed method made mistakes because we found what words the proposed method emphasized.},
keywords={convolutional neural nets;learning (artificial intelligence);neural net architecture;sentiment analysis;neural network architecture;self-attention mechanism;Amazon reviews;GCNN;sentient analysis;attention visualization;natural language processing;gated convolutional neural networks;deep learning;Logic gates;Convolutional neural networks;Kernel;Sentiment analysis;Task analysis;Deep learning;Natural language processing;Gated CNN;Sentiment analysis;the self-attention mechanism},
doi={10.1109/iCMLDE.2018.00024},
ISSN={},
month={Dec},}
@INPROCEEDINGS{614197,
author={R. {Kamimura}},
booktitle={Proceedings of International Conference on Neural Networks (ICNN'97)},
title={D-entropy controller for interpretation and generalization},
year={1997},
volume={3},
number={},
pages={1948-1953 vol.3},
abstract={In this paper, we propose a method to control D-entropy for better generalization and explicit interpretation of internal representations. By controlling D-entropy, a few hidden units are detected as important units without saturation. In addition, a small number of important input-hidden connections are detected and the majority of the connections are eliminated. Thus, we can obtain much simplified internal representations with better interpretation and generalization. The D-entropy control method was applied to the inference of well-formedness of an artificial language. Experimental results confirmed that by maximizing and minimizing D-entropy, generalization performance can significantly be improved.},
keywords={neural nets;learning (artificial intelligence);maximum entropy methods;minimum entropy methods;inference mechanisms;formal languages;generalisation (artificial intelligence);D-entropy controller;interpretation;generalization;inference;artificial language;neural learning;neural networks;Entropy;Minimization methods;Mutual information;Uncertainty;Laboratories;Artificial neural networks;Degradation;Neural networks;Difference equations},
doi={10.1109/ICNN.1997.614197},
ISSN={},
month={June},}
@INPROCEEDINGS{5376749,
author={R. {Bai} and X. {Qiu} and M. {Cao}},
booktitle={2009 International Conference on Computational Intelligence and Security},
title={Factor Sensitivity Analysis for Multivariable Systems Using Bayesian Neural Networks},
year={2009},
volume={1},
number={},
pages={30-33},
abstract={Neural interpretation is of increasing interest in artificial neural networks and it is potential to reveal the intrinsic mechanism of multivariable systems. This study aims at investigating the efficiency of Bayesian neural networks in neural interpretation. The measures to ensure the stability of the network model are first elaborated and then, two types of Bayesian networks with linear and partly-linear transfer functions are exploited to conduct neural interpretation for simulated multivariable systems. Experimental results show that aided with connection weight calculation, Bayesian neural networks own distinct advantages over other network models in evaluating the relative contribution of independent variables to single dependent one. Therefore, the method proposed in this study is promising to perform factor sensitivity analysis for multivariable systems.},
keywords={belief networks;multivariable systems;neural nets;sensitivity analysis;transfer functions;Bayesian neural networks;factor sensitivity analysis;neural interpretation;partly-linear transfer functions;linear transfer functions;simulated multivariable systems;connection weight calculation;Sensitivity analysis;MIMO;Bayesian methods;Neural networks;Artificial neural networks;Neurons;Educational institutions;Civil engineering;Stability;Cost function;connection weight approach;Bayesian neural networks;neural interpretation;factor sensitivity analysis;multivariable systems},
doi={10.1109/CIS.2009.43},
ISSN={},
month={Dec},}
@INPROCEEDINGS{167089,
author={A. V. {Hudli} and M. J. {Palakal} and M. J. {Zoran}},
booktitle={[Proceedings] Third International Conference on Tools for Artificial Intelligence - TAI 91},
title={A neural network based expert system model},
year={1991},
volume={},
number={},
pages={145-149},
abstract={The architecture of an expert system model using artificial neural networks is proposed. The proposed model effectively supports the necessary components of an expert system such as user interface facility knowledge base, inference engine, and explanation system. The expert system model (ESM) consists of several orders of simple neural networks, each realizing a simple task. These simple neural networks are organized vertically, thereby achieving a second level of parallelism. A novel way to handle both forward and backward chaining reasoning mechanisms is presented. A secondary network model monitors the reasoning patterns of the primary model.<<ETX>>},
keywords={expert systems;explanation;inference mechanisms;neural nets;forward chaining reasoning;parallel processing;expert system model;artificial neural networks;user interface facility knowledge base;inference engine;explanation;backward chaining reasoning;Neural networks;Expert systems;Artificial neural networks;Engines;Problem-solving;Knowledge acquisition;Humans;Computer networks;Information science;Computer architecture},
doi={10.1109/TAI.1991.167089},
ISSN={},
month={Nov},}
@ARTICLE{5451119,
author={Y. {Yu} and C. {Hui} and T. {Choi} and R. {Au}},
journal={IEEE Transactions on Systems, Man, and Cybernetics, Part C (Applications and Reviews)},
title={Intelligent Fabric Hand Prediction System With Fuzzy Neural Network},
year={2010},
volume={40},
number={6},
pages={619-629},
abstract={Fabric selection is a crucial step in fashion product development. Prior research works have studied the prediction of fabric specimens based on the fabric hand descriptors via either traditional statistical methods or artificial intelligence methods. Despite showing good prediction accuracy, these methods usually lack an understandable ruleset, which means their “interpretability” is low. In this paper, a fuzzy neural network (FNN) based intelligent fabric hand prediction system is explored. Unlike some traditional FNN models in which a full ruleset of the artificial neural network (ANN) is presumed, the proposed FNN system includes a simplification of the network structure and feature selection, so that the number of rules is significantly reduced without big sacrifice on prediction accuracy. Real datasets collected from 30 participants' evaluation on a set of ten fabric specimens are used to train and test the performance of the proposed system. The system's prediction accuracy is found to be over 80%. Applications of the proposed system are discussed and future research directions are outlined.},
keywords={artificial intelligence;fabrics;feature extraction;fuzzy logic;fuzzy neural nets;textile industry;intelligent fabric hand prediction system;fuzzy neural network;fabric selection;fashion product development;artificial intelligence method;interpretability;artificial neural network;FNN system;network structure;feature selection;fabric specimen;Intelligent networks;Fabrics;Fuzzy neural networks;Artificial intelligence;Accuracy;Artificial neural networks;Product development;Statistical analysis;Predictive models;System testing;Artificial neural network (ANN);fabric hand prediction;fuzzy logic;fuzzy neural network (FNN)},
doi={10.1109/TSMCC.2010.2045121},
ISSN={1094-6977},
month={Nov},}
@ARTICLE{7552539,
author={W. {Samek} and A. {Binder} and G. {Montavon} and S. {Lapuschkin} and K. {Müller}},
journal={IEEE Transactions on Neural Networks and Learning Systems},
title={Evaluating the Visualization of What a Deep Neural Network Has Learned},
year={2017},
volume={28},
number={11},
pages={2660-2673},
abstract={Deep neural networks (DNNs) have demonstrated impressive performance in complex machine learning tasks such as image classification or speech recognition. However, due to their multilayer nonlinear structure, they are not transparent, i.e., it is hard to grasp what makes them arrive at a particular classification or recognition decision, given a new unseen data sample. Recently, several approaches have been proposed enabling one to understand and interpret the reasoning embodied in a DNN for a single test image. These methods quantify the “importance” of individual pixels with respect to the classification decision and allow a visualization in terms of a heatmap in pixel/input space. While the usefulness of heatmaps can be judged subjectively by a human, an objective quality measure is missing. In this paper, we present a general methodology based on region perturbation for evaluating ordered collections of pixels such as heatmaps. We compare heatmaps computed by three different methods on the SUN397, ILSVRC2012, and MIT Places data sets. Our main result is that the recently proposed layer-wise relevance propagation algorithm qualitatively and quantitatively provides a better explanation of what made a DNN arrive at a particular classification decision than the sensitivity-based approach or the deconvolution method. We provide theoretical arguments to explain this result and discuss its practical implications. Finally, we investigate the use of heatmaps for unsupervised assessment of the neural network performance.},
keywords={data visualisation;image classification;learning (artificial intelligence);neural nets;sensitivity-based approach;deconvolution method;heatmap;deep neural network;complex machine learning tasks;multilayer nonlinear structure;DNN;MIT Places data sets;SUN397;ILSVRC2012;relevance propagation algorithm;data visualization;Heating;Neurons;Biological neural networks;Deconvolution;Sensitivity;Learning systems;Algorithm design and analysis;Convolutional neural networks;explaining classification;image classification;interpretable machine learning;relevance models},
doi={10.1109/TNNLS.2016.2599820},
ISSN={2162-237X},
month={Nov},}
@INPROCEEDINGS{8591457,
author={D. L. {Marino} and C. S. {Wickramasinghe} and M. {Manic}},
booktitle={IECON 2018 - 44th Annual Conference of the IEEE Industrial Electronics Society},
title={An Adversarial Approach for Explainable AI in Intrusion Detection Systems},
year={2018},
volume={},
number={},
pages={3237-3243},
abstract={Despite the growing popularity of modern machine learning techniques (e.g, Deep Neural Networks) in cyber-security applications, most of these models are perceived as a black-box for the user. Adversarial machine learning offers an approach to increase our understanding of these models. In this paper we present an approach to generate explanations for incorrect classifications made by data-driven Intrusion Detection Systems (IDSs) An adversarial approach is used to find the minimum modifications (of the input features) required to correctly classify a given set of misclassified samples. The magnitude of such modifications is used to visualize the most relevant features that explain the reason for the misclassification. The presented methodology generated satisfactory explanations that describe the reasoning behind the mis-classifications, with descriptions that match expert knowledge. The advantages of the presented methodology are: 1) applicable to any classifier with defined gradients. 2) does not require any modification of the classifier model. 3) can be extended to perform further diagnosis (e.g. vulnerability assessment) and gain further understanding of the system. Experimental evaluation was conducted on the NSL-KDD99 benchmark dataset using Linear and Multilayer perceptron classifiers. The results are shown using intuitive visualizations in order to improve the interpretability of the results.},
keywords={learning (artificial intelligence);multilayer perceptrons;neural nets;pattern classification;security of data;adversarial approach;explainable AI;cyber-security applications;adversarial machine learning;multilayer perceptron classifiers;machine learning techniques;deep neural networks;data-driven intrusion detection systems;IDSs;Machine learning;Intrusion detection;Mathematical model;Visualization;Estimation;Adversarial Machine Learning;Adversarial samples;Explainable AI;cyber-security},
doi={10.1109/IECON.2018.8591457},
ISSN={2577-1647},
month={Oct},}
@INPROCEEDINGS{4761819,
author={K. S. {Tay} and K. {Koile}},
booktitle={2008 19th International Conference on Pattern Recognition},
title={Improving digital ink interpretation through expected type prediction and dynamic dispatch},
year={2008},
volume={},
number={},
pages={1-4},
abstract={Interpretation accuracy of current handwriting applications can be improved by providing contextual information about an ink samplepsilas expected type. We have developed a novel approach that uses a classic machine learning technique to predict this expected type from an ink sample. With this approach, we can create a ldquodynamic dispatch interpreterrdquo by biasing interpretation differently according to the predicted expected types of the ink samples. When evaluated in the domain of introductory computer science, our interpreter achieves high interpretation accuracy (87%), an improvement from Microsoftpsilas default interpreter (62%), and comparable with other previous interpreters (87-89%), which, unlike ours, require additional user-specified expected type information for each ink sample.},
keywords={computer aided instruction;learning (artificial intelligence);digital ink interpretation;expected type prediction;dynamic dispatch interpreter;handwriting applications;contextual information;machine learning technique;Microsoft default interpreter;Ink;Computer science;Machine learning;Artificial intelligence;Handwriting recognition;Hidden Markov models;Artificial neural networks;Laboratories;Application software;Feature extraction},
doi={10.1109/ICPR.2008.4761819},
ISSN={1051-4651},
month={Dec},}
@INPROCEEDINGS{1001348,
author={A. R. {Sadeghian}},
booktitle={2002 IEEE International Magnetics Conference (INTERMAG)},
title={An interpretation of Preisach-Krasnoselskii hysteresis model with the use of artificial neural networks},
year={2002},
volume={},
number={},
pages={FS5-},
abstract={Summary form only given. This paper presents the application of artificial neural networks to implement an accurate magnetic hysteresis model based on the mathematical definition provided Preisach-Krasnoselskii (P-K) model. Accurate modeling of hysteresis is essential for both the design and the performance evaluation of electromagnetic devices. This paper shows that artificial neural networks (ANN) provide the natural setting whereby the P-K model can be successfully implemented.},
keywords={magnetic hysteresis;physics computing;neural nets;Preisach-Krasnoselskii hysteresis model;artificial neural networks;electromagnetic devices;Artificial neural networks;Magnetic hysteresis;Neural networks;Magnetization processes;Artificial intelligence;Context modeling;Magnetic analysis;Computer networks;Physics;Lakes},
doi={10.1109/INTMAG.2002.1001348},
ISSN={},
month={April},}
@INPROCEEDINGS{8614130,
author={S. {Ghanta} and S. {Subramanian} and S. {Sundararaman} and L. {Khermosh} and V. {Sridhar} and D. {Arteaga} and Q. {Luo} and D. {Das} and N. {Talagala}},
booktitle={2018 17th IEEE International Conference on Machine Learning and Applications (ICMLA)},
title={Interpretability and Reproducability in Production Machine Learning Applications},
year={2018},
volume={},
number={},
pages={658-664},
abstract={Explainability/Interpretability in machine learning applications is becoming critical, with legal and industry requirements demanding human understandable machine learning results. We describe the additional complexities that occur when a known interpretability technique (canary models) is applied to a real production scenario. We furthermore argue that reproducibility is a key feature in practical usages of such interpretability techniques in production scenarios. With this motivation, we present a production ML reproducibility solution, namely a comprehensive time ordered event sequence for machine learning applications. We demonstrate how our approach can bring this known common interpretability technique into production viability. We further present the system design and early performance characteristics of our reproducibility solution.},
keywords={learning (artificial intelligence);production engineering computing;production scenario;interpretability techniques;production ML reproducibility solution;production viability;reproducability;production machine learning applications;legal industry requirements;human understandable machine learning;Production;Pipelines;Predictive models;Machine learning;Training;Data models;Load modeling;reproducability;explainability;interpretability;systems;tracking},
doi={10.1109/ICMLA.2018.00105},
ISSN={},
month={Dec},}
@INPROCEEDINGS{8631448,
author={L. H. {Gilpin} and D. {Bau} and B. Z. {Yuan} and A. {Bajwa} and M. {Specter} and L. {Kagal}},
booktitle={2018 IEEE 5th International Conference on Data Science and Advanced Analytics (DSAA)},
title={Explaining Explanations: An Overview of Interpretability of Machine Learning},
year={2018},
volume={},
number={},
pages={80-89},
abstract={There has recently been a surge of work in explanatory artificial intelligence (XAI). This research area tackles the important problem that complex machines and algorithms often cannot provide insights into their behavior and thought processes. XAI allows users and parts of the internal system to be more transparent, providing explanations of their decisions in some level of detail. These explanations are important to ensure algorithmic fairness, identify potential bias/problems in the training data, and to ensure that the algorithms perform as expected. However, explanations produced by these systems is neither standardized nor systematically assessed. In an effort to create best practices and identify open challenges, we describe foundational concepts of explainability and show how they can be used to classify existing literature. We discuss why current approaches to explanatory methods especially for deep neural networks are insufficient. Finally, based on our survey, we conclude with suggested future research directions for explanatory artificial intelligence.},
keywords={artificial intelligence;data analysis;learning (artificial intelligence);neural nets;complex machines;algorithmic fairness;training data;suggested future research directions;explanatory artificial intelligence;explaining explanations;machine learning;XAI;potential bias-problems;Artificial intelligence;Computational modeling;Decision trees;Biological neural networks;Taxonomy;Complexity theory;Machine learning theories;Models and systems;Deep learning and deep analytics;Fairness and transparency in data science},
doi={10.1109/DSAA.2018.00018},
ISSN={},
month={Oct},}
@INPROCEEDINGS{8204039,
author={S. {Virmani} and S. {Gite}},
booktitle={2017 8th International Conference on Computing, Communication and Networking Technologies (ICCCNT)},
title={Performance of convolutional neural network and recurrent neural network for anticipation of driver's conduct},
year={2017},
volume={},
number={},
pages={1-8},
abstract={With the advancements in Internet of Things (IoT), we could efficiently improve our daily life activities like health care, monitoring, transportation, smart homes etc. Artificial Intelligence along with Machine learning has played a very supportive role to analyze various situations and take decisions accordingly. Maneuver anticipation supplements existing Advance Driver Assistance Systems (ADAS) by anticipating mishaps and giving drivers more opportunity to respond to road circumstances proactively. The capacity to sort the driver conduct is extremely beneficial for advance driver assistance system (ADAS). Deep learning solutions would further be an endeavor of for driving conduct recognition. A technique for distinguishing driver's conduct is imperative to help operative mode transition between the driver and independent vehicles. We propose a novel approach of dissecting driver's conduct by using Convolutional Neural Network (CNN), Recurrent Neural Network(RNN) and a combination of Convolutional Neural Network with Long-Short Term Memory (LSTM) that would give better results in less response time. We are likewise proposing to concentrate high level features and interpretable features depicting complex driving examples by trying CNN, RNN and then CNN with LSTM. We could improve the system accuracy to 95% by combining CNN with LSTM.},
keywords={driver information systems;feedforward neural nets;Internet of Things;learning (artificial intelligence);recurrent neural nets;road vehicles;convolutional neural network;daily life activities;Recurrent Neural Network;Internet of Things;IoT;artificial intelligence;machine learning;maneuver anticipation;road circumstances;driving conduct recognition;operative mode transition;CNN;RNN;long-short term memory;LSTM;high level features;independent vehicles;deep learning solutions;advance driver assistance system;driver conduct;ADAS;Advance Driver Assistance Systems;Recurrent neural networks;Machine learning;Technological innovation;Automobiles;Hidden Markov models;ITS;ADAS;Deep learning CNN;RNN;LSTM},
doi={10.1109/ICCCNT.2017.8204039},
ISSN={},
month={July},}
@INPROCEEDINGS{713989,
author={T. D. {Gedeon} and S. {Turner}},
booktitle={Proceedings of 1993 International Conference on Neural Networks (IJCNN-93-Nagoya, Japan)},
title={Explaining student grades predicted by a neural network},
year={1993},
volume={1},
number={},
pages={609-612 vol.1},
abstract={We have trained a backpropagation trained feedforward neural network to predict student performance in a large undergraduate computer science subject at the University of New South Wales. The prediction uses partial grades from during the teaching session to predict the final grade. The exam mark which is the major component (60%) of the overall grade is not used. The purpose of this network is to allow students to predict the final grade they are likely to achieve based on current performance, and obviously to improve their performance if the predicted grade is below their expectations. By itself, however, the network is not adequate as it provides no feedback as to why their performance merits a particular grade. We therefore generate an explanation of the conclusion reached by the neural network for predicting particular student grades.},
keywords={educational computing;feedforward neural nets;explanation;educational administrative data processing;backpropagation;feedforward neural network;student performance prediction;University of New South Wales;student grade;explanation;Neural networks;Neurons;Computer science;Australia;Feedforward systems;Feedforward neural networks;Education;Neurofeedback;Laboratories;Aggregates},
doi={10.1109/IJCNN.1993.713989},
ISSN={},
month={Oct},}
@ARTICLE{1501920,
author={K. {Suzuki} and and S. {Sone} and K. {Doi}},
journal={IEEE Transactions on Medical Imaging},
title={Computer-aided diagnostic scheme for distinction between benign and malignant nodules in thoracic low-dose CT by use of massive training artificial neural network},
year={2005},
volume={24},
number={9},
pages={1138-1150},
abstract={Low-dose helical computed tomography (LDCT) is being applied as a modality for lung cancer screening. It may be difficult, however, for radiologists to distinguish malignant from benign nodules in LDCT. Our purpose in this study was to develop a computer-aided diagnostic (CAD) scheme for distinction between benign and malignant nodules in LDCT scans by use of a massive training artificial neural network (MTANN). The MTANN is a trainable, highly nonlinear filter based on an artificial neural network. To distinguish malignant nodules from six different types of benign nodules, we developed multiple MTANNs (multi-MTANN) consisting of six expert MTANNs that are arranged in parallel. Each of the MTANNs was trained by use of input CT images and teaching images containing the estimate of the distribution for the "likelihood of being a malignant nodule", i.e., the teaching image for a malignant nodule contains a two-dimensional Gaussian distribution and that for a benign nodule contains zero. Each MTANN was trained independently with ten typical malignant nodules and ten benign nodules from each of the six types. The outputs of the six MTANNs were combined by use of an integration ANN such that the six types of benign nodules could be distinguished from malignant nodules. After training of the integration ANN, our scheme provided a value related to the "likelihood of malignancy" of a nodule, i.e., a higher value indicates a malignant nodule, and a lower value indicates a benign nodule. Our database consisted of 76 primary lung cancers in 73 patients and 413 benign nodules in 342 patients, which were obtained from a lung cancer screening program on 7847 screenees with LDCT for three years in Nagano, Japan. The performance of our scheme for distinction between benign and malignant nodules was evaluated by use of receiver operating characteristic (ROC) analysis. Our scheme achieved an Az (area under the ROC curve) value of 0.882 in a round-robin test. Our scheme correctly identified 100% (76/76) of malignant nodules as malignant, whereas 48% (200/413) of benign nodules were identified correctly as benign. Therefore, our scheme may be useful in assisting radiologists in the diagnosis of lung nodules in LDCT.},
keywords={patient diagnosis;computerised tomography;dosimetry;artificial intelligence;neural nets;medical computing;lung;cancer;Gaussian distribution;computer-aided diagnostic scheme;benign nodules;malignant modules;thoracic CT;low-dose CT;massive training neural network;artificial neural network;low-dose computed tomography;helical computed tomography;lung cancer screening;nonlinear filter;two-dimensional Gaussian distribution;likelihood pf malignancy;receiver operating characteristic analysis;round-robin test;lung nodules;Computer networks;Cancer;Artificial neural networks;Lungs;Computed tomography;Education;Nonlinear filters;Gaussian distribution;Databases;Performance analysis;Artificial neural network;computer-aided diagnosis (CAD);likelihood of malignancy;low-dose CT;lung nodule;Algorithms;Artificial Intelligence;Coin Lesion, Pulmonary;Humans;Lung Neoplasms;Neural Networks (Computer);Pattern Recognition, Automated;Radiation Dosage;Radiographic Image Enhancement;Radiographic Image Interpretation, Computer-Assisted;Radiography, Thoracic;Reproducibility of Results;Retrospective Studies;Sensitivity and Specificity;Tomography, Spiral Computed},
doi={10.1109/TMI.2005.852048},
ISSN={0278-0062},
month={Sep.},}
@ARTICLE{6138313,
author={A. {Hirose} and S. {Yoshida}},
journal={IEEE Transactions on Neural Networks and Learning Systems},
title={Generalization Characteristics of Complex-Valued Feedforward Neural Networks in Relation to Signal Coherence},
year={2012},
volume={23},
number={4},
pages={541-551},
abstract={Applications of complex-valued neural networks (CVNNs) have expanded widely in recent years-in particular in radar and coherent imaging systems. In general, the most important merit of neural networks lies in their generalization ability. This paper compares the generalization characteristics of complex-valued and real-valued feedforward neural networks in terms of the coherence of the signals to be dealt with. We assume a task of function approximation such as interpolation of temporal signals. Simulation and real-world experiments demonstrate that CVNNs with amplitude-phase-type activation function show smaller generalization error than real-valued networks, such as bivariate and dual-univariate real-valued neural networks. Based on the results, we discuss how the generalization characteristics are influenced by the coherence of the signals depending on the degree of freedom in the learning and on the circularity in neural dynamics.},
keywords={function approximation;generalisation (artificial intelligence);learning (artificial intelligence);neural nets;signal processing;generalization characteristics;complex-valued feedforward neural networks;signal coherence;radar systems;coherent imaging systems;real-valued feedforward neural networks;function approximation;temporal signal interpolation;amplitude-phase-type activation function;bivariate real-valued neural networks;dual-univariate real-valued neural networks;learning;neural dynamics;Neurons;Coherence;Biological neural networks;Vectors;Feedforward neural networks;Signal to noise ratio;Complex-valued neural network;function approximation;generalization;supervised learning;Algorithms;Computer Simulation;Feedback;Image Interpretation, Computer-Assisted;Models, Statistical;Neural Networks (Computer);Pattern Recognition, Automated;Tomography, Optical Coherence},
doi={10.1109/TNNLS.2012.2183613},
ISSN={2162-237X},
month={April},}
@INPROCEEDINGS{4375533,
author={Y. {Pan}},
booktitle={2007 IEEE 7th International Symposium on BioInformatics and BioEngineering},
title={Protein Structure Prediction and Its Understanding Based on Machine Learning Methods},
year={2007},
volume={},
number={},
pages={7-7},
abstract={Understanding protein structures is vital to determining the function of a protein and its interaction with DNA, RNA and enzyme. The information about its conformation can provide essential information for drug design and protein engineering. While there are over a million known protein sequences, only a limited number of protein structures are experimentally determined. Hence, prediction of protein structures from protein sequences using computer programs is an important step to unveil proteins' three dimensional conformation and functions. As a result, prediction of protein structures has profound theoretical and practical influence over biological study. The explanation of how a decision is made during prediction is also important for improving protein structure prediction and guiding the "wet experiments". In this talk, we will show how to use machine learning methods to improve the accuracy of protein structure prediction and to interpret prediction results. We will report our research on using neural networks, support vector machines combined with decision tree and association rule for protein structure prediction, rule extraction and prediction interpretation. Evaluation and comparisons of various prediction and rule extraction systems will be presented and future research direction in this area will also be identified.},
keywords={biology computing;data mining;decision trees;learning (artificial intelligence);molecular biophysics;molecular configurations;neural nets;proteins;support vector machines;protein structure prediction;machine learning methods;conformation;protein sequences;neural networks;support vector machines;decision tree;association rule;Learning systems;Protein engineering;Sequences;DNA;RNA;Biochemistry;Drugs;Biology computing;Neural networks;Support vector machines},
doi={10.1109/BIBE.2007.4375533},
ISSN={},
month={Oct},}
@ARTICLE{6555905,
author={P. {González} and E. {Álvarez} and J. {Barranquero} and J. {Díez} and R. {González-Quirós} and E. {Nogueira} and Á. {López-Urrutia} and J. J. {del Coz}},
journal={IEEE Transactions on Neural Networks and Learning Systems},
title={Multiclass Support Vector Machines With Example-Dependent Costs Applied to Plankton Biomass Estimation},
year={2013},
volume={24},
number={11},
pages={1901-1905},
abstract={In many applications, the mistakes made by an automatic classifier are not equal, they have different costs. These problems may be solved using a cost-sensitive learning approach. The main idea is not to minimize the number of errors, but the total cost produced by such mistakes. This brief presents a new multiclass cost-sensitive algorithm, in which each example has attached its corresponding misclassification cost. Our proposal is theoretically well-founded and is designed to optimize cost-sensitive loss functions. This research was motivated by a real-world problem, the biomass estimation of several plankton taxonomic groups. In this particular application, our method improves the performance of traditional multiclass classification approaches that optimize the accuracy.},
keywords={biology computing;learning (artificial intelligence);pattern classification;support vector machines;multiclass support vector machines;example-dependent costs;plankton biomass estimation;cost-sensitive learning approach;multiclass cost-sensitive algorithm;cost-sensitive loss functions;plankton taxonomic groups;multiclass classification approach;Biomass;Support vector machines;Optimization;Estimation;Learning systems;Kernel;Organisms;Cost-sensitive learning;example-dependent costs;kernel methods;plankton recognition;SVM;Algorithms;Image Interpretation, Computer-Assisted;Microscopy;Pattern Recognition, Automated;Plankton;Reproducibility of Results;Sensitivity and Specificity;Support Vector Machine},
doi={10.1109/TNNLS.2013.2271535},
ISSN={2162-237X},
month={Nov},}
@INPROCEEDINGS{8418593,
author={T. {Gehr} and M. {Mirman} and D. {Drachsler-Cohen} and P. {Tsankov} and S. {Chaudhuri} and M. {Vechev}},
booktitle={2018 IEEE Symposium on Security and Privacy (SP)},
title={AI2: Safety and Robustness Certification of Neural Networks with Abstract Interpretation},
year={2018},
volume={},
number={},
pages={3-18},
abstract={We present AI2, the first sound and scalable analyzer for deep neural networks. Based on overapproximation, AI2can automatically prove safety properties (e.g., robustness) of realistic neural networks (e.g., convolutional neural networks). The key insight behind AI2is to phrase reasoning about safety and robustness of neural networks in terms of classic abstract interpretation, enabling us to leverage decades of advances in that area. Concretely, we introduce abstract transformers that capture the behavior of fully connected and convolutional neural network layers with rectified linear unit activations (ReLU), as well as max pooling layers. This allows us to handle real-world neural networks, which are often built out of those types of layers. We present a complete implementation of AI2together with an extensive evaluation on 20 neural networks. Our results demonstrate that: (i) AI2is precise enough to prove useful specifications (e.g., robustness), (ii) AI2can be used to certify the effectiveness of state-of-the-art defenses for neural networks, (iii) AI2is significantly faster than existing analyzers based on symbolic analysis, which often take hours to verify simple fully connected networks, and (iv) AI2can handle deep convolutional networks, which are beyond the reach of existing methods.},
keywords={convolution;feedforward neural nets;learning (artificial intelligence);program diagnostics;convolutional neural network layers;fully connected networks;AI2;abstract interpretation;scalable analyzer;sound analyzer;phrase reasoning;rectified linear unit activations;max pooling layers;symbolic analysis;neural networks safety;neural networks robustness;Robustness;Biological neural networks;Cats;Neurons;Safety;Perturbation methods;Reliable Machine Learning;Robustness;Neural Networks;Abstract Interpretation},
doi={10.1109/SP.2018.00058},
ISSN={2375-1207},
month={May},}
@ARTICLE{4359184,
author={B. {Vigdor} and B. {Lerner}},
journal={IEEE Transactions on Neural Networks},
title={The Bayesian ARTMAP},
year={2007},
volume={18},
number={6},
pages={1628-1644},
abstract={In this paper, we modify the fuzzy ARTMAP (FA) neural network (NN) using the Bayesian framework in order to improve its classification accuracy while simultaneously reduce its category proliferation. The proposed algorithm, called Bayesian ARTMAP (BA), preserves the FA advantages and also enhances its performance by the following: (1) representing a category using a multidimensional Gaussian distribution, (2) allowing a category to grow or shrink, (3) limiting a category hypervolume, (4) using Bayes' decision theory for learning and inference, and (5) employing the probabilistic association between every category and a class in order to predict the class. In addition, the BA estimates the class posterior probability and thereby enables the introduction of loss and classification according to the minimum expected loss. Based on these characteristics and using synthetic and 20 real-world databases, we show that the BA outperformes the FA, either trained for one epoch or until completion, with respect to classification accuracy, sensitivity to statistical overlapping, learning curves, expected loss, and category proliferation.},
keywords={ART neural nets;Bayes methods;category theory;decision theory;fuzzy neural nets;Gaussian distribution;generalisation (artificial intelligence);inference mechanisms;learning (artificial intelligence);pattern classification;Bayesian ARTMAP;fuzzy ARTMAP neural network;classification accuracy;category proliferation;multidimensional Gaussian distribution;category hypervolume;Bayes decision theory;inference;probabilistic association;class posterior probability;statistical overlapping;learning curves;expected loss;Bayesian methods;Neural networks;Target recognition;Fuzzy neural networks;Handwriting recognition;Decision theory;Databases;Inference algorithms;Multidimensional systems;Gaussian distribution;Bayes' decision theory;category proliferation;classification;fuzzy ARTMAP (FA);neural network (NN);Bayes' decision theory;category proliferation;classification;fuzzy ARTMAP (FA);neural network (NN);Algorithms;Artificial Intelligence;Bayes Theorem;Computer Simulation;Databases as Topic;Diagnosis, Computer-Assisted;Fuzzy Logic;Image Interpretation, Computer-Assisted;Neural Networks (Computer);Normal Distribution;Pattern Recognition, Automated;Software;Software Validation},
doi={10.1109/TNN.2007.900234},
ISSN={1045-9227},
month={Nov},}
@INPROCEEDINGS{713915,
author={ and },
booktitle={Proceedings of 1993 International Conference on Neural Networks (IJCNN-93-Nagoya, Japan)},
title={A neural network for interpretation of multi-meaning Chinese words},
year={1993},
volume={1},
number={},
pages={291-294 vol.1},
abstract={We proposed a neural network that can interpret multimeaning Chinese words correctly by using context information. The network is generated automatically basing on a Chinese-English dictionary and a knowledge-base of weights and self-organizingly builds a context according to key words of the processed text. Simulation experiment result proved that the network worked as expected.},
keywords={natural languages;neural nets;multimeaning Chinese word interpretation;self-organizing neural network;context information;Chinese-English dictionary;knowledge-base;key words;Neural networks;Morphology;Information analysis;Dictionaries;Natural languages;Temperature;Helium;Automatic generation control;Computer networks;Concrete},
doi={10.1109/IJCNN.1993.713915},
ISSN={},
month={Oct},}
@INPROCEEDINGS{8661467,
author={O. H. {Aréu} and A. M. G. {Menéndez} and J. I. H. {Sánchez} and E. S. {Valdés}},
booktitle={2018 IEEE International Autumn Meeting on Power, Electronics and Computing (ROPEC)},
title={Diagnosis of faults in power transformers through the interpretation of FRA testing with artificial intelligence},
year={2018},
volume={},
number={},
pages={1-5},
abstract={In the present work, the artificial intelligence is used, through neural networks, in the diagnosis of power transformers for the interpretation of the results obtained in the frequency response analysis test. The results of the classification of three types of failures in this technique are exposed. The characteristics of the statistical indicators that function as input variables of the neural network and the reason for implementing a multilayer network with backpropagation algorithm, in the training are exposed. The results of the discrimination of acceptable or not acceptable state of the transformer are presented and if it has any of the following faults: open winding, short circuit winding and winding with a point to ground. The response of the neural network is determined in case of study of real transformers.},
keywords={backpropagation;fault diagnosis;frequency response;neural nets;power engineering computing;power transformer testing;statistical analysis;transformer windings;power transformers;artificial intelligence;neural network;frequency response analysis test;statistical indicators;multilayer network;faults diagnosis;FRA testing;backpropagation algorithm;open winding;short circuit winding;Artificial intelligence;transformer diagnostic;artificial neuronal network},
doi={10.1109/ROPEC.2018.8661467},
ISSN={2573-0770},
month={Nov},}
@INPROCEEDINGS{860756,
author={T. {Waschulzik} and W. {Brauer} and T. {Castedello} and B. {Henery}},
booktitle={Proceedings of the IEEE-INNS-ENNS International Joint Conference on Neural Networks. IJCNN 2000. Neural Computing: New Challenges and Perspectives for the New Millennium},
title={Quality assured efficient engineering of feedforward neural networks with supervised learning (QUEEN) evaluated with the"pima indians diabetes database"},
year={2000},
volume={4},
number={},
pages={97-102 vol.4},
abstract={The QUEEN method is based on four main concepts: 1 The QUEEN phase model is derived from the spiral model for the evaluation of the constructed neural network; 2. An overall strategy for the development process enables a continuous supervision, assessment and quality assurance of each step, from the collection of the examples to the evaluation of the constructed neural network. For the assessment of the quality achieved in the development process, a novel quality indicator is introduced. This indicator gives a measure of the complexity of a task in a given representation. This strategy of QUEEN involves the stepwise simplification of the task; 3. The development of the neural networks is structured by the definition of an order over neural networks. The order takes into account the complexity of the interpretation of the neural network by an expert of the application domain. To yield easily interpretable neural networks, and also to get simple models that enable the detection of data artefacts, the development is started with the simplest adequate neural network; 4. The developer is provided with a set of diagnostic methods and tools that will identify and eliminate reasons for difficulties. The novel quality indicator for example, provides the developer with a diagnostic tool that will identify situations where a representation or a network is unnecessarily complex. QUEEN was developed and successfully evaluated in more than 20 projects mostly in the medical application domain. The paper presents the concepts of QUEEN and describes how QUEEN was applied to set-up a feedforward neural network on the pima indians diabetes database, a database that has been used as a benchmark in several studies, QUEEN highlighted several severe data artefacts in this database.},
keywords={feedforward neural nets;learning (artificial intelligence);medical computing;quality assured efficient engineering;feedforward neural networks;supervised learning;pima indians diabetes database;QUEEN method;phase model;spiral model;development process;supervision;assessment;quality assurance;quality indicator;stepwise simplification;data artefacts;diagnostic methods;diagnostic tool;Neural networks;Feedforward neural networks;Supervised learning;Databases;Quality assurance;Diabetes;Statistics;Spirals;Machine learning;Data engineering},
doi={10.1109/IJCNN.2000.860756},
ISSN={1098-7576},
month={July},}
@INPROCEEDINGS{1007533,
author={K. F. {Leung} and H. K. {Lam} and F. H. F. {Leung} and P. K. S. {Tam}},
booktitle={Proceedings of the 2002 International Joint Conference on Neural Networks. IJCNN'02 (Cat. No.02CH37290)},
title={Graffiti commands interpretation for eBooks using a self-structured neural network and genetic algorithm},
year={2002},
volume={3},
number={},
pages={2487-2492 vol.3},
abstract={This paper presents the interpretation of graffiti commands for electronic books (eBooks). A neural network is employed to perform the graffiti interpretation. By introducing a switch to each link of the neural network, the structure of the neural network can be obtained and tuned automatically by a genetic algorithm (GA) with arithmetic crossover and non-uniform mutation. Simulation results on interpreting graffiti commands for eBooks using the proposed neural network are shown.},
keywords={handwritten character recognition;character recognition equipment;computer graphic equipment;graphical user interfaces;notebook computers;electronic publishing;self-organising feature maps;neural net architecture;tuning;genetic algorithms;touch sensitive screens;symbol manipulation;graffiti command interpretation;electronic books;self-structured neural network;genetic algorithm;neural network link switch;neural network structure tuning;arithmetic crossover;nonuniform mutation;simulation;Neural networks;Switches;Arithmetic;Genetic mutations;Personal digital assistants;Genetic algorithms;Signal processing algorithms;Electronic publishing;Genetic engineering;Computational modeling},
doi={10.1109/IJCNN.2002.1007533},
ISSN={1098-7576},
month={May},}
@ARTICLE{1262340,
author={P. {Mitra} and C. A. {Murthy} and S. K. {Pal}},
journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
title={A probabilistic active support vector learning algorithm},
year={2004},
volume={26},
number={3},
pages={413-418},
abstract={The paper describes a probabilistic active learning strategy for support vector machine (SVM) design in large data applications. The learning strategy is motivated by the statistical query model. While most existing methods of active SVM learning query for points based on their proximity to the current separating hyperplane, the proposed method queries for a set of points according to a distribution as determined by the current separating hyperplane and a newly defined concept of an adaptive confidence factor. This enables the algorithm to have more robust and efficient learning capabilities. The confidence factor is estimated from local information using the k nearest neighbor principle. The effectiveness of the method is demonstrated on real-life data sets both in terms of generalization performance, query complexity, and training time.},
keywords={learning (artificial intelligence);probability;support vector machines;pattern recognition;data mining;probabilistic active learning;support vector learning algorithm;support vector machine;SVM;statistical query model;adaptive confidence factor;k nearest neighbor principle;real life data sets;generalization performance;query complexity;training time;pattern recognition;data mining;Support vector machines;Quadratic programming;Lagrangian functions;Support vector machine classification;Machine learning;Algorithm design and analysis;Design optimization;Large-scale systems;Iterative algorithms;Robustness;Algorithms;Artificial Intelligence;Breast Neoplasms;Cluster Analysis;Computing Methodologies;Diagnosis, Computer-Assisted;Humans;Image Interpretation, Computer-Assisted;Information Storage and Retrieval;Models, Statistical;Numerical Analysis, Computer-Assisted;Pattern Recognition, Automated;Reproducibility of Results;Sensitivity and Specificity;Signal Processing, Computer-Assisted;Subtraction Technique},
doi={10.1109/TPAMI.2004.1262340},
ISSN={0162-8828},
month={March},}
@INPROCEEDINGS{7966301,
author={H. {Ponce} and M. {de Lourdes Martinez-Villaseñor}},
booktitle={2017 International Joint Conference on Neural Networks (IJCNN)},
title={Interpretability of artificial hydrocarbon networks for breast cancer classification},
year={2017},
volume={},
number={},
pages={3535-3542},
abstract={In machine learning, interpretability refers to understand the underlying behavior of the prediction of a model in order to identify diagnosis criteria and/or new rules from its output. Interpretability contributes to increase the usability of the method. Also, it is relevant in decision support systems, such as in medical applications. White-box models like tree-based, rule-based and linear models are considered the most comprehensible, but less accurate or simplistic. In contrast, black-box models like nonlinear and ensemble models are more accurate hence more complex to interpret. Thus, a trade-off between accuracy and interpretability is often made when building models to support human experts in a decision-making process. Artificial hydrocarbon networks (AHN) is a supervised learning method that has been proved to be very effective for regression and classification problems. In fact, its training process suggests a kind of interpretability. Thus, the objective of this work is to present first efforts proving the capacity of artificial hydrocarbon networks (AHN) to deliver interpretable models. In order to assess the interpretability of AHN, we address the breast cancer problem using a public dataset. Results showed that AHN can be transformed in treebased and rule-based models preserving high accuracy in the output classification.},
keywords={cancer;learning (artificial intelligence);medical computing;pattern classification;artificial hydrocarbon networks;breast cancer classification;machine learning;diagnosis criteria;decision support systems;white-box models;tree-based model;rule-based model;linear model;black-box models;nonlinear model;ensemble model;supervised learning method;regression problem;classification problem;breast cancer problem;public dataset;Compounds;Hydrocarbons;Predictive models;Breast cancer;Usability;Supervised learning;interpretability;machine learning;medical applications;supervised learning;white-box models},
doi={10.1109/IJCNN.2017.7966301},
ISSN={2161-4407},
month={May},}
