@inproceedings{7066257,
 abstract = {Text extraction plays an important role in numerous applications. Research on its method still need to be improved in order to achieve better performance, to increase the reliability of text extraction system and to deal with complex cases of text extraction. The majority of the text extraction methods are focusing on horizontal and near horizontal text lines; however, text in natural scene might be in arbitrary line in real time. Thus, this paper aims to solve the issue of extracting the arbitrary oriented text by suggesting a method for text detection and localization based on the Stroke Width Transform. The proposed method is tested on an arbitrary text dataset and ICDAR dataset. The result of the experiment shows that the proposed method adapts well to the arbitrary text.},
 author = {J. {Jameson} and S. N. H. S. {Abdullah}},
 booktitle = {2014 14th International Conference on Intelligent Systems Design and Applications},
 comments = {, The publication does not focus on explainability},
 doi = {10.1109/ISDA.2014.7066257},
 issn = {2164-7143},
 keywords = {text detection;transforms;arbitrary text extraction;natural scene image;stroke width transform;text detection;text localization;ICDAR dataset;Image edge detection;Text analysis;Transforms;Optical character recognition software;Licenses;Integrated circuits;Text extraction;Text detection and localization;Stroke Width Transform;Scene understanding},
 month = {Nov},
 number = {},
 pages = {124-128},
 title = {Extraction of arbitrary text in natural scene image based on stroke width transform},
 volume = {},
 year = {2014}
}

@inproceedings{716778,
 abstract = {A novel pattern searching method using neural networks and correlation is presented. This method combines the quickness and adaptiveness of neural networks with the accuracy of the mathematical correlation approach. Images are divided into small sub-images which are presented to the trained neural network. Sub-images that may contain the pattern or partial pattern are selected by the neural network. The neural network also provides the approximate location of the pattern, therefore the selected sub-images can be adjusted to contain the complete pattern. Desired patterns can be located by measuring the new sub-images' correlation values against the reference models in a small area. Experiments show that this superior method is able to find the desired patterns. Moreover, this method is much faster and more adaptable than traditional pattern searching methods.},
 author = {C. {Chiu} and T. {Oki} and P. {Paolellia}},
 booktitle = {Proceedings of 1993 International Conference on Neural Networks (IJCNN-93-Nagoya, Japan)},
 comments = {, The publication does not focus on explainability},
 doi = {10.1109/IJCNN.1993.716778},
 issn = {},
 keywords = {image recognition;neural nets;correlation methods;pattern searching method;neural networks;adaptiveness;mathematical correlation;sub-images;Neural networks;Pattern recognition;Brightness;Character recognition;Image recognition;Pixel;Manufacturing automation;Inspection;Printed circuits;Correlation},
 month = {Oct},
 number = {},
 pages = {1277-1280 vol.2},
 title = {A novel pattern searching method using neural networks and correlation},
 volume = {2},
 year = {1993}
}

@inproceedings{7193210,
 abstract = {Text recognition in images is a research area which attempts to develop a computer system with the ability to automatically read the text from images. These days there is a huge demand in storing the information available in paper documents format in to a computer storage disk and then later reusing this information by searching process. One simple way to store information from these paper documents in to computer system is to first scan the documents and then store them as images. But to reuse this information it is very difficult to read the individual contents and searching the contents form these documents line-by-line and word-by-word. The challenges involved in this the font characteristics of the characters in paper documents and quality of images. Due to these challenges, computer is unable to recognize the characters while reading them. Thus there is a need of character recognition mechanisms to perform Document Image Analysis (DIA) which transforms documents in paper format to electronic format. In this paper we have discuss method for text recognition from images. The objective of this paper is to recognition of text from image for better understanding of the reader by using particular sequence of different processing module.},
 author = {P. M. {Manwatkar} and S. H. {Yadav}},
 booktitle = {2015 International Conference on Innovations in Information, Embedded and Communication Systems (ICIIECS)},
 comments = {, The publication does not focus on explainability},
 doi = {10.1109/ICIIECS.2015.7193210},
 issn = {},
 keywords = {character recognition;document image processing;image resolution;image texture;text detection;image text recognition;computer storage disk;computer system;image quality;character recognition;document image analysis;DIA;Text recognition;Biological neural networks;Computers;Image segmentation;Character recognition;Neurons;Feature extraction;Document Image Analysis (DIA);electronic format;text recognition;font characteristics},
 month = {March},
 number = {},
 pages = {1-6},
 title = {Text recognition from images},
 volume = {},
 year = {2015}
}

@inproceedings{7311974,
 abstract = {In this paper we present a semi-automated analysis of student reading performance from the perspective of her text reading level and text understanding. Silences (pauses) between uttered words or read sentences as well as silences between verbalizations given by students are the key points in the analysis of their learning activities. Pause is an essential element in the analysis of a text, which also gives good control over interactions during the processes of text reading and explanation of understanding. This study presents the results specific to pauses in the reading and verbalization using Praat, a tool to analyze spoken productions. Correlations between students' fluency, story understanding, and mean pause duration of reading and explanation phases show consistent results across texts for reading. Results about pauses during explaining yielded low correlations, showing that other variables may influence the pausing behaviors during explaining.},
 author = {S. {Denisleam Molomer} and S. {Trausan-Matu} and P. {Dessus} and M. {Bianco}},
 booktitle = {2015 14th RoEduNet International Conference - Networking in Education and Research (RoEduNet NER)},
 comments = {, The publication does not focus on explainability},
 doi = {10.1109/RoEduNet.2015.7311974},
 issn = {2068-1038},
 keywords = {computer aided instruction;linguistics;speech processing;text analysis;students pauses;semiautomated analysis;student reading performance;text reading level;text understanding;uttered words;read sentences;silences;verbalizations;learning activities;text analysis;Praat tool;spoken productions;students fluency;story understanding;mean pause duration;reading phases;explanation phases;pausing behaviors;explaining;Decision support systems;Pause;Reading;Explanation},
 month = {Sep.},
 number = {},
 pages = {90-93},
 title = {Analyzing students pauses during reading and explaining a story},
 volume = {},
 year = {2015}
}

@inproceedings{7333750,
 abstract = {Text line extraction in document images is an important prerequisite for many content based image understanding applications. In this paper, we propose an accurate and robust method for generic text line extraction, which can be applied on large categories of document images, diverse languages, and text lines with different orientations. Firstly, the candidate connected components are extracted from document image using Maximal Stable Extremal Region (MSER) with the noises filtered by Adaboost and Convolution Neural Network (CNN). Then, the coarse text lines are generated from hierarchical edges reconstruction and cut by local linearity of text lines in the document spanning tree. Finally, for accurate text line extraction, the cut multi-components are re-connected based on text line energy minimization in terms of text line consistency and the fitting error. Experimental results on multilingual test dataset demonstrate the effectiveness and robust of the proposed method, which yields higher performance compared with state-of-the-art methods.},
 author = {L. {Wang} and W. {Fan} and J. {Sun} and S. {Naoi} and T. {Hiroshi}},
 booktitle = {2015 13th International Conference on Document Analysis and Recognition (ICDAR)},
 comments = {, The publication does not focus on explainability},
 doi = {10.1109/ICDAR.2015.7333750},
 issn = {},
 keywords = {document image processing;edge detection;feature extraction;image reconstruction;learning (artificial intelligence);natural language processing;neural nets;text analysis;trees (mathematics);text line extraction;document images;content based image understanding applications;generic text line extraction;candidate connected components;maximal stable extremal region;noise filtering;Adaboost;convolution neural network;CNN;hierarchical edge reconstruction;document spanning tree;text line energy minimization;text line consistency;fitting error;multilingual test dataset;Robustness;Benchmark testing;Image segmentation;Surveillance;Image recognition;Integrated optics;Optical imaging;generic text line extraction;MSER;hierarchical edge reconstruction and cut;text line energy minimization},
 month = {Aug},
 number = {},
 pages = {191-195},
 title = {Text line extraction in document images},
 volume = {},
 year = {2015}
}

@inproceedings{7333799,
 abstract = {In practical applications of document understanding, if the documents have multiple languages and orientations, the conventional OCR systems can not be directly applied. This is because those OCR systems are usually designed for texts of single language and normal orientation. To solve this problem, many non-character based recognition approaches were proposed. However, the performance of those methods were not comparable with the mature OCR systems. Consequently, a better idea is to recognize the language type and orientation before the OCR is applied. Besides, the characters of different languages have very ambiguous shape, so it is very difficult to extract stable feature for the recognition. Recently, the convolutional neural networks (CNN) have achieved great success in pattern recognition tasks. Therefore, for such difficult tasks, the CNN is one of the best choice. In this paper, we first applied CNN to the recognition of the document properties. A novel sliding window voting process is proposed to reduce the network scale and fully use the information of the text line. In the experiments, our method had very high recognition rate. The results proved the advantage of the proposed method and which also can be applied to create a document understanding system with OCR systems.},
 author = {L. {Chen} and S. {Wang} and W. {Fan} and J. {Sun} and N. {Satoshi}},
 booktitle = {2015 13th International Conference on Document Analysis and Recognition (ICDAR)},
 comments = {, The publication does not focus on explainability},
 doi = {10.1109/ICDAR.2015.7333799},
 issn = {},
 keywords = {document image processing;image recognition;neural nets;text detection;deep learning;orientation recognition;language recognition;document analysis;convolutional neural networks;CNN;document properties recognition;sliding window voting process;text line information;recognition rate;document understanding system;Kernel;Optical character recognition software},
 month = {Aug},
 number = {},
 pages = {436-440},
 title = {Deep learning based language and orientation recognition in document analysis},
 volume = {},
 year = {2015}
}

@inproceedings{777686,
 abstract = {Document Analysis and Understanding (DAU) is a complex AI application with high industrial impact. For the increasing demands upon the bandwidth and quality of the analysis it is crucial to enable different analysis modules to collaborate. For making collaboration possible, we first examine the question of whether there exists a common ontological basis which can serve as a platform for communication of different DAU modules. Once communication is enabled, we investigate the second question, how DAU modules originally designed as stand-alone systems must be modified in order to benefit from collaboration with others.},
 author = {B. {Klein} and A. {Abecker}},
 booktitle = {Proceedings IEEE Forum on Research and Technology Advances in Digital Libraries},
 comments = {, The publication does not focus on explainability},
 doi = {10.1109/ADL.1999.777686},
 issn = {1092-9959},
 keywords = {document handling;knowledge based systems;grammars;groupware;distributed knowledge based parsing;document analysis and understanding;DAU;complex AI application;industrial impact;analysis modules;collaboration;common ontological basis;DAU modules;Text analysis;Information analysis;Data mining;Collaboration;Text recognition;SGML;Automata;Artificial intelligence;Bandwidth;Ontologies},
 month = {May},
 number = {},
 pages = {6-15},
 title = {Distributed knowledge-based parsing for document analysis and understanding},
 volume = {},
 year = {1999}
}

@inproceedings{7821768,
 abstract = {The problem being addressed in this paper is that using brute force in Natural Language Processing and Machine Learning combined with advanced statistics will only approximate meaning and thus will not deliver in terms of real text understanding. Counting words and tracking word order or parsing by syntax will also result in probability and guesswork at best. Their vendors struggle in delivering accurate quality and this results in ill-functioning applications. The newer generation methodologies like Deep Learning and Cognitive Computing are breaking barriers in the (Big Data) fields of Internet of Things, Robotics and Image/Video Recognition but cannot be successfully deployed for text without huge amounts of training and sample data. In the short term, we believe non-biological Artificial Intelligence will produce the best results for text understanding. Miia applied advanced Linguistic and Semantic Technologies combined with ConceptNet modeling and Machine Learning to successfully cater deep intelligent and cross-language quality to several industries.},
 author = {L. {Stephen} and D. {Geert} and K. {Andreas} and P. {Frank}},
 booktitle = {2016 Future Technologies Conference (FTC)},
 comments = {, The publication does not focus on explainability},
 doi = {10.1109/FTC.2016.7821768},
 issn = {},
 keywords = {Big Data;Internet of Things;learning (artificial intelligence);mobile computing;natural language processing;semantic networks;statistics;text analysis;nonbiological AI approach;natural language understanding;natural language processing;machine learning;advanced statistics;meaning approximation;text understanding;word counting;word order tracking;syntax parsing;deep learning;cognitive computing;Big Data;Internet of Things;robotics;image/video recognition;nonbiological artificial intelligence;advanced linguistic technologies;semantic technologies;ConceptNet modeling;cross-language quality;Companies;Natural languages;Artificial intelligence;Semantics;Law;Engines;Natural Language Processing;Natural Language Understanding;Artificial Intelligence;Linguistics;Semantics;Machine Learning;ConceptNet Modelling;Data Mining;Sentiment Analysis;Data Analysis;Big Data;Business Intelligence},
 month = {Dec},
 number = {},
 pages = {1300-1302},
 title = {A non-biological AI approach towards natural language understanding},
 volume = {},
 year = {2016}
}

@inproceedings{7846312,
 abstract = {Spoken language understanding (SLU) is one of the important problem in natural language processing, and especially in dialog system. Fifth Dialog State Tracking Challenge (DSTC5) introduced a SLU challenge task, which is automatic tagging to speech utterances by two speaker roles with speech acts tag and semantic slots tag. In this paper, we focus on speech acts tagging. We propose local coactivate multi-task learning model for capturing structured speech acts, based on sentence features by recurrent convolutional neural networks. An experiment result, shows that our model outperformed all other submitted entries, and were able to capture coactivated local features of category and attribute, which are parts of speech act.},
 author = {T. {Ushio} and H. {Shi} and M. {Endo} and K. {Yamagami} and N. {Horii}},
 booktitle = {2016 IEEE Spoken Language Technology Workshop (SLT)},
 comments = {, The publication does not focus on explainability},
 doi = {10.1109/SLT.2016.7846312},
 issn = {},
 keywords = {feedforward neural nets;learning (artificial intelligence);natural language processing;pattern classification;recurrent neural nets;speech processing;text analysis;attribute feature;category feature;sentence feature;local coactivate multitask learning model;semantic-slot tag;speech-act tag;speech utterances;automatic tagging;SLU challenge task;DSTC5;Fifth-Dialog State Tracking Challenge;dialog system;natural language processing;spoken language understanding;structured speech act tagging;recurrent convolutional neural networks;Speech;Tagging;Neural networks;Hidden Markov models;Training;Text categorization;Neurons;spoken language understanding;speech act tagging;text classification;multi-task learning;neural networks},
 month = {Dec},
 number = {},
 pages = {518-524},
 title = {Recurrent convolutional neural networks for structured speech act tagging},
 volume = {},
 year = {2016}
}

@inproceedings{791799,
 abstract = {HUE (the Handwriting Understanding Environment) is a software framework for handwriting and document analysis built around a two-level programming model in which components are implemented in a system programming language (typically C++) and are connected together into prototype systems using the scripting language Tcl Tk. HUE is an extended version of TABS (a previous handwriting analysis framework), and incorporates the authors' experience of using TABS for around 2 years in data-intensive handwriting and document analysis research and evaluation. HUE currently contains 94 C++ components, 7 native data types, 11 custom-built Tcl Tk packages, a novel dynamic user interface, and several demonstration systems implemented as Tcl scripts.},
 author = {C. {Cracknell} and A. C. {Downton}},
 booktitle = {Proceedings of the Fifth International Conference on Document Analysis and Recognition. ICDAR '99 (Cat. No.PR00318)},
 comments = {, The publication does not focus on explainability},
 doi = {10.1109/ICDAR.1999.791799},
 issn = {},
 keywords = {document image processing;object-oriented programming;handwritten character recognition;user interfaces;software prototyping;Handwriting Understanding Environment;rapid prototyping;document analysis;handwriting analysis;software framework;two-level programming model;system programming language;Tcl Tk scripting language;TABS;C++ components;native data types;custom-built Tcl Tk packages;dynamic user interface;demonstration systems;Prototypes;Computer languages;Text analysis;Handwriting recognition;Image processing;Computer vision;Libraries;Programming profession;Design engineering;Systems engineering and theory},
 month = {Sep.},
 number = {},
 pages = {362-365},
 title = {A Handwriting Understanding Environment (HUE) for rapid prototyping in handwriting and document analysis research},
 volume = {},
 year = {1999}
}

@inproceedings{7982151,
 abstract = {The accuracy of conventional DGA interpretation methods can be different when each of these methods are used in different places or different circumstances. Rogers Ratio Method (RRM), IEC Ratio Method (IRM) (Basic Gas Ratios Method), GB/T 7252 (National Standard of the People's Republic of China) are popular conventional methods for interpreting the possible faults indicator of transformer in Indonesia and China. This research proposes artificial intelligence to interpret DGA by combining conventional method and artificial intelligence method using weighting factor. The artificial intelligence method which are used in this research is fuzzy logic. DGA practical data which used as refer data for data mining in this research were taken from China and Indonesia. This research also uses Thompson tau method to filter the data from outlier and fuzzy c means clustering to cluster the data to make sure the data are used is valid and good enough to be used to build artificial intelligence through data mining. The output of this research is to create an artificial intelligence and the combination between artificial intelligence which have been built with conventional method to interpret DGA whether there is any fault in transformer or not.},
 author = {C. {Subroto} and and and G. {Zhang}},
 booktitle = {2017 1st International Conference on Electrical Materials and Power Equipment (ICEMPE)},
 comments = {, The described method is neither general, nor focused on NLP},
 doi = {10.1109/ICEMPE.2017.7982151},
 issn = {},
 keywords = {artificial intelligence;fuzzy logic;fuzzy set theory;power engineering computing;power transformers;artificial intelligence;DGA interpretation methods;weighting factor;Rogers ratio method;RRM;IEC Ratio Method;IRM;basic gas ratios method;transformer faults indicator;fuzzy logic;Thompson tau method;fuzzy c means clustering;data mining;Artificial intelligence;Fuzzy logic;Partial discharges;Data mining;Discharges (electric);Power transformer insulation;DGA;Fuzzy Logic;Weighting factor;Thompson tau method;Fuzzy C Means},
 month = {May},
 number = {},
 pages = {85-88},
 title = {Artificial intelligence for DGA interpretation methods using weighting factor},
 volume = {},
 year = {2017}
}

@inproceedings{8047390,
 abstract = {The beginner counselors have more likely to continue counseling in their own interest, they have a high tendency to make great use of the closed-ended question in order to confirm the interpretation with the client. While expert counselors are instructing the counseling skill to beginner counselors, we consider that the reaction of a client for a beginner counselor's question is important to visualize in an appropriate method. To respond the request, we have developed a system for visualizing the flow of conversation in counseling. However, the expert counselor as the system user requires to correct the initial classification result manually, and the work burden is large, because the accuracy of the category classification of conversation data is very low in the current system. To improve this problem, we have implemented on the category classification method of text data with SVM (Support Vector Machine) as machine learning technique to visualize the flow of conversation in counseling. In addition, we have compared and evaluated with results of the initial classification method of the current system. As these results, we have shown that the accuracy rate of the classification method with SVM become higher than the results in the current system.},
 author = {Y. {Hayashida} and T. {Uetsuji} and Y. {Ebara} and K. {Koyamada}},
 booktitle = {2017 Nicograph International (NicoInt)},
 comments = {, The publication does not focus on explainability},
 doi = {10.1109/NICOInt.2017.35},
 issn = {},
 keywords = {data visualisation;learning (artificial intelligence);pattern classification;psychology;support vector machines;text analysis;category classification;text data;machine learning;conversation flow visualization;counseling;support vector machine;SVM;Employee welfare;Support vector machines;Data visualization;Psychology;Dictionaries;Data models;Employment;Counseling;Visualization;Machine Learning;Text Classification},
 month = {June},
 number = {},
 pages = {37-40},
 title = {Category Classification of Text Data with Machine Learning Technique for Visualizing Flow of Conversation in Counseling},
 volume = {},
 year = {2017}
}

@inproceedings{8128175,
 abstract = {The use of LiDAR and multiples digital images jointly with 3-D reconstruction techniques for creating 3-D models of natural outcrops and surfaces studies have increased dramatically in the last few years. These techniques have provided an enormous amount of data for interpretation by geoscientists. However, these researchers have no available software capable of offering a user experience comparable to the fieldwork. The majority of solutions have considered desktop systems, which presents inherent limitations due to the 2-D characteristics of displays and loss of immersion into the 3-D model, or up until expensive and complex stereoscopic based approaches to improve the 3-D user experience do not offer well suitable solutions. To address these limitations, this paper presents a low-cost completely disruptive solution for processing, visualizing, sharing and directly handling Digital Outcrop Models with the support of a full interpretation toolset, the MOSIS System. The proposed system provides a fully immersive computational environment, capable of teleporting virtually geoscientists to the fieldwork, giving an awareness of being there physically with an extensible toolset for the DOM's interpretation. Besides, desktop, web and mobile versions of MOSIS have been under development and fulfill the lack of tools for digital outcrop modeling.},
 author = {L. {Gonzaga} and M. R. {Veronez} and D. N. {Alves} and F. {Bordin} and G. L. {Kannenberg} and F. P. {Marson} and F. M. W. {Tognoli} and L. C. {Inocencio}},
 booktitle = {2017 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)},
 comments = {, The publication does not focus on explainability, The described method is neither general, nor focused on NLP},
 doi = {10.1109/IGARSS.2017.8128175},
 issn = {2153-7003},
 keywords = {data visualisation;geophysical techniques;image reconstruction;optical radar;radar imaging;stereo image processing;MOSIS;multioutcrop sharing multiples digital images;digital outcrop models;DOM interpretation;digital outcrop modeling;fully immersive computational environment;MOSIS System;interpretation toolset;complex stereoscopic based approaches;natural outcrops;3-D model;3-D reconstruction techniques;Three-dimensional displays;Geology;Data visualization;Solid modeling;Tools;Visualization;Standards;immersive visualization;digital outcop model (DOM);virtual outcrop;interpretation;3-D visualization;GPU Computing},
 month = {July},
 number = {},
 pages = {5209-5212},
 title = {MOSIS — Multi-outcrop sharing interpretation system},
 volume = {},
 year = {2017}
}

@inproceedings{8256457,
 abstract = {It must be rather difficult for ordinary people to communicate with robots using special technical languages. Therefore, it must be more desirable for them to use natural language (NL) for such a purpose because it is the most conventional among them. This work proposes a methodology for natural language understanding through an AI system named Conversation Management System (CMS) based on Mental Image Directed Semantic Theory proposed by M. Yokota. CMS is intended to enable a robot to understand NL in the same way as people do, and actually can reach the most plausible semantic interpretation of an input text and return desirable outcomes by employing word concepts, postulates, and inference rules. Recently, the authors have applied several spatial terms in English language, for example verbs, prepositions (e.g. between, along, left, right, and so on). We found that the methodology is outstanding from conventional approaches with the attempt to provide robots understand NL based on mental image model. This paper focuses on how CMS understands static spatial (3D) relations expressed in NL.},
 author = {R. {Khummongkol} and M. {Yokota}},
 booktitle = {2017 IEEE 8th International Conference on Awareness Science and Technology (iCAST)},
 comments = {, The publication does not focus on explainability},
 doi = {10.1109/ICAwST.2017.8256457},
 issn = {2325-5994},
 keywords = {artificial intelligence;human-robot interaction;natural language processing;mental image based understanding;static relations;dynamic spatial relations;special technical languages;NL;natural language understanding;AI system;Conversation Management System;CMS;Mental Image Directed Semantic Theory;spatial terms;English language;mental image model;robot communication;semantic interpretation;static spatial 3D relations;Robots;Semantics;Natural languages;Rivers;Conferences;Artificial intelligence;Cognition;natural language understanding;human — robot interaction;semantic interpretation},
 month = {Nov},
 number = {},
 pages = {254-259},
 title = {An approach to mental image based understanding of natural language: Focused on static and dynamic spatial relations},
 volume = {},
 year = {2017}
}

@inproceedings{8276047,
 abstract = {Sentiment analysis is a methodology used to analyse the emotion or view of an individual to a situation or topic. In present scenario, Social media is the source for the collection of individual's feedbacks, user's emotions, reviews and personal experiences which lead to a need for efficient mining of the text to derive knowledge. An optimal classification of text based on emotion is an unsolved problem in text mining. To extract knowledge from text many machine learning tools and techniques were proposed. An onto-based process is proposed to analyse the customer's emotion in this paper. The input emotional text that needs to be classified is given as input to the NLP and processed and an emotional ontology is created for better understanding of the semantics and relationships. When adding new instances, Ontology can be automatically classify them based on emotional relationship. The Emowords from ontology can be further classified using any of the standard machine learning techniques which definitively gives a better performance. This paper is a review of all the machine learning techniques that can be applied on the semantic analysis of sentiments.},
 author = {K. {Saranya} and S. {Jayanthy}},
 booktitle = {2017 International Conference on Innovations in Information, Embedded and Communication Systems (ICIIECS)},
 comments = {, The publication does not focus on explainability},
 doi = {10.1109/ICIIECS.2017.8276047},
 issn = {},
 keywords = {data mining;emotion recognition;knowledge based systems;learning (artificial intelligence);natural language processing;ontologies (artificial intelligence);pattern classification;sentiment analysis;social networking (online);text analysis;text mining;machine learning tools;customer;input emotional text;emotional ontology;emotional relationship;standard machine learning techniques;sentiment analysis;Social media;feedbacks;optimal classification;Emowords;Onto-based sentiment classification;NLP;Ontologies;Sentiment analysis;Social network services;Text mining;Semantics;Support vector machines;sentimental analysis;ontology;machine learning;NLP;semantics},
 month = {March},
 number = {},
 pages = {1-5},
 title = {Onto-based sentiment classification using machine learning techniques},
 volume = {},
 year = {2017}
}

@inproceedings{8308186,
 abstract = {The term Deep Learning or Deep Neural Network refers to Artificial Neural Networks (ANN) with multi layers. Over the last few decades, it has been considered to be one of the most powerful tools, and has become very popular in the literature as it is able to handle a huge amount of data. The interest in having deeper hidden layers has recently begun to surpass classical methods performance in different fields; especially in pattern recognition. One of the most popular deep neural networks is the Convolutional Neural Network (CNN). It take this name from mathematical linear operation between matrixes called convolution. CNN have multiple layers; including convolutional layer, non-linearity layer, pooling layer and fully-connected layer. The convolutional and fully-connected layers have parameters but pooling and non-linearity layers don't have parameters. The CNN has an excellent performance in machine learning problems. Specially the applications that deal with image data, such as largest image classification data set (Image Net), computer vision, and in natural language processing (NLP) and the results achieved were very amazing. In this paper we will explain and define all the elements and important issues related to CNN, and how these elements work. In addition, we will also state the parameters that effect CNN efficiency. This paper assumes that the readers have adequate knowledge about both machine learning and artificial neural network.},
 author = {S. {Albawi} and T. A. {Mohammed} and S. {Al-Zawi}},
 booktitle = {2017 International Conference on Engineering and Technology (ICET)},
 comments = {, The publication does not focus on explainability},
 doi = {10.1109/ICEngTechnol.2017.8308186},
 issn = {},
 keywords = {computer vision;feedforward neural nets;image classification;learning (artificial intelligence);natural language processing;fully-connected layers;convolutional connected layers;nonlinearity layer;multiple layers;matrixes called convolution;mathematical linear operation;classical methods performance;deeper hidden layers;multilayers;Artificial Neural Networks;Deep Neural Network;term Deep Learning;convolutional neural network;artificial neural network;largest image classification data;image data;CNN;pooling;Convolution;Neurons;Convolutional neural networks;Feature extraction;Image edge detection;machine learning;artificial neural networks;deep learning;convolutional neural networks;computer vision;Image recognition},
 month = {Aug},
 number = {},
 pages = {1-6},
 title = {Understanding of a convolutional neural network},
 volume = {},
 year = {2017}
}

@inproceedings{8320258,
 abstract = {These days, text summarization is an active research field to identify the relevant information from large documents produced in various domains such as finance, news media, academics, politics, etc. Text summarization is the process of shortening the documents by preserving the important contents of the text. This can be achieved through extractive and abstractive summarization. In this paper, we have proposed an approach to extract a good set of features followed by neural network for supervised extractive summarization. Our experimental results on Document Understanding Conferences 2002 dataset show the effectiveness of the proposed method against various online extractive text summarizers.},
 author = {A. {Jain} and D. {Bhatia} and M. K. {Thakur}},
 booktitle = {2017 International Conference on Machine Learning and Data Science (MLDS)},
 comments = {, The publication does not focus on explainability},
 doi = {10.1109/MLDS.2017.12},
 issn = {},
 keywords = {text analysis;news media;abstractive summarization;supervised extractive summarization;Document Understanding Conferences 2002 dataset;online extractive text summarizers;word vector;active research field;Feature extraction;Neural networks;Data mining;Training;Mathematical model;Computational modeling;Testing;Extractive Text Summarization;Neural Network;Machine Learning;Word Vector Embedding},
 month = {Dec},
 number = {},
 pages = {51-55},
 title = {Extractive Text Summarization Using Word Vector Embedding},
 volume = {},
 year = {2017}
}

@inproceedings{8332874,
 abstract = {Semantic Text Similarity plays a major role in natural language processing. In recent years, researchers have paid considerable attention to Semantic Text Similarity. Some breakthroughs have been made in English, but there are two disadvantages when these models are applied to Chinese: Single sequence models don't consider semantic ambiguity such as polysemy, synonym; these models don't consider that Chinese stop words are important for Chinese word segmentation, voice analysis, semantic understanding. Firstly, in order to overcome the first problem, we proposed the double short text sequences model that has two identical LSTM (Long Short-Term Memory) processing two text sequences at the same time. Secondly, in order to overcome the second problem, according to the characteristics of Chinese, we used the Chinese semantic similarity data sets designed by experts to train and test the model, and retained the stop words in the model training process. Finally, the proposed model was compared with the Semantic Text Similarity model based on CNN (Convolution Neural Network) and the Baidu Semantic Text Similarity model. The results show that the model is greater than the previous two in terms of accuracy, recall rate and so on, and the generalization ability is improved also.},
 author = {T. {Shancheng} and B. {Yunyue} and M. {Fuyu}},
 booktitle = {2018 International Conference on Intelligent Transportation, Big Data Smart City (ICITBS)},
 comments = {, The publication does not focus on explainability},
 doi = {10.1109/ICITBS.2018.00190},
 issn = {},
 keywords = {feedforward neural nets;learning (artificial intelligence);natural language processing;text analysis;natural language processing;semantic ambiguity;Chinese stop words;Chinese word segmentation;semantic understanding;double short text sequences model;Long Short-Term Memory;Chinese semantic similarity data sets;single sequence models;double short Chinese sequences;Baidu semantic text similarity model;CNN;convolution neural network;Semantics;Training;Computational modeling;Data models;Analytical models;Training data;Encyclopedias;Semantic similarity;Chinese short text;double sequence;deep learning},
 month = {Jan},
 number = {},
 pages = {736-739},
 title = {A Semantic Text Similarity Model for Double Short Chinese Sequences},
 volume = {},
 year = {2018}
}

@inproceedings{8356909,
 abstract = {Deep Learning for the game of Go recently had a tremendous success with the victory of AlphaGo against Ke Jie in May 2017. However, there is no clear understanding of why they perform so well. In this paper, we introduce a visualization technique that performs a sensitivity analysis of the classifier output by occluding portions of the input Go board, revealing which parts of the board are important for predicting the next move. Using this tool, we start with the experiment about the accuracy of the critical area revealed. We also suppose that by showing the critical area, it will allow Go beginners to understand the board visually that they may have been confused about.},
 author = {Y. {Pang} and T. {Ito}},
 booktitle = {2017 Conference on Technologies and Applications of Artificial Intelligence (TAAI)},
 comments = {Presents a specific method for enhancing explainability for models, The described method is neither general, nor focused on NLP},
 doi = {10.1109/TAAI.2017.42},
 issn = {2376-6824},
 keywords = {computer games;data visualisation;learning (artificial intelligence);pattern classification;sensitivity analysis;sensitivity analysis;classifier output;critical area;visualization method;Ke Jie;deep learning;computer go;Go game;AlphaGo;input Go board;Machine learning;Data visualization;Training;Deep Learning;Computer Go;Visualization},
 month = {Dec},
 number = {},
 pages = {62-65},
 title = {A Proposal of Visualization Method for Critical Area in Computer Go},
 volume = {},
 year = {2017}
}

@inproceedings{8371950,
 abstract = {Most of the technical documents are composed by several modalities, like diagrams, tables, formulas, graphics, pictures and natural language text. Each of these modalities and their associations significantly contribute to the overall deep understanding of the technical document and the knowledge represented in it. Here for us all these modalities, except NL text, are considered as "images". Thus, each technical document mainly is composed by NL text sentences and "images". Thus, in this paper we present a methodology where all these modalities can be expressed into the same two modalities (natural languages text sentences and SPN graphs) for better associations and deeper understanding of a technical document. This deeper understanding will come from two different contributions. The first unique contribution will be an enrichment of the NL text part with additional NL text sentences extracted from the "images" of the technical document. The second unique contribution will come from the SPM models of these images that enrich the main diagram by generating a simulator for the system that technical document describes.},
 author = {N. {Bourbakis}},
 booktitle = {2017 IEEE 29th International Conference on Tools with Artificial Intelligence (ICTAI)},
 comments = {, The publication does not focus on explainability},
 doi = {10.1109/ICTAI.2017.00047},
 issn = {2375-0197},
 keywords = {document image processing;graph theory;natural language processing;Petri nets;stochastic processes;text analysis;technical document;natural languages text sentences;stochastic Petri-net forms;SPN graphs;knowledge representation;Pictures;Graphics;Tables;Formulas;Diagrams;NL text sentences;Databases;Text recognition;Shape;Image recognition;Natural languages;Visualization;SPN;Technical Documents;NL text Sentences},
 month = {Nov},
 number = {},
 pages = {247-254},
 title = {Converting Diagrams, Formulas, Tables, Graphics and Pictures into SPN and NL-text Sentences for Automatic Deep Understanding of Technical Documents},
 volume = {},
 year = {2017}
}

@article{8399509,
 abstract = {In hyperspectral image processing, classification is one of the most popular research topics. In recent years, research progress made in deep-learning-based hierarchical feature extraction and classification has shown a great power in many applications. In this paper, we propose a novel local spatial sequential (LSS) method, which is used in a recurrent neural network (RNN). Using this model, we can extract local and semantic information for hyperspectral image classification. First, we extract low-level features from hyperspectral images, including texture and differential morphological profiles. Second, we combine the low-level features together and propose a method to construct the LSS features. Afterwards, we build an RNN and use the LSS features as the input to train the network for optimizing the system parameters. Finally, the high-level semantic features generated by the RNN is fed into a softmax layer for the final classification. In addition, a nonlocal spatial sequential method is presented for the recurrent neural network model (NLSS-RNN) to further enhance the classification performance. NLSS-RNN finds nonlocal similar structures to a given pixel and extracts corresponding LSS features, which not only preserve the local spatial information, but also integrate the information of nonlocal similar samples. The experimental results on three publicly accessible datasets show that our proposed method can obtain competitive performance compared with several state-of-the-art classifiers.},
 author = {X. {Zhang} and Y. {Sun} and K. {Jiang} and C. {Li} and L. {Jiao} and H. {Zhou}},
 comments = {, The publication does not focus on explainability},
 doi = {10.1109/JSTARS.2018.2844873},
 issn = {1939-1404},
 journal = {IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing},
 keywords = {feature extraction;image classification;learning (artificial intelligence);recurrent neural nets;local spatial information;spatial sequential recurrent neural network;hyperspectral image classification;hyperspectral image processing;popular research topics;deep-learning-based hierarchical feature extraction;local spatial sequential method;local information;semantic information;low-level features;hyperspectral images;high-level semantic features;nonlocal spatial sequential method;recurrent neural network model;NLSS-RNN;LSS feature extraction;Feature extraction;Recurrent neural networks;Machine learning;Hyperspectral imaging;Computer architecture;Feedforward neural networks;Deep learning;high-level semantic feature;hyperspectral image (HSI) classification;low-level feature;recurrent neural network (RNN)},
 month = {Nov},
 number = {11},
 pages = {4141-4155},
 title = {Spatial Sequential Recurrent Neural Network for Hyperspectral Image Classification},
 volume = {11},
 year = {2018}
}

@article{8432512,
 abstract = {Hyperspectral unmixing (HU) is a method used to estimate the fractional abundances corresponding to endmembers in each of the mixed pixels in the hyperspectral remote sensing image. In recent times, deep learning has been recognized as an effective technique for hyperspectral image classification. In this letter, an end-to-end HU method is proposed based on the convolutional neural network (CNN). The proposed method uses a CNN architecture that consists of two stages: the first stage extracts features and the second stage performs the mapping from the extracted features to obtain the abundance percentages. Furthermore, a pixel-based CNN and cube-based CNN, which can improve the accuracy of HU, are presented in this letter. More importantly, we also use dropout to avoid overfitting. The evaluation of the complete performance is carried out on two hyperspectral data sets: Jasper Ridge and Urban. Compared with that of the existing method, our results show significantly higher accuracy.},
 author = {X. {Zhang} and Y. {Sun} and J. {Zhang} and P. {Wu} and L. {Jiao}},
 comments = {, The publication does not focus on explainability},
 doi = {10.1109/LGRS.2018.2857804},
 issn = {1545-598X},
 journal = {IEEE Geoscience and Remote Sensing Letters},
 keywords = {feature extraction;hyperspectral imaging;image classification;learning (artificial intelligence);recurrent neural nets;hyperspectral unmixing;deep convolutional neural networks;hyperspectral remote sensing image;deep learning;hyperspectral image classification;end-to-end HU method;convolutional neural network;CNN architecture;pixel-based CNN;hyperspectral data sets;Jasper Ridge dataset;Urban dataset;Feature extraction;Hyperspectral imaging;Convolution;Artificial neural networks;Indexes;Kernel;Convolutional neural networks (CNNs);end-to-end model;spectral unmixing;spectral–spatial information},
 month = {Nov},
 number = {11},
 pages = {1755-1759},
 title = {Hyperspectral Unmixing via Deep Convolutional Neural Networks},
 volume = {15},
 year = {2018}
}

@article{8440842,
 abstract = {We have recently seen many successful applications of recurrent neural networks (RNNs) on electronic medical records (EMRs), which contain histories of patients' diagnoses, medications, and other various events, in order to predict the current and future states of patients. Despite the strong performance of RNNs, it is often challenging for users to understand why the model makes a particular prediction. Such black-box nature of RNNs can impede its wide adoption in clinical practice. Furthermore, we have no established methods to interactively leverage users' domain expertise and prior knowledge as inputs for steering the model. Therefore, our design study aims to provide a visual analytics solution to increase interpretability and interactivity of RNNs via a joint effort of medical experts, artificial intelligence scientists, and visual analytics researchers. Following the iterative design process between the experts, we design, implement, and evaluate a visual analytics tool called RetainVis, which couples a newly improved, interpretable, and interactive RNN-based model called RetainEX and visualizations for users' exploration of EMR data in the context of prediction tasks. Our study shows the effective use of RetainVis for gaining insights into how individual medical codes contribute to making risk predictions, using EMRs of patients with heart failure and cataract symptoms. Our study also demonstrates how we made substantial changes to the state-of-the-art RNN model called RETAIN in order to make use of temporal information and increase interactivity. This study will provide a useful guideline for researchers that aim to design an interpretable and interactive visual analytics tool for RNNs.},
 author = {B. C. {Kwon} and M. {Choi} and J. T. {Kim} and E. {Choi} and Y. B. {Kim} and S. {Kwon} and J. {Sun} and J. {Choo}},
 comments = {Presents a specific method for enhancing explainability for models, The described method is neither general, nor focused on NLP},
 doi = {10.1109/TVCG.2018.2865027},
 issn = {1077-2626},
 journal = {IEEE Transactions on Visualization and Computer Graphics},
 keywords = {artificial intelligence;data analysis;data visualisation;interactive systems;medical information systems;recurrent neural nets;interactive RNN-based model;EMR data;prediction tasks;RetainVis;individual medical codes;risk predictions;temporal information;increase interactivity;interpretable analytics tool;interpretable networks;interactive recurrent neural networks;electronic medical records;black-box nature;interactively leverage users;design study;visual analytics solution;medical experts;artificial intelligence scientists;iterative design process;newly improved RNN-based model;RNN-based model;visual analytic researchers;interactive visual analytic tool;Machine learning;Medical diagnostic imaging;Task analysis;Predictive models;Computational modeling;Visual analytics;Data models;Interactive Artificial Intelligence;XAI (Explainable Artificial Intelligence);Interpretable Deep Learning;Healthcare},
 month = {Jan},
 number = {1},
 pages = {299-309},
 title = {RetainVis: Visual Analytics with Interpretable and Interactive Recurrent Neural Networks on Electronic Medical Records},
 volume = {25},
 year = {2019}
}

@inproceedings{8468758,
 abstract = {Machine learning technology has been greatly developed in the last decade, which makes artificial intelligence reach a revolutionary breakthrough and lets us really perceive the potential of artificial intelligence in changing human life. In order to improve the understanding and application ability of artificial intelligence, carrying out the corresponding machine learning course is of significance for the students during the undergraduate period. This paper probes into the teaching content, teaching form and other aspects of the undergraduate machine learning course based on this issue and proposes a teaching method driven by application scenarios to guide the undergraduate students to understand the development, current situation and frontier technology of machine learning. In the experimental design, the students' theoretical knowledge is fully considered, the practical questions are simplified, and the students' ability to think and solve problems is also raised, so as to lay a theoretical and practical basis for further study of machine learning.},
 author = {W. {Sun} and X. {Gao}},
 booktitle = {2018 13th International Conference on Computer Science Education (ICCSE)},
 comments = {, The publication does not focus on explainability},
 doi = {10.1109/ICCSE.2018.8468758},
 issn = {2473-9464},
 keywords = {artificial intelligence;computer aided instruction;computer science education;educational courses;further education;learning (artificial intelligence);teaching;artificial intelligence era;machine learning technology;undergraduate period;undergraduate students;undergraduate machine learning course;machine learning course;teaching content;teaching form;Machine learning;Machine learning algorithms;Classification algorithms;Prediction algorithms;Education;Decision trees;artificial intelligence;machine learning;undergraduate},
 month = {Aug},
 number = {},
 pages = {1-5},
 title = {The Construction of Undergraduate Machine Learning Course in the Artificial Intelligence Era},
 volume = {},
 year = {2018}
}

@article{8494828,
 abstract = {Neural sequence-to-sequence models have proven to be accurate and robust for many sequence prediction tasks, and have become the standard approach for automatic translation of text. The models work with a five-stage blackbox pipeline that begins with encoding a source sequence to a vector space and then decoding out to a new target sequence. This process is now standard, but like many deep learning methods remains quite difficult to understand or debug. In this work, we present a visual analysis tool that allows interaction and “what if”-style exploration of trained sequence-to-sequence models through each stage of the translation process. The aim is to identify which patterns have been learned, to detect model errors, and to probe the model with counterfactual scenario. We demonstrate the utility of our tool through several real-world sequence-to-sequence use cases on large-scale models.},
 author = {H. {Strobelt} and S. {Gehrmann} and M. {Behrisch} and A. {Perer} and H. {Pfister} and A. M. {Rush}},
 comments = {Presents a specific method for enhancing explainability for models, The described method is neither general, nor focused on NLP},
 doi = {10.1109/TVCG.2018.2865044},
 issn = {1077-2626},
 journal = {IEEE Transactions on Visualization and Computer Graphics},
 keywords = {data visualisation;learning (artificial intelligence);neural nets;program debugging;sequences;seq2seq-Vis;source sequence;target sequence;visual debugging tool;neural sequence-to-sequence models;blackbox pipeline;vector space;deep learning methods;visual analysis tool;Analytical models;Visualization;Tools;Predictive models;Machine learning;Data models;Atmosphere;Explainable AI;Visual Debugging;Visual Analytics;Machine Learning;Deep Learning;NLP},
 month = {Jan},
 number = {1},
 pages = {353-363},
 title = {Seq2seq-Vis: A Visual Debugging Tool for Sequence-to-Sequence Models},
 volume = {25},
 year = {2019}
}

@inproceedings{8519384,
 abstract = {Identifying the aspect for a given target is an important issue in synthetic aperture radar (SAR) image interpretation. A new SAR target aspect identification method based on machine learning theory is proposed in this paper. First, the aspect angles of the SAR target are discretized, and the spatial relationships of the neighborhoods of the SAR target samples are established. Then an optimal linear mapping is solved based on the proposed subspace aspect discriminant analysis. The samples will be projected into a low-dimensional space and be of a better aspect identifiability than in their original space. Finally, the projected samples are fed into a multilayer neural network, and the aspects of the SAR targets will be indicated. Experimental results have shown the superiority of the proposed method based on the moving and stationary target acquisition and recognition (MSTAR) data set.},
 author = {J. {Pei} and Y. {Huang} and W. {Huo} and Y. {Zhang} and J. {Yang}},
 booktitle = {IGARSS 2018 - 2018 IEEE International Geoscience and Remote Sensing Symposium},
 comments = {, The publication does not focus on explainability},
 doi = {10.1109/IGARSS.2018.8519384},
 issn = {2153-7003},
 keywords = {image sampling;learning (artificial intelligence);multilayer perceptrons;radar computing;radar imaging;radar target recognition;synthetic aperture radar;optimal linear mapping;low-dimensional space;moving-and-stationary target acquisition-and-recognition data set;MSTAR data set;multilayer neural network;aspect angles;machine learning theory;SAR target aspect identification method;synthetic aperture radar image interpretation;SAR image;stationary target acquisition;projected samples;aspect identifiability;subspace aspect discriminant analysis;SAR target samples;Synthetic aperture radar;Multi-layer neural network;Estimation;Training;Neurons;Machine learning;Synthetic aperture radar;target aspect identification;machine learning;multi-layer neural network},
 month = {July},
 number = {},
 pages = {2310-2313},
 title = {Target Aspect Identification in SAR Image: A Machine Learning Approach},
 volume = {},
 year = {2018}
}

@article{8540793,
 abstract = {This technology manager's note piece identifies the major components in the artificial intelligence (AI) business ecosystem and discusses several implications for managers. Specifically, it emphasizes on the designing of AI user scenarios, data acquisition for AI, and building the AI ecosystem.},
 author = {X. I. {Quan} and J. {Sanderson}},
 comments = {, The publication does not focus on explainability},
 doi = {10.1109/EMR.2018.2882430},
 issn = {0360-8581},
 journal = {IEEE Engineering Management Review},
 keywords = {artificial intelligence;business data processing;competitive intelligence;data acquisition;technology management;artificial intelligence business ecosystem;technology manager;AI user scenarios;AI ecosystem;data acquisition;Business;Ecosystems;Machine learning;Medical services;Buildings;Artificial intelligence;business ecosystem;technology management},
 month = {Fourthquarter},
 number = {4},
 pages = {22-25},
 title = {Understanding the Artificial Intelligence Business Ecosystem},
 volume = {46},
 year = {2018}
}

@inproceedings{8551093,
 abstract = {Natural Language (NL) is an essential part of ourlife. Humans use language for communication. NL is a prevailing tool used by the humans to convey the information. Natural Language Understanding (NLU) is a major challenge in Natural Language Processing (NLP). NLP is a part of Artificial Intelligence (AI). NLP provides a significant tool for communication. It attempts to produces noise free data and conversion of noise to text. NLU is having different levels. This paper presents the issue with respect to one of the level such as syntax analysis. To provide a solution for syntax analysis, dynamic fuzzy parser is designed and implemented to parse the English input sentences. Traditional approach of parsing is enhanced by applying fuzzy logic. This helps to know the syntactic correctness of the sentence. Penns tree bank parts of speech tags are used for the Parts of Speech Tagger (POS). POS tagger assigns the parts of speech tags for the input English sentence. Then these tags of the words are parsed using the grammar rules. Finally the result is displayed to represent the number of words parsed in a sentence with its associated fuzzy membership value. This parser produces Precision value of 1(100%), Recall value of 0.92 (92%) and F-measure value of 0.9583 for the sample of 50 correct and 50 incorrect sentences.},
 author = {S. G. {Kanakaraddi} and S. S. {Nandval}},
 booktitle = {2018 International Conference on Current Trends towards Converging Technologies (ICCTCT)},
 comments = {, The publication does not focus on explainability},
 doi = {10.1109/ICCTCT.2018.8551093},
 issn = {},
 keywords = {artificial intelligence;computational linguistics;context-free grammars;fuzzy logic;natural language processing;text analysis;syntax analysis;dynamic fuzzy parser;natural language;recall value;precision value;F-measure value;grammar rules;parts of speech tagger;Penns tree bank parts of speech tags;parse English input sentences;artificial intelligence;natural language processing;natural language understanding;fuzzy membership value;POS tagger;NLP;NLU;fuzzy max-min technique;fuzzy logic;Grammar;Syntactics;Natural language processing;Conferences;Market research;Artificial intelligence;POS;FCFG;NL;NLU;NLP;POS;AI;CFG},
 month = {March},
 number = {},
 pages = {1-5},
 title = {Dynamic Fuzzy Parser to Parse English Sentence Using POS Tagger and Fuzzy Max-Min Technique},
 volume = {},
 year = {2018}
}

@inproceedings{8588744,
 abstract = {We address the interpretability of convolutional neural networks (CNNs) for predicting a geo-location from an image. In a pilot experiment we classify images of Pittsburgh vs Tokyo and visualize the learned CNN filters. We found that varying the CNN architecture leads to variating in the visualized filters. This calls for further investigation of the effective parameters on the interpretability of CNNs.},
 author = {S. {Khademi} and X. {Shi} and T. {Mager} and R. {Siebes} and C. {Hein} and V. {de Boer} and J. {van Gemert}},
 booktitle = {2018 IEEE 14th International Conference on e-Science (e-Science)},
 comments = {Presents a specific method for enhancing explainability for models, The described method is neither general, nor focused on NLP},
 doi = {10.1109/eScience.2018.00125},
 issn = {},
 keywords = {feedforward neural nets;learning (artificial intelligence);neural net architecture;sight-seeing;eyes;deep neural networks;interpretability;convolutional neural networks;CNNs;geo-location;Tokyo;learned CNN filters;CNN architecture;visualized filters;Visualization;Computer architecture;Neural networks;Image recognition;Conferences;Computer science;Intelligent systems;convolutional neural network (CNN);interpretability;place recognition;visualization;classification},
 month = {Oct},
 number = {},
 pages = {407-408},
 title = {Sight-Seeing in the Eyes of Deep Neural Networks},
 volume = {},
 year = {2018}
}

@inproceedings{8613997,
 abstract = {Personalized Healthcare (PH) is a new patientoriented healthcare approach which expects to improve the traditional healthcare system. The focus of this new advancement is the patient data collected from patient Electronic health records (EHR), Internet of Things (IoT) sensor devices, wearables and mobile devices, web-based information and social media. PH applies Artificial Intelligence (AI) techniques to the collected dataset to improve disease progression technique, disease prediction, patient selfmanagement and clinical intervention. Machine learning techniques are widely used in this regard to develop analytic models. These models are integrated into different healthcare service applications and clinical decision support systems. These models mainly analyse the collected data from sensor devices and other sources to identify behavioral patterns and clinical conditions of the patient. For example, these models analyse the collected data to identify the patient's improvements, habits and anomaly in daily routine, changes in sleeping and mobility, eating, drinking and digestive pattern. Based on those patterns the healthcare applications and the clinical decision support systems recommend lifestyle advice, special treatment and care plans for the patient. The doctors and caregivers can also be engaged in the care plan process to validate lifestyle advice. However, there are many uncertainties and a grey area when it comes to applying machine learning in this context. Clinical, behaviour and lifestyle data in nature are very sensitive. There could be different types of biased involved in the process of data collection and interpretation. The training data model could have an older version of the dataset. All these could lead to an incorrect decision from the system without the user's knowledge. In this paper, some of the standards of the ML models reported in the recent research trends, identify the reliability issues and propose improvements.},
 author = {F. {Ahamed} and F. {Farid}},
 booktitle = {2018 International Conference on Machine Learning and Data Engineering (iCMLDE)},
 comments = {, The described method is neither general, nor focused on NLP},
 doi = {10.1109/iCMLDE.2018.00014},
 issn = {},
 keywords = {data acquisition;decision support systems;diseases;electronic health records;health care;Internet of Things;learning (artificial intelligence);patient treatment;healthcare service applications;patient self-management;artificial intelligence techniques;Web-based information;Internet of Things sensor devices;electronic health records;healthcare system;electronic health records;ML models;training data model;data collection;lifestyle data;healthcare applications;clinical conditions;behavioral patterns;clinical decision support systems;machine learning techniques;clinical intervention;disease prediction;disease progression technique;social media;mobile devices;patient data;personalized healthcare;Machine learning;Internet of Things;Hospitals;Monitoring;Sleep apnea;Personalized Healthcare;Internet of Things;Machine Learning},
 month = {Dec},
 number = {},
 pages = {19-21},
 title = {Applying Internet of Things and Machine-Learning for Personalized Healthcare: Issues and Challenges},
 volume = {},
 year = {2018}
}

@inproceedings{8621470,
 abstract = {Development of chromosome conformation capture methods boosted progress in the study of the spatial organization of chromatin. Accumulation of large amounts of experimental data provides an opportunity to apply machine learning methods to examine the connection between epigenetics and the three-dimensional structure of chromatin. The aim of this study was to predict the characteristics of the chromatin structure, namely the transitional gamma, from ChIP-Seq experimental data by means of machine learning methods, and also to reveal the properties of epigenetic data influencing prediction. The neural network and the loss function designed for the prediction task are shown to perform with a sufficiently high accuracy. In addition, the genomic size of the chromatin context required for improving the quality of the prediction was assessed. Several neural network visualization techniques were tested as a means for improving interpretability of network, showing the possibility for using visualization to study interrelations in epigenetic data relevant for three-dimensional chromatin structure. To sum up, a close relationship between epigenetic factors and the structure of chromatin has been confirmed.},
 author = {S. {Starikov} and E. {Khrameeva} and M. {Gelfand}},
 booktitle = {2018 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)},
 comments = {, The publication does not focus on explainability, The described method is neither general, nor focused on NLP},
 doi = {10.1109/BIBM.2018.8621470},
 issn = {},
 keywords = {biology computing;data visualisation;genetics;genomics;learning (artificial intelligence);neural nets;chromosome conformation capture methods;ChIP-Seq experimental data;machine learning methods;epigenetic data influencing prediction;neural network visualization techniques;three-dimensional chromatin structure;chromatin spatial structure characteristics;Machine learning;Bioinformatics;Neural networks;Data visualization;Conferences;Biomedical engineering;Life sciences;Hi-C;machine learning;neural networks;ChIP-Seq},
 month = {Dec},
 number = {},
 pages = {2489-2489},
 title = {Prediction of chromatin spatial structure characteristics using machine learning methods},
 volume = {},
 year = {2018}
}

@inproceedings{8622439,
 abstract = {Explaining recommendations helps users to make more accurate and effective decisions and improves system credibility and transparency. Current explainable recommender systems tend to provide fixed statements such as "customers who purchased this item also purchased....". This explanation is generated only on the basis of the purchase history of similar customers, so it does not include the preferences of customers who have purchased the item or a description of the item. Since user-generated reviews generally contain information about the reviewer's preferences and a description of the item, such reviews typically have more effect on purchase decisions. Therefore, using reviews to explain recommendations should be more useful than providing only a fixed statement explanation. Aiming to create a system that provides personalized explanations for recommendations, we have developed a recurrent neural network model that uses multicriteria evaluation data to generate reviews.},
 author = {T. {Suzuki} and S. {Oyama} and M. {Kurihara}},
 booktitle = {2018 IEEE International Conference on Big Data (Big Data)},
 comments = {, The publication does not focus on explainability},
 doi = {10.1109/BigData.2018.8622439},
 issn = {},
 keywords = {information filtering;information filters;recommender systems;recurrent neural nets;explainable recommendations;explainable recommender systems;review text;personalized explanations;fixed statement explanation;purchase decisions;reviewer;user-generated reviews;purchase history;fixed statements;transparency;system credibility;multicriteria evaluation data;Decoding;Data models;Recommender systems;Mathematical model;Computational modeling;History;Recurrent neural networks;explainable recommendation;text generation;RNN;recommender systems},
 month = {Dec},
 number = {},
 pages = {3549-3551},
 title = {Toward Explainable Recommendations: Generating Review Text from Multicriteria Evaluation Data},
 volume = {},
 year = {2018}
}

@inproceedings{8679370,
 abstract = {Facial expression is the most powerful and natural non-verbal emotional communication method. Facial Expression Recognition(FER) has significance in machine learning tasks. Deep Learning models perform well in FER tasks, but it doesn't provide any justification for its decisions. Based on the hypothesis that facial expression is a combination of facial muscle movements, we find that Facial Action Coding Units(AUs) and Emotion label have a relationship in CK+ Dataset. In this paper, we propose a model which utilises AUs to explain Convolutional Neural Network(CNN) model's classification results. The CNN model is trained with CK+ Dataset and classifies emotion based on extracted features. Explanation model classifies the multiple AUs with the extracted features and emotion classes from the CNN model. Our experiment shows that with only features and emotion classes obtained from the CNN model, Explanation model generates AUs very well.},
 author = {S. {Kim} and H. {Kim}},
 booktitle = {2019 IEEE International Conference on Big Data and Smart Computing (BigComp)},
 comments = {, The described method is neither general, nor focused on NLP},
 doi = {10.1109/BIGCOMP.2019.8679370},
 issn = {2375-9356},
 keywords = {convolutional neural nets;emotion recognition;face recognition;feature extraction;learning (artificial intelligence);nonverbal emotional communication method;machine learning tasks;Deep Learning models;FER tasks;facial muscle movements;CK+ Dataset;CNN model;emotion classes;facial expression recognition;convolutional neural network model;facial action coding units;deep explanation model;facial action coding unit;Hidden Markov models;Gold;Feature extraction;Face recognition;Deep learning;Computational modeling;Task analysis;Explanation Model;Facial Expression Recognition;Deep learning;Justification;Facial Action Coding System},
 month = {Feb},
 number = {},
 pages = {1-4},
 title = {Deep Explanation Model for Facial Expression Recognition Through Facial Action Coding Unit},
 volume = {},
 year = {2019}
}

@inproceedings{953778,
 abstract = {Document image understanding denotes the recognition of semantically relevant components in the layout extracted from a document image. This recognition process is based on some visual models, whose manual specification can be a highly demanding task. In order to automatically acquire these models, we propose the application of machine learning techniques. Problems raised by possible dependencies between concepts to be learned are illustrated and solved with a computational strategy based on the separate-and-parallel-conquer search. The approach is tested on a set of real multi-page documents processed by the system WISDOM++. New results confirm the validity of the proposed strategy and show some limits of the learning system used in this work.},
 author = {D. {Malerba} and F. {Esposito} and F. A. {Lisi} and O. {Altamura}},
 booktitle = {Proceedings of Sixth International Conference on Document Analysis and Recognition},
 comments = {, The publication does not focus on explainability},
 doi = {10.1109/ICDAR.2001.953778},
 issn = {},
 keywords = {document image processing;optical character recognition;learning (artificial intelligence);divide and conquer methods;search problems;document image understanding;logical component dependence discovery;document image recognition;visual models;machine learning;computational strategy;separate-and-parallel-conquer search;multi-page documents;WISDOM system;OCR;Image recognition;Text analysis;Image analysis;Optical character recognition software;XML;System testing;Publishing;Image databases;Digital images;Optical devices},
 month = {Sep.},
 number = {},
 pages = {174-178},
 title = {Automated discovery of dependencies between logical components in document image understanding},
 volume = {},
 year = {2001}
}

@incollection{aakurInherentExplainabilityPattern2018,
 abstract = {The ability of artificial intelligence systems to offer explanations for its decisions is central to building user confidence and structuring smart human-machine interactions. Expressing the rationale behind such a system's output is an important aspect of human-machine interaction as AI continues to be prominent in general, everyday use-cases. In this paper, we introduce a novel framework integrating Grenander's pattern theory structures to produce inherently explainable, symbolic representations for activity interpretations. These representations provide semantically rich and coherent interpretations of video activity using connected structures of detected (grounded) concepts, such as objects and actions, that are bound by semantics through background concepts not directly observed, i.e. contextualization cues. We use contextualization cues to establish semantic relationships among concepts to infer a deeper interpretation of events than what can be directly sensed. We propose the use of six questions that can be used to gain insight into the models ability to justify its decision and enhance its ability to interact with humans. The six questions are designed to (1) build an understanding of how the model is able to infer interpretations, (2) enable us to walk through its decision-making process, and (3) understand its drawbacks and possibly address them. We demonstrate the viability of this idea on video data using a dialog model that uses interpretations to generate explanations grounded in both video data and semantics.},
 address = {Cham},
 author = {Aakur, Sathyanarayanan N. and {de Souza}, Fillipe D. M. and Sarkar, Sudeep},
 booktitle = {Explainable and {{Interpretable Models}} in {{Computer Vision}} and {{Machine Learning}}},
 comments = {, The described method is neither general, nor focused on NLP},
 doi = {10.1007/978-3-319-98131-4_11},
 editor = {Escalante, Hugo Jair and Escalera, Sergio and Guyon, Isabelle and Bar\'o, Xavier and G\"u{\c c}l\"ut\"urk, Ya{\u g}mur and G\"u{\c c}l\"u, Umut and {van Gerven}, Marcel},
 isbn = {978-3-319-98131-4},
 keywords = {Activity interpretation,ConceptNet,Explainability,Semantics},
 language = {en},
 pages = {277-299},
 publisher = {{Springer International Publishing}},
 series = {The {{Springer Series}} on {{Challenges}} in {{Machine Learning}}},
 title = {On the {{Inherent Explainability}} of {{Pattern Theory}}-{{Based Video Event Interpretations}}},
 year = {2018}
}

@inproceedings{Abdollahi:2017:UEC:3109859.3109913,
 acmid = {3109913},
 address = {New York, NY, USA},
 author = {Abdollahi, Behnoush and Nasraoui, Olfa},
 booktitle = {Proceedings of the Eleventh ACM Conference on Recommender Systems},
 comments = {, The described method is neither general, nor focused on NLP},
 doi = {10.1145/3109859.3109913},
 isbn = {978-1-4503-4652-8},
 keywords = {explanations, interpretable models, latent factor models, matrix factorization, recommender systems},
 location = {Como, Italy},
 numpages = {5},
 pages = {79--83},
 publisher = {ACM},
 series = {RecSys '17},
 title = {Using Explainability for Constrained Matrix Factorization},
 url = {http://doi.acm.org/10.1145/3109859.3109913},
 year = {2017}
}

@inproceedings{Abreu:2009:RSF:1529282.1529374,
 acmid = {1529374},
 address = {New York, NY, USA},
 author = {Abreu, Rui and Mayer, Wolfgang and Stumptner, Markus and van Gemund, Arjan J. C.},
 booktitle = {Proceedings of the 2009 ACM Symposium on Applied Computing},
 comments = {, The publication does not focus on explainability},
 doi = {10.1145/1529282.1529374},
 isbn = {978-1-60558-166-8},
 keywords = {abstract interpretation, fault localization, program spectra},
 location = {Honolulu, Hawaii},
 numpages = {6},
 pages = {409--414},
 publisher = {ACM},
 series = {SAC '09},
 title = {Refining Spectrum-based Fault Localization Rankings},
 url = {http://doi.acm.org/10.1145/1529282.1529374},
 year = {2009}
}

@article{Abstracts2016Society2016,
 comments = {, Is not scientific literature, The publication does not focus on explainability},
 doi = {10.1007/s11606-016-3657-7},
 file = {/home/tim/Zotero/storage/R9S8V92J/2016 - Abstracts from the 2016 Society of General Interna.pdf;/home/tim/Zotero/storage/SSWJIBRH/2016 - Abstracts from the 2016 Society of General Interna.pdf},
 issn = {1525-1497},
 journal = {Journal of General Internal Medicine},
 language = {en},
 month = {May},
 number = {2},
 pages = {85-922},
 title = {Abstracts from the 2016 {{Society}} of {{General Internal Medicine Annual Meeting}}},
 volume = {31},
 year = {2016}
}

@article{Abstracts2017Society2017,
 comments = {, Is not scientific literature, The publication does not focus on explainability},
 doi = {10.1007/s11606-017-4028-8},
 file = {/home/tim/Zotero/storage/DF6QGEYW/2017 - Abstracts from the 2017 Society of General Interna.pdf;/home/tim/Zotero/storage/PXA8F9U6/2017 - Abstracts from the 2017 Society of General Interna.pdf},
 issn = {1525-1497},
 journal = {Journal of General Internal Medicine},
 language = {en},
 month = {April},
 number = {2},
 pages = {83-808},
 title = {Abstracts from the 2017 {{Society}} of {{General Internal Medicine Annual Meeting}}},
 volume = {32},
 year = {2017}
}

@article{Abstracts36thAnnual2013,
 comments = {, Is not scientific literature, The publication does not focus on explainability},
 doi = {10.1007/s11606-013-2436-y},
 file = {/home/tim/Zotero/storage/NP4WH8EI/2013 - Abstracts from the 36th Annual Meeting of the Soci.pdf},
 issn = {1525-1497},
 journal = {Journal of General Internal Medicine},
 language = {en},
 month = {June},
 number = {1},
 pages = {1-489},
 title = {Abstracts from the 36th {{Annual Meeting}} of the {{Society}} of {{General Internal Medicine}}},
 volume = {28},
 year = {2013}
}

@incollection{AbstractsDocumentsThis1997,
 address = {Boston, MA},
 booktitle = {Political {{Science Abstracts}}: 1996 {{Annual Supplement}};{{Volume}} 1},
 comments = {, Is not scientific literature, The publication does not focus on explainability},
 doi = {10.1007/978-1-4615-5971-9_1},
 isbn = {978-1-4615-5971-9},
 language = {en},
 pages = {1-817},
 publisher = {{Springer US}},
 title = {Abstracts of {{Documents}} in {{This Supplement}}},
 year = {1997}
}

@article{AbstractsScientificPapers1999,
 comments = {, Is not scientific literature, The publication does not focus on explainability},
 doi = {10.1007/BF03323585},
 issn = {1432-1084},
 journal = {European Radiology},
 keywords = {Magnetic Resonance Angiography,Magnetic Resonance Imaging,Spiral Compute Tomography,Takayasu Arteritis,Transjugular Intrahepatic Portosystemic Shunt},
 language = {en},
 month = {March},
 number = {1},
 pages = {S1-S362},
 title = {Abstracts {{Scientific Papers Honorary Lectures Categorical Courses Workshops State}}-of-the-{{Art Symposia}}},
 volume = {9},
 year = {1999}
}

@incollection{aggarwalMachineLearningShallow2018,
 abstract = {Conventional machine learning often uses optimization and gradient-descent methods for learning parameterized models. Examples of such models include linear regression, support vector machines, logistic regression, dimensionality reduction, and matrix factorization. Neural networks are also parameterized models that are learned with continuous optimization methods.},
 address = {Cham},
 author = {Aggarwal, Charu C.},
 booktitle = {Neural {{Networks}} and {{Deep Learning}}: {{A Textbook}}},
 comments = {, The publication does not focus on explainability},
 doi = {10.1007/978-3-319-94463-0_2},
 editor = {Aggarwal, Charu C.},
 isbn = {978-3-319-94463-0},
 language = {en},
 pages = {53-104},
 publisher = {{Springer International Publishing}},
 title = {Machine {{Learning}} with {{Shallow Neural Networks}}},
 year = {2018}
}

@incollection{aggarwalModelBasedCollaborativeFiltering2016,
 abstract = {The neighborhood-based methods of the previous chapter can be viewed as generalizations of k-nearest neighbor classifiers, which are commonly used in machine learning.},
 address = {Cham},
 author = {Aggarwal, Charu C.},
 booktitle = {Recommender {{Systems}}: {{The Textbook}}},
 comments = {, The publication does not focus on explainability, The described method is neither general, nor focused on NLP},
 doi = {10.1007/978-3-319-29659-3_3},
 editor = {Aggarwal, Charu C.},
 isbn = {978-3-319-29659-3},
 language = {en},
 pages = {71-138},
 publisher = {{Springer International Publishing}},
 title = {Model-{{Based Collaborative Filtering}}},
 year = {2016}
}

@inproceedings{Amir:2018:ASS:3237383.3237877,
 acmid = {3237877},
 address = {Richland, SC},
 author = {Amir, Ofra and Doshi-Velez, Finale and Sarne, David},
 booktitle = {Proceedings of the 17th International Conference on Autonomous Agents and MultiAgent Systems},
 comments = {, The publication does not focus on explainability},
 keywords = {explainable ai, strategy summarization},
 location = {Stockholm, Sweden},
 numpages = {5},
 pages = {1203--1207},
 publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
 series = {AAMAS '18},
 title = {Agent Strategy Summarization},
 url = {http://dl.acm.org/citation.cfm?id=3237383.3237877},
 year = {2018}
}

@inproceedings{Amir:2018:HSA:3237383.3237869,
 acmid = {3237869},
 address = {Richland, SC},
 author = {Amir, Dan and Amir, Ofra},
 booktitle = {Proceedings of the 17th International Conference on Autonomous Agents and MultiAgent Systems},
 comments = {, },
 keywords = {explainable ai, strategy summarization},
 location = {Stockholm, Sweden},
 numpages = {9},
 pages = {1168--1176},
 publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
 series = {AAMAS '18},
 title = {HIGHLIGHTS: Summarizing Agent Behavior to People},
 url = {http://dl.acm.org/citation.cfm?id=3237383.3237869},
 year = {2018}
}

@article{AnnualCongressEuropean2018,
 comments = {, The publication does not focus on explainability},
 doi = {10.1007/s00259-018-4148-3},
 issn = {1619-7089},
 journal = {European Journal of Nuclear Medicine and Molecular Imaging},
 language = {en},
 month = {October},
 number = {1},
 pages = {1-844},
 title = {Annual {{Congress}} of the {{European Association}} of {{Nuclear Medicine October}} 13 \textendash{} 17, 2018 {{D\"usseldorf}}, {{Germany}}},
 volume = {45},
 year = {2018}
}

