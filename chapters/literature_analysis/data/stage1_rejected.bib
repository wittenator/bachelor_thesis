@inproceedings{7066257,
 abstract = {Text extraction plays an important role in numerous applications. Research on its method still need to be improved in order to achieve better performance, to increase the reliability of text extraction system and to deal with complex cases of text extraction. The majority of the text extraction methods are focusing on horizontal and near horizontal text lines; however, text in natural scene might be in arbitrary line in real time. Thus, this paper aims to solve the issue of extracting the arbitrary oriented text by suggesting a method for text detection and localization based on the Stroke Width Transform. The proposed method is tested on an arbitrary text dataset and ICDAR dataset. The result of the experiment shows that the proposed method adapts well to the arbitrary text.},
 author = {J. {Jameson} and S. N. H. S. {Abdullah}},
 booktitle = {2014 14th International Conference on Intelligent Systems Design and Applications},
 comments = { The publication does not focus on explainability},
 doi = {10.1109/ISDA.2014.7066257},
 issn = {2164-7143},
 keywords = {text detection;transforms;arbitrary text extraction;natural scene image;stroke width transform;text detection;text localization;ICDAR dataset;Image edge detection;Text analysis;Transforms;Optical character recognition software;Licenses;Integrated circuits;Text extraction;Text detection and localization;Stroke Width Transform;Scene understanding},
 month = {Nov},
 number = {},
 pages = {124-128},
 title = {Extraction of arbitrary text in natural scene image based on stroke width transform},
 volume = {},
 year = {2014}
}

@inproceedings{716778,
 abstract = {A novel pattern searching method using neural networks and correlation is presented. This method combines the quickness and adaptiveness of neural networks with the accuracy of the mathematical correlation approach. Images are divided into small sub-images which are presented to the trained neural network. Sub-images that may contain the pattern or partial pattern are selected by the neural network. The neural network also provides the approximate location of the pattern, therefore the selected sub-images can be adjusted to contain the complete pattern. Desired patterns can be located by measuring the new sub-images' correlation values against the reference models in a small area. Experiments show that this superior method is able to find the desired patterns. Moreover, this method is much faster and more adaptable than traditional pattern searching methods.},
 author = {C. {Chiu} and T. {Oki} and P. {Paolellia}},
 booktitle = {Proceedings of 1993 International Conference on Neural Networks (IJCNN-93-Nagoya, Japan)},
 comments = { The publication does not focus on explainability},
 doi = {10.1109/IJCNN.1993.716778},
 issn = {},
 keywords = {image recognition;neural nets;correlation methods;pattern searching method;neural networks;adaptiveness;mathematical correlation;sub-images;Neural networks;Pattern recognition;Brightness;Character recognition;Image recognition;Pixel;Manufacturing automation;Inspection;Printed circuits;Correlation},
 month = {Oct},
 number = {},
 pages = {1277-1280 vol.2},
 title = {A novel pattern searching method using neural networks and correlation},
 volume = {2},
 year = {1993}
}

@inproceedings{7193210,
 abstract = {Text recognition in images is a research area which attempts to develop a computer system with the ability to automatically read the text from images. These days there is a huge demand in storing the information available in paper documents format in to a computer storage disk and then later reusing this information by searching process. One simple way to store information from these paper documents in to computer system is to first scan the documents and then store them as images. But to reuse this information it is very difficult to read the individual contents and searching the contents form these documents line-by-line and word-by-word. The challenges involved in this the font characteristics of the characters in paper documents and quality of images. Due to these challenges, computer is unable to recognize the characters while reading them. Thus there is a need of character recognition mechanisms to perform Document Image Analysis (DIA) which transforms documents in paper format to electronic format. In this paper we have discuss method for text recognition from images. The objective of this paper is to recognition of text from image for better understanding of the reader by using particular sequence of different processing module.},
 author = {P. M. {Manwatkar} and S. H. {Yadav}},
 booktitle = {2015 International Conference on Innovations in Information, Embedded and Communication Systems (ICIIECS)},
 comments = { The publication does not focus on explainability},
 doi = {10.1109/ICIIECS.2015.7193210},
 issn = {},
 keywords = {character recognition;document image processing;image resolution;image texture;text detection;image text recognition;computer storage disk;computer system;image quality;character recognition;document image analysis;DIA;Text recognition;Biological neural networks;Computers;Image segmentation;Character recognition;Neurons;Feature extraction;Document Image Analysis (DIA);electronic format;text recognition;font characteristics},
 month = {March},
 number = {},
 pages = {1-6},
 title = {Text recognition from images},
 volume = {},
 year = {2015}
}

@inproceedings{7311974,
 abstract = {In this paper we present a semi-automated analysis of student reading performance from the perspective of her text reading level and text understanding. Silences (pauses) between uttered words or read sentences as well as silences between verbalizations given by students are the key points in the analysis of their learning activities. Pause is an essential element in the analysis of a text, which also gives good control over interactions during the processes of text reading and explanation of understanding. This study presents the results specific to pauses in the reading and verbalization using Praat, a tool to analyze spoken productions. Correlations between students' fluency, story understanding, and mean pause duration of reading and explanation phases show consistent results across texts for reading. Results about pauses during explaining yielded low correlations, showing that other variables may influence the pausing behaviors during explaining.},
 author = {S. {Denisleam Molomer} and S. {Trausan-Matu} and P. {Dessus} and M. {Bianco}},
 booktitle = {2015 14th RoEduNet International Conference - Networking in Education and Research (RoEduNet NER)},
 comments = { The publication does not focus on explainability},
 doi = {10.1109/RoEduNet.2015.7311974},
 issn = {2068-1038},
 keywords = {computer aided instruction;linguistics;speech processing;text analysis;students pauses;semiautomated analysis;student reading performance;text reading level;text understanding;uttered words;read sentences;silences;verbalizations;learning activities;text analysis;Praat tool;spoken productions;students fluency;story understanding;mean pause duration;reading phases;explanation phases;pausing behaviors;explaining;Decision support systems;Pause;Reading;Explanation},
 month = {Sep.},
 number = {},
 pages = {90-93},
 title = {Analyzing students pauses during reading and explaining a story},
 volume = {},
 year = {2015}
}

@inproceedings{7333750,
 abstract = {Text line extraction in document images is an important prerequisite for many content based image understanding applications. In this paper, we propose an accurate and robust method for generic text line extraction, which can be applied on large categories of document images, diverse languages, and text lines with different orientations. Firstly, the candidate connected components are extracted from document image using Maximal Stable Extremal Region (MSER) with the noises filtered by Adaboost and Convolution Neural Network (CNN). Then, the coarse text lines are generated from hierarchical edges reconstruction and cut by local linearity of text lines in the document spanning tree. Finally, for accurate text line extraction, the cut multi-components are re-connected based on text line energy minimization in terms of text line consistency and the fitting error. Experimental results on multilingual test dataset demonstrate the effectiveness and robust of the proposed method, which yields higher performance compared with state-of-the-art methods.},
 author = {L. {Wang} and W. {Fan} and J. {Sun} and S. {Naoi} and T. {Hiroshi}},
 booktitle = {2015 13th International Conference on Document Analysis and Recognition (ICDAR)},
 comments = { The publication does not focus on explainability},
 doi = {10.1109/ICDAR.2015.7333750},
 issn = {},
 keywords = {document image processing;edge detection;feature extraction;image reconstruction;learning (artificial intelligence);natural language processing;neural nets;text analysis;trees (mathematics);text line extraction;document images;content based image understanding applications;generic text line extraction;candidate connected components;maximal stable extremal region;noise filtering;Adaboost;convolution neural network;CNN;hierarchical edge reconstruction;document spanning tree;text line energy minimization;text line consistency;fitting error;multilingual test dataset;Robustness;Benchmark testing;Image segmentation;Surveillance;Image recognition;Integrated optics;Optical imaging;generic text line extraction;MSER;hierarchical edge reconstruction and cut;text line energy minimization},
 month = {Aug},
 number = {},
 pages = {191-195},
 title = {Text line extraction in document images},
 volume = {},
 year = {2015}
}

@inproceedings{7333799,
 abstract = {In practical applications of document understanding, if the documents have multiple languages and orientations, the conventional OCR systems can not be directly applied. This is because those OCR systems are usually designed for texts of single language and normal orientation. To solve this problem, many non-character based recognition approaches were proposed. However, the performance of those methods were not comparable with the mature OCR systems. Consequently, a better idea is to recognize the language type and orientation before the OCR is applied. Besides, the characters of different languages have very ambiguous shape, so it is very difficult to extract stable feature for the recognition. Recently, the convolutional neural networks (CNN) have achieved great success in pattern recognition tasks. Therefore, for such difficult tasks, the CNN is one of the best choice. In this paper, we first applied CNN to the recognition of the document properties. A novel sliding window voting process is proposed to reduce the network scale and fully use the information of the text line. In the experiments, our method had very high recognition rate. The results proved the advantage of the proposed method and which also can be applied to create a document understanding system with OCR systems.},
 author = {L. {Chen} and S. {Wang} and W. {Fan} and J. {Sun} and N. {Satoshi}},
 booktitle = {2015 13th International Conference on Document Analysis and Recognition (ICDAR)},
 comments = { The publication does not focus on explainability},
 doi = {10.1109/ICDAR.2015.7333799},
 issn = {},
 keywords = {document image processing;image recognition;neural nets;text detection;deep learning;orientation recognition;language recognition;document analysis;convolutional neural networks;CNN;document properties recognition;sliding window voting process;text line information;recognition rate;document understanding system;Kernel;Optical character recognition software},
 month = {Aug},
 number = {},
 pages = {436-440},
 title = {Deep learning based language and orientation recognition in document analysis},
 volume = {},
 year = {2015}
}

@inproceedings{777686,
 abstract = {Document Analysis and Understanding (DAU) is a complex AI application with high industrial impact. For the increasing demands upon the bandwidth and quality of the analysis it is crucial to enable different analysis modules to collaborate. For making collaboration possible, we first examine the question of whether there exists a common ontological basis which can serve as a platform for communication of different DAU modules. Once communication is enabled, we investigate the second question, how DAU modules originally designed as stand-alone systems must be modified in order to benefit from collaboration with others.},
 author = {B. {Klein} and A. {Abecker}},
 booktitle = {Proceedings IEEE Forum on Research and Technology Advances in Digital Libraries},
 comments = { The publication does not focus on explainability},
 doi = {10.1109/ADL.1999.777686},
 issn = {1092-9959},
 keywords = {document handling;knowledge based systems;grammars;groupware;distributed knowledge based parsing;document analysis and understanding;DAU;complex AI application;industrial impact;analysis modules;collaboration;common ontological basis;DAU modules;Text analysis;Information analysis;Data mining;Collaboration;Text recognition;SGML;Automata;Artificial intelligence;Bandwidth;Ontologies},
 month = {May},
 number = {},
 pages = {6-15},
 title = {Distributed knowledge-based parsing for document analysis and understanding},
 volume = {},
 year = {1999}
}

@inproceedings{7821768,
 abstract = {The problem being addressed in this paper is that using brute force in Natural Language Processing and Machine Learning combined with advanced statistics will only approximate meaning and thus will not deliver in terms of real text understanding. Counting words and tracking word order or parsing by syntax will also result in probability and guesswork at best. Their vendors struggle in delivering accurate quality and this results in ill-functioning applications. The newer generation methodologies like Deep Learning and Cognitive Computing are breaking barriers in the (Big Data) fields of Internet of Things, Robotics and Image/Video Recognition but cannot be successfully deployed for text without huge amounts of training and sample data. In the short term, we believe non-biological Artificial Intelligence will produce the best results for text understanding. Miia applied advanced Linguistic and Semantic Technologies combined with ConceptNet modeling and Machine Learning to successfully cater deep intelligent and cross-language quality to several industries.},
 author = {L. {Stephen} and D. {Geert} and K. {Andreas} and P. {Frank}},
 booktitle = {2016 Future Technologies Conference (FTC)},
 comments = { The publication does not focus on explainability},
 doi = {10.1109/FTC.2016.7821768},
 issn = {},
 keywords = {Big Data;Internet of Things;learning (artificial intelligence);mobile computing;natural language processing;semantic networks;statistics;text analysis;nonbiological AI approach;natural language understanding;natural language processing;machine learning;advanced statistics;meaning approximation;text understanding;word counting;word order tracking;syntax parsing;deep learning;cognitive computing;Big Data;Internet of Things;robotics;image/video recognition;nonbiological artificial intelligence;advanced linguistic technologies;semantic technologies;ConceptNet modeling;cross-language quality;Companies;Natural languages;Artificial intelligence;Semantics;Law;Engines;Natural Language Processing;Natural Language Understanding;Artificial Intelligence;Linguistics;Semantics;Machine Learning;ConceptNet Modelling;Data Mining;Sentiment Analysis;Data Analysis;Big Data;Business Intelligence},
 month = {Dec},
 number = {},
 pages = {1300-1302},
 title = {A non-biological AI approach towards natural language understanding},
 volume = {},
 year = {2016}
}

@inproceedings{7846312,
 abstract = {Spoken language understanding (SLU) is one of the important problem in natural language processing, and especially in dialog system. Fifth Dialog State Tracking Challenge (DSTC5) introduced a SLU challenge task, which is automatic tagging to speech utterances by two speaker roles with speech acts tag and semantic slots tag. In this paper, we focus on speech acts tagging. We propose local coactivate multi-task learning model for capturing structured speech acts, based on sentence features by recurrent convolutional neural networks. An experiment result, shows that our model outperformed all other submitted entries, and were able to capture coactivated local features of category and attribute, which are parts of speech act.},
 author = {T. {Ushio} and H. {Shi} and M. {Endo} and K. {Yamagami} and N. {Horii}},
 booktitle = {2016 IEEE Spoken Language Technology Workshop (SLT)},
 comments = { The publication does not focus on explainability},
 doi = {10.1109/SLT.2016.7846312},
 issn = {},
 keywords = {feedforward neural nets;learning (artificial intelligence);natural language processing;pattern classification;recurrent neural nets;speech processing;text analysis;attribute feature;category feature;sentence feature;local coactivate multitask learning model;semantic-slot tag;speech-act tag;speech utterances;automatic tagging;SLU challenge task;DSTC5;Fifth-Dialog State Tracking Challenge;dialog system;natural language processing;spoken language understanding;structured speech act tagging;recurrent convolutional neural networks;Speech;Tagging;Neural networks;Hidden Markov models;Training;Text categorization;Neurons;spoken language understanding;speech act tagging;text classification;multi-task learning;neural networks},
 month = {Dec},
 number = {},
 pages = {518-524},
 title = {Recurrent convolutional neural networks for structured speech act tagging},
 volume = {},
 year = {2016}
}

@inproceedings{791799,
 abstract = {HUE (the Handwriting Understanding Environment) is a software framework for handwriting and document analysis built around a two-level programming model in which components are implemented in a system programming language (typically C++) and are connected together into prototype systems using the scripting language Tcl Tk. HUE is an extended version of TABS (a previous handwriting analysis framework), and incorporates the authors' experience of using TABS for around 2 years in data-intensive handwriting and document analysis research and evaluation. HUE currently contains 94 C++ components, 7 native data types, 11 custom-built Tcl Tk packages, a novel dynamic user interface, and several demonstration systems implemented as Tcl scripts.},
 author = {C. {Cracknell} and A. C. {Downton}},
 booktitle = {Proceedings of the Fifth International Conference on Document Analysis and Recognition. ICDAR '99 (Cat. No.PR00318)},
 comments = { The publication does not focus on explainability},
 doi = {10.1109/ICDAR.1999.791799},
 issn = {},
 keywords = {document image processing;object-oriented programming;handwritten character recognition;user interfaces;software prototyping;Handwriting Understanding Environment;rapid prototyping;document analysis;handwriting analysis;software framework;two-level programming model;system programming language;Tcl Tk scripting language;TABS;C++ components;native data types;custom-built Tcl Tk packages;dynamic user interface;demonstration systems;Prototypes;Computer languages;Text analysis;Handwriting recognition;Image processing;Computer vision;Libraries;Programming profession;Design engineering;Systems engineering and theory},
 month = {Sep.},
 number = {},
 pages = {362-365},
 title = {A Handwriting Understanding Environment (HUE) for rapid prototyping in handwriting and document analysis research},
 volume = {},
 year = {1999}
}

@inproceedings{7982151,
 abstract = {The accuracy of conventional DGA interpretation methods can be different when each of these methods are used in different places or different circumstances. Rogers Ratio Method (RRM), IEC Ratio Method (IRM) (Basic Gas Ratios Method), GB/T 7252 (National Standard of the People's Republic of China) are popular conventional methods for interpreting the possible faults indicator of transformer in Indonesia and China. This research proposes artificial intelligence to interpret DGA by combining conventional method and artificial intelligence method using weighting factor. The artificial intelligence method which are used in this research is fuzzy logic. DGA practical data which used as refer data for data mining in this research were taken from China and Indonesia. This research also uses Thompson tau method to filter the data from outlier and fuzzy c means clustering to cluster the data to make sure the data are used is valid and good enough to be used to build artificial intelligence through data mining. The output of this research is to create an artificial intelligence and the combination between artificial intelligence which have been built with conventional method to interpret DGA whether there is any fault in transformer or not.},
 author = {C. {Subroto} and and and G. {Zhang}},
 booktitle = {2017 1st International Conference on Electrical Materials and Power Equipment (ICEMPE)},
 comments = { The described method is neither general, nor focused on NLP},
 doi = {10.1109/ICEMPE.2017.7982151},
 issn = {},
 keywords = {artificial intelligence;fuzzy logic;fuzzy set theory;power engineering computing;power transformers;artificial intelligence;DGA interpretation methods;weighting factor;Rogers ratio method;RRM;IEC Ratio Method;IRM;basic gas ratios method;transformer faults indicator;fuzzy logic;Thompson tau method;fuzzy c means clustering;data mining;Artificial intelligence;Fuzzy logic;Partial discharges;Data mining;Discharges (electric);Power transformer insulation;DGA;Fuzzy Logic;Weighting factor;Thompson tau method;Fuzzy C Means},
 month = {May},
 number = {},
 pages = {85-88},
 title = {Artificial intelligence for DGA interpretation methods using weighting factor},
 volume = {},
 year = {2017}
}

@inproceedings{8047390,
 abstract = {The beginner counselors have more likely to continue counseling in their own interest, they have a high tendency to make great use of the closed-ended question in order to confirm the interpretation with the client. While expert counselors are instructing the counseling skill to beginner counselors, we consider that the reaction of a client for a beginner counselor's question is important to visualize in an appropriate method. To respond the request, we have developed a system for visualizing the flow of conversation in counseling. However, the expert counselor as the system user requires to correct the initial classification result manually, and the work burden is large, because the accuracy of the category classification of conversation data is very low in the current system. To improve this problem, we have implemented on the category classification method of text data with SVM (Support Vector Machine) as machine learning technique to visualize the flow of conversation in counseling. In addition, we have compared and evaluated with results of the initial classification method of the current system. As these results, we have shown that the accuracy rate of the classification method with SVM become higher than the results in the current system.},
 author = {Y. {Hayashida} and T. {Uetsuji} and Y. {Ebara} and K. {Koyamada}},
 booktitle = {2017 Nicograph International (NicoInt)},
 comments = { The publication does not focus on explainability},
 doi = {10.1109/NICOInt.2017.35},
 issn = {},
 keywords = {data visualisation;learning (artificial intelligence);pattern classification;psychology;support vector machines;text analysis;category classification;text data;machine learning;conversation flow visualization;counseling;support vector machine;SVM;Employee welfare;Support vector machines;Data visualization;Psychology;Dictionaries;Data models;Employment;Counseling;Visualization;Machine Learning;Text Classification},
 month = {June},
 number = {},
 pages = {37-40},
 title = {Category Classification of Text Data with Machine Learning Technique for Visualizing Flow of Conversation in Counseling},
 volume = {},
 year = {2017}
}

@inproceedings{8128175,
 abstract = {The use of LiDAR and multiples digital images jointly with 3-D reconstruction techniques for creating 3-D models of natural outcrops and surfaces studies have increased dramatically in the last few years. These techniques have provided an enormous amount of data for interpretation by geoscientists. However, these researchers have no available software capable of offering a user experience comparable to the fieldwork. The majority of solutions have considered desktop systems, which presents inherent limitations due to the 2-D characteristics of displays and loss of immersion into the 3-D model, or up until expensive and complex stereoscopic based approaches to improve the 3-D user experience do not offer well suitable solutions. To address these limitations, this paper presents a low-cost completely disruptive solution for processing, visualizing, sharing and directly handling Digital Outcrop Models with the support of a full interpretation toolset, the MOSIS System. The proposed system provides a fully immersive computational environment, capable of teleporting virtually geoscientists to the fieldwork, giving an awareness of being there physically with an extensible toolset for the DOM's interpretation. Besides, desktop, web and mobile versions of MOSIS have been under development and fulfill the lack of tools for digital outcrop modeling.},
 author = {L. {Gonzaga} and M. R. {Veronez} and D. N. {Alves} and F. {Bordin} and G. L. {Kannenberg} and F. P. {Marson} and F. M. W. {Tognoli} and L. C. {Inocencio}},
 booktitle = {2017 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)},
 comments = { The publication does not focus on explainability, The described method is neither general, nor focused on NLP},
 doi = {10.1109/IGARSS.2017.8128175},
 issn = {2153-7003},
 keywords = {data visualisation;geophysical techniques;image reconstruction;optical radar;radar imaging;stereo image processing;MOSIS;multioutcrop sharing multiples digital images;digital outcrop models;DOM interpretation;digital outcrop modeling;fully immersive computational environment;MOSIS System;interpretation toolset;complex stereoscopic based approaches;natural outcrops;3-D model;3-D reconstruction techniques;Three-dimensional displays;Geology;Data visualization;Solid modeling;Tools;Visualization;Standards;immersive visualization;digital outcop model (DOM);virtual outcrop;interpretation;3-D visualization;GPU Computing},
 month = {July},
 number = {},
 pages = {5209-5212},
 title = {MOSIS — Multi-outcrop sharing interpretation system},
 volume = {},
 year = {2017}
}

@inproceedings{8215791,
 abstract = {Automatic creation of polarity dictionaries is an important issue, as explanations of prediction models are often required in the financial industry. This paper proposes a novel method of developing an interpretable and predictable neural network model. The neural network model we built can extract polarity scores of concepts from documents. Furthermore, we can detect pairwise interactions between concepts, and create polarity concept dictionaries using our neural network model. The model was built using vector representations of words and polarity scores for about 100 words provided by financial professionals, and we obtained about a hundred times more polarity scores for unknown words through backpropagation. First, we analyze the properties of our method from a theoretical point of view. We then confirm its capabilities by conducting simulations of assigning polarity scores to unknown words and detecting interactions using artificial data. We subsequently estimate sentiment tags using real financial textual datasets. Compared with other conventional methods, the proposed approach can forecast sentiments with higher F1 scores. Finally, we develop a polarity concept dictionary based on Yahoo! Finance board textual data.},
 author = {T. {Ito} and H. {Sakaji} and K. {Izumi} and K. {Tsubouchi} and T. {Yamashita}},
 booktitle = {2017 IEEE International Conference on Data Mining Workshops (ICDMW)},
 comments = { The publication does not focus on explainability},
 doi = {10.1109/ICDMW.2017.159},
 issn = {2375-9259},
 keywords = {backpropagation;data mining;dictionaries;financial data processing;natural language processing;neural nets;text analysis;interpretable neural network model;polarity concept dictionaries;automatic creation;polarity dictionaries;prediction models;interpretable network model;predictable neural network model;polarity scores;unknown words;detecting interactions;financial industry;vector representations;Yahoo! Finance board textual data;Dictionaries;Artificial neural networks;Predictive models;Data mining;Industries;Analytical models;Neural Network Model;Text-mining;Sentiment analysis},
 month = {Nov},
 number = {},
 pages = {1122-1131},
 title = {Development of an Interpretable Neural Network Model for Creation of Polarity Concept Dictionaries},
 volume = {},
 year = {2017}
}

@inproceedings{8256457,
 abstract = {It must be rather difficult for ordinary people to communicate with robots using special technical languages. Therefore, it must be more desirable for them to use natural language (NL) for such a purpose because it is the most conventional among them. This work proposes a methodology for natural language understanding through an AI system named Conversation Management System (CMS) based on Mental Image Directed Semantic Theory proposed by M. Yokota. CMS is intended to enable a robot to understand NL in the same way as people do, and actually can reach the most plausible semantic interpretation of an input text and return desirable outcomes by employing word concepts, postulates, and inference rules. Recently, the authors have applied several spatial terms in English language, for example verbs, prepositions (e.g. between, along, left, right, and so on). We found that the methodology is outstanding from conventional approaches with the attempt to provide robots understand NL based on mental image model. This paper focuses on how CMS understands static spatial (3D) relations expressed in NL.},
 author = {R. {Khummongkol} and M. {Yokota}},
 booktitle = {2017 IEEE 8th International Conference on Awareness Science and Technology (iCAST)},
 comments = { The publication does not focus on explainability},
 doi = {10.1109/ICAwST.2017.8256457},
 issn = {2325-5994},
 keywords = {artificial intelligence;human-robot interaction;natural language processing;mental image based understanding;static relations;dynamic spatial relations;special technical languages;NL;natural language understanding;AI system;Conversation Management System;CMS;Mental Image Directed Semantic Theory;spatial terms;English language;mental image model;robot communication;semantic interpretation;static spatial 3D relations;Robots;Semantics;Natural languages;Rivers;Conferences;Artificial intelligence;Cognition;natural language understanding;human — robot interaction;semantic interpretation},
 month = {Nov},
 number = {},
 pages = {254-259},
 title = {An approach to mental image based understanding of natural language: Focused on static and dynamic spatial relations},
 volume = {},
 year = {2017}
}

@inproceedings{8276047,
 abstract = {Sentiment analysis is a methodology used to analyse the emotion or view of an individual to a situation or topic. In present scenario, Social media is the source for the collection of individual's feedbacks, user's emotions, reviews and personal experiences which lead to a need for efficient mining of the text to derive knowledge. An optimal classification of text based on emotion is an unsolved problem in text mining. To extract knowledge from text many machine learning tools and techniques were proposed. An onto-based process is proposed to analyse the customer's emotion in this paper. The input emotional text that needs to be classified is given as input to the NLP and processed and an emotional ontology is created for better understanding of the semantics and relationships. When adding new instances, Ontology can be automatically classify them based on emotional relationship. The Emowords from ontology can be further classified using any of the standard machine learning techniques which definitively gives a better performance. This paper is a review of all the machine learning techniques that can be applied on the semantic analysis of sentiments.},
 author = {K. {Saranya} and S. {Jayanthy}},
 booktitle = {2017 International Conference on Innovations in Information, Embedded and Communication Systems (ICIIECS)},
 comments = { The publication does not focus on explainability},
 doi = {10.1109/ICIIECS.2017.8276047},
 issn = {},
 keywords = {data mining;emotion recognition;knowledge based systems;learning (artificial intelligence);natural language processing;ontologies (artificial intelligence);pattern classification;sentiment analysis;social networking (online);text analysis;text mining;machine learning tools;customer;input emotional text;emotional ontology;emotional relationship;standard machine learning techniques;sentiment analysis;Social media;feedbacks;optimal classification;Emowords;Onto-based sentiment classification;NLP;Ontologies;Sentiment analysis;Social network services;Text mining;Semantics;Support vector machines;sentimental analysis;ontology;machine learning;NLP;semantics},
 month = {March},
 number = {},
 pages = {1-5},
 title = {Onto-based sentiment classification using machine learning techniques},
 volume = {},
 year = {2017}
}

@inproceedings{8308186,
 abstract = {The term Deep Learning or Deep Neural Network refers to Artificial Neural Networks (ANN) with multi layers. Over the last few decades, it has been considered to be one of the most powerful tools, and has become very popular in the literature as it is able to handle a huge amount of data. The interest in having deeper hidden layers has recently begun to surpass classical methods performance in different fields; especially in pattern recognition. One of the most popular deep neural networks is the Convolutional Neural Network (CNN). It take this name from mathematical linear operation between matrixes called convolution. CNN have multiple layers; including convolutional layer, non-linearity layer, pooling layer and fully-connected layer. The convolutional and fully-connected layers have parameters but pooling and non-linearity layers don't have parameters. The CNN has an excellent performance in machine learning problems. Specially the applications that deal with image data, such as largest image classification data set (Image Net), computer vision, and in natural language processing (NLP) and the results achieved were very amazing. In this paper we will explain and define all the elements and important issues related to CNN, and how these elements work. In addition, we will also state the parameters that effect CNN efficiency. This paper assumes that the readers have adequate knowledge about both machine learning and artificial neural network.},
 author = {S. {Albawi} and T. A. {Mohammed} and S. {Al-Zawi}},
 booktitle = {2017 International Conference on Engineering and Technology (ICET)},
 comments = { The publication does not focus on explainability},
 doi = {10.1109/ICEngTechnol.2017.8308186},
 issn = {},
 keywords = {computer vision;feedforward neural nets;image classification;learning (artificial intelligence);natural language processing;fully-connected layers;convolutional connected layers;nonlinearity layer;multiple layers;matrixes called convolution;mathematical linear operation;classical methods performance;deeper hidden layers;multilayers;Artificial Neural Networks;Deep Neural Network;term Deep Learning;convolutional neural network;artificial neural network;largest image classification data;image data;CNN;pooling;Convolution;Neurons;Convolutional neural networks;Feature extraction;Image edge detection;machine learning;artificial neural networks;deep learning;convolutional neural networks;computer vision;Image recognition},
 month = {Aug},
 number = {},
 pages = {1-6},
 title = {Understanding of a convolutional neural network},
 volume = {},
 year = {2017}
}

@inproceedings{8320258,
 abstract = {These days, text summarization is an active research field to identify the relevant information from large documents produced in various domains such as finance, news media, academics, politics, etc. Text summarization is the process of shortening the documents by preserving the important contents of the text. This can be achieved through extractive and abstractive summarization. In this paper, we have proposed an approach to extract a good set of features followed by neural network for supervised extractive summarization. Our experimental results on Document Understanding Conferences 2002 dataset show the effectiveness of the proposed method against various online extractive text summarizers.},
 author = {A. {Jain} and D. {Bhatia} and M. K. {Thakur}},
 booktitle = {2017 International Conference on Machine Learning and Data Science (MLDS)},
 comments = { The publication does not focus on explainability},
 doi = {10.1109/MLDS.2017.12},
 issn = {},
 keywords = {text analysis;news media;abstractive summarization;supervised extractive summarization;Document Understanding Conferences 2002 dataset;online extractive text summarizers;word vector;active research field;Feature extraction;Neural networks;Data mining;Training;Mathematical model;Computational modeling;Testing;Extractive Text Summarization;Neural Network;Machine Learning;Word Vector Embedding},
 month = {Dec},
 number = {},
 pages = {51-55},
 title = {Extractive Text Summarization Using Word Vector Embedding},
 volume = {},
 year = {2017}
}

@inproceedings{8332874,
 abstract = {Semantic Text Similarity plays a major role in natural language processing. In recent years, researchers have paid considerable attention to Semantic Text Similarity. Some breakthroughs have been made in English, but there are two disadvantages when these models are applied to Chinese: Single sequence models don't consider semantic ambiguity such as polysemy, synonym; these models don't consider that Chinese stop words are important for Chinese word segmentation, voice analysis, semantic understanding. Firstly, in order to overcome the first problem, we proposed the double short text sequences model that has two identical LSTM (Long Short-Term Memory) processing two text sequences at the same time. Secondly, in order to overcome the second problem, according to the characteristics of Chinese, we used the Chinese semantic similarity data sets designed by experts to train and test the model, and retained the stop words in the model training process. Finally, the proposed model was compared with the Semantic Text Similarity model based on CNN (Convolution Neural Network) and the Baidu Semantic Text Similarity model. The results show that the model is greater than the previous two in terms of accuracy, recall rate and so on, and the generalization ability is improved also.},
 author = {T. {Shancheng} and B. {Yunyue} and M. {Fuyu}},
 booktitle = {2018 International Conference on Intelligent Transportation, Big Data Smart City (ICITBS)},
 comments = { The publication does not focus on explainability},
 doi = {10.1109/ICITBS.2018.00190},
 issn = {},
 keywords = {feedforward neural nets;learning (artificial intelligence);natural language processing;text analysis;natural language processing;semantic ambiguity;Chinese stop words;Chinese word segmentation;semantic understanding;double short text sequences model;Long Short-Term Memory;Chinese semantic similarity data sets;single sequence models;double short Chinese sequences;Baidu semantic text similarity model;CNN;convolution neural network;Semantics;Training;Computational modeling;Data models;Analytical models;Training data;Encyclopedias;Semantic similarity;Chinese short text;double sequence;deep learning},
 month = {Jan},
 number = {},
 pages = {736-739},
 title = {A Semantic Text Similarity Model for Double Short Chinese Sequences},
 volume = {},
 year = {2018}
}

@inproceedings{8356909,
 abstract = {Deep Learning for the game of Go recently had a tremendous success with the victory of AlphaGo against Ke Jie in May 2017. However, there is no clear understanding of why they perform so well. In this paper, we introduce a visualization technique that performs a sensitivity analysis of the classifier output by occluding portions of the input Go board, revealing which parts of the board are important for predicting the next move. Using this tool, we start with the experiment about the accuracy of the critical area revealed. We also suppose that by showing the critical area, it will allow Go beginners to understand the board visually that they may have been confused about.},
 author = {Y. {Pang} and T. {Ito}},
 booktitle = {2017 Conference on Technologies and Applications of Artificial Intelligence (TAAI)},
 comments = {Presents a specific method for enhancing explainability for models, The described method is neither general, nor focused on NLP},
 doi = {10.1109/TAAI.2017.42},
 issn = {2376-6824},
 keywords = {computer games;data visualisation;learning (artificial intelligence);pattern classification;sensitivity analysis;sensitivity analysis;classifier output;critical area;visualization method;Ke Jie;deep learning;computer go;Go game;AlphaGo;input Go board;Machine learning;Data visualization;Training;Deep Learning;Computer Go;Visualization},
 month = {Dec},
 number = {},
 pages = {62-65},
 title = {A Proposal of Visualization Method for Critical Area in Computer Go},
 volume = {},
 year = {2017}
}

@inproceedings{8371950,
 abstract = {Most of the technical documents are composed by several modalities, like diagrams, tables, formulas, graphics, pictures and natural language text. Each of these modalities and their associations significantly contribute to the overall deep understanding of the technical document and the knowledge represented in it. Here for us all these modalities, except NL text, are considered as "images". Thus, each technical document mainly is composed by NL text sentences and "images". Thus, in this paper we present a methodology where all these modalities can be expressed into the same two modalities (natural languages text sentences and SPN graphs) for better associations and deeper understanding of a technical document. This deeper understanding will come from two different contributions. The first unique contribution will be an enrichment of the NL text part with additional NL text sentences extracted from the "images" of the technical document. The second unique contribution will come from the SPM models of these images that enrich the main diagram by generating a simulator for the system that technical document describes.},
 author = {N. {Bourbakis}},
 booktitle = {2017 IEEE 29th International Conference on Tools with Artificial Intelligence (ICTAI)},
 comments = { The publication does not focus on explainability},
 doi = {10.1109/ICTAI.2017.00047},
 issn = {2375-0197},
 keywords = {document image processing;graph theory;natural language processing;Petri nets;stochastic processes;text analysis;technical document;natural languages text sentences;stochastic Petri-net forms;SPN graphs;knowledge representation;Pictures;Graphics;Tables;Formulas;Diagrams;NL text sentences;Databases;Text recognition;Shape;Image recognition;Natural languages;Visualization;SPN;Technical Documents;NL text Sentences},
 month = {Nov},
 number = {},
 pages = {247-254},
 title = {Converting Diagrams, Formulas, Tables, Graphics and Pictures into SPN and NL-text Sentences for Automatic Deep Understanding of Technical Documents},
 volume = {},
 year = {2017}
}

@article{8399509,
 abstract = {In hyperspectral image processing, classification is one of the most popular research topics. In recent years, research progress made in deep-learning-based hierarchical feature extraction and classification has shown a great power in many applications. In this paper, we propose a novel local spatial sequential (LSS) method, which is used in a recurrent neural network (RNN). Using this model, we can extract local and semantic information for hyperspectral image classification. First, we extract low-level features from hyperspectral images, including texture and differential morphological profiles. Second, we combine the low-level features together and propose a method to construct the LSS features. Afterwards, we build an RNN and use the LSS features as the input to train the network for optimizing the system parameters. Finally, the high-level semantic features generated by the RNN is fed into a softmax layer for the final classification. In addition, a nonlocal spatial sequential method is presented for the recurrent neural network model (NLSS-RNN) to further enhance the classification performance. NLSS-RNN finds nonlocal similar structures to a given pixel and extracts corresponding LSS features, which not only preserve the local spatial information, but also integrate the information of nonlocal similar samples. The experimental results on three publicly accessible datasets show that our proposed method can obtain competitive performance compared with several state-of-the-art classifiers.},
 author = {X. {Zhang} and Y. {Sun} and K. {Jiang} and C. {Li} and L. {Jiao} and H. {Zhou}},
 comments = { The publication does not focus on explainability},
 doi = {10.1109/JSTARS.2018.2844873},
 issn = {1939-1404},
 journal = {IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing},
 keywords = {feature extraction;image classification;learning (artificial intelligence);recurrent neural nets;local spatial information;spatial sequential recurrent neural network;hyperspectral image classification;hyperspectral image processing;popular research topics;deep-learning-based hierarchical feature extraction;local spatial sequential method;local information;semantic information;low-level features;hyperspectral images;high-level semantic features;nonlocal spatial sequential method;recurrent neural network model;NLSS-RNN;LSS feature extraction;Feature extraction;Recurrent neural networks;Machine learning;Hyperspectral imaging;Computer architecture;Feedforward neural networks;Deep learning;high-level semantic feature;hyperspectral image (HSI) classification;low-level feature;recurrent neural network (RNN)},
 month = {Nov},
 number = {11},
 pages = {4141-4155},
 title = {Spatial Sequential Recurrent Neural Network for Hyperspectral Image Classification},
 volume = {11},
 year = {2018}
}

@article{8432512,
 abstract = {Hyperspectral unmixing (HU) is a method used to estimate the fractional abundances corresponding to endmembers in each of the mixed pixels in the hyperspectral remote sensing image. In recent times, deep learning has been recognized as an effective technique for hyperspectral image classification. In this letter, an end-to-end HU method is proposed based on the convolutional neural network (CNN). The proposed method uses a CNN architecture that consists of two stages: the first stage extracts features and the second stage performs the mapping from the extracted features to obtain the abundance percentages. Furthermore, a pixel-based CNN and cube-based CNN, which can improve the accuracy of HU, are presented in this letter. More importantly, we also use dropout to avoid overfitting. The evaluation of the complete performance is carried out on two hyperspectral data sets: Jasper Ridge and Urban. Compared with that of the existing method, our results show significantly higher accuracy.},
 author = {X. {Zhang} and Y. {Sun} and J. {Zhang} and P. {Wu} and L. {Jiao}},
 comments = { The publication does not focus on explainability},
 doi = {10.1109/LGRS.2018.2857804},
 issn = {1545-598X},
 journal = {IEEE Geoscience and Remote Sensing Letters},
 keywords = {feature extraction;hyperspectral imaging;image classification;learning (artificial intelligence);recurrent neural nets;hyperspectral unmixing;deep convolutional neural networks;hyperspectral remote sensing image;deep learning;hyperspectral image classification;end-to-end HU method;convolutional neural network;CNN architecture;pixel-based CNN;hyperspectral data sets;Jasper Ridge dataset;Urban dataset;Feature extraction;Hyperspectral imaging;Convolution;Artificial neural networks;Indexes;Kernel;Convolutional neural networks (CNNs);end-to-end model;spectral unmixing;spectral–spatial information},
 month = {Nov},
 number = {11},
 pages = {1755-1759},
 title = {Hyperspectral Unmixing via Deep Convolutional Neural Networks},
 volume = {15},
 year = {2018}
}

@article{8440842,
 abstract = {We have recently seen many successful applications of recurrent neural networks (RNNs) on electronic medical records (EMRs), which contain histories of patients' diagnoses, medications, and other various events, in order to predict the current and future states of patients. Despite the strong performance of RNNs, it is often challenging for users to understand why the model makes a particular prediction. Such black-box nature of RNNs can impede its wide adoption in clinical practice. Furthermore, we have no established methods to interactively leverage users' domain expertise and prior knowledge as inputs for steering the model. Therefore, our design study aims to provide a visual analytics solution to increase interpretability and interactivity of RNNs via a joint effort of medical experts, artificial intelligence scientists, and visual analytics researchers. Following the iterative design process between the experts, we design, implement, and evaluate a visual analytics tool called RetainVis, which couples a newly improved, interpretable, and interactive RNN-based model called RetainEX and visualizations for users' exploration of EMR data in the context of prediction tasks. Our study shows the effective use of RetainVis for gaining insights into how individual medical codes contribute to making risk predictions, using EMRs of patients with heart failure and cataract symptoms. Our study also demonstrates how we made substantial changes to the state-of-the-art RNN model called RETAIN in order to make use of temporal information and increase interactivity. This study will provide a useful guideline for researchers that aim to design an interpretable and interactive visual analytics tool for RNNs.},
 author = {B. C. {Kwon} and M. {Choi} and J. T. {Kim} and E. {Choi} and Y. B. {Kim} and S. {Kwon} and J. {Sun} and J. {Choo}},
 comments = {Presents a specific method for enhancing explainability for models, The described method is neither general, nor focused on NLP},
 doi = {10.1109/TVCG.2018.2865027},
 issn = {1077-2626},
 journal = {IEEE Transactions on Visualization and Computer Graphics},
 keywords = {artificial intelligence;data analysis;data visualisation;interactive systems;medical information systems;recurrent neural nets;interactive RNN-based model;EMR data;prediction tasks;RetainVis;individual medical codes;risk predictions;temporal information;increase interactivity;interpretable analytics tool;interpretable networks;interactive recurrent neural networks;electronic medical records;black-box nature;interactively leverage users;design study;visual analytics solution;medical experts;artificial intelligence scientists;iterative design process;newly improved RNN-based model;RNN-based model;visual analytic researchers;interactive visual analytic tool;Machine learning;Medical diagnostic imaging;Task analysis;Predictive models;Computational modeling;Visual analytics;Data models;Interactive Artificial Intelligence;XAI (Explainable Artificial Intelligence);Interpretable Deep Learning;Healthcare},
 month = {Jan},
 number = {1},
 pages = {299-309},
 title = {RetainVis: Visual Analytics with Interpretable and Interactive Recurrent Neural Networks on Electronic Medical Records},
 volume = {25},
 year = {2019}
}

@inproceedings{8468758,
 abstract = {Machine learning technology has been greatly developed in the last decade, which makes artificial intelligence reach a revolutionary breakthrough and lets us really perceive the potential of artificial intelligence in changing human life. In order to improve the understanding and application ability of artificial intelligence, carrying out the corresponding machine learning course is of significance for the students during the undergraduate period. This paper probes into the teaching content, teaching form and other aspects of the undergraduate machine learning course based on this issue and proposes a teaching method driven by application scenarios to guide the undergraduate students to understand the development, current situation and frontier technology of machine learning. In the experimental design, the students' theoretical knowledge is fully considered, the practical questions are simplified, and the students' ability to think and solve problems is also raised, so as to lay a theoretical and practical basis for further study of machine learning.},
 author = {W. {Sun} and X. {Gao}},
 booktitle = {2018 13th International Conference on Computer Science Education (ICCSE)},
 comments = { The publication does not focus on explainability},
 doi = {10.1109/ICCSE.2018.8468758},
 issn = {2473-9464},
 keywords = {artificial intelligence;computer aided instruction;computer science education;educational courses;further education;learning (artificial intelligence);teaching;artificial intelligence era;machine learning technology;undergraduate period;undergraduate students;undergraduate machine learning course;machine learning course;teaching content;teaching form;Machine learning;Machine learning algorithms;Classification algorithms;Prediction algorithms;Education;Decision trees;artificial intelligence;machine learning;undergraduate},
 month = {Aug},
 number = {},
 pages = {1-5},
 title = {The Construction of Undergraduate Machine Learning Course in the Artificial Intelligence Era},
 volume = {},
 year = {2018}
}

@inproceedings{8491501,
 abstract = {To date, numerous ways have been created to learn a fusion solution from data. However, a gap exists in terms of understanding the quality of what was learned and how trustworthy the fusion is for future-i.e., new-data. In part, the current paper is driven by the demand for so-called explainable AI (XAI). Herein, we discuss methods for XAI of the Choquet integral (ChI), a parametric nonlinear aggregation function. Specifically, we review existing indices, and we introduce new data-centric XAI tools. These various XAI-ChI methods are explored in the context of fusing a set of heterogeneous deep convolutional neural networks for remote sensing.},
 author = {B. {Murray} and M. A. {Islam} and A. J. {Pinar} and T. C. {Havens} and D. T. {Anderson} and G. {Scott}},
 booktitle = {2018 IEEE International Conference on Fuzzy Systems (FUZZ-IEEE)},
 comments = { The described method is neither general, nor focused on NLP},
 doi = {10.1109/FUZZ-IEEE.2018.8491501},
 issn = {},
 keywords = {convolution;feedforward neural nets;learning (artificial intelligence);optimisation;remote sensing;sensor fusion;data-driven optimization;Choquet integral;fusion solution;parametric nonlinear aggregation function;data-centric XAI tools;XAI-ChI methods;explainable AI;heterogeneous deep convolutional neural networks;remote sensing;Frequency modulation;Indexes;Remote sensing;Optimization;Artificial intelligence;Electronic mail;Convolutional neural networks;Choquet Integral;Fuzzy Integral;Explainable AI;Machine Learning},
 month = {July},
 number = {},
 pages = {1-8},
 title = {Explainable AI for Understanding Decisions and Data-Driven Optimization of the Choquet Integral},
 volume = {},
 year = {2018}
}

@article{8494828,
 abstract = {Neural sequence-to-sequence models have proven to be accurate and robust for many sequence prediction tasks, and have become the standard approach for automatic translation of text. The models work with a five-stage blackbox pipeline that begins with encoding a source sequence to a vector space and then decoding out to a new target sequence. This process is now standard, but like many deep learning methods remains quite difficult to understand or debug. In this work, we present a visual analysis tool that allows interaction and “what if”-style exploration of trained sequence-to-sequence models through each stage of the translation process. The aim is to identify which patterns have been learned, to detect model errors, and to probe the model with counterfactual scenario. We demonstrate the utility of our tool through several real-world sequence-to-sequence use cases on large-scale models.},
 author = {H. {Strobelt} and S. {Gehrmann} and M. {Behrisch} and A. {Perer} and H. {Pfister} and A. M. {Rush}},
 comments = {Presents a specific method for enhancing explainability for models, The described method is neither general, nor focused on NLP},
 doi = {10.1109/TVCG.2018.2865044},
 issn = {1077-2626},
 journal = {IEEE Transactions on Visualization and Computer Graphics},
 keywords = {data visualisation;learning (artificial intelligence);neural nets;program debugging;sequences;seq2seq-Vis;source sequence;target sequence;visual debugging tool;neural sequence-to-sequence models;blackbox pipeline;vector space;deep learning methods;visual analysis tool;Analytical models;Visualization;Tools;Predictive models;Machine learning;Data models;Atmosphere;Explainable AI;Visual Debugging;Visual Analytics;Machine Learning;Deep Learning;NLP},
 month = {Jan},
 number = {1},
 pages = {353-363},
 title = {Seq2seq-Vis: A Visual Debugging Tool for Sequence-to-Sequence Models},
 volume = {25},
 year = {2019}
}

@inproceedings{8519384,
 abstract = {Identifying the aspect for a given target is an important issue in synthetic aperture radar (SAR) image interpretation. A new SAR target aspect identification method based on machine learning theory is proposed in this paper. First, the aspect angles of the SAR target are discretized, and the spatial relationships of the neighborhoods of the SAR target samples are established. Then an optimal linear mapping is solved based on the proposed subspace aspect discriminant analysis. The samples will be projected into a low-dimensional space and be of a better aspect identifiability than in their original space. Finally, the projected samples are fed into a multilayer neural network, and the aspects of the SAR targets will be indicated. Experimental results have shown the superiority of the proposed method based on the moving and stationary target acquisition and recognition (MSTAR) data set.},
 author = {J. {Pei} and Y. {Huang} and W. {Huo} and Y. {Zhang} and J. {Yang}},
 booktitle = {IGARSS 2018 - 2018 IEEE International Geoscience and Remote Sensing Symposium},
 comments = { The publication does not focus on explainability},
 doi = {10.1109/IGARSS.2018.8519384},
 issn = {2153-7003},
 keywords = {image sampling;learning (artificial intelligence);multilayer perceptrons;radar computing;radar imaging;radar target recognition;synthetic aperture radar;optimal linear mapping;low-dimensional space;moving-and-stationary target acquisition-and-recognition data set;MSTAR data set;multilayer neural network;aspect angles;machine learning theory;SAR target aspect identification method;synthetic aperture radar image interpretation;SAR image;stationary target acquisition;projected samples;aspect identifiability;subspace aspect discriminant analysis;SAR target samples;Synthetic aperture radar;Multi-layer neural network;Estimation;Training;Neurons;Machine learning;Synthetic aperture radar;target aspect identification;machine learning;multi-layer neural network},
 month = {July},
 number = {},
 pages = {2310-2313},
 title = {Target Aspect Identification in SAR Image: A Machine Learning Approach},
 volume = {},
 year = {2018}
}

@article{8540793,
 abstract = {This technology manager's note piece identifies the major components in the artificial intelligence (AI) business ecosystem and discusses several implications for managers. Specifically, it emphasizes on the designing of AI user scenarios, data acquisition for AI, and building the AI ecosystem.},
 author = {X. I. {Quan} and J. {Sanderson}},
 comments = { The publication does not focus on explainability},
 doi = {10.1109/EMR.2018.2882430},
 issn = {0360-8581},
 journal = {IEEE Engineering Management Review},
 keywords = {artificial intelligence;business data processing;competitive intelligence;data acquisition;technology management;artificial intelligence business ecosystem;technology manager;AI user scenarios;AI ecosystem;data acquisition;Business;Ecosystems;Machine learning;Medical services;Buildings;Artificial intelligence;business ecosystem;technology management},
 month = {Fourthquarter},
 number = {4},
 pages = {22-25},
 title = {Understanding the Artificial Intelligence Business Ecosystem},
 volume = {46},
 year = {2018}
}

@inproceedings{8551093,
 abstract = {Natural Language (NL) is an essential part of ourlife. Humans use language for communication. NL is a prevailing tool used by the humans to convey the information. Natural Language Understanding (NLU) is a major challenge in Natural Language Processing (NLP). NLP is a part of Artificial Intelligence (AI). NLP provides a significant tool for communication. It attempts to produces noise free data and conversion of noise to text. NLU is having different levels. This paper presents the issue with respect to one of the level such as syntax analysis. To provide a solution for syntax analysis, dynamic fuzzy parser is designed and implemented to parse the English input sentences. Traditional approach of parsing is enhanced by applying fuzzy logic. This helps to know the syntactic correctness of the sentence. Penns tree bank parts of speech tags are used for the Parts of Speech Tagger (POS). POS tagger assigns the parts of speech tags for the input English sentence. Then these tags of the words are parsed using the grammar rules. Finally the result is displayed to represent the number of words parsed in a sentence with its associated fuzzy membership value. This parser produces Precision value of 1(100%), Recall value of 0.92 (92%) and F-measure value of 0.9583 for the sample of 50 correct and 50 incorrect sentences.},
 author = {S. G. {Kanakaraddi} and S. S. {Nandval}},
 booktitle = {2018 International Conference on Current Trends towards Converging Technologies (ICCTCT)},
 comments = { The publication does not focus on explainability},
 doi = {10.1109/ICCTCT.2018.8551093},
 issn = {},
 keywords = {artificial intelligence;computational linguistics;context-free grammars;fuzzy logic;natural language processing;text analysis;syntax analysis;dynamic fuzzy parser;natural language;recall value;precision value;F-measure value;grammar rules;parts of speech tagger;Penns tree bank parts of speech tags;parse English input sentences;artificial intelligence;natural language processing;natural language understanding;fuzzy membership value;POS tagger;NLP;NLU;fuzzy max-min technique;fuzzy logic;Grammar;Syntactics;Natural language processing;Conferences;Market research;Artificial intelligence;POS;FCFG;NL;NLU;NLP;POS;AI;CFG},
 month = {March},
 number = {},
 pages = {1-5},
 title = {Dynamic Fuzzy Parser to Parse English Sentence Using POS Tagger and Fuzzy Max-Min Technique},
 volume = {},
 year = {2018}
}

@inproceedings{8588744,
 abstract = {We address the interpretability of convolutional neural networks (CNNs) for predicting a geo-location from an image. In a pilot experiment we classify images of Pittsburgh vs Tokyo and visualize the learned CNN filters. We found that varying the CNN architecture leads to variating in the visualized filters. This calls for further investigation of the effective parameters on the interpretability of CNNs.},
 author = {S. {Khademi} and X. {Shi} and T. {Mager} and R. {Siebes} and C. {Hein} and V. {de Boer} and J. {van Gemert}},
 booktitle = {2018 IEEE 14th International Conference on e-Science (e-Science)},
 comments = {Presents a specific method for enhancing explainability for models, The described method is neither general, nor focused on NLP},
 doi = {10.1109/eScience.2018.00125},
 issn = {},
 keywords = {feedforward neural nets;learning (artificial intelligence);neural net architecture;sight-seeing;eyes;deep neural networks;interpretability;convolutional neural networks;CNNs;geo-location;Tokyo;learned CNN filters;CNN architecture;visualized filters;Visualization;Computer architecture;Neural networks;Image recognition;Conferences;Computer science;Intelligent systems;convolutional neural network (CNN);interpretability;place recognition;visualization;classification},
 month = {Oct},
 number = {},
 pages = {407-408},
 title = {Sight-Seeing in the Eyes of Deep Neural Networks},
 volume = {},
 year = {2018}
}

@inproceedings{8613997,
 abstract = {Personalized Healthcare (PH) is a new patientoriented healthcare approach which expects to improve the traditional healthcare system. The focus of this new advancement is the patient data collected from patient Electronic health records (EHR), Internet of Things (IoT) sensor devices, wearables and mobile devices, web-based information and social media. PH applies Artificial Intelligence (AI) techniques to the collected dataset to improve disease progression technique, disease prediction, patient selfmanagement and clinical intervention. Machine learning techniques are widely used in this regard to develop analytic models. These models are integrated into different healthcare service applications and clinical decision support systems. These models mainly analyse the collected data from sensor devices and other sources to identify behavioral patterns and clinical conditions of the patient. For example, these models analyse the collected data to identify the patient's improvements, habits and anomaly in daily routine, changes in sleeping and mobility, eating, drinking and digestive pattern. Based on those patterns the healthcare applications and the clinical decision support systems recommend lifestyle advice, special treatment and care plans for the patient. The doctors and caregivers can also be engaged in the care plan process to validate lifestyle advice. However, there are many uncertainties and a grey area when it comes to applying machine learning in this context. Clinical, behaviour and lifestyle data in nature are very sensitive. There could be different types of biased involved in the process of data collection and interpretation. The training data model could have an older version of the dataset. All these could lead to an incorrect decision from the system without the user's knowledge. In this paper, some of the standards of the ML models reported in the recent research trends, identify the reliability issues and propose improvements.},
 author = {F. {Ahamed} and F. {Farid}},
 booktitle = {2018 International Conference on Machine Learning and Data Engineering (iCMLDE)},
 comments = { The described method is neither general, nor focused on NLP},
 doi = {10.1109/iCMLDE.2018.00014},
 issn = {},
 keywords = {data acquisition;decision support systems;diseases;electronic health records;health care;Internet of Things;learning (artificial intelligence);patient treatment;healthcare service applications;patient self-management;artificial intelligence techniques;Web-based information;Internet of Things sensor devices;electronic health records;healthcare system;electronic health records;ML models;training data model;data collection;lifestyle data;healthcare applications;clinical conditions;behavioral patterns;clinical decision support systems;machine learning techniques;clinical intervention;disease prediction;disease progression technique;social media;mobile devices;patient data;personalized healthcare;Machine learning;Internet of Things;Hospitals;Monitoring;Sleep apnea;Personalized Healthcare;Internet of Things;Machine Learning},
 month = {Dec},
 number = {},
 pages = {19-21},
 title = {Applying Internet of Things and Machine-Learning for Personalized Healthcare: Issues and Challenges},
 volume = {},
 year = {2018}
}

@inproceedings{8621470,
 abstract = {Development of chromosome conformation capture methods boosted progress in the study of the spatial organization of chromatin. Accumulation of large amounts of experimental data provides an opportunity to apply machine learning methods to examine the connection between epigenetics and the three-dimensional structure of chromatin. The aim of this study was to predict the characteristics of the chromatin structure, namely the transitional gamma, from ChIP-Seq experimental data by means of machine learning methods, and also to reveal the properties of epigenetic data influencing prediction. The neural network and the loss function designed for the prediction task are shown to perform with a sufficiently high accuracy. In addition, the genomic size of the chromatin context required for improving the quality of the prediction was assessed. Several neural network visualization techniques were tested as a means for improving interpretability of network, showing the possibility for using visualization to study interrelations in epigenetic data relevant for three-dimensional chromatin structure. To sum up, a close relationship between epigenetic factors and the structure of chromatin has been confirmed.},
 author = {S. {Starikov} and E. {Khrameeva} and M. {Gelfand}},
 booktitle = {2018 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)},
 comments = { The publication does not focus on explainability, The described method is neither general, nor focused on NLP},
 doi = {10.1109/BIBM.2018.8621470},
 issn = {},
 keywords = {biology computing;data visualisation;genetics;genomics;learning (artificial intelligence);neural nets;chromosome conformation capture methods;ChIP-Seq experimental data;machine learning methods;epigenetic data influencing prediction;neural network visualization techniques;three-dimensional chromatin structure;chromatin spatial structure characteristics;Machine learning;Bioinformatics;Neural networks;Data visualization;Conferences;Biomedical engineering;Life sciences;Hi-C;machine learning;neural networks;ChIP-Seq},
 month = {Dec},
 number = {},
 pages = {2489-2489},
 title = {Prediction of chromatin spatial structure characteristics using machine learning methods},
 volume = {},
 year = {2018}
}

@inproceedings{8622439,
 abstract = {Explaining recommendations helps users to make more accurate and effective decisions and improves system credibility and transparency. Current explainable recommender systems tend to provide fixed statements such as "customers who purchased this item also purchased....". This explanation is generated only on the basis of the purchase history of similar customers, so it does not include the preferences of customers who have purchased the item or a description of the item. Since user-generated reviews generally contain information about the reviewer's preferences and a description of the item, such reviews typically have more effect on purchase decisions. Therefore, using reviews to explain recommendations should be more useful than providing only a fixed statement explanation. Aiming to create a system that provides personalized explanations for recommendations, we have developed a recurrent neural network model that uses multicriteria evaluation data to generate reviews.},
 author = {T. {Suzuki} and S. {Oyama} and M. {Kurihara}},
 booktitle = {2018 IEEE International Conference on Big Data (Big Data)},
 comments = { The publication does not focus on explainability},
 doi = {10.1109/BigData.2018.8622439},
 issn = {},
 keywords = {information filtering;information filters;recommender systems;recurrent neural nets;explainable recommendations;explainable recommender systems;review text;personalized explanations;fixed statement explanation;purchase decisions;reviewer;user-generated reviews;purchase history;fixed statements;transparency;system credibility;multicriteria evaluation data;Decoding;Data models;Recommender systems;Mathematical model;Computational modeling;History;Recurrent neural networks;explainable recommendation;text generation;RNN;recommender systems},
 month = {Dec},
 number = {},
 pages = {3549-3551},
 title = {Toward Explainable Recommendations: Generating Review Text from Multicriteria Evaluation Data},
 volume = {},
 year = {2018}
}

@inproceedings{8679370,
 abstract = {Facial expression is the most powerful and natural non-verbal emotional communication method. Facial Expression Recognition(FER) has significance in machine learning tasks. Deep Learning models perform well in FER tasks, but it doesn't provide any justification for its decisions. Based on the hypothesis that facial expression is a combination of facial muscle movements, we find that Facial Action Coding Units(AUs) and Emotion label have a relationship in CK+ Dataset. In this paper, we propose a model which utilises AUs to explain Convolutional Neural Network(CNN) model's classification results. The CNN model is trained with CK+ Dataset and classifies emotion based on extracted features. Explanation model classifies the multiple AUs with the extracted features and emotion classes from the CNN model. Our experiment shows that with only features and emotion classes obtained from the CNN model, Explanation model generates AUs very well.},
 author = {S. {Kim} and H. {Kim}},
 booktitle = {2019 IEEE International Conference on Big Data and Smart Computing (BigComp)},
 comments = { The described method is neither general, nor focused on NLP},
 doi = {10.1109/BIGCOMP.2019.8679370},
 issn = {2375-9356},
 keywords = {convolutional neural nets;emotion recognition;face recognition;feature extraction;learning (artificial intelligence);nonverbal emotional communication method;machine learning tasks;Deep Learning models;FER tasks;facial muscle movements;CK+ Dataset;CNN model;emotion classes;facial expression recognition;convolutional neural network model;facial action coding units;deep explanation model;facial action coding unit;Hidden Markov models;Gold;Feature extraction;Face recognition;Deep learning;Computational modeling;Task analysis;Explanation Model;Facial Expression Recognition;Deep learning;Justification;Facial Action Coding System},
 month = {Feb},
 number = {},
 pages = {1-4},
 title = {Deep Explanation Model for Facial Expression Recognition Through Facial Action Coding Unit},
 volume = {},
 year = {2019}
}

@inproceedings{953778,
 abstract = {Document image understanding denotes the recognition of semantically relevant components in the layout extracted from a document image. This recognition process is based on some visual models, whose manual specification can be a highly demanding task. In order to automatically acquire these models, we propose the application of machine learning techniques. Problems raised by possible dependencies between concepts to be learned are illustrated and solved with a computational strategy based on the separate-and-parallel-conquer search. The approach is tested on a set of real multi-page documents processed by the system WISDOM++. New results confirm the validity of the proposed strategy and show some limits of the learning system used in this work.},
 author = {D. {Malerba} and F. {Esposito} and F. A. {Lisi} and O. {Altamura}},
 booktitle = {Proceedings of Sixth International Conference on Document Analysis and Recognition},
 comments = { The publication does not focus on explainability},
 doi = {10.1109/ICDAR.2001.953778},
 issn = {},
 keywords = {document image processing;optical character recognition;learning (artificial intelligence);divide and conquer methods;search problems;document image understanding;logical component dependence discovery;document image recognition;visual models;machine learning;computational strategy;separate-and-parallel-conquer search;multi-page documents;WISDOM system;OCR;Image recognition;Text analysis;Image analysis;Optical character recognition software;XML;System testing;Publishing;Image databases;Digital images;Optical devices},
 month = {Sep.},
 number = {},
 pages = {174-178},
 title = {Automated discovery of dependencies between logical components in document image understanding},
 volume = {},
 year = {2001}
}

@incollection{aakurInherentExplainabilityPattern2018,
 abstract = {The ability of artificial intelligence systems to offer explanations for its decisions is central to building user confidence and structuring smart human-machine interactions. Expressing the rationale behind such a system's output is an important aspect of human-machine interaction as AI continues to be prominent in general, everyday use-cases. In this paper, we introduce a novel framework integrating Grenander's pattern theory structures to produce inherently explainable, symbolic representations for activity interpretations. These representations provide semantically rich and coherent interpretations of video activity using connected structures of detected (grounded) concepts, such as objects and actions, that are bound by semantics through background concepts not directly observed, i.e. contextualization cues. We use contextualization cues to establish semantic relationships among concepts to infer a deeper interpretation of events than what can be directly sensed. We propose the use of six questions that can be used to gain insight into the models ability to justify its decision and enhance its ability to interact with humans. The six questions are designed to (1) build an understanding of how the model is able to infer interpretations, (2) enable us to walk through its decision-making process, and (3) understand its drawbacks and possibly address them. We demonstrate the viability of this idea on video data using a dialog model that uses interpretations to generate explanations grounded in both video data and semantics.},
 address = {Cham},
 author = {Aakur, Sathyanarayanan N. and {de Souza}, Fillipe D. M. and Sarkar, Sudeep},
 booktitle = {Explainable and {{Interpretable Models}} in {{Computer Vision}} and {{Machine Learning}}},
 comments = { The described method is neither general, nor focused on NLP},
 doi = {10.1007/978-3-319-98131-4_11},
 editor = {Escalante, Hugo Jair and Escalera, Sergio and Guyon, Isabelle and Bar\'o, Xavier and G\"u{\c c}l\"ut\"urk, Ya{\u g}mur and G\"u{\c c}l\"u, Umut and {van Gerven}, Marcel},
 isbn = {978-3-319-98131-4},
 keywords = {Activity interpretation,ConceptNet,Explainability,Semantics},
 language = {en},
 pages = {277-299},
 publisher = {{Springer International Publishing}},
 series = {The {{Springer Series}} on {{Challenges}} in {{Machine Learning}}},
 title = {On the {{Inherent Explainability}} of {{Pattern Theory}}-{{Based Video Event Interpretations}}},
 year = {2018}
}

@inproceedings{Abdollahi:2017:UEC:3109859.3109913,
 acmid = {3109913},
 address = {New York, NY, USA},
 author = {Abdollahi, Behnoush and Nasraoui, Olfa},
 booktitle = {Proceedings of the Eleventh ACM Conference on Recommender Systems},
 comments = { The described method is neither general, nor focused on NLP},
 doi = {10.1145/3109859.3109913},
 isbn = {978-1-4503-4652-8},
 keywords = {explanations, interpretable models, latent factor models, matrix factorization, recommender systems},
 location = {Como, Italy},
 numpages = {5},
 pages = {79--83},
 publisher = {ACM},
 series = {RecSys '17},
 title = {Using Explainability for Constrained Matrix Factorization},
 url = {http://doi.acm.org/10.1145/3109859.3109913},
 year = {2017}
}

@inproceedings{Abreu:2009:RSF:1529282.1529374,
 acmid = {1529374},
 address = {New York, NY, USA},
 author = {Abreu, Rui and Mayer, Wolfgang and Stumptner, Markus and van Gemund, Arjan J. C.},
 booktitle = {Proceedings of the 2009 ACM Symposium on Applied Computing},
 comments = { The publication does not focus on explainability},
 doi = {10.1145/1529282.1529374},
 isbn = {978-1-60558-166-8},
 keywords = {abstract interpretation, fault localization, program spectra},
 location = {Honolulu, Hawaii},
 numpages = {6},
 pages = {409--414},
 publisher = {ACM},
 series = {SAC '09},
 title = {Refining Spectrum-based Fault Localization Rankings},
 url = {http://doi.acm.org/10.1145/1529282.1529374},
 year = {2009}
}

@article{Abstracts2016Society2016,
 comments = { Is not scientific literature, The publication does not focus on explainability},
 doi = {10.1007/s11606-016-3657-7},
 file = {/home/tim/Zotero/storage/R9S8V92J/2016 - Abstracts from the 2016 Society of General Interna.pdf;/home/tim/Zotero/storage/SSWJIBRH/2016 - Abstracts from the 2016 Society of General Interna.pdf},
 issn = {1525-1497},
 journal = {Journal of General Internal Medicine},
 language = {en},
 month = {May},
 number = {2},
 pages = {85-922},
 title = {Abstracts from the 2016 {{Society}} of {{General Internal Medicine Annual Meeting}}},
 volume = {31},
 year = {2016}
}

@article{Abstracts2017Society2017,
 comments = { Is not scientific literature, The publication does not focus on explainability},
 doi = {10.1007/s11606-017-4028-8},
 file = {/home/tim/Zotero/storage/DF6QGEYW/2017 - Abstracts from the 2017 Society of General Interna.pdf;/home/tim/Zotero/storage/PXA8F9U6/2017 - Abstracts from the 2017 Society of General Interna.pdf},
 issn = {1525-1497},
 journal = {Journal of General Internal Medicine},
 language = {en},
 month = {April},
 number = {2},
 pages = {83-808},
 title = {Abstracts from the 2017 {{Society}} of {{General Internal Medicine Annual Meeting}}},
 volume = {32},
 year = {2017}
}

@article{Abstracts36thAnnual2013,
 comments = { Is not scientific literature, The publication does not focus on explainability},
 doi = {10.1007/s11606-013-2436-y},
 file = {/home/tim/Zotero/storage/NP4WH8EI/2013 - Abstracts from the 36th Annual Meeting of the Soci.pdf},
 issn = {1525-1497},
 journal = {Journal of General Internal Medicine},
 language = {en},
 month = {June},
 number = {1},
 pages = {1-489},
 title = {Abstracts from the 36th {{Annual Meeting}} of the {{Society}} of {{General Internal Medicine}}},
 volume = {28},
 year = {2013}
}

@incollection{AbstractsDocumentsThis1997,
 address = {Boston, MA},
 booktitle = {Political {{Science Abstracts}}: 1996 {{Annual Supplement}};{{Volume}} 1},
 comments = { Is not scientific literature, The publication does not focus on explainability},
 doi = {10.1007/978-1-4615-5971-9_1},
 isbn = {978-1-4615-5971-9},
 language = {en},
 pages = {1-817},
 publisher = {{Springer US}},
 title = {Abstracts of {{Documents}} in {{This Supplement}}},
 year = {1997}
}

@article{AbstractsScientificPapers1999,
 comments = { Is not scientific literature, The publication does not focus on explainability},
 doi = {10.1007/BF03323585},
 issn = {1432-1084},
 journal = {European Radiology},
 keywords = {Magnetic Resonance Angiography,Magnetic Resonance Imaging,Spiral Compute Tomography,Takayasu Arteritis,Transjugular Intrahepatic Portosystemic Shunt},
 language = {en},
 month = {March},
 number = {1},
 pages = {S1-S362},
 title = {Abstracts {{Scientific Papers Honorary Lectures Categorical Courses Workshops State}}-of-the-{{Art Symposia}}},
 volume = {9},
 year = {1999}
}

@incollection{aggarwalMachineLearningShallow2018,
 abstract = {Conventional machine learning often uses optimization and gradient-descent methods for learning parameterized models. Examples of such models include linear regression, support vector machines, logistic regression, dimensionality reduction, and matrix factorization. Neural networks are also parameterized models that are learned with continuous optimization methods.},
 address = {Cham},
 author = {Aggarwal, Charu C.},
 booktitle = {Neural {{Networks}} and {{Deep Learning}}: {{A Textbook}}},
 comments = { The publication does not focus on explainability},
 doi = {10.1007/978-3-319-94463-0_2},
 editor = {Aggarwal, Charu C.},
 isbn = {978-3-319-94463-0},
 language = {en},
 pages = {53-104},
 publisher = {{Springer International Publishing}},
 title = {Machine {{Learning}} with {{Shallow Neural Networks}}},
 year = {2018}
}

@incollection{aggarwalModelBasedCollaborativeFiltering2016,
 abstract = {The neighborhood-based methods of the previous chapter can be viewed as generalizations of k-nearest neighbor classifiers, which are commonly used in machine learning.},
 address = {Cham},
 author = {Aggarwal, Charu C.},
 booktitle = {Recommender {{Systems}}: {{The Textbook}}},
 comments = { The publication does not focus on explainability, The described method is neither general, nor focused on NLP},
 doi = {10.1007/978-3-319-29659-3_3},
 editor = {Aggarwal, Charu C.},
 isbn = {978-3-319-29659-3},
 language = {en},
 pages = {71-138},
 publisher = {{Springer International Publishing}},
 title = {Model-{{Based Collaborative Filtering}}},
 year = {2016}
}

@inproceedings{Amir:2018:ASS:3237383.3237877,
 acmid = {3237877},
 address = {Richland, SC},
 author = {Amir, Ofra and Doshi-Velez, Finale and Sarne, David},
 booktitle = {Proceedings of the 17th International Conference on Autonomous Agents and MultiAgent Systems},
 comments = { The publication does not focus on explainability},
 keywords = {explainable ai, strategy summarization},
 location = {Stockholm, Sweden},
 numpages = {5},
 pages = {1203--1207},
 publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
 series = {AAMAS '18},
 title = {Agent Strategy Summarization},
 url = {http://dl.acm.org/citation.cfm?id=3237383.3237877},
 year = {2018}
}

@inproceedings{Amir:2018:HSA:3237383.3237869,
 acmid = {3237869},
 address = {Richland, SC},
 author = {Amir, Dan and Amir, Ofra},
 booktitle = {Proceedings of the 17th International Conference on Autonomous Agents and MultiAgent Systems},
 comments = { The publication does not focus on explainability },
 keywords = {explainable ai, strategy summarization},
 location = {Stockholm, Sweden},
 numpages = {9},
 pages = {1168--1176},
 publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
 series = {AAMAS '18},
 title = {HIGHLIGHTS: Summarizing Agent Behavior to People},
 url = {http://dl.acm.org/citation.cfm?id=3237383.3237869},
 year = {2018}
}

@article{AnnualCongressEuropean2018,
 comments = { The publication does not focus on explainability},
 doi = {10.1007/s00259-018-4148-3},
 issn = {1619-7089},
 journal = {European Journal of Nuclear Medicine and Molecular Imaging},
 language = {en},
 month = {October},
 number = {1},
 pages = {1-844},
 title = {Annual {{Congress}} of the {{European Association}} of {{Nuclear Medicine October}} 13 \textendash{} 17, 2018 {{D\"usseldorf}}, {{Germany}}},
 volume = {45},
 year = {2018}
}

@incollection{azizMachineLearningAI2019,
 abstract = {We explore how machine learning and artificial intelligence (AI) solutions are transforming risk management. A non-technical overview is first given of the main machine learning and AI techniques of benefit to risk management. Then a review is provided, using current practice and empirical evidence, of the application of these techniques to the risk management fields of credit risk, market risk, operational risk, and compliance (`RegTech'). We conclude with some thoughts on current limitations and views on how the field is likely to develop in the short- to medium-term. Overall, we present an optimistic picture of the role of machine learning and AI in risk management, but note some practical limitations around suitable data management policies, transparency, and lack of necessary skillsets within firms.},
 address = {Cham},
 author = {Aziz, Saqib and Dowling, Michael},
 booktitle = {Disrupting {{Finance}}: {{FinTech}} and {{Strategy}} in the 21st {{Century}}},
 comments = { The publication does not focus on explainability},
 doi = {10.1007/978-3-030-02330-0_3},
 editor = {Lynn, Theo and Mooney, John G. and Rosati, Pierangelo and Cummins, Mark},
 file = {/home/tim/Zotero/storage/EY8T5IEC/Aziz and Dowling - 2019 - Machine Learning and AI for Risk Management.pdf},
 isbn = {978-3-030-02330-0},
 keywords = {AI,Credit risk,Machine learning,Market risk,Operational risk,RegTech,Risk management},
 language = {en},
 pages = {33-50},
 publisher = {{Springer International Publishing}},
 series = {Palgrave {{Studies}} in {{Digital Business}} \& {{Enabling Technologies}}},
 title = {Machine {{Learning}} and {{AI}} for {{Risk Management}}},
 year = {2019}
}

@inproceedings{Baral:2018:RRA:3209219.3209237,
 acmid = {3209237},
 address = {New York, NY, USA},
 author = {Baral, Ramesh and Zhu, XiaoLong and Iyengar, S. S. and Li, Tao},
 booktitle = {Proceedings of the 26th Conference on User Modeling, Adaptation and Personalization},
 comments = {Presents a specific method for enhancing explainability for models, The described method is neither general, nor focused on NLP},
 doi = {10.1145/3209219.3209237},
 isbn = {978-1-4503-5589-6},
 keywords = {explainable recommendation, information retrieval, social networks},
 location = {Singapore, Singapore},
 numpages = {10},
 pages = {23--32},
 publisher = {ACM},
 series = {UMAP '18},
 title = {ReEL: Review Aware Explanation of Location Recommendation},
 url = {http://doi.acm.org/10.1145/3209219.3209237},
 year = {2018}
}

@inproceedings{Bashar:2014:IDP:2682647.2682753,
 acmid = {2682753},
 address = {Washington, DC, USA},
 author = {Bashar, Md Abul and Li, Yuefeng and Shen, Yan and Albathan, Mubarak},
 booktitle = {Proceedings of the 2014 IEEE/WIC/ACM International Joint Conferences on Web Intelligence (WI) and Intelligent Agent Technologies (IAT) - Volume 01},
 comments = { The publication does not focus on explainability},
 doi = {10.1109/WI-IAT.2014.67},
 isbn = {978-1-4799-4143-8},
 keywords = {Pattern Interpretation, Information Mismatch and Overload, Ontology-based Mining, Text Mining, Semantic Web},
 numpages = {6},
 pages = {432--437},
 publisher = {IEEE Computer Society},
 series = {WI-IAT '14},
 title = {Interpreting Discovered Patterns in Terms of Ontology Concepts},
 url = {http://dx.doi.org/10.1109/WI-IAT.2014.67},
 year = {2014}
}

@article{bench-caponHistoryAILaw2012,
 abstract = {We provide a retrospective of 25 years of the International Conference on AI and Law, which was first held in 1987. Fifty papers have been selected from the thirteen conferences and each of them is described in a short subsection individually written by one of the 24 authors. These subsections attempt to place the paper discussed in the context of the development of AI and Law, while often offering some personal reactions and reflections. As a whole, the subsections build into a history of the last quarter century of the field, and provide some insights into where it has come from, where it is now, and where it might go.},
 author = {{Bench-Capon}, Trevor and Araszkiewicz, Micha\l{} and Ashley, Kevin and Atkinson, Katie and Bex, Floris and Borges, Filipe and Bourcier, Daniele and Bourgine, Paul and Conrad, Jack G. and Francesconi, Enrico and Gordon, Thomas F. and Governatori, Guido and Leidner, Jochen L. and Lewis, David D. and Loui, Ronald P. and McCarty, L. Thorne and Prakken, Henry and Schilder, Frank and Schweighofer, Erich and Thompson, Paul and Tyrrell, Alex and Verheij, Bart and Walton, Douglas N. and Wyner, Adam Z.},
 comments = { The publication does not focus on explainability},
 doi = {10.1007/s10506-012-9131-x},
 file = {/home/tim/Zotero/storage/9RUMRANY/Bench-Capon et al. - 2012 - A history of AI and Law in 50 papers 25 years of .pdf;/home/tim/Zotero/storage/XXTKI56R/Bench-Capon et al. - 2012 - A history of AI and Law in 50 papers 25 years of .pdf},
 issn = {1572-8382},
 journal = {Artificial Intelligence and Law},
 keywords = {Artificial intelligence and law,Legal informatics,Models of legal reasoning},
 language = {en},
 month = {September},
 number = {3},
 pages = {215-319},
 shorttitle = {A History of {{AI}} and {{Law}} in 50 Papers},
 title = {A History of {{AI}} and {{Law}} in 50 Papers: 25~Years of the International Conference on {{AI}} and {{Law}}},
 volume = {20},
 year = {2012}
}

@inproceedings{berzinsInnovationsNaturalLanguage2008,
 abstract = {This paper evaluates the potential contributions of natural language processing to requirements engineering. We present a selective history of the relationship between requirements engineering (RE) and natural-language processing (NLP), and briefly summarize relevant recent trends in NLP. The paper outlines basic issues in RE and how they relate to interactions between a NLP front end and system-development processes. We suggest some improvements to NLP that may be possible in the context of RE and conclude with an assessment of what should be done to improve likelihood of practical impact in this direction.},
 author = {Berzins, Valdis and Martell, Craig and {Luqi} and Adams, Paige},
 booktitle = {Innovations for {{Requirement Analysis}}. {{From Stakeholders}}' {{Needs}} to {{Formal Designs}}},
 comments = { The publication does not focus on explainability},
 editor = {Paech, Barbara and Martell, Craig},
 isbn = {978-3-540-89778-1},
 keywords = {Ambiguity,Domain-Specific Methods,Gaps,Natural Language,Requirements},
 language = {en},
 pages = {125-146},
 publisher = {{Springer Berlin Heidelberg}},
 series = {Lecture {{Notes}} in {{Computer Science}}},
 title = {Innovations in {{Natural Language Document Processing}} for {{Requirements Engineering}}},
 year = {2008}
}

@article{bharadhwajExplanationsTemporalRecommendations2018,
 abstract = {Recommendation systems (RS) are an integral part of artificial intelligence (AI) and have become increasingly important in the growing age of commercialization in AI. Deep learning (DL) techniques for RS provide powerful latent-feature models for effective recommendation but suffer from the major drawback of being non-interpretable. In this paper we describe a framework for explainable temporal recommendations in a DL model. We consider an LSTM based Recurrent Neural Network architecture for recommendation and a neighbourhood based scheme for generating explanations in the model. We demonstrate the effectiveness of our approach through experiments on the Netflix dataset by jointly optimizing for both prediction accuracy and explainability.},
 author = {Bharadhwaj, Homanga and Joshi, Shruti},
 comments = { The described method is neither general, nor focused on NLP},
 doi = {10.1007/s13218-018-0560-x},
 file = {/home/tim/Zotero/storage/4J8DH8MG/Bharadhwaj and Joshi - 2018 - Explanations for Temporal Recommendations.pdf},
 issn = {1610-1987},
 journal = {KI - K\"unstliche Intelligenz},
 keywords = {Explainable AI,Recommendation systems,Recurrent Neural Networks},
 language = {en},
 month = {November},
 number = {4},
 pages = {267-272},
 title = {Explanations for {{Temporal Recommendations}}},
 volume = {32},
 year = {2018}
}

@article{Biecek:2018:DEC:3291125.3309646,
 acmid = {3309646},
 author = {Biecek, Przemys\law},
 comments = { The publication does not focus on explainability, The described method is neither general, nor focused on NLP},
 issn = {1532-4435},
 issue_date = {January 2018},
 journal = {J. Mach. Learn. Res.},
 keywords = {explainable artificial intelligence, interpretable machine learning, model visualization, predictive modelling},
 month = {January},
 number = {1},
 numpages = {5},
 pages = {3245--3249},
 publisher = {JMLR.org},
 title = {DALEX: Explainers for Complex Predictive Models in R},
 url = {http://dl.acm.org/citation.cfm?id=3291125.3309646},
 volume = {19},
 year = {2018}
}

@inproceedings{biermannNaturalLanguageProgramming1983,
 abstract = {A procedural semantics system is described for English imperative sentences in natural language programming. Issues related to the handling of dialog focus, noun group resolution, quantifier processing, and imperative verb execution are discussed. Sequences of imperative sentences may be assembled to build natural language programs and techniques are given for processing such programs. The final sections include a discussion of related research and a brief overview of the field.},
 author = {Biermann, Alan W.},
 booktitle = {Computer {{Program Synthesis Methodologies}}},
 comments = { The publication does not focus on explainability},
 editor = {Biermann, Alan W. and Guiho, G\'erard},
 isbn = {978-94-009-7019-9},
 keywords = {Focus Mechanism,Head Noun,Natural Language,Naval Postgraduate School,Procedural Representation},
 language = {en},
 pages = {335-368},
 publisher = {{Springer Netherlands}},
 series = {{{NATO Advanced Study Institutes Series}}},
 title = {Natural {{Language Programming}}},
 year = {1983}
}

@inproceedings{Blank:2018:DLC:3159450.3162370,
 acmid = {3162370},
 address = {New York, NY, USA},
 author = {Blank, Douglas and Meeden, Lisa and Marshall, Jim},
 booktitle = {Proceedings of the 49th ACM Technical Symposium on Computer Science Education},
 comments = { The publication does not focus on explainability},
 doi = {10.1145/3159450.3162370},
 isbn = {978-1-4503-5103-4},
 keywords = {artificial intelligence, artificial neural networks, deep learning, python},
 location = {Baltimore, Maryland, USA},
 numpages = {1},
 pages = {1055--1055},
 publisher = {ACM},
 series = {SIGCSE '18},
 title = {Deep Learning in the Classroom: (Abstract Only)},
 url = {http://doi.acm.org/10.1145/3159450.3162370},
 year = {2018}
}

@inproceedings{Bock:2018:VNN:3281505.3281605,
 acmid = {3281605},
 address = {New York, NY, USA},
 articleno = {132},
 author = {Bock, Marcel and Schreiber, Andreas},
 booktitle = {Proceedings of the 24th ACM Symposium on Virtual Reality Software and Technology},
 comments = { The described method is neither general, nor focused on NLP},
 doi = {10.1145/3281505.3281605},
 isbn = {978-1-4503-6086-9},
 keywords = {deep learning, explainable ai, neural networks, visualization},
 location = {Tokyo, Japan},
 numpages = {2},
 pages = {132:1--132:2},
 publisher = {ACM},
 series = {VRST '18},
 title = {Visualization of Neural Networks in Virtual Reality Using Unreal Engine},
 url = {http://doi.acm.org/10.1145/3281505.3281605},
 year = {2018}
}

@article{Bultan:1999:MCS:325478.325480,
 acmid = {325480},
 address = {New York, NY, USA},
 author = {Bultan, Tevfik and Gerber, Richard and Pugh, William},
 comments = { The publication does not focus on explainability},
 doi = {10.1145/325478.325480},
 issn = {0164-0925},
 issue_date = {July 1999},
 journal = {ACM Trans. Program. Lang. Syst.},
 keywords = {Presburger arithmetic, abstract interpretation, symbolic model checking},
 month = {July},
 number = {4},
 numpages = {43},
 pages = {747--789},
 publisher = {ACM},
 title = {Model-checking Concurrent Systems with Unbounded Integer Variables: Symbolic Representations, Approximations, and Experimental Results},
 url = {http://doi.acm.org/10.1145/325478.325480},
 volume = {21},
 year = {1999}
}

@article{butz12thBiannualConference2014,
 author = {Butz, Martin V.},
 comments = { The publication does not focus on explainability},
 doi = {10.1007/s10339-014-0632-2},
 issn = {1612-4790},
 journal = {Cognitive Processing},
 keywords = {Head Noun,Lateralized Readiness Potential,Mental Rotation,Relative Clause,SNARC Effect},
 language = {en},
 month = {September},
 number = {1},
 pages = {1-158},
 title = {12th {{Biannual}} Conference of the {{German}} Cognitive Science Society ({{Gesellschaft}} F\"ur {{Kognitionswissenschaft}})},
 volume = {15},
 year = {2014}
}

@article{CARS2016Computer2016,
 comments = { The publication does not focus on explainability},
 doi = {10.1007/s11548-016-1412-5},
 issn = {1861-6429},
 journal = {International Journal of Computer Assisted Radiology and Surgery},
 language = {en},
 month = {June},
 number = {1},
 pages = {1-286},
 title = {{{CARS}} 2016\textemdash{{Computer Assisted Radiology}} and {{Surgery Proceedings}} of the 30th {{International Congress}} and {{Exhibition Heidelberg}}, {{Germany}}, {{June}} 21\textendash{}25, 2016},
 volume = {11},
 year = {2016}
}

@article{CARS2017Computer2017,
 comments = { The publication does not focus on explainability},
 doi = {10.1007/s11548-017-1588-3},
 file = {/home/tim/Zotero/storage/9MHAY3SY/2017 - CARS 2017—Computer Assisted Radiology and Surgery .pdf},
 issn = {1861-6429},
 journal = {International Journal of Computer Assisted Radiology and Surgery},
 language = {en},
 month = {June},
 number = {1},
 pages = {1-286},
 title = {{{CARS}} 2017\textemdash{{Computer Assisted Radiology}} and {{Surgery Proceedings}} of the 31st {{International Congress}} and {{Exhibition Barcelona}}, {{Spain}}, {{June}} 20\textendash{}24, 2017},
 volume = {12},
 year = {2017}
}

@article{CARS2018Computer2018,
 comments = { The publication does not focus on explainability},
 doi = {10.1007/s11548-018-1766-y},
 file = {/home/tim/Zotero/storage/UDZ8MQ7K/2018 - CARS 2018—Computer Assisted Radiology and Surgery .pdf},
 issn = {1861-6429},
 journal = {International Journal of Computer Assisted Radiology and Surgery},
 language = {en},
 month = {June},
 number = {1},
 pages = {1-273},
 title = {{{CARS}} 2018\textemdash{{Computer Assisted Radiology}} and {{Surgery Proceedings}} of the 32nd {{International Congress}} and {{Exhibition Berlin}}, {{Germany}}, {{June}} 20\textendash{}23, 2018},
 volume = {13},
 year = {2018}
}

@inproceedings{Chen:2018:NAR:3178876.3186070,
 acmid = {3186070},
 address = {Republic and Canton of Geneva, Switzerland},
 author = {Chen, Chong and Zhang, Min and Liu, Yiqun and Ma, Shaoping},
 booktitle = {Proceedings of the 2018 World Wide Web Conference},
 comments = {Presents a specific method for enhancing explainability for models, The described method is neither general, nor focused on NLP},
 doi = {10.1145/3178876.3186070},
 isbn = {978-1-4503-5639-8},
 keywords = {explainable recommendation, neural attention network, recommender systems, review usefulness},
 location = {Lyon, France},
 numpages = {10},
 pages = {1583--1592},
 publisher = {International World Wide Web Conferences Steering Committee},
 series = {WWW '18},
 title = {Neural Attentional Rating Regression with Review-level Explanations},
 url = {https://doi.org/10.1145/3178876.3186070},
 year = {2018}
}

@article{Cheng:2019:MER:3306215.3291060,
 acmid = {3291060},
 address = {New York, NY, USA},
 articleno = {16},
 author = {Cheng, Zhiyong and Chang, Xiaojun and Zhu, Lei and Kanjirathinkal, Rose C. and Kankanhalli, Mohan},
 comments = {Presents a specific method for enhancing explainability for models, The described method is neither general, nor focused on NLP},
 doi = {10.1145/3291060},
 issn = {1046-8188},
 issue_date = {March 2019},
 journal = {ACM Trans. Inf. Syst.},
 keywords = {Aspect, explainable recommendation, latent factor model, multi-modal, rating prediction},
 month = {January},
 number = {2},
 numpages = {28},
 pages = {16:1--16:28},
 publisher = {ACM},
 title = {MMALFM: Explainable Recommendation by Leveraging Reviews and Images},
 url = {http://doi.acm.org/10.1145/3291060},
 volume = {37},
 year = {2019}
}

@inproceedings{Chu:2018:ECI:3219819.3220063,
 acmid = {3220063},
 address = {New York, NY, USA},
 author = {Chu, Lingyang and Hu, Xia and Hu, Juhua and Wang, Lanjun and Pei, Jian},
 booktitle = {Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery \&\#38; Data Mining},
 comments = {Presents a specific method for enhancing explainability for models, The described method is neither general, nor focused on NLP},
 doi = {10.1145/3219819.3220063},
 isbn = {978-1-4503-5552-0},
 keywords = {closed form, deep neural network, exact and consistent interpretation},
 location = {London, United Kingdom},
 numpages = {10},
 pages = {1244--1253},
 publisher = {ACM},
 series = {KDD '18},
 title = {Exact and Consistent Interpretation for Piecewise Linear Neural Networks: A Closed Form Solution},
 url = {http://doi.acm.org/10.1145/3219819.3220063},
 year = {2018}
}

@inproceedings{Croitoru:2010:GEN:1838206.1838404,
 acmid = {1838404},
 address = {Richland, SC},
 author = {Croitoru, Madalina and Oren, Nir and Miles, Simon and Luck, Michael},
 booktitle = {Proceedings of the 9th International Conference on Autonomous Agents and Multiagent Systems: Volume 1 - Volume 1},
 comments = { The publication does not focus on explainability},
 isbn = {978-0-9826571-1-9},
 keywords = {conceptual graphs, norms},
 location = {Toronto, Canada},
 numpages = {2},
 pages = {1405--1406},
 publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
 series = {AAMAS '10},
 title = {Graphically Explaining Norms},
 url = {http://dl.acm.org/citation.cfm?id=1838206.1838404},
 year = {2010}
}

@incollection{curuksuPrinciplesDataScience2018,
 abstract = {This chapter covers advanced analytics principles and applications. Let us first back up on our objectives and progress so far. In Chap. 6, we defined the key concepts underlying the mathematical science of data analysis. The discussion was structured in two categories: descriptive and inferential statistics. In the context of a data science project, these two categories may be referred to as unsupervised and supervised modeling respectively. These two categories are ubiquitous because the objective of a data science project is always (bear with me please) to better understand some data or else to predict something. Chapter 7 thus again follows this binary structure, although some topics (e.g. computer simulation, Sect. 7.3) may be used to collect and understand data, forecast events, or both.},
 address = {Cham},
 author = {Curuksu, Jeremy David},
 booktitle = {Data {{Driven}}: {{An Introduction}} to {{Management Consulting}} in the 21st {{Century}}},
 comments = { The publication does not focus on explainability},
 doi = {10.1007/978-3-319-70229-2_7},
 editor = {Curuksu, Jeremy David},
 isbn = {978-3-319-70229-2},
 language = {en},
 pages = {87-127},
 publisher = {{Springer International Publishing}},
 series = {Management for {{Professionals}}},
 shorttitle = {Principles of {{Data Science}}},
 title = {Principles of {{Data Science}}: {{Advanced}}},
 year = {2018}
}

@inproceedings{Dalmia:2018:TIN:3184558.3191523,
 acmid = {3191523},
 address = {Republic and Canton of Geneva, Switzerland},
 author = {Dalmia, Ayushi and J, Ganesh and Gupta, Manish},
 booktitle = {Companion Proceedings of the The Web Conference 2018},
 comments = {Presents a specific method for enhancing explainability for models, The described method is neither general, nor focused on NLP},
 doi = {10.1145/3184558.3191523},
 isbn = {978-1-4503-5640-4},
 keywords = {graph representation, model interpretability, neural networks},
 location = {Lyon, France},
 numpages = {8},
 pages = {945--952},
 publisher = {International World Wide Web Conferences Steering Committee},
 series = {WWW '18},
 title = {Towards Interpretation of Node Embeddings},
 url = {https://doi.org/10.1145/3184558.3191523},
 year = {2018}
}

@inproceedings{deGraaf:2018:ERS:3173386.3173568,
 acmid = {3173568},
 address = {New York, NY, USA},
 author = {de Graaf, Maartje M.A. and Malle, Bertram F. and Dragan, Anca and Ziemke, Tom},
 booktitle = {Companion of the 2018 ACM/IEEE International Conference on Human-Robot Interaction},
 comments = {Presents a specific method for enhancing explainability for models, The described method is neither general, nor focused on NLP},
 doi = {10.1145/3173386.3173568},
 isbn = {978-1-4503-5615-2},
 keywords = {behavior explanation, explainable robotics, intentionality, theory of mind, transparency, trust calibration.},
 location = {Chicago, IL, USA},
 numpages = {2},
 pages = {387--388},
 publisher = {ACM},
 series = {HRI '18},
 title = {Explainable Robotic Systems},
 url = {http://doi.acm.org/10.1145/3173386.3173568},
 year = {2018}
}

@incollection{dengJointIntroductionNatural2018,
 abstract = {In this chapter, we set up the fundamental framework for the book. We first provide an introduction to the basics of natural language processing (NLP) as an integral part of artificial intelligence. We then survey the historical development of NLP, spanning over five decades, in terms of three waves. The first two waves arose as rationalism and empiricism, paving ways to the current deep learning wave. The key pillars underlying the deep learning revolution for NLP consist of (1) distributed representations of linguistic entities via embedding, (2) semantic generalization due to the embedding, (3) long-span deep sequence modeling of natural language, (4) hierarchical networks effective for representing linguistic levels from low to high, and (5) end-to-end deep learning methods to jointly solve many NLP tasks. After the survey, several key limitations of current deep learning technology for NLP are analyzed. This analysis leads to five research directions for future advances in NLP.},
 address = {Singapore},
 author = {Deng, Li and Liu, Yang},
 booktitle = {Deep {{Learning}} in {{Natural Language Processing}}},
 comments = { The publication does not focus on explainability},
 doi = {10.1007/978-981-10-5209-5_1},
 editor = {Deng, Li and Liu, Yang},
 isbn = {978-981-10-5209-5},
 language = {en},
 pages = {1-22},
 publisher = {{Springer Singapore}},
 title = {A {{Joint Introduction}} to {{Natural Language Processing}} and to {{Deep Learning}}},
 year = {2018}
}

@inproceedings{Dominguez:2019:EEA:3301275.3302274,
 acmid = {3302274},
 address = {New York, NY, USA},
 author = {Dominguez, Vicente and Messina, Pablo and Donoso-Guzm\'{a}n, Ivania and Parra, Denis},
 booktitle = {Proceedings of the 24th International Conference on Intelligent User Interfaces},
 comments = {Reviews the current state of explainability research, The described method is neither general, nor focused on NLP},
 doi = {10.1145/3301275.3302274},
 isbn = {978-1-4503-6272-6},
 keywords = {art, explainable AI, visual recommender systems},
 location = {Marina del Ray, California},
 numpages = {9},
 pages = {408--416},
 publisher = {ACM},
 series = {IUI '19},
 title = {The Effect of Explanations and Algorithmic Accuracy on Visual Recommender Systems of Artistic Images},
 url = {http://doi.acm.org/10.1145/3301275.3302274},
 year = {2019}
}

@article{EANM152015,
 comments = { The publication does not focus on explainability},
 doi = {10.1007/s00259-015-3198-z},
 issn = {1619-7089},
 journal = {European Journal of Nuclear Medicine and Molecular Imaging},
 language = {en},
 month = {October},
 number = {1},
 pages = {1-924},
 title = {{{EANM}}'15},
 volume = {42},
 year = {2015}
}

@article{ECR2005Scientific2005,
 comments = { The publication does not focus on explainability},
 doi = {10.1007/s10406-005-0100-2},
 issn = {1613-3757},
 journal = {European Radiology Supplements},
 keywords = {Public Health,Scientific Programme},
 language = {en},
 month = {March},
 number = {1},
 pages = {1-688},
 title = {{{ECR}} 2005 \textendash{} {{Scientific Programme}} \textendash{} {{Abstracts}}},
 volume = {15},
 year = {2005}
}

@inproceedings{Ehsan:2019:ARG:3301275.3302316,
 acmid = {3302316},
 address = {New York, NY, USA},
 author = {Ehsan, Upol and Tambwekar, Pradyumna and Chan, Larry and Harrison, Brent and Riedl, Mark O.},
 booktitle = {Proceedings of the 24th International Conference on Intelligent User Interfaces},
 comments = {Presents a specific method for enhancing explainability for models, The described method is neither general, nor focused on NLP},
 doi = {10.1145/3301275.3302316},
 isbn = {978-1-4503-6272-6},
 keywords = {algorithmic decision-making, algorithmic explanation, artificial intelligence, explainable AI, interpretability, machine learning, rationale generation, transparency, user perception},
 location = {Marina del Ray, California},
 numpages = {12},
 pages = {263--274},
 publisher = {ACM},
 series = {IUI '19},
 title = {Automated Rationale Generation: A Technique for Explainable AI and Its Effects on Human Perceptions},
 url = {http://doi.acm.org/10.1145/3301275.3302316},
 year = {2019}
}

@incollection{elmiedanyArtificialIntelligence2019,
 abstract = {Artificial intelligence can be defined as computer systems which have been designed to interact with the world through abilities (e.g. visual perception and speech recognition) and intelligent behaviours (e.g. evaluating the available information and then taking the most sensible action to achieve a defined aim) that we would think of as principally humans. Initially, research has focused on letting software do things better, in which computers have always been doing better, such as the analysis of large datasets. However, the use of artificial intelligence in our day-to-day life has increased exponentially. Data forms the basis for the development of artificial intelligent software systems that will not only collect information but is able to learn, understand and interpret information, adapt its behaviour, plan, conclude, solve problems, think abstract, come up with ideas and understand and interpret language. Thanks to AI, a smart phone can detect cancer and a smart watch can detect a stroke. Machine learning is infiltrating and optimizing nearly every aspect of medicine from the way 911 emergency services are dispatched to assisting doctors during surgery. People can even quit smoking or kick opiate addiction with the help of AI. AI scientists are currently developing new approaches in machine learning, computer modelling and probability statistics to improve decision-making processes and are using decision theory and neuroscience to drive the progress of more effective healthcare and education as well as economics. This chapter will discuss the science of AI and explore the importance of big data and AI strategies. It will expand to discuss AI and medicine as well as medical education. It will conclude with discussion of AI and education as well as the future of artificial intelligence.},
 address = {Cham},
 author = {El Miedany, Yasser},
 booktitle = {Rheumatology {{Teaching}}: {{The Art}} and {{Science}} of {{Medical Education}}},
 comments = { The publication does not focus on explainability},
 doi = {10.1007/978-3-319-98213-7_18},
 editor = {El Miedany, Yasser},
 isbn = {978-3-319-98213-7},
 keywords = {Artificial intelligence,Big data,Medical education,Science of artificial intelligence,Virtual reality in education},
 language = {en},
 pages = {347-378},
 publisher = {{Springer International Publishing}},
 title = {Artificial {{Intelligence}}},
 year = {2019}
}

@inproceedings{Farsal:2018:DLO:3289402.3289538,
 acmid = {3289538},
 address = {New York, NY, USA},
 articleno = {38},
 author = {Farsal, Wissal and Anter, Samir and Ramdani, Mohammed},
 booktitle = {Proceedings of the 12th International Conference on Intelligent Systems: Theories and Applications},
 comments = { The publication does not focus on explainability},
 doi = {10.1145/3289402.3289538},
 isbn = {978-1-4503-6462-1},
 keywords = {Artificial Intelligence, Deep Learning, Neural Networks},
 location = {Rabat, Morocco},
 numpages = {6},
 pages = {38:1--38:6},
 publisher = {ACM},
 series = {SITA'18},
 title = {Deep Learning: An Overview},
 url = {http://doi.acm.org/10.1145/3289402.3289538},
 year = {2018}
}

@inproceedings{Feng:2018:IPE:3206025.3206048,
 acmid = {3206048},
 address = {New York, NY, USA},
 author = {Feng, Zunlei and Yu, Zhenyun and Yang, Yezhou and Jing, Yongcheng and Jiang, Junxiao and Song, Mingli},
 booktitle = {Proceedings of the 2018 ACM on International Conference on Multimedia Retrieval},
 comments = {Presents a specific method for enhancing explainability for models, The described method is neither general, nor focused on NLP},
 doi = {10.1145/3206025.3206048},
 isbn = {978-1-4503-5046-4},
 keywords = {adversarial, embedding, interpretable, outfit composition},
 location = {Yokohama, Japan},
 numpages = {9},
 pages = {143--151},
 publisher = {ACM},
 series = {ICMR '18},
 title = {Interpretable Partitioned Embedding for Customized Multi-item Fashion Outfit Composition},
 url = {http://doi.acm.org/10.1145/3206025.3206048},
 year = {2018}
}

@inproceedings{Gad-Elrab:2019:EFE:3289600.3290996,
 acmid = {3290996},
 address = {New York, NY, USA},
 author = {Gad-Elrab, Mohamed H. and Stepanova, Daria and Urbani, Jacopo and Weikum, Gerhard},
 booktitle = {Proceedings of the Twelfth ACM International Conference on Web Search and Data Mining},
 comments = {Presents a specific method for enhancing explainability for models, The described method is neither general, nor focused on NLP},
 doi = {10.1145/3289600.3290996},
 isbn = {978-1-4503-5940-5},
 keywords = {explainable evidence, fact-checking, knowledge graph, reasoning},
 location = {Melbourne VIC, Australia},
 numpages = {9},
 pages = {87--95},
 publisher = {ACM},
 series = {WSDM '19},
 title = {ExFaKT: A Framework for Explaining Facts over Knowledge Graphs and Text},
 url = {http://doi.acm.org/10.1145/3289600.3290996},
 year = {2019}
}

@incollection{galitskyDevelopingConversationalNatural2019,
 abstract = {In this Chapter we focus on a problem of a natural language access to a database, well-known and highly desired to be solved. We start with the modern approaches based on deep learning and analyze lessons learned from unusable database access systems. This chapter can serve as a brief introduction to neural networks for learning logic representations. Then a number of hybrid approaches are presented and their strong points are analyzed. Finally, we describe our approach that relies on parsing, thesaurus and disambiguation via chatbot communication mode. The conclusion is that a reliable and flexible database access via NL needs to employ a broad spectrum of linguistic, knowledge representation and learning techniques. We conclude this chapter by surveying the general technology trends related to NL2SQL, observing how AI and ML are seeping into virtually everything and represent a major battleground for technology providers.},
 address = {Cham},
 author = {Galitsky, Boris},
 booktitle = {Developing {{Enterprise Chatbots}}: {{Learning Linguistic Structures}}},
 comments = { The publication does not focus on explainability},
 doi = {10.1007/978-3-030-04299-8_4},
 editor = {Galitsky, Boris},
 isbn = {978-3-030-04299-8},
 language = {en},
 pages = {85-120},
 publisher = {{Springer International Publishing}},
 title = {Developing {{Conversational Natural Language Interface}} to a {{Database}}},
 year = {2019}
}

@inproceedings{Gaura:2003:UAT:944868.944890,
 acmid = {944890},
 address = {New York, NY, USA},
 author = {Gaura, Elena I. and Newman, Robert M.},
 booktitle = {Proceedings of the 21st Annual International Conference on Documentation},
 comments = { The publication does not focus on explainability},
 doi = {10.1145/944868.944890},
 isbn = {1-58113-696-X},
 keywords = {artificial intelligence, artificial neural networks, hypermedia},
 location = {San Francisco, CA, USA},
 numpages = {5},
 pages = {100--104},
 publisher = {ACM},
 series = {SIGDOC '03},
 title = {Using AI Techniques to Aid Hypermedia Design},
 url = {http://doi.acm.org/10.1145/944868.944890},
 year = {2003}
}

@inproceedings{Ghazimatin:2019:FFU:3289600.3290990,
 acmid = {3290990},
 address = {New York, NY, USA},
 author = {Ghazimatin, Azin and Saha Roy, Rishiraj and Weikum, Gerhard},
 booktitle = {Proceedings of the Twelfth ACM International Conference on Web Search and Data Mining},
 comments = {Presents a specific method for enhancing explainability for models, The described method is neither general, nor focused on NLP},
 doi = {10.1145/3289600.3290990},
 isbn = {978-1-4503-5940-5},
 keywords = {explanation paths, interpretability, social feeds, user actions},
 location = {Melbourne VIC, Australia},
 numpages = {9},
 pages = {240--248},
 publisher = {ACM},
 series = {WSDM '19},
 title = {FAIRY: A Framework for Understanding Relationships Between Users' Actions and Their Social Feeds},
 url = {http://doi.acm.org/10.1145/3289600.3290990},
 year = {2019}
}

@inproceedings{Gilpin:2018:RPC:3173386.3176994,
 acmid = {3176994},
 address = {New York, NY, USA},
 author = {Gilpin, Leilani H. and Zaman, Cagri and Olson, Danielle and Yuan, Ben Z.},
 booktitle = {Companion of the 2018 ACM/IEEE International Conference on Human-Robot Interaction},
 comments = {Presents a specific method for enhancing explainability for models, The described method is neither general, nor focused on NLP},
 doi = {10.1145/3173386.3176994},
 isbn = {978-1-4503-5615-2},
 keywords = {commonsense reasoning, explainable ai, explainable robotic systems, virtual reality},
 location = {Chicago, IL, USA},
 numpages = {2},
 pages = {115--116},
 publisher = {ACM},
 series = {HRI '18},
 title = {Reasonable Perception: Connecting Vision and Language Systems for Validating Scene Descriptions},
 url = {http://doi.acm.org/10.1145/3173386.3176994},
 year = {2018}
}

@article{grillHealthExploringComplexity2016,
 author = {Grill, Eva and M\"uller, Martin and Mansmann, Ulrich},
 comments = { The publication does not focus on explainability},
 doi = {10.1007/s10654-016-0183-1},
 file = {/home/tim/Zotero/storage/PB6D7S2L/Grill et al. - 2016 - Health—exploring complexity an interdisciplinary .pdf},
 issn = {1573-7284},
 journal = {European Journal of Epidemiology},
 language = {en},
 month = {August},
 number = {1},
 pages = {1-239},
 shorttitle = {Health\textemdash{}Exploring Complexity},
 title = {Health\textemdash{}Exploring Complexity: An Interdisciplinary Systems Approach {{HEC2016}}},
 volume = {31},
 year = {2016}
}

@article{guhaInterpretationInterpretabilityQuantitative2008,
 abstract = {The goal of a quantitative structure\textendash{}activity relationship (QSAR) model is to encode the relationship between molecular structure and biological activity or physical property. Based on this encoding, such models can be used for predictive purposes. Assuming the use of relevant and meaningful descriptors, and a statistically significant model, extraction of the encoded structure\textendash{}activity relationships (SARs) can provide insight into what makes a molecule active or inactive. Such analyses by QSAR models are useful in a number of scenarios, such as suggesting structural modifications to enhance activity, explanation of outliers and exploratory analysis of novel SARs. In this paper we discuss the need for interpretation and an overview of the factors that affect interpretability of QSAR models. We then describe interpretation protocols for different types of models, highlighting the different types of interpretations, ranging from very broad, global, trends to very specific, case-by-case, descriptions of the SAR, using examples from the training set. Finally, we discuss a number of case studies where workers have provide some form of interpretation of a QSAR model.},
 author = {Guha, Rajarshi},
 comments = {Presents a specific method for enhancing explainability for models, The described method is neither general, nor focused on NLP},
 doi = {10.1007/s10822-008-9240-5},
 issn = {1573-4951},
 journal = {Journal of Computer-Aided Molecular Design},
 keywords = {Interpretation,Linear regression,Neural network,Partial least squares (PLS),Quantitative structure–activity relationship (QSAR)},
 language = {en},
 month = {December},
 number = {12},
 pages = {857-871},
 title = {On the Interpretation and Interpretability of Quantitative Structure\textendash{}Activity Relationship Models},
 volume = {22},
 year = {2008}
}

@inproceedings{Guo:2018:LED:3243734.3243792,
 acmid = {3243792},
 address = {New York, NY, USA},
 author = {Guo, Wenbo and Mu, Dongliang and Xu, Jun and Su, Purui and Wang, Gang and Xing, Xinyu},
 booktitle = {Proceedings of the 2018 ACM SIGSAC Conference on Computer and Communications Security},
 comments = { The described method is neither general, nor focused on NLP},
 doi = {10.1145/3243734.3243792},
 isbn = {978-1-4503-5693-0},
 keywords = {binary analysis, deep recurrent neural networks, explainable AI},
 location = {Toronto, Canada},
 numpages = {16},
 pages = {364--379},
 publisher = {ACM},
 series = {CCS '18},
 title = {LEMNA: Explaining Deep Learning Based Security Applications},
 url = {http://doi.acm.org/10.1145/3243734.3243792},
 year = {2018}
}

@inproceedings{Hayes:2017:IRC:2909824.3020233,
 acmid = {3020233},
 address = {New York, NY, USA},
 author = {Hayes, Bradley and Shah, Julie A.},
 booktitle = {Proceedings of the 2017 ACM/IEEE International Conference on Human-Robot Interaction},
 comments = { The described method is neither general, nor focused on NLP},
 doi = {10.1145/2909824.3020233},
 isbn = {978-1-4503-4336-7},
 keywords = {human-robot collaboration, human-robot interaction, human-robot teaming, interpretable machine learning},
 location = {Vienna, Austria},
 numpages = {10},
 pages = {303--312},
 publisher = {ACM},
 series = {HRI '17},
 title = {Improving Robot Controller Transparency Through Autonomous Policy Explanation},
 url = {http://doi.acm.org/10.1145/2909824.3020233},
 year = {2017}
}

@inproceedings{Hicks:2018:CRA:3204949.3208113,
 acmid = {3208113},
 address = {New York, NY, USA},
 author = {Hicks, Steven Alexander and Pogorelov, Konstantin and de Lange, Thomas and Lux, Mathias and Jeppsson, Mattis and Randel, Kristin Ranheim and Eskeland, Sigrun and Halvorsen, P{\aa}l and Riegler, Michael},
 booktitle = {Proceedings of the 9th ACM Multimedia Systems Conference},
 comments = { The described method is neither general, nor focused on NLP},
 doi = {10.1145/3204949.3208113},
 isbn = {978-1-4503-5192-8},
 keywords = {automatic disease detection, deep learning, interpretable neural networks, medical documentation},
 location = {Amsterdam, Netherlands},
 numpages = {4},
 pages = {490--493},
 publisher = {ACM},
 series = {MMSys '18},
 title = {Comprehensible Reasoning and Automated Reporting of Medical Examinations Based on Deep Learning Analysis},
 url = {http://doi.acm.org/10.1145/3204949.3208113},
 year = {2018}
}

@inproceedings{Hicks:2018:MAR:3204949.3208129,
 acmid = {3208129},
 address = {New York, NY, USA},
 author = {Hicks, Steven Alexander and Eskeland, Sigrun and Lux, Mathias and de Lange, Thomas and Randel, Kristin Ranheim and Jeppsson, Mattis and Pogorelov, Konstantin and Halvorsen, P{\aa}l and Riegler, Michael},
 booktitle = {Proceedings of the 9th ACM Multimedia Systems Conference},
 comments = { The described method is neither general, nor focused on NLP},
 doi = {10.1145/3204949.3208129},
 isbn = {978-1-4503-5192-8},
 keywords = {automatic disease detection, deep learning, interpretable neural networks, medical documentation},
 location = {Amsterdam, Netherlands},
 numpages = {6},
 pages = {369--374},
 publisher = {ACM},
 series = {MMSys '18},
 title = {Mimir: An Automatic Reporting and Reasoning System for Deep Learning Based Analysis in the Medical Domain},
 url = {http://doi.acm.org/10.1145/3204949.3208129},
 year = {2018}
}

@inproceedings{Holcomb:2018:ODA:3206157.3206174,
 acmid = {3206174},
 address = {New York, NY, USA},
 author = {Holcomb, Sean D. and Porter, William K. and Ault, Shaun V. and Mao, Guifen and Wang, Jin},
 booktitle = {Proceedings of the 2018 International Conference on Big Data and Education},
 comments = { The publication does not focus on explainability},
 doi = {10.1145/3206157.3206174},
 isbn = {978-1-4503-6358-7},
 keywords = {AI, AlphaGo Zero, Deep Learning, Deep Mind, Neural Networks, Reinforcement Learning},
 location = {Honolulu, HI, USA},
 numpages = {5},
 pages = {67--71},
 publisher = {ACM},
 series = {ICBDE '18},
 title = {Overview on DeepMind and Its AlphaGo Zero AI},
 url = {http://doi.acm.org/10.1145/3206157.3206174},
 year = {2018}
}

@incollection{holzingerLectureMultimediaData2014,
 abstract = {At the end of this sixth lecture you:},
 address = {Cham},
 author = {Holzinger, Andreas},
 booktitle = {Biomedical {{Informatics}}: {{Discovering Knowledge}} in {{Big Data}}},
 comments = { Is not scientific literature},
 doi = {10.1007/978-3-319-04528-3_6},
 editor = {Holzinger, Andreas},
 isbn = {978-3-319-04528-3},
 language = {en},
 pages = {251-298},
 publisher = {{Springer International Publishing}},
 title = {Lecture 6 {{Multimedia Data Mining}} and {{Knowledge Discovery}}},
 year = {2014}
}

@inproceedings{holzingerMachineLearningKnowledge2017,
 abstract = {During the last decade pathology has benefited from the rapid progress of image digitizing technologies, which led to the development of scanners, capable to produce so-called Whole Slide images (WSI) which can be explored by a pathologist on a computer screen comparable to the conventional microscope and can be used for diagnostics, research, archiving and also education and training. Digital pathology is not just the transformation of the classical microscopic analysis of histological slides by pathologists to just a digital visualization. It is a disruptive innovation that will dramatically change medical work-flows in the coming years and help to foster personalized medicine. Really powerful gets a pathologist if she/he is augmented by machine learning, e.g. by support vector machines, random forests and deep learning. The ultimate benefit of digital pathology is to enable to learn, to extract knowledge and to make predictions from a combination of heterogenous data, i.e. the histological image, the patient history and the *omics data. These challenges call for integrated/integrative machine learning approach fostering transparency, trust, acceptance and the ability to explain step-by-step why a decision has been made.},
 author = {Holzinger, Andreas and Malle, Bernd and Kieseberg, Peter and Roth, Peter M. and M\"uller, Heimo and Reihs, Robert and Zatloukal, Kurt},
 booktitle = {Towards {{Integrative Machine Learning}} and {{Knowledge Extraction}}},
 comments = { Does not describe the used explainability method},
 editor = {Holzinger, Andreas and Goebel, Randy and Ferri, Massimo and Palade, Vasile},
 isbn = {978-3-319-69775-8},
 keywords = {Data integration,Deep learning,Digital pathology,Integrative machine learning,Transfer learning},
 language = {en},
 pages = {13-50},
 publisher = {{Springer International Publishing}},
 series = {Lecture {{Notes}} in {{Computer Science}}},
 title = {Machine {{Learning}} and {{Knowledge Extraction}} in {{Digital Pathology Needs}} an {{Integrative Approach}}},
 year = {2017}
}

@incollection{hoschkeSelforganizingSensingSystem2008,
 address = {London},
 author = {Hoschke, N. and Lewis, C. J. and Price, D. C. and Scott, D. A. and Gerasimov, V. and Wang, P.},
 booktitle = {Advances in {{Applied Self}}-Organizing {{Systems}}},
 comments = { The publication does not focus on explainability},
 doi = {10.1007/978-1-84628-982-8_4},
 editor = {Prokopenko, Mikhail},
 isbn = {978-1-84628-982-8},
 keywords = {Cellular Automaton,Genetic Programming,Mobile Agent,Multiagent System},
 language = {en},
 pages = {51-76},
 publisher = {{Springer London}},
 series = {Advanced {{Information}} and {{Knowledge Processing}}},
 title = {A {{Self}}-Organizing {{Sensing System}} for {{Structural Health Monitoring}} of {{Aerospace Vehicles}}},
 year = {2008}
}

@article{http://arxiv.org/abs/1401.5390v1,
 abstract = {Domain knowledge is crucial for effective performance in autonomous control
systems. Typically, human effort is required to encode this knowledge into a
control algorithm. In this paper, we present an approach to language grounding
which automatically interprets text in the context of a complex control
application, such as a game, and uses domain knowledge extracted from the text
to improve control performance. Both text analysis and control strategies are
learned jointly using only a feedback signal inherent to the application. To
effectively leverage textual information, our method automatically extracts the
text segment most relevant to the current game state, and labels it with a
task-centric predicate structure. This labeled text is then used to bias an
action selection policy for the game, guiding it towards promising regions of
the action space. We encode our model for text analysis and game playing in a
multi-layer neural network, representing linguistic decisions via latent
variables in the hidden layers, and game action quality via the output layer.
Operating within the Monte-Carlo Search framework, we estimate model parameters
using feedback from simulated games. We apply our approach to the complex
strategy game Civilization II using the official game manual as the text guide.
Our results show that a linguistically-informed game-playing agent
significantly outperforms its language-unaware counterpart, yielding a 34%
absolute improvement and winning over 65% of games when playing against the
built-in AI of Civilization.},
 author = {Branavan, S. R. K. and Silver, David and Barzilay, Regina},
 comments = { The publication does not focus on explainability},
 journal = {arxiv},
 month = {1},
 title = {Learning to Win by Reading Manuals in a Monte-Carlo Framework},
 url = {http://arxiv.org/pdf/1401.5390v1},
 year = {2014}
}

@article{http://arxiv.org/abs/1702.08635v1,
 abstract = {Machine learning is essentially the sciences of playing with data. An
adaptive data selection strategy, enabling to dynamically choose different data
at various training stages, can reach a more effective model in a more
efficient way. In this paper, we propose a deep reinforcement learning
framework, which we call \emph{\textbf{N}eural \textbf{D}ata \textbf{F}ilter}
(\textbf{NDF}), to explore automatic and adaptive data selection in the
training process. In particular, NDF takes advantage of a deep neural network
to adaptively select and filter important data instances from a sequential
stream of training data, such that the future accumulative reward (e.g., the
convergence speed) is maximized. In contrast to previous studies in data
selection that is mainly based on heuristic strategies, NDF is quite generic
and thus can be widely suitable for many machine learning tasks. Taking neural
network training with stochastic gradient descent (SGD) as an example,
comprehensive experiments with respect to various neural network modeling
(e.g., multi-layer perceptron networks, convolutional neural networks and
recurrent neural networks) and several applications (e.g., image classification
and text understanding) demonstrate that NDF powered SGD can achieve comparable
accuracy with standard SGD process by using less data and fewer iterations.},
 author = {Fan, Yang and Tian, Fei and Qin, Tao and Bian, Jiang and Liu, Tie-Yan},
 comments = { The publication does not focus on explainability},
 journal = {arxiv},
 month = {2},
 title = {Learning What Data to Learn},
 url = {http://arxiv.org/pdf/1702.08635v1},
 year = {2017}
}

@article{http://arxiv.org/abs/1703.06914v2,
 abstract = {In the modern era, each Internet user leaves enormous amounts of auxiliary
digital residuals (footprints) by using a variety of on-line services. All this
data is already collected and stored for many years. In recent works, it was
demonstrated that it's possible to apply simple machine learning methods to
analyze collected digital footprints and to create psycho-demographic profiles
of individuals. However, while these works clearly demonstrated the
applicability of machine learning methods for such an analysis, created simple
prediction models still lacks accuracy necessary to be successfully applied for
practical needs. We have assumed that using advanced deep machine learning
methods may considerably increase the accuracy of predictions. We started with
simple machine learning methods to estimate basic prediction performance and
moved further by applying advanced methods based on shallow and deep neural
networks. Then we compared prediction power of studied models and made
conclusions about its performance. Finally, we made hypotheses how prediction
accuracy can be further improved. As result of this work, we provide full
source code used in the experiments for all interested researchers and
practitioners in corresponding GitHub repository. We believe that applying deep
machine learning for psycho-demographic profiling may have an enormous impact
on the society (for good or worse) and provides means for Artificial
Intelligence (AI) systems to better understand humans by creating their
psychological profiles. Thus AI agents may achieve the human-like ability to
participate in conversation (communication) flow by anticipating human
opponents' reactions, expectations, and behavior.},
 author = {Omelianenko, Iaroslav},
 comments = { The described method is neither general, nor focused on NLP},
 journal = {arxiv},
 month = {3},
 title = {Applying Deep Machine Learning for psycho-demographic profiling of
Internet users using O.C.E.A.N. model of personality},
 url = {http://arxiv.org/pdf/1703.06914v2},
 year = {2017}
}

@article{http://arxiv.org/abs/1708.04988v1,
 abstract = {We show a proof of principle for warping, a method to interpret the inner
working of neural networks in the context of gene expression analysis. Warping
is an efficient way to gain insight to the inner workings of neural nets and
make them more interpretable. We demonstrate the ability of warping to recover
meaningful information for a given class on a samplespecific individual basis.
We found warping works well in both linearly and nonlinearly separable
datasets. These encouraging results show that warping has a potential to be the
answer to neural networks interpretability in computational biology.},
 author = {Assya, Trofimov and Sebastien, Lemieux and Claude, Perreault},
 comments = { The described method is neither general, nor focused on NLP},
 journal = {arxiv},
 month = {8},
 title = {Warp: a method for neural network interpretability applied to gene
expression profiles},
 url = {http://arxiv.org/pdf/1708.04988v1},
 year = {2017}
}

@article{http://arxiv.org/abs/1710.10967v3,
 abstract = {Artificial intelligence (AI) has achieved superhuman performance in a growing
number of tasks, but understanding and explaining AI remain challenging. This
paper clarifies the connections between machine-learning algorithms to develop
AIs and the econometrics of dynamic structural models through the case studies
of three famous game AIs. Chess-playing Deep Blue is a calibrated value
function, whereas shogi-playing Bonanza is an estimated value function via
Rust's (1987) nested fixed-point method. AlphaGo's "supervised-learning policy
network" is a deep neural network implementation of Hotz and Miller's (1993)
conditional choice probability estimation; its "reinforcement-learning value
network" is equivalent to Hotz, Miller, Sanders, and Smith's (1994) conditional
choice simulation method. Relaxing these AIs' implicit econometric assumptions
would improve their structural interpretability.},
 author = {Igami, Mitsuru},
 comments = { The publication does not focus on explainability},
 journal = {arxiv},
 month = {10},
 title = {Artificial Intelligence as Structural Estimation: Economic
Interpretations of Deep Blue, Bonanza, and AlphaGo},
 url = {http://arxiv.org/pdf/1710.10967v3},
 year = {2017}
}

@article{http://arxiv.org/abs/1711.00404v1,
 abstract = {As data-driven methods rise in popularity in materials science applications,
a key question is how these machine learning models can be used to understand
microstructure. Given the importance of process-structure-property relations
throughout materials science, it seems logical that models that can leverage
microstructural data would be more capable of predicting property information.
While there have been some recent attempts to use convolutional neural networks
to understand microstructural images, these early studies have focused only on
which featurizations yield the highest machine learning model accuracy for a
single data set. This paper explores the use of convolutional neural networks
for classifying microstructure with a more holistic set of objectives in mind:
generalization between data sets, number of features required, and
interpretability.},
 author = {Ling, Julia and Hutchinson, Maxwell and Antono, Erin and DeCost, Brian and Holm, Elizabeth A. and Meredig, Bryce},
 comments = {Presents a specific method for enhancing explainability for models, The described method is neither general, nor focused on NLP},
 journal = {arxiv},
 month = {11},
 title = {Building Data-driven Models with Microstructural Images: Generalization
and Interpretability},
 url = {http://arxiv.org/pdf/1711.00404v1},
 year = {2017}
}

@article{http://arxiv.org/abs/1711.06431v2,
 abstract = {We present a method for explaining the image classification predictions of
deep convolution neural networks, by highlighting the pixels in the image which
influence the final class prediction. Our method requires the identification of
a heuristic method to select parameters hypothesized to be most relevant in
this prediction, and here we use Kullback-Leibler divergence to provide this
focus. Overall, our approach helps in understanding and interpreting deep
network predictions and we hope contributes to a foundation for such
understanding of deep learning networks. In this brief paper, our experiments
evaluate the performance of two popular networks in this context of
interpretability.},
 author = {Babiker, Housam Khalifa Bashier and Goebel, Randy},
 comments = {Presents a specific method for enhancing explainability for models, The described method is neither general, nor focused on NLP},
 journal = {arxiv},
 month = {11},
 title = {Using KL-divergence to focus Deep Visual Explanation},
 url = {http://arxiv.org/pdf/1711.06431v2},
 year = {2017}
}

@article{http://arxiv.org/abs/1711.09482v2,
 abstract = {The practical impact of deep learning on complex supervised learning problems
has been significant, so much so that almost every Artificial Intelligence
problem, or at least a portion thereof, has been somehow recast as a deep
learning problem. The applications appeal is significant, but this appeal is
increasingly challenged by what some call the challenge of explainability, or
more generally the more traditional challenge of debuggability: if the outcomes
of a deep learning process produce unexpected results (e.g., less than expected
performance of a classifier), then there is little available in the way of
theories or tools to help investigate the potential causes of such unexpected
behavior, especially when this behavior could impact people's lives. We
describe a preliminary framework to help address this issue, which we call
"deep visual explanation" (DVE). "Deep," because it is the development and
performance of deep neural network models that we want to understand. "Visual,"
because we believe that the most rapid insight into a complex multi-dimensional
model is provided by appropriate visualization techniques, and "Explanation,"
because in the spectrum from instrumentation by inserting print statements to
the abductive inference of explanatory hypotheses, we believe that the key to
understanding deep learning relies on the identification and exposure of
hypotheses about the performance behavior of a learned deep model. In the
exposition of our preliminary framework, we use relatively straightforward
image classification examples and a variety of choices on initial configuration
of a deep model building scenario. By careful but not complicated
instrumentation, we expose classification outcomes of deep models using
visualization, and also show initial results for one potential application of
interpretability.},
 author = {Babiker, Housam Khalifa Bashier and Goebel, Randy},
 comments = {Presents a specific method for enhancing explainability for models, The described method is neither general, nor focused on NLP},
 journal = {arxiv},
 month = {11},
 title = {An Introduction to Deep Visual Explanation},
 url = {http://arxiv.org/pdf/1711.09482v2},
 year = {2017}
}

@article{http://arxiv.org/abs/1712.02034v2,
 abstract = {Chemical databases store information in text representations, and the SMILES
format is a universal standard used in many cheminformatics software. Encoded
in each SMILES string is structural information that can be used to predict
complex chemical properties. In this work, we develop SMILES2vec, a deep RNN
that automatically learns features from SMILES to predict chemical properties,
without the need for additional explicit feature engineering. Using Bayesian
optimization methods to tune the network architecture, we show that an
optimized SMILES2vec model can serve as a general-purpose neural network for
predicting distinct chemical properties including toxicity, activity,
solubility and solvation energy, while also outperforming contemporary MLP
neural networks that uses engineered features. Furthermore, we demonstrate
proof-of-concept of interpretability by developing an explanation mask that
localizes on the most important characters used in making a prediction. When
tested on the solubility dataset, it identified specific parts of a chemical
that is consistent with established first-principles knowledge with an accuracy
of 88%. Our work demonstrates that neural networks can learn technically
accurate chemical concept and provide state-of-the-art accuracy, making
interpretable deep neural networks a useful tool of relevance to the chemical
industry.},
 author = {Goh, Garrett B. and Hodas, Nathan O. and Siegel, Charles and Vishnu, Abhinav},
 comments = {Presents a specific method for enhancing explainability for models, The described method is neither general, nor focused on NLP},
 journal = {arxiv},
 month = {12},
 title = {SMILES2Vec: An Interpretable General-Purpose Deep Neural Network for
Predicting Chemical Properties},
 url = {http://arxiv.org/pdf/1712.02034v2},
 year = {2017}
}

@article{http://arxiv.org/abs/1712.08107v1,
 abstract = {Deep neural network models have been proven to be very successful in image
classification tasks, also for medical diagnosis, but their main concern is its
lack of interpretability. They use to work as intuition machines with high
statistical confidence but unable to give interpretable explanations about the
reported results. The vast amount of parameters of these models make difficult
to infer a rationale interpretation from them. In this paper we present a
diabetic retinopathy interpretable classifier able to classify retine images
into the different levels of disease severity and of explaining its results by
assigning a score for every point in the hidden and input space, evaluating its
contribution to the final classification in a linear way. The generated visual
maps can be interpreted by an expert in order to compare its own knowledge with
the interpretation given by the model.},
 author = {Torre, Jordi de la and Valls, Aida and Puig, Domenec},
 comments = {Presents a specific method for enhancing explainability for models, The described method is neither general, nor focused on NLP},
 journal = {arxiv},
 month = {12},
 title = {A Deep Learning Interpretable Classifier for Diabetic Retinopathy
Disease Grading},
 url = {http://arxiv.org/pdf/1712.08107v1},
 year = {2017}
}

@article{http://arxiv.org/abs/1802.00541v1,
 abstract = {Deep neural networks are complex and opaque. As they enter application in a
variety of important and safety critical domains, users seek methods to explain
their output predictions. We develop an approach to explaining deep neural
networks by constructing causal models on salient concepts contained in a CNN.
We develop methods to extract salient concepts throughout a target network by
using autoencoders trained to extract human-understandable representations of
network activations. We then build a bayesian causal model using these
extracted concepts as variables in order to explain image classification.
Finally, we use this causal model to identify and visualize features with
significant causal influence on final classification.},
 author = {Harradon, Michael and Druce, Jeff and Ruttenberg, Brian},
 comments = { The publication does not focus on explainability },
 journal = {arxiv},
 month = {2},
 title = {Causal Learning and Explanation of Deep Neural Networks via Autoencoded
Activations},
 url = {http://arxiv.org/pdf/1802.00541v1},
 year = {2018}
}

@article{http://arxiv.org/abs/1802.03043v1,
 abstract = {With the popularity of deep learning (DL), artificial intelligence (AI) has
been applied in many areas of human life. Neural network or artificial neural
network (NN), the main technique behind DL, has been extensively studied to
facilitate computer vision and natural language recognition. However, the more
we rely on information technology, the more vulnerable we are. That is,
malicious NNs could bring huge threat in the so-called coming AI era. In this
paper, for the first time in the literature, we propose a novel approach to
design and insert powerful neural-level trojans or PoTrojan in pre-trained NN
models. Most of the time, PoTrojans remain inactive, not affecting the normal
functions of their host NN models. PoTrojans could only be triggered in very
rare conditions. Once activated, however, the PoTrojans could cause the host NN
models to malfunction, either falsely predicting or classifying, which is a
significant threat to human society of the AI era. We would explain the
principles of PoTrojans and the easiness of designing and inserting them in
pre-trained deep learning models. PoTrojans doesn't modify the existing
architecture or parameters of the pre-trained models, without re-training.
Hence, the proposed method is very efficient.},
 author = {Zou, Minhui and Shi, Yang and Wang, Chengliang and Li, Fangyu and Song, WenZhan and Wang, Yu},
 comments = { The publication does not focus on explainability},
 journal = {arxiv},
 month = {2},
 title = {PoTrojan: powerful neural-level trojan designs in deep learning models},
 url = {http://arxiv.org/pdf/1802.03043v1},
 year = {2018}
}

@article{http://arxiv.org/abs/1807.03418v1,
 abstract = {Interpretability of deep neural networks is a recently emerging area of
machine learning research targeting a better understanding of how models
perform feature selection and derive their classification decisions. In this
paper, two neural network architectures are trained on spectrogram and raw
waveform data for audio classification tasks on a newly created audio dataset
and layer-wise relevance propagation (LRP), a previously proposed
interpretability method, is applied to investigate the models' feature
selection and decision making. It is demonstrated that the networks are highly
reliant on feature marked as relevant by LRP through systematic manipulation of
the input data. Our results show that by making deep audio classifiers
interpretable, one can analyze and compare the properties and strategies of
different models beyond classification accuracy, which potentially opens up new
ways for model improvements.},
 author = {Becker, Sören and Ackermann, Marcel and Lapuschkin, Sebastian and Müller, Klaus-Robert and Samek, Wojciech},
 comments = { The described method is neither general, nor focused on NLP},
 journal = {arxiv},
 month = {7},
 title = {Interpreting and Explaining Deep Neural Networks for Classification of
Audio Signals},
 url = {http://arxiv.org/pdf/1807.03418v1},
 year = {2018}
}

@article{http://arxiv.org/abs/1807.04178v1,
 abstract = {The Defense Advanced Research Projects Agency (DARPA) recently launched the
Explainable Artificial Intelligence (XAI) program that aims to create a suite
of new AI techniques that enable end users to understand, appropriately trust,
and effectively manage the emerging generation of AI systems.
In this paper, inspired by DARPA's XAI program, we propose a new paradigm in
security research: Explainable Security (XSec). We discuss the ``Six Ws'' of
XSec (Who? What? Where? When? Why? and How?) and argue that XSec has unique and
complex characteristics: XSec involves several different stakeholders (i.e.,
the system's developers, analysts, users and attackers) and is multi-faceted by
nature (as it requires reasoning about system model, threat model and
properties of security, privacy and trust as well as about concrete attacks,
vulnerabilities and countermeasures). We define a roadmap for XSec that
identifies several possible research directions.},
 author = {Viganò, Luca and Magazzeni, Daniele},
 comments = { The described method is neither general, nor focused on NLP},
 journal = {arxiv},
 month = {7},
 title = {Explainable Security},
 url = {http://arxiv.org/pdf/1807.04178v1},
 year = {2018}
}

@article{http://arxiv.org/abs/1807.06978v1,
 abstract = {An important task for a recommender system to provide interpretable
explanations for the user. This is important for the credibility of the system.
Current interpretable recommender systems tend to focus on certain features
known to be important to the user and offer their explanations in a structured
form. It is well known that user generated reviews and feedback from reviewers
have strong leverage over the users' decisions. On the other hand, recent text
generation works have been shown to generate text of similar quality to human
written text, and we aim to show that generated text can be successfully used
to explain recommendations.
In this paper, we propose a framework consisting of popular review-oriented
generation models aiming to create personalised explanations for
recommendations. The interpretations are generated at both character and word
levels. We build a dataset containing reviewers' feedback from the Amazon books
review dataset. Our cross-domain experiments are designed to bridge from
natural language processing to the recommender system domain. Besides language
model evaluation methods, we employ DeepCoNN, a novel review-oriented
recommender system using a deep neural network, to evaluate the recommendation
performance of generated reviews by root mean square error (RMSE). We
demonstrate that the synthetic personalised reviews have better recommendation
performance than human written reviews. To our knowledge, this presents the
first machine-generated natural language explanations for rating prediction.},
 author = {Ouyang, Sixun and Lawlor, Aonghus and Costa, Felipe and Dolog, Peter},
 comments = { The described method is neither general, nor focused on NLP},
 journal = {arxiv},
 month = {7},
 title = {Improving Explainable Recommendations with Synthetic Reviews},
 url = {http://arxiv.org/pdf/1807.06978v1},
 year = {2018}
}

@article{http://arxiv.org/abs/1807.07404v1,
 abstract = {Predictive geometric models deliver excellent results for many Machine
Learning use cases. Despite their undoubted performance, neural predictive
algorithms can show unexpected degrees of instability and variance,
particularly when applied to large datasets. We present an approach to measure
changes in geometric models with respect to both output consistency and
topological stability. Considering the example of a recommender system using
word2vec, we analyze the influence of single data points, approximation methods
and parameter settings. Our findings can help to stabilize models where needed
and to detect differences in informational value of data points on a large
scale.},
 author = {Regneri, Michaela and Hoffmann, Malte and Kost, Jurij and Pietsch, Niklas and Schulz, Timo and Stamm, Sabine},
 comments = { The publication does not focus on explainability},
 journal = {arxiv},
 month = {7},
 title = {Analyzing Hypersensitive AI: Instability in Corporate-Scale Machine
Learning},
 url = {http://arxiv.org/pdf/1807.07404v1},
 year = {2018}
}

@article{http://arxiv.org/abs/1809.02479v1,
 abstract = {Recently machine learning is being applied to almost every data domain one of
which is Question Answering Systems (QAS). A typical Question Answering System
is fairly an information retrieval system, which matches documents or text and
retrieve the most accurate one. The idea of open domain question answering
system put forth, involves convolutional neural network text classifiers. The
Classification model presented in this paper is multi-class text classifier.
The neural network classifier can be trained on large dataset. We report series
of experiments conducted on Convolution Neural Network (CNN) by training it on
two different datasets. Neural network model is trained on top of word
embedding. Softmax layer is applied to calculate loss and mapping of
semantically related words. Gathered results can help justify the fact that
proposed hypothetical QAS is feasible. We further propose a method to integrate
Convolutional Neural Network Classifier to an open domain question answering
system. The idea of Open domain will be further explained, but the generality
of it indicates to the system of domain specific trainable models, thus making
it an open domain.},
 author = {Amin, Muhammad Zain and Nadeem, Noman},
 comments = { The publication does not focus on explainability},
 journal = {arxiv},
 month = {9},
 title = {Convolutional Neural Network: Text Classification Model for Open Domain
Question Answering System},
 url = {http://arxiv.org/pdf/1809.02479v1},
 year = {2018}
}

@article{http://arxiv.org/abs/1809.08037v1,
 abstract = {We present an analysis into the inner workings of Convolutional Neural
Networks (CNNs) for processing text. CNNs used for computer vision can be
interpreted by projecting filters into image space, but for discrete sequence
inputs CNNs remain a mystery. We aim to understand the method by which the
networks process and classify text. We examine common hypotheses to this
problem: that filters, accompanied by global max-pooling, serve as ngram
detectors. We show that filters may capture several different semantic classes
of ngrams by using different activation patterns, and that global max-pooling
induces behavior which separates important ngrams from the rest. Finally, we
show practical use cases derived from our findings in the form of model
interpretability (explaining a trained model by deriving a concrete identity
for each filter, bridging the gap between visualization tools in vision tasks
and NLP) and prediction interpretability (explaining predictions).},
 author = {Jacovi, Alon and Shalom, Oren Sar and Goldberg, Yoav},
 comments = { The publication does not focus on explainability},
 journal = {arxiv},
 month = {9},
 title = {Understanding Convolutional Neural Networks for Text Classification},
 url = {http://arxiv.org/pdf/1809.08037v1},
 year = {2018}
}

@article{http://arxiv.org/abs/1810.00024v1,
 abstract = {Establishing unique identities for both humans and end systems has been an
active research problem in the security community, giving rise to innovative
machine learning-based authentication techniques. Although such techniques
offer an automated method to establish identity, they have not been vetted
against sophisticated attacks that target their core machine learning
technique. This paper demonstrates that mimicking the unique signatures
generated by host fingerprinting and biometric authentication systems is
possible. We expose the ineffectiveness of underlying machine learning
classification models by constructing a blind attack based around the query
synthesis framework and utilizing Explainable-AI (XAI) techniques. We launch an
attack in under 130 queries on a state-of-the-art face authentication system,
and under 100 queries on a host authentication system. We examine how these
attacks can be defended against and explore their limitations. XAI provides an
effective means for adversaries to infer decision boundaries and provides a new
way forward in constructing attacks against systems using machine learning
models for authentication.},
 author = {Garcia, Washington and Choi, Joseph I. and Adari, Suman K. and Jha, Somesh and Butler, Kevin R. B.},
 comments = { The publication does not focus on explainability, The described method is neither general, nor focused on NLP},
 journal = {arxiv},
 month = {9},
 title = {Explainable Black-Box Attacks Against Model-based Authentication},
 url = {http://arxiv.org/pdf/1810.00024v1},
 year = {2018}
}

@article{http://arxiv.org/abs/1810.13192v4,
 abstract = {The developments of deep neural networks (DNN) in recent years have ushered a
brand new era of artificial intelligence. DNNs are proved to be excellent in
solving very complex problems, e.g., visual recognition and text understanding,
to the extent of competing with or even surpassing people. Despite inspiring
and encouraging success of DNNs, thorough theoretical analyses still lack to
unravel the mystery of their magics. The design of DNN structure is dominated
by empirical results in terms of network depth, number of neurons and
activations. A few of remarkable works published recently in an attempt to
interpret DNNs have established the first glimpses of their internal
mechanisms. Nevertheless, research on exploring how DNNs operate is still at
the initial stage with plenty of room for refinement. In this paper, we extend
precedent research on neural networks with piecewise linear activations (PLNN)
concerning linear regions bounds. We present (i) the exact maximal number of
linear regions for single layer PLNNs; (ii) a upper bound for multi-layer
PLNNs; and (iii) a tighter upper bound for the maximal number of liner regions
on rectifier networks. The derived bounds also indirectly explain why deep
models are more powerful than shallow counterparts, and how non-linearity of
activation functions impacts on expressiveness of networks.},
 author = {Hu, Qiang and Zhang, Hao},
 comments = { The described method is neither general, nor focused on NLP},
 journal = {arxiv},
 month = {10},
 title = {Nearly-tight bounds on linear regions of piecewise linear neural
networks},
 url = {http://arxiv.org/pdf/1810.13192v4},
 year = {2018}
}

@article{http://arxiv.org/abs/1810.13373v1,
 abstract = {Deep neural networks (DNNs) transform stimuli across multiple processing
stages to produce representations that can be used to solve complex tasks, such
as object recognition in images. However, a full understanding of how they
achieve this remains elusive. The complexity of biological neural networks
substantially exceeds the complexity of DNNs, making it even more challenging
to understand the representations that they learn. Thus, both machine learning
and computational neuroscience are faced with a shared challenge: how can we
analyze their representations in order to understand how they solve complex
tasks?
We review how data-analysis concepts and techniques developed by
computational neuroscientists can be useful for analyzing representations in
DNNs, and in turn, how recently developed techniques for analysis of DNNs can
be useful for understanding representations in biological neural networks. We
explore opportunities for synergy between the two fields, such as the use of
DNNs as in-silico model systems for neuroscience, and how this synergy can lead
to new hypotheses about the operating principles of biological neural networks.},
 author = {Barrett, David G. T. and Morcos, Ari S. and Macke, Jakob H.},
 comments = { The publication does not focus on explainability},
 journal = {arxiv},
 month = {10},
 title = {Analyzing biological and artificial neural networks: challenges with
opportunities for synergy?},
 url = {http://arxiv.org/pdf/1810.13373v1},
 year = {2018}
}

@article{http://arxiv.org/abs/1810.13425v2,
 abstract = {Techniques for understanding the functioning of complex machine learning
models are becoming increasingly popular, not only to improve the validation
process, but also to extract new insights about the data via exploratory
analysis. Though a large class of such tools currently exists, most assume that
predictions are point estimates and use a sensitivity analysis of these
estimates to interpret the model. Using lightweight probabilistic networks we
show how including prediction uncertainties in the sensitivity analysis leads
to: (i) more robust and generalizable models; and (ii) a new approach for model
interpretation through uncertainty decomposition. In particular, we introduce a
new regularization that takes both the mean and variance of a prediction into
account and demonstrate that the resulting networks provide improved
generalization to unseen data. Furthermore, we propose a new technique to
explain prediction uncertainties through uncertainties in the input domain,
thus providing new ways to validate and interpret deep learning models.},
 author = {Thiagarajan, Jayaraman J. and Kim, Irene and Anirudh, Rushil and Bremer, Peer-Timo},
 comments = { The described method is neither general, nor focused on NLP},
 journal = {arxiv},
 month = {10},
 title = {Understanding Deep Neural Networks through Input Uncertainties},
 url = {http://arxiv.org/pdf/1810.13425v2},
 year = {2018}
}

@article{http://arxiv.org/abs/1811.00196v1,
 abstract = {Building explainable systems is a critical problem in the field of Natural
Language Processing (NLP), since most machine learning models provide no
explanations for the predictions. Existing approaches for explainable machine
learning systems tend to focus on interpreting the outputs or the connections
between inputs and outputs. However, the fine-grained information is often
ignored, and the systems do not explicitly generate the human-readable
explanations. To better alleviate this problem, we propose a novel generative
explanation framework that learns to make classification decisions and generate
fine-grained explanations at the same time. More specifically, we introduce the
explainable factor and the minimum risk training approach that learn to
generate more reasonable explanations. We construct two new datasets that
contain summaries, rating scores, and fine-grained reasons. We conduct
experiments on both datasets, comparing with several strong neural network
baseline systems. Experimental results show that our method surpasses all
baselines on both datasets, and is able to generate concise explanations at the
same time.},
 author = {Liu, Hui and Yin, Qingyu and Wang, William Yang},
 comments = { The publication does not focus on explainability },
 journal = {arxiv},
 month = {11},
 title = {Towards Explainable NLP: A Generative Explanation Framework for Text
Classification},
 url = {http://arxiv.org/pdf/1811.00196v1},
 year = {2018}
}

@article{http://arxiv.org/abs/1811.06471v2,
 abstract = {Deep learning adoption in the financial services industry has been limited
due to a lack of model interpretability. However, several techniques have been
proposed to explain predictions made by a neural network. We provide an initial
investigation into these techniques for the assessment of credit risk with
neural networks.},
 author = {Modarres, Ceena and Ibrahim, Mark and Louie, Melissa and Paisley, John},
 comments = { The described method is neither general, nor focused on NLP},
 journal = {arxiv},
 month = {11},
 title = {Towards Explainable Deep Learning for Credit Lending: A Case Study},
 url = {http://arxiv.org/pdf/1811.06471v2},
 year = {2018}
}

@article{http://arxiv.org/abs/1811.07253v1,
 abstract = {Reliable uncertainty quantification is a first step towards building
explainable, transparent, and accountable artificial intelligent systems.
Recent progress in Bayesian deep learning has made such quantification
realizable. In this paper, we propose novel methods to study the benefits of
characterizing model and data uncertainties for natural language processing
(NLP) tasks. With empirical experiments on sentiment analysis, named entity
recognition, and language modeling using convolutional and recurrent neural
network models, we show that explicitly modeling uncertainties is not only
necessary to measure output confidence levels, but also useful at enhancing
model performances in various NLP tasks.},
 author = {Xiao, Yijun and Wang, William Yang},
 comments = { The publication does not focus on explainability},
 journal = {arxiv},
 month = {11},
 title = {Quantifying Uncertainties in Natural Language Processing Tasks},
 url = {http://arxiv.org/pdf/1811.07253v1},
 year = {2018}
}

@article{http://arxiv.org/abs/1811.08120v1,
 abstract = {Latent factor models (LFMs) such as matrix factorization achieve the
state-of-the-art performance among various Collaborative Filtering (CF)
approaches for recommendation. Despite the high recommendation accuracy of
LFMs, a critical issue to be resolved is the lack of explainability. Extensive
efforts have been made in the literature to incorporate explainability into
LFMs. However, they either rely on auxiliary information which may not be
available in practice, or fail to provide easy-to-understand explanations. In
this paper, we propose a fast influence analysis method named FIA, which
successfully enforces explicit neighbor-style explanations to LFMs with the
technique of influence functions stemmed from robust statistics. We first
describe how to employ influence functions to LFMs to deliver neighbor-style
explanations. Then we develop a novel influence computation algorithm for
matrix factorization with high efficiency. We further extend it to the more
general neural collaborative filtering and introduce an approximation algorithm
to accelerate influence analysis over neural network models. Experimental
results on real datasets demonstrate the correctness, efficiency and usefulness
of our proposed method.},
 author = {Cheng, Weiyu and Shen, Yanyan and Zhu, Yanmin and Huang, Linpeng},
 comments = { The described method is neither general, nor focused on NLP},
 journal = {arxiv},
 month = {11},
 title = {Explaining Latent Factor Models for Recommendation with Influence
Functions},
 url = {http://arxiv.org/pdf/1811.08120v1},
 year = {2018}
}

@article{http://arxiv.org/abs/1811.09725v1,
 abstract = {Deep learning is currently playing a crucial role toward higher levels of
artificial intelligence. This paradigm allows neural networks to learn complex
and abstract representations, that are progressively obtained by combining
simpler ones. Nevertheless, the internal "black-box" representations
automatically discovered by current neural architectures often suffer from a
lack of interpretability, making of primary interest the study of explainable
machine learning techniques. This paper summarizes our recent efforts to
develop a more interpretable neural model for directly processing speech from
the raw waveform. In particular, we propose SincNet, a novel Convolutional
Neural Network (CNN) that encourages the first layer to discover more
meaningful filters by exploiting parametrized sinc functions. In contrast to
standard CNNs, which learn all the elements of each filter, only low and high
cutoff frequencies of band-pass filters are directly learned from data. This
inductive bias offers a very compact way to derive a customized filter-bank
front-end, that only depends on some parameters with a clear physical meaning.
Our experiments, conducted on both speaker and speech recognition, show that
the proposed architecture converges faster, performs better, and is more
interpretable than standard CNNs.},
 author = {Ravanelli, Mirco and Bengio, Yoshua},
 comments = { The described method is neither general, nor focused on NLP},
 journal = {arxiv},
 month = {11},
 title = {Interpretable Convolutional Filters with SincNet},
 url = {http://arxiv.org/pdf/1811.09725v1},
 year = {2018}
}

@article{http://arxiv.org/abs/1811.12615v1,
 abstract = {We propose a possible solution to a public challenge posed by the Fair Isaac
Corporation (FICO), which is to provide an explainable model for credit risk
assessment. Rather than present a black box model and explain it afterwards, we
provide a globally interpretable model that is as accurate as other neural
networks. Our "two-layer additive risk model" is decomposable into subscales,
where each node in the second layer represents a meaningful subscale, and all
of the nonlinearities are transparent. We provide three types of explanations
that are simpler than, but consistent with, the global model. One of these
explanation methods involves solving a minimum set cover problem to find
high-support globally-consistent explanations. We present a new online
visualization tool to allow users to explore the global model and its
explanations.},
 author = {Chen, Chaofan and Lin, Kangcheng and Rudin, Cynthia and Shaposhnik, Yaron and Wang, Sijia and Wang, Tong},
 comments = { The described method is neither general, nor focused on NLP},
 journal = {arxiv},
 month = {11},
 title = {An Interpretable Model with Globally Consistent Explanations for Credit
Risk},
 url = {http://arxiv.org/pdf/1811.12615v1},
 year = {2018}
}

@article{http://arxiv.org/abs/1812.10537v2,
 abstract = {In the present paper, a method of defining the industrial process parameters
for a new product using machine learning algorithms will be presented. The
study will describe how to go from the product characteristics till the
prediction of the suitable machine parameters to produce a good quality of this
product, and this is based on an historical training dataset of similar
products with their respective process parameters. In the first part of our
study, we will focus on the ultrasonic welding process definition, welding
parameters and on how it operate. While in second part, we present the design
and implementation of the prediction models such multiple linear regression,
support vector regression, and we compare them to an artificial neural networks
algorithm. In the following part, we present a new application of Convolutional
Neural Networks (CNN) to the industrial process parameters prediction. In
addition, we will propose the generalization approach of our CNN to any
prediction problem of industrial process parameters. Finally the results of the
four methods will be interpreted and discussed.},
 author = {Khdoudi, Abdelmoula and Masrour, Tawfik},
 comments = { The publication does not focus on explainability},
 journal = {arxiv},
 month = {12},
 title = {Prediction of Industrial Process Parameters using Artificial
Intelligence Algorithms},
 url = {http://arxiv.org/pdf/1812.10537v2},
 year = {2018}
}

@article{http://arxiv.org/abs/1902.03380v2,
 abstract = {Discovering and exploiting the causality in deep neural networks (DNNs) are
crucial challenges for understanding and reasoning causal effects (CE) on an
explainable visual model. "Intervention" has been widely used for recognizing a
causal relation ontologically. In this paper, we propose a causal inference
framework for visual reasoning via do-calculus. To study the intervention
effects on pixel-level feature(s) for causal reasoning, we introduce pixel-wise
masking and adversarial perturbation. In our framework, CE is calculated using
features in a latent space and perturbed prediction from a DNN-based model. We
further provide a first look into the characteristics of discovered CE of
adversarially perturbed images generated by gradient-based methods.
Experimental results show that CE is a competitive and robust index for
understanding DNNs when compared with conventional methods such as
class-activation mappings (CAMs) on the ChestX-ray 14 dataset for
human-interpretable feature(s) (e.g., symptom) reasoning. Moreover, CE holds
promises for detecting adversarial examples as it possesses distinct
characteristics in the presence of adversarial perturbations.},
 author = {Yang, Chao-Han Huck and Liu, Yi-Chieh and Chen, Pin-Yu and Ma, Xiaoli and Tsai, Yi-Chang James},
 comments = {Presents a specific method for enhancing explainability for models, The described method is neither general, nor focused on NLP},
 journal = {arxiv},
 month = {2},
 title = {When Causal Intervention Meets Image Masking and Adversarial
Perturbation for Deep Neural Networks},
 url = {http://arxiv.org/pdf/1902.03380v2},
 year = {2019}
}

@article{http://arxiv.org/abs/1903.10246v1,
 abstract = {We review computational and robotics models of early language learning and
development. We first explain why and how these models are used to understand
better how children learn language. We argue that they provide concrete
theories of language learning as a complex dynamic system, complementing
traditional methods in psychology and linguistics. We review different modeling
formalisms, grounded in techniques from machine learning and artificial
intelligence such as Bayesian and neural network approaches. We then discuss
their role in understanding several key mechanisms of language development:
cross-situational statistical learning, embodiment, situated social
interaction, intrinsically motivated learning, and cultural evolution. We
conclude by discussing future challenges for research, including modeling of
large-scale empirical data about language acquisition in real-world
environments.
Keywords: Early language learning, Computational and robotic models, machine
learning, development, embodiment, social interaction, intrinsic motivation,
self-organization, dynamical systems, complexity.},
 author = {Oudeyer, Pierre-Yves and Kachergis, George and Schueller, William},
 comments = { The publication does not focus on explainability},
 journal = {arxiv},
 month = {3},
 title = {Computational and Robotic Models of Early Language Development: A Review},
 url = {http://arxiv.org/pdf/1903.10246v1},
 year = {2019}
}

@article{http://arxiv.org/abs/1905.00122v1,
 abstract = {Converting malware into images followed by vision-based deep learning
algorithms has shown superior threat detection efficacy compared with classical
machine learning algorithms. When malware are visualized as images,
visual-based interpretation schemes can also be applied to extract insights of
why individual samples are classified as malicious. In this work, via two case
studies of dynamic malware classification, we extend the local interpretable
model-agnostic explanation algorithm to explain image-based dynamic malware
classification and examine its interpretation fidelity. For both case studies,
we first train deep learning models via transfer learning on malware images,
demonstrate high classification effectiveness, apply an explanation method on
the images, and correlate the results back to the samples to validate whether
the algorithmic insights are consistent with security domain expertise. In our
first case study, the interpretation framework identifies indirect calls that
uniquely characterize the underlying exploit behavior of a malware family. In
our second case study, the interpretation framework extracts insightful
information such as cryptography-related APIs when applied on images created
from API existence, but generate ambiguous interpretation on images created
from API sequences and frequencies. Our findings indicate that current
image-based interpretation techniques are promising for explaining vision-based
malware classification. We continue to develop image-based interpretation
schemes specifically for security applications.},
 author = {Chen, Li and Yagemann, Carter and Downing, Evan},
 comments = {Presents a specific method for enhancing explainability for models, The described method is neither general, nor focused on NLP},
 journal = {arxiv},
 month = {4},
 title = {To believe or not to believe: Validating explanation fidelity for
dynamic malware analysis},
 url = {http://arxiv.org/pdf/1905.00122v1},
 year = {2019}
}

@inproceedings{Hu:2017:IWI:3132847.3133198,
 acmid = {3133198},
 address = {New York, NY, USA},
 author = {Hu, Xia and Ji, Shuiwang},
 booktitle = {Proceedings of the 2017 ACM on Conference on Information and Knowledge Management},
 comments = { Does not describe the used explainability method},
 doi = {10.1145/3132847.3133198},
 isbn = {978-1-4503-4918-5},
 keywords = {data mining, deep models, interpretability, machine learning, shallow models},
 location = {Singapore, Singapore},
 numpages = {2},
 pages = {2565--2566},
 publisher = {ACM},
 series = {CIKM '17},
 title = {IDM 2017: Workshop on Interpretable Data Mining -- Bridging the Gap Between Shallow and Deep Models},
 url = {http://doi.acm.org/10.1145/3132847.3133198},
 year = {2017}
}

@incollection{ivancevicIntroductionHumanComputational2007,
 address = {Berlin, Heidelberg},
 booktitle = {Computational {{Mind}}: {{A Complex Dynamics Perspective}}},
 comments = { The publication does not focus on explainability},
 doi = {10.1007/978-3-540-71561-0_1},
 editor = {Ivancevic, Vladimir G. and Ivancevic, Tijana T.},
 isbn = {978-3-540-71561-0},
 keywords = {Adaptive Resonance Theory,Cellular Automaton,Horn Clause,Human Mind},
 language = {en},
 pages = {1-269},
 publisher = {{Springer Berlin Heidelberg}},
 series = {Studies in {{Computational Intelligence}}},
 shorttitle = {Introduction},
 title = {Introduction: {{Human}} and {{Computational Mind}}},
 year = {2007}
}

@inproceedings{Iyer:2018:TED:3278721.3278776,
 acmid = {3278776},
 address = {New York, NY, USA},
 author = {Iyer, Rahul and Li, Yuezhang and Li, Huao and Lewis, Michael and Sundar, Ramitha and Sycara, Katia},
 booktitle = {Proceedings of the 2018 AAAI/ACM Conference on AI, Ethics, and Society},
 comments = {Presents a specific method for enhancing explainability for models, The described method is neither general, nor focused on NLP},
 doi = {10.1145/3278721.3278776},
 isbn = {978-1-4503-6012-8},
 keywords = {deep reinforcement learning, explainable ai, human factors, human-ai interaction, system transparency},
 location = {New Orleans, LA, USA},
 numpages = {7},
 pages = {144--150},
 publisher = {ACM},
 series = {AIES '18},
 title = {Transparency and Explanation in Deep Reinforcement Learning Neural Networks},
 url = {http://doi.acm.org/10.1145/3278721.3278776},
 year = {2018}
}

@inproceedings{Jacobson:2018:VNN:3243250.3243266,
 acmid = {3243266},
 address = {New York, NY, USA},
 author = {Jacobson, Victor and Li, J. Jenny and Tapia, Kevin and Morreale, Patricia},
 booktitle = {Proceedings of the International Conference on Pattern Recognition and Artificial Intelligence},
 comments = {Presents a specific method for enhancing explainability for models, The described method is neither general, nor focused on NLP},
 doi = {10.1145/3243250.3243266},
 isbn = {978-1-4503-6482-9},
 keywords = {CNN, Neural networks, RNN, pattern recognition},
 location = {Union, NJ, USA},
 numpages = {5},
 pages = {18--22},
 publisher = {ACM},
 series = {PRAI 2018},
 title = {Visualizing Neural Networks for Pattern Recognition},
 url = {http://doi.acm.org/10.1145/3243250.3243266},
 year = {2018}
}

@incollection{kashyapPracticalConceptsMachine2017,
 abstract = {This is an important chapter because it discusses the basic and practical concepts of machine learning (ML). I did not take the academic book style to explain these concepts. I have directed my thoughts and energy to provide you with the concepts that are useful during practical decision making. Hence, while explaining the concepts, terminologies, and technical details, I use examples and case studies that are be helpful in extracting relevant insight from the chapter.},
 address = {Berkeley, CA},
 author = {Kashyap, Patanjali},
 booktitle = {Machine {{Learning}} for {{Decision Makers}}: {{Cognitive Computing Fundamentals}} for {{Better Decision Making}}},
 comments = { The publication does not focus on explainability},
 doi = {10.1007/978-1-4842-2988-0_2},
 editor = {Kashyap, Patanjali},
 isbn = {978-1-4842-2988-0},
 language = {en},
 pages = {35-90},
 publisher = {{Apress}},
 title = {The {{Practical Concepts}} of {{Machine Learning}}},
 year = {2017}
}

@incollection{kayaMultimodalPersonalityTrait2018,
 abstract = {Automatic analysis of job interview screening decisions is useful for establishing the nature of biases that may play a role in such decisions. In particular, assessment of apparent personality gives insights into the first impressions evoked by a candidate. Such analysis tools can be used for training purposes, if they can be configured to provide appropriate and clear feedback. In this chapter, we describe a multimodal system that analyzes a short video of a job candidate, producing apparent personality scores and a prediction about whether the candidate will be invited for a further job interview or not. This system provides a visual and textual explanation about its decision, and was ranked first in the ChaLearn 2017 Job Candidate Screening Competition. We discuss the application scenario and the considerations from a broad perspective.},
 address = {Cham},
 author = {Kaya, Heysem and Salah, Albert Ali},
 booktitle = {Explainable and {{Interpretable Models}} in {{Computer Vision}} and {{Machine Learning}}},
 comments = { The publication does not focus on explainability},
 doi = {10.1007/978-3-319-98131-4_10},
 editor = {Escalante, Hugo Jair and Escalera, Sergio and Guyon, Isabelle and Bar\'o, Xavier and G\"u{\c c}l\"ut\"urk, Ya{\u g}mur and G\"u{\c c}l\"u, Umut and {van Gerven}, Marcel},
 isbn = {978-3-319-98131-4},
 keywords = {Explainable machine learning,Job candidate screening,Multimodal affective computing,Personality trait analysis},
 language = {en},
 pages = {255-275},
 publisher = {{Springer International Publishing}},
 series = {The {{Springer Series}} on {{Challenges}} in {{Machine Learning}}},
 title = {Multimodal {{Personality Trait Analysis}} for {{Explainable Modeling}} of {{Job Interview Decisions}}},
 year = {2018}
}

@incollection{kimExplainableDeepDriving2018,
 abstract = {Deep neural perception and control networks are likely to be a key component of self-driving vehicles. These models need to be explainable\textemdash{}they should provide easy-to-interpret rationales for their behavior\textemdash{}so that passengers, insurance companies, law enforcement, developers etc., can understand what triggered a particular behavior. Here, we explore the use of visual explanations. These explanations take the form of real-time highlighted regions of an image that causally influence the network's output (steering control). Our approach is two-stage. In the first stage, we use a visual attention model to train a convolutional network end-to-end from images to steering angle. The attention model highlights image regions that potentially influence the network's output. Some of these are true influences, but some are spurious. We then apply a causal filtering step to determine which input regions actually influence the output. This produces more succinct visual explanations and more accurately exposes the network's behavior. We demonstrate the effectiveness of our model on three datasets totaling 16 h of driving. We first show that training with attention does not degrade the performance of the end-to-end network. Then we show that the network highlights interpretable features that are used by humans while driving, and causal filtering achieves a useful reduction in explanation complexity by removing features which do not significantly affect the output.},
 address = {Cham},
 author = {Kim, Jinkyu and Canny, John},
 booktitle = {Explainable and {{Interpretable Models}} in {{Computer Vision}} and {{Machine Learning}}},
 comments = {Presents a specific method for enhancing explainability for models, The described method is neither general, nor focused on NLP},
 doi = {10.1007/978-3-319-98131-4_8},
 editor = {Escalante, Hugo Jair and Escalera, Sergio and Guyon, Isabelle and Bar\'o, Xavier and G\"u{\c c}l\"ut\"urk, Ya{\u g}mur and G\"u{\c c}l\"u, Umut and {van Gerven}, Marcel},
 isbn = {978-3-319-98131-4},
 keywords = {Explainable AI,Self-driving vehicles,Visual attention},
 language = {en},
 pages = {173-193},
 publisher = {{Springer International Publishing}},
 series = {The {{Springer Series}} on {{Challenges}} in {{Machine Learning}}},
 title = {Explainable {{Deep Driving}} by {{Visualizing Causal Attention}}},
 year = {2018}
}

@article{kotsiantisMachineLearningReview2006,
 abstract = {Supervised classification is one of the tasks most frequently carried out by so-called Intelligent Systems. Thus, a large number of techniques have been developed based on Artificial Intelligence (Logic-based techniques, Perceptron-based techniques) and Statistics (Bayesian Networks, Instance-based techniques). The goal of supervised learning is to build a concise model of the distribution of class labels in terms of predictor features. The resulting classifier is then used to assign class labels to the testing instances where the values of the predictor features are known, but the value of the class label is unknown. This paper describes various classification algorithms and the recent attempt for improving classification accuracy\textemdash{}ensembles of classifiers.},
 author = {Kotsiantis, S. B. and Zaharakis, I. D. and Pintelas, P. E.},
 comments = { The publication does not focus on explainability},
 doi = {10.1007/s10462-007-9052-3},
 issn = {1573-7462},
 journal = {Artificial Intelligence Review},
 keywords = {Classifiers,Data mining techniques,Intelligent data analysis,Learning algorithms},
 language = {en},
 month = {November},
 number = {3},
 pages = {159-190},
 shorttitle = {Machine Learning},
 title = {Machine Learning: A Review of Classification and Combining Techniques},
 volume = {26},
 year = {2006}
}

@inproceedings{Kouki:2019:PEH:3301275.3302306,
 acmid = {3302306},
 address = {New York, NY, USA},
 author = {Kouki, Pigi and Schaffer, James and Pujara, Jay and O'Donovan, John and Getoor, Lise},
 booktitle = {Proceedings of the 24th International Conference on Intelligent User Interfaces},
 comments = {Presents a specific method for enhancing explainability for models, The described method is neither general, nor focused on NLP},
 doi = {10.1145/3301275.3302306},
 isbn = {978-1-4503-6272-6},
 keywords = {explainable artificial intelligence, explainable intelligent user interfaces, explainable recommender systems, hybrid recommender systems},
 location = {Marina del Ray, California},
 numpages = {12},
 pages = {379--390},
 publisher = {ACM},
 series = {IUI '19},
 title = {Personalized Explanations for Hybrid Recommender Systems},
 url = {http://doi.acm.org/10.1145/3301275.3302306},
 year = {2019}
}

@inproceedings{Kuo:2008:FEA:1486927.1486968,
 acmid = {1486968},
 address = {Washington, DC, USA},
 author = {Kuo, Yen-Ting and Sonenberg, Liz and Lonie, Andrew},
 booktitle = {Proceedings of the 2008 IEEE/WIC/ACM International Conference on Web Intelligence and Intelligent Agent Technology - Volume 01},
 comments = { The described method is neither general, nor focused on NLP},
 doi = {10.1109/WIIAT.2008.330},
 isbn = {978-0-7695-3496-1},
 keywords = {explanation generation, pattern interpretation},
 numpages = {4},
 pages = {48--51},
 publisher = {IEEE Computer Society},
 series = {WI-IAT '08},
 title = {Finding Explanations for Assisting Pattern Interpretation},
 url = {http://dx.doi.org/10.1109/WIIAT.2008.330},
 year = {2008}
}

@article{kuwajimaImprovingTransparencyDeep2019,
 abstract = {Deep learning techniques are rapidly advanced recently and becoming a necessity component for widespread systems. However, the inference process of deep learning is black box and is not very suitable to safety-critical systems which must exhibit high transparency. In this paper, to address this black-box limitation, we develop a simple analysis method which consists of (1) structural feature analysis: lists of the features contributing to inference process, (2) linguistic feature analysis: lists of the natural language labels describing the visual attributes for each feature contributing to inference process, and (3) consistency analysis: measuring consistency among input data, inference (label), and the result of our structural and linguistic feature analysis. Our analysis is simplified to reflect the actual inference process for high transparency, whereas it does not include any additional black-box mechanisms such as LSTM for highly human readable results. We conduct experiments and discuss the results of our analysis qualitatively and quantitatively and come to believe that our work improves the transparency of neural networks. Evaluated through 12,800 human tasks, 75\% workers answer that input data and result of our feature analysis are consistent, and 70\% workers answer that inference (label) and result of our feature analysis are consistent. In addition to the evaluation of the proposed analysis, we find that our analysis also provides suggestions, or possible next actions such as expanding neural network complexity or collecting training data to improve a neural network.},
 author = {Kuwajima, Hiroshi and Tanaka, Masayuki and Okutomi, Masatoshi},
 comments = {Presents a specific method for enhancing explainability for models, The described method is neither general, nor focused on NLP},
 doi = {10.1007/s13748-019-00179-x},
 issn = {2192-6360},
 journal = {Progress in Artificial Intelligence},
 keywords = {Black box,Deep neural network,Explainable AI,Transparency,Visual attribute,Visualization},
 language = {en},
 month = {April},
 title = {Improving Transparency of Deep Neural Inference Process},
 year = {2019}
}

@incollection{liaoMiningHumanInterpretable2006,
 abstract = {This chapter focuses on one particular class of data mining methodologies that expresses the mined knowledge in the form of fuzzy If-Then rules or fuzzy decision trees that can be easily understood by a human. Past studies on generating fuzzy If-Then rules (mostly from exemplar crisp data and a few from exemplar fuzzy data) are grouped into six major categories: grid partitioning, fuzzy clustering, genetic algorithms, neural networks, hybrid methods, and others. The representative method in each category is detailed. The latest improvements and advancements in each category are also reviewed. Similarly, past studies on generating fuzzy decision trees (from exemplar nominal and/or numeric data as well as from exemplar fuzzy data) are surveyed. The essence of each method is presented. Moreover, we discuss selected studies that address most of the necessary conditions for a fuzzy model to be interpretable and highlight areas for future studies. To give an idea of where fuzzy modeling methods have been applied, major application areas are also summarized.},
 address = {Boston, MA},
 author = {Liao, T. Warren},
 booktitle = {Data {{Mining}} and {{Knowledge Discovery Approaches Based}} on {{Rule Induction Techniques}}},
 comments = { The publication does not focus on explainability},
 doi = {10.1007/0-387-34296-6_15},
 editor = {Triantaphyllou, Evangelos and Felici, Giovanni},
 isbn = {978-0-387-34296-2},
 keywords = {Data mining,Fuzzy clustering,Fuzzy decision trees,Fuzzy If-Then rules,Fuzzy modeling,Fuzzy-neural networks,Genetic algorithms,Neural networks},
 language = {en},
 pages = {495-550},
 publisher = {{Springer US}},
 series = {Massive {{Computing}}},
 shorttitle = {Mining {{Human Interpretable Knowledge}} with {{Fuzzy Modeling Methods}}},
 title = {Mining {{Human Interpretable Knowledge}} with {{Fuzzy Modeling Methods}}: {{An Overview}}},
 year = {2006}
}

@inproceedings{Lim:2019:EES:3308557.3313112,
 acmid = {3313112},
 address = {New York, NY, USA},
 author = {Lim, Brian and Sarkar, Advait and Smith-Renner, Alison and Stumpf, Simone},
 booktitle = {Proceedings of the 24th International Conference on Intelligent User Interfaces: Companion},
 comments = { The publication does not focus on explainability, The described method is neither general, nor focused on NLP},
 doi = {10.1145/3308557.3313112},
 isbn = {978-1-4503-6673-1},
 keywords = {explanations, intelligent systems, intelligibility, machine learning, transparency, visualizations},
 location = {Marina del Ray, California},
 numpages = {2},
 pages = {125--126},
 publisher = {ACM},
 series = {IUI '19},
 title = {ExSS: Explainable Smart Systems 2019},
 url = {http://doi.acm.org/10.1145/3308557.3313112},
 year = {2019}
}

@inproceedings{Liu:2018:ADM:3219819.3220027,
 acmid = {3220027},
 address = {New York, NY, USA},
 author = {Liu, Ninghao and Yang, Hongxia and Hu, Xia},
 booktitle = {Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery \&\#38; Data Mining},
 comments = { The publication does not focus on explainability},
 doi = {10.1145/3219819.3220027},
 isbn = {978-1-4503-5552-0},
 keywords = {adversarial detection, machine learning interpretation, spammer detection},
 location = {London, United Kingdom},
 numpages = {9},
 pages = {1803--1811},
 publisher = {ACM},
 series = {KDD '18},
 title = {Adversarial Detection with Model Interpretation},
 url = {http://doi.acm.org/10.1145/3219819.3220027},
 year = {2018}
}

@incollection{luceBasicsArtificialIntelligence2019,
 abstract = {Fashion not only provides functional purpose, but captures mysterious and elusive aspects of being human. Fashion expresses and invokes human emotion and creativity. How we look and sometimes even how we feel is intertwined in this industry. Fashion has always been forward looking, grabbing onto new technologies as they arise. Artificial intelligence is no exception, and it's moving as quickly as fashion does.},
 address = {Berkeley, CA},
 author = {Luce, Leanne},
 booktitle = {Artificial {{Intelligence}} for {{Fashion}}: {{How AI}} Is {{Revolutionizing}} the {{Fashion Industry}}},
 comments = { The publication does not focus on explainability},
 doi = {10.1007/978-1-4842-3931-5_1},
 editor = {Luce, Leanne},
 isbn = {978-1-4842-3931-5},
 language = {en},
 pages = {3-18},
 publisher = {{Apress}},
 title = {Basics of {{Artificial Intelligence}}},
 year = {2019}
}

@inproceedings{maragoudakisMiningNaturalLanguage2008,
 abstract = {Learning a programming language is a painstaking process, as it requires knowledge of its syntax, apart from knowing the basic process of representing logical sequences to programming stages. This fact deteriorates the coding process and expels most users from programming. Particularly for novice users or persons with vision problems, learning of how to program and tracing the syntax errors could be improved dramatically by using the most natural of all interfaces, i.e. natural language. Towards this orientation, we suggest a wider framework for allowing programming using natural language. The framework can be easily extended to support different object-oriented programming languages such as C, C++, Visual Basic or Java. Our suggested model is named ``Language Oriented Basic'' and it concerns an intelligent interface that supports code creation, modification and control in Visual Basic. Users can use simple-structured Greek sentences in natural language and the system can output the corresponding syntactic tree. When users declare end of input, the system transforms the syntactic trees to source code. Throughout the whole interaction process, users can check the under-development code in order to verify its correspondence to their expectations. Due to the fact that using natural language can cause a great degree of ambiguity, Bayesian networks and learning from examples have been utilized as an attempt to reason on the most probable programming representation, given a natural language input sentence. In order to enhance the classifier, we propose a novel variation of Bayesian networks that favor the classification process. Experimental results have depicted precision and recall measures in a range of 73\% and 70\% respectively.},
 author = {Maragoudakis, Manolis and Cosmas, Nikolaos and Garbis, Aristogiannis},
 booktitle = {Advanced {{Data Mining}} and {{Applications}}},
 comments = { The publication does not focus on explainability},
 editor = {Tang, Changjie and Ling, Charles X. and Zhou, Xiaofang and Cercone, Nick J. and Li, Xue},
 isbn = {978-3-540-88192-6},
 keywords = {Bayesian Classifier,Bayesian Network,Conditional Independence Assumption,Conditional Probability Table,Natural Language},
 language = {en},
 pages = {15-26},
 publisher = {{Springer Berlin Heidelberg}},
 series = {Lecture {{Notes}} in {{Computer Science}}},
 title = {Mining {{Natural Language Programming Directives}} with {{Class}}-{{Oriented Bayesian Networks}}},
 year = {2008}
}

@inproceedings{Mei:2018:IGA:3209280.3229119,
 acmid = {3229119},
 address = {New York, NY, USA},
 articleno = {49},
 author = {Mei, Jie and Jiang, Xiang and Islam, Aminul and Moh'd, Abidalrahman and Milios, Evangelos},
 booktitle = {Proceedings of the ACM Symposium on Document Engineering 2018},
 comments = { The publication does not focus on explainability},
 doi = {10.1145/3209280.3229119},
 isbn = {978-1-4503-5769-2},
 keywords = {Attention Mechanism, Neural Network, Self-Attention},
 location = {Halifax, NS, Canada},
 numpages = {4},
 pages = {49:1--49:4},
 publisher = {ACM},
 series = {DocEng '18},
 title = {Integrating Global Attention for Pairwise Text Comparison},
 url = {http://doi.acm.org/10.1145/3209280.3229119},
 year = {2018}
}

@incollection{miradiKnowledgeDiscoveryData2009,
 abstract = {The main goal of this study was to discover knowledge from data about Porous Asphalt Concrete (PAC) roads to achieve a better understanding of the behavior of them and via this understanding improve pavement quality and enhance its lifespan. The knowledge discovery process includes five steps, being understanding the problem, understanding the data, data preparation, data mining (modeling), and the interpretation/evaluation of the results of the models. At the moment, almost 75\% of the Dutch motorways network has a PAC top layer. The main damage of PAC is raveling, which is when the top layer of the road loses stones. The SHRP-NL databases provided ten years of material property data from PAC roads. The data for climate and traffic were obtained from databases of the Royal Dutch Meteorological Institute (KNMI) and the Ministry of Transport and Water Management, respectively. Due to the low number of data points (74 data points), an extensive variable selection was performed using eight different methods to determine the four or five most influential input variables and consequently reduce the input dimension. These methods were decision trees, genetic polynomial, artificial neural network, rough set theory, correlation based variable selection with bidirectional and genetic search, wrappers of neural network with genetic search, and relief ranking filter. The modeling step resulted in 8 intelligent models which were developed using two prediction techniques, being artificial neural networks and support vector machines and two rule-based techniques, being decision trees and rough set theory. Taking the low number of data points into account, the prediction models showed a good performance (R2 = 0.95). The rule based models were transparent and easy to interpret but performed less.},
 address = {Berlin, Heidelberg},
 author = {Miradi, Maryam and Molenaar, Andre A. A. and {van de Ven}, Martin F. C.},
 booktitle = {Intelligent and {{Soft Computing}} in {{Infrastructure Systems Engineering}}: {{Recent Advances}}},
 comments = { The described method is neither general, nor focused on NLP},
 doi = {10.1007/978-3-642-04586-8_5},
 editor = {Gopalakrishnan, Kasthurirangan and Ceylan, Halil and {Attoh-Okine}, Nii O.},
 isbn = {978-3-642-04586-8},
 keywords = {Artificial Neural Network,Data Mining,Knowledge Discovery,Support Vector Machine,Test Section},
 language = {en},
 pages = {107-176},
 publisher = {{Springer Berlin Heidelberg}},
 series = {Studies in {{Computational Intelligence}}},
 title = {Knowledge {{Discovery}} and {{Data Mining Using Artificial Intelligence}} to {{Unravel Porous Asphalt Concrete}} in the {{Netherlands}}},
 year = {2009}
}

@inproceedings{Model:1980:MVI:800087.802805,
 acmid = {802805},
 address = {New York, NY, USA},
 author = {Model, Mitchell L},
 booktitle = {Proceedings of the 1980 ACM Conference on LISP and Functional Programming},
 comments = { The publication does not focus on explainability},
 doi = {10.1145/800087.802805},
 location = {Stanford University, California, USA},
 numpages = {8},
 pages = {188--195},
 publisher = {ACM},
 series = {LFP '80},
 title = {Multiprocessing via Intercommunicating LISP Systems},
 url = {http://doi.acm.org/10.1145/800087.802805},
 year = {1980}
}

@article{moriBalancingTradeoffAccuracy2019,
 abstract = {ContextClassification techniques of supervised machine learning have been successfully applied to various domains of practice. When building a predictive model, there are two important criteria: predictive accuracy and interpretability, which generally have a trade-off relationship. In particular, interpretability should be accorded greater emphasis in the domains where the incorporation of expert knowledge into a predictive model is required.ObjectiveThe aim of this research is to propose a new classification model, called superposed naive Bayes (SNB), which transforms a naive Bayes ensemble into a simple naive Bayes model by linear approximation.MethodIn order to evaluate the predictive accuracy and interpretability of the proposed method, we conducted a comparative study using well-known classification techniques such as rule-based learners, decision trees, regression models, support vector machines, neural networks, Bayesian learners, and ensemble learners, over 13 real-world public datasets.ResultsA trade-off analysis between the accuracy and interpretability of different classification techniques was performed with a scatter plot comparing relative ranks of accuracy with those of interpretability. The experiment results show that the proposed method (SNB) can produce a balanced output that satisfies both accuracy and interpretability criteria.ConclusionsSNB offers a comprehensible predictive model based on a simple and transparent model structure, which can provide an effective way for balancing the trade-off between accuracy and interpretability.},
 author = {Mori, Toshiki and Uchihira, Naoshi},
 comments = { The described method is neither general, nor focused on NLP},
 doi = {10.1007/s10664-018-9638-1},
 issn = {1573-7616},
 journal = {Empirical Software Engineering},
 keywords = {Ensemble learning,Interpretability,Model approximation,Naive Bayes classifier,Predictive accuracy,Software defect prediction,Trade-off analysis,Weights of evidence},
 language = {en},
 month = {April},
 number = {2},
 pages = {779-825},
 title = {Balancing the Trade-off between Accuracy and Interpretability in Software Defect Prediction},
 volume = {24},
 year = {2019}
}

@article{Mulkers:1994:LDA:174662.174664,
 acmid = {174664},
 address = {New York, NY, USA},
 author = {Mulkers, Anne and Winsborough, William and Bruynooghe, Maurice},
 comments = { The publication does not focus on explainability},
 doi = {10.1145/174662.174664},
 issn = {0164-0925},
 issue_date = {March 1994},
 journal = {ACM Trans. Program. Lang. Syst.},
 keywords = {Prolog, abstract interpretation, compile-time garbage collection, liveness, program analysis},
 month = {March},
 number = {2},
 numpages = {54},
 pages = {205--258},
 publisher = {ACM},
 title = {Live-structure Dataflow Analysis for Prolog},
 url = {http://doi.acm.org/10.1145/174662.174664},
 volume = {16},
 year = {1994}
}

@incollection{ngomoIntroductionLinkedData2014,
 abstract = {With Linked Data, a very pragmatic approach towards achieving the vision of the Semantic Web has gained some traction in the last years. The term Linked Data refers to a set of best practices for publishing and interlinking structured data on the Web. While many standards, methods and technologies developed within by the Semantic Web community are applicable for Linked Data, there are also a number of specific characteristics of Linked Data, which have to be considered. In this article we introduce the main concepts of Linked Data. We present an overview of the Linked Data life-cycle and discuss individual approaches as well as the state-of-the-art with regard to extraction, authoring, linking, enrichment as well as quality of Linked Data. We conclude the chapter with a discussion of issues, limitations and further research and development challenges of Linked Data. This article is an updated version of a similar lecture given at Reasoning Web Summer School 2013.},
 address = {Cham},
 author = {Ngomo, Axel-Cyrille Ngonga and Auer, S\"oren and Lehmann, Jens and Zaveri, Amrapali},
 booktitle = {Reasoning {{Web}}. {{Reasoning}} on the {{Web}} in the {{Big Data Era}}: 10th {{International Summer School}} 2014, {{Athens}}, {{Greece}}, {{September}} 8-13, 2014. {{Proceedings}}},
 comments = { The publication does not focus on explainability},
 doi = {10.1007/978-3-319-10587-1_1},
 editor = {Koubarakis, Manolis and Stamou, Giorgos and Stoilos, Giorgos and Horrocks, Ian and Kolaitis, Phokion and Lausen, Georg and Weikum, Gerhard},
 file = {/home/tim/Zotero/storage/6M2EVAFK/Ngomo et al. - 2014 - Introduction to Linked Data and Its Lifecycle on t.pdf;/home/tim/Zotero/storage/X9CPENNW/Ngomo et al. - 2014 - Introduction to Linked Data and Its Lifecycle on t.pdf},
 isbn = {978-3-319-10587-1},
 keywords = {Inductive Logic Programming,Link Data,Link Open Data,Resource Description Framework,SPARQL Query},
 language = {en},
 pages = {1-99},
 publisher = {{Springer International Publishing}},
 series = {Lecture {{Notes}} in {{Computer Science}}},
 title = {Introduction to {{Linked Data}} and {{Its Lifecycle}} on the {{Web}}},
 year = {2014}
}

@article{nguyenMachineLearningDeep2019,
 abstract = {The combined impact of new computing resources and techniques with an increasing avalanche of large datasets, is transforming many research areas and may lead to technological breakthroughs that can be used by billions of people. In the recent years, Machine Learning and especially its subfield Deep Learning have seen impressive advances. Techniques developed within these two fields are now able to analyze and learn from huge amounts of real world examples in a disparate formats. While the number of Machine Learning algorithms is extensive and growing, their implementations through frameworks and libraries is also extensive and growing too. The software development in this field is fast paced with a large number of open-source software coming from the academy, industry, start-ups or wider open-source communities. This survey presents a recent time-slide comprehensive overview with comparisons as well as trends in development and usage of cutting-edge Artificial Intelligence software. It also provides an overview of massive parallelism support that is capable of scaling computation effectively and efficiently in the era of Big Data.},
 author = {Nguyen, Giang and Dlugolinsky, Stefan and Bob\'ak, Martin and Tran, Viet and L\'opez Garc\'ia, \'Alvaro and Heredia, Ignacio and Mal\'ik, Peter and Hluch\'y, Ladislav},
 comments = { The publication does not focus on explainability},
 doi = {10.1007/s10462-018-09679-z},
 file = {/home/tim/Zotero/storage/U6RYW6DN/Nguyen et al. - 2019 - Machine Learning and Deep Learning frameworks and .pdf},
 issn = {1573-7462},
 journal = {Artificial Intelligence Review},
 keywords = {Artificial Intelligence software,Deep Learning,Graphics processing unit (GPU),Intensive computing,Large-scale data mining,Machine Learning,Parallel processing},
 language = {en},
 month = {January},
 shorttitle = {Machine {{Learning}} and {{Deep Learning}} Frameworks and Libraries for Large-Scale Data Mining},
 title = {Machine {{Learning}} and {{Deep Learning}} Frameworks and Libraries for Large-Scale Data Mining: A Survey},
 year = {2019}
}

@inproceedings{Nobrega:2019:TER:3297280.3297443,
 acmid = {3297443},
 address = {New York, NY, USA},
 author = {N\'{o}brega, Caio and Marinho, Leandro},
 booktitle = {Proceedings of the 34th ACM/SIGAPP Symposium on Applied Computing},
 comments = {Presents a specific method for enhancing explainability for models, The described method is neither general, nor focused on NLP},
 doi = {10.1145/3297280.3297443},
 isbn = {978-1-4503-5933-7},
 keywords = {explanations, factorization machines, recommender systems, transparency},
 location = {Limassol, Cyprus},
 numpages = {8},
 pages = {1671--1678},
 publisher = {ACM},
 series = {SAC '19},
 title = {Towards Explaining Recommendations Through Local Surrogate Models},
 url = {http://doi.acm.org/10.1145/3297280.3297443},
 year = {2019}
}

@article{NUTSBOLTSBEHAVIORAL2017,
 comments = { The publication does not focus on explainability},
 doi = {10.1007/s12160-017-9903-3},
 issn = {1532-4796},
 journal = {Annals of Behavioral Medicine},
 language = {en},
 month = {March},
 number = {1},
 pages = {1-2867},
 shorttitle = {{{THE}} ``{{NUTS AND BOLTS}}'' {{OF BEHAVIORAL INTERVENTION DEVELOPMENT}}},
 title = {{{THE}} ``{{NUTS AND BOLTS}}'' {{OF BEHAVIORAL INTERVENTION DEVELOPMENT}}: {{STUDY DESIGNS}}, {{METHODS AND FUNDING OPPORTUNITIES}}},
 volume = {51},
 year = {2017}
}

@inproceedings{Nyawira:2018:UNP:3219104.3229285,
 acmid = {3229285},
 address = {New York, NY, USA},
 articleno = {65},
 author = {Nyaw\~{i}ra, Ishtar and Bushman, Kristi and Qian, Iris and Zhang, Annie},
 booktitle = {Proceedings of the Practice and Experience on Advanced Research Computing},
 comments = { The publication does not focus on explainability},
 doi = {10.1145/3219104.3229285},
 isbn = {978-1-4503-6446-1},
 keywords = {Artificial Intelligence, Biomedical Image Processing, Convolutional Neural Networks, Deep Learning, Machine Learning},
 location = {Pittsburgh, PA, USA},
 numpages = {8},
 pages = {65:1--65:8},
 publisher = {ACM},
 series = {PEARC '18},
 title = {Understanding Neural Pathways in Zebrafish Through Deep Learning and High Resolution Electron Microscope Data},
 url = {http://doi.acm.org/10.1145/3219104.3229285},
 year = {2018}
}

@inproceedings{oitaReverseEngineeringCreativity2020,
 abstract = {In the field of AI the ultimate goal is to achieve generic intelligence, also called ``true AI'', but which depends on the successful enablement of imagination and creativity in artificial agents. To address this problem, this paper presents a novel deep learning framework for creativity, called INNGenuity. Pursuing an interdisciplinary implementation of creativity conditions, INNGenuity aims at the resolution of the various flaws of current AI learning architectures, which stem from the opacity of their models. Inspired by the neuroanatomy of the brain during creative cognition, the proposed framework's hybrid architecture blends both symbolic and connectionist AI, inline with Minsky's ``society of mind''. At its core, semantic gates are designed to facilitate an input/output flow of semantic structures and enable the usage of aligning mechanisms between neural activation clusters and semantic graphs. Having as goal alignment maximization, such a system would enable interpretability through the creation of labeled patterns of computation, and propose unaligned but relevant computation patterns as novel and useful, therefore creative.},
 author = {Oita, Marilena},
 booktitle = {Advances in {{Information}} and {{Communication}}},
 comments = {Presents a specific method for enhancing explainability for models, The described method is neither general, nor focused on NLP},
 editor = {Arai, Kohei and Bhatia, Rahul},
 isbn = {978-3-030-12385-7},
 keywords = {Creativity,Imagination,Interpretability,Knowledge,Neural architecture,Neural networks,Semantic networks},
 language = {en},
 pages = {235-247},
 publisher = {{Springer International Publishing}},
 series = {Lecture {{Notes}} in {{Networks}} and {{Systems}}},
 title = {Reverse {{Engineering Creativity}} into {{Interpretable Neural Networks}}},
 year = {2020}
}

@incollection{pace-siggeWhereCorpusLinguistics2018,
 abstract = {This chapter will provide a platform to showcase the more recent developments that have grown out of the early laid groundwork. The latest theories in the field of linguistics will be presented, based on empirical data taken from naturally occurring language. In particular, the lexical priming theory will be introduced as a way to explain structures of language that corpus linguists have uncovered. Furthermore, the chapter will discuss the development of increasingly sophisticated algorithms that also deal with the use of language. Here, the focus will be on key achievements in the 1980s by IBM which created a solid foundation for applications that are now widely used in mobile and desktop devices\textemdash{}namely ``assistants'' like Amazon's Echo, Apple's SIRI or Google's (and Android's) Google Go.},
 address = {Cham},
 author = {{Pace-Sigge}, Michael},
 booktitle = {Spreading {{Activation}}, {{Lexical Priming}} and the {{Semantic Web}}: {{Early Psycholinguistic Theories}}, {{Corpus Linguistics}} and {{AI Applications}}},
 comments = { The publication does not focus on explainability},
 doi = {10.1007/978-3-319-90719-2_3},
 editor = {{Pace-Sigge}, Michael},
 isbn = {978-3-319-90719-2},
 keywords = {Digital translators,Hoey,Lexical priming,LSTM,N-gram model,Norvig,Quillian},
 language = {en},
 pages = {29-82},
 publisher = {{Springer International Publishing}},
 title = {Where {{Corpus Linguistics}} and {{Artificial Intelligence}} ({{AI}}) {{Meet}}},
 year = {2018}
}

@inproceedings{Palmirani:2011:FMS:2018358.2018385,
 acmid = {2018385},
 address = {New York, NY, USA},
 author = {Palmirani, Monica and Ceci, Marcello and Radicioni, Daniele and Mazzei, Alessandro},
 booktitle = {Proceedings of the 13th International Conference on Artificial Intelligence and Law},
 comments = { The publication does not focus on explainability},
 doi = {10.1145/2018358.2018385},
 isbn = {978-1-4503-0755-0},
 keywords = {FrameNet, NLP, legal knowledge modelling, semantic interpretation},
 location = {Pittsburgh, Pennsylvania},
 numpages = {5},
 pages = {189--193},
 publisher = {ACM},
 series = {ICAIL '11},
 title = {FrameNet Model of the Suspension of Norms},
 url = {http://doi.acm.org/10.1145/2018358.2018385},
 year = {2011}
}

@incollection{panesarMachineLearningAlgorithms2019,
 abstract = {You do not need a background in algebra and statistics to get started in machine learning. However, be under no illusions, mathematics is a huge part of machine learning. Math is key to understanding how the algorithm works and why coding a machine learning project from scratch is a great way to improve your mathematical and statistical skills. Not understanding the underlying principles behind an algorithm can lead to a limited understanding of methods or adopting limited interpretations of algorithms. If nothing else, it is useful to understand the mathematical principles that algorithms are based on and thus understand best which machine learning techniques are most appropriate.},
 address = {Berkeley, CA},
 author = {Panesar, Arjun},
 booktitle = {Machine {{Learning}} and {{AI}} for {{Healthcare}}       : {{Big Data}} for {{Improved Health Outcomes}}},
 comments = { The publication does not focus on explainability},
 doi = {10.1007/978-1-4842-3799-1_4},
 editor = {Panesar, Arjun},
 isbn = {978-1-4842-3799-1},
 language = {en},
 pages = {119-188},
 publisher = {{Apress}},
 title = {Machine {{Learning Algorithms}}},
 year = {2019}
}

@inproceedings{Popat:2017:TLE:3041021.3055133,
 acmid = {3055133},
 address = {Republic and Canton of Geneva, Switzerland},
 author = {Popat, Kashyap and Mukherjee, Subhabrata and Str\"{o}tgen, Jannik and Weikum, Gerhard},
 booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
 comments = { The publication does not focus on explainability},
 doi = {10.1145/3041021.3055133},
 isbn = {978-1-4503-4914-7},
 keywords = {credibility analysis, rumor and hoax detection, text mining},
 location = {Perth, Australia},
 numpages = {10},
 pages = {1003--1012},
 publisher = {International World Wide Web Conferences Steering Committee},
 series = {WWW '17 Companion},
 title = {Where the Truth Lies: Explaining the Credibility of Emerging Claims on the Web and Social Media},
 url = {https://doi.org/10.1145/3041021.3055133},
 year = {2017}
}

@article{Posters2009,
 comments = { Is not scientific literature},
 doi = {10.1007/s12603-009-0095-9},
 issn = {1760-4788},
 journal = {JNHA - The Journal of Nutrition, Health and Aging},
 language = {en},
 month = {June},
 number = {1},
 pages = {210-723},
 title = {Posters},
 volume = {13},
 year = {2009}
}

@inproceedings{Pynadath:2018:CBR:3237383.3237923,
 acmid = {3237923},
 address = {Richland, SC},
 author = {Pynadath, David V. and Wang, Ning and Rovira, Ericka and Barnes, Michael J.},
 booktitle = {Proceedings of the 17th International Conference on Autonomous Agents and MultiAgent Systems},
 comments = { The publication does not focus on explainability},
 keywords = {affect recognition, explainable ai, human-agent teams, trust},
 location = {Stockholm, Sweden},
 numpages = {9},
 pages = {1495--1503},
 publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
 series = {AAMAS '18},
 title = {Clustering Behavior to Recognize Subjective Beliefs in Human-Agent Teams},
 url = {http://dl.acm.org/citation.cfm?id=3237383.3237923},
 year = {2018}
}

@article{qureshiEVEExplainableVector2018,
 abstract = {We present an unsupervised explainable vector embedding technique, called EVE, which is built upon the structure of Wikipedia. The proposed model defines the dimensions of a semantic vector representing a concept using human-readable labels, thereby it is readily interpretable. Specifically, each vector is constructed using the Wikipedia category graph structure together with the Wikipedia article link structure. To test the effectiveness of the proposed model, we consider its usefulness in three fundamental tasks: 1) intruder detection\textemdash{}to evaluate its ability to identify a non-coherent vector from a list of coherent vectors, 2) ability to cluster\textemdash{}to evaluate its tendency to group related vectors together while keeping unrelated vectors in separate clusters, and 3) sorting relevant items first\textemdash{}to evaluate its ability to rank vectors (items) relevant to the query in the top order of the result. For each task, we also propose a strategy to generate a task-specific human-interpretable explanation from the model. These demonstrate the overall effectiveness of the explainable embeddings generated by EVE. Finally, we compare EVE with the Word2Vec, FastText, and GloVe embedding techniques across the three tasks, and report improvements over the state-of-the-art.},
 author = {Qureshi, M. Atif and Greene, Derek},
 comments = { The publication does not focus on explainability},
 doi = {10.1007/s10844-018-0511-x},
 file = {/home/tim/Zotero/storage/9BHZ5UXW/Qureshi and Greene - 2018 - EVE explainable vector based embedding technique .pdf},
 issn = {1573-7675},
 journal = {Journal of Intelligent Information Systems},
 keywords = {Distributional semantics,Unsupervised learning,Wikipedia},
 language = {en},
 month = {June},
 shorttitle = {{{EVE}}},
 title = {{{EVE}}: Explainable Vector Based Embedding Technique Using {{Wikipedia}}},
 year = {2018}
}

@inproceedings{Sang:2018:DLI:3240508.3241472,
 acmid = {3241472},
 address = {New York, NY, USA},
 author = {Sang, Jitao},
 booktitle = {Proceedings of the 26th ACM International Conference on Multimedia},
 comments = { The publication does not focus on explainability},
 doi = {10.1145/3240508.3241472},
 isbn = {978-1-4503-5665-7},
 keywords = {deep learning, interpretable machine learning},
 location = {Seoul, Republic of Korea},
 numpages = {3},
 pages = {2098--2100},
 publisher = {ACM},
 series = {MM '18},
 title = {Deep Learning Interpretation},
 url = {http://doi.acm.org/10.1145/3240508.3241472},
 year = {2018}
}

@incollection{sarkarAnalyzingMovieReviews2018,
 abstract = {In this chapter, we continue with our focus on case-study oriented chapters, where we will focus on specific real-world problems and scenarios and how we can use Machine Learning to solve them. We will cover aspects pertaining to natural language processing (NLP), text analytics, and Machine Learning in this chapter. The problem at hand is sentiment analysis or opinion mining, where we want to analyze some textual documents and predict their sentiment or opinion based on the content of these documents. Sentiment analysis is perhaps one of the most popular applications of natural language processing and text analytics with a vast number of websites, books and tutorials on this subject. Typically sentiment analysis seems to work best on subjective text, where people express opinions, feelings, and their mood. From a real-world industry standpoint, sentiment analysis is widely used to analyze corporate surveys, feedback surveys, social media data, and reviews for movies, places, commodities, and many more. The idea is to analyze and understand the reactions of people toward a specific entity and take insightful actions based on their sentiment.},
 address = {Berkeley, CA},
 author = {Sarkar, Dipanjan and Bali, Raghav and Sharma, Tushar},
 booktitle = {Practical {{Machine Learning}} with {{Python}}: {{A Problem}}-{{Solver}}'s {{Guide}} to {{Building Real}}-{{World Intelligent Systems}}},
 comments = { Does not describe the used explainability method},
 doi = {10.1007/978-1-4842-3207-1_7},
 editor = {Sarkar, Dipanjan and Bali, Raghav and Sharma, Tushar},
 isbn = {978-1-4842-3207-1},
 language = {en},
 pages = {331-372},
 publisher = {{Apress}},
 title = {Analyzing {{Movie Reviews Sentiment}}},
 year = {2018}
}

@incollection{sarkarMachineLearningBasics2018,
 abstract = {The idea of making intelligent, sentient, and self-aware machines is not something that suddenly came into existence in the last few years. In fact a lot of lore from Greek mythology talks about intelligent machines and inventions having self-awareness and intelligence of their own. The origins and the evolution of the computer have been really revolutionary over a period of several centuries, starting from the basic Abacus and its descendant the slide rule in the 17th Century to the first general purpose computer designed by Charles Babbage in the 1800s. In fact, once computers started evolving with the invention of the Analytical Engine by Babbage and the first computer program, which was written by Ada Lovelace in 1842, people started wondering and contemplating that could there be a time when computers or machines truly become intelligent and start thinking for themselves. In fact, the renowned computer scientist, Alan Turing, was highly influential in the development of theoretical computer science, algorithms, and formal language and addressed concepts like artificial intelligence and Machine Learning as early as the 1950s. This brief insight into the evolution of making machines learn is just to give you an idea of something that has been out there since centuries but has recently started gaining a lot of attention and focus.},
 address = {Berkeley, CA},
 author = {Sarkar, Dipanjan and Bali, Raghav and Sharma, Tushar},
 booktitle = {Practical {{Machine Learning}} with {{Python}}: {{A Problem}}-{{Solver}}'s {{Guide}} to {{Building Real}}-{{World Intelligent Systems}}},
 comments = { The publication does not focus on explainability},
 doi = {10.1007/978-1-4842-3207-1_1},
 editor = {Sarkar, Dipanjan and Bali, Raghav and Sharma, Tushar},
 isbn = {978-1-4842-3207-1},
 language = {en},
 pages = {3-65},
 publisher = {{Apress}},
 title = {Machine {{Learning Basics}}},
 year = {2018}
}

@incollection{schetininAdvancedFeatureRecognition2007,
 address = {Berlin, Heidelberg},
 author = {Schetinin, V. and Zharkova, Valentina and Brazhnikov, A. and Zharkov, S. I. and Salerno, Emanuele and Bedini, Luigi and Kuruoglu, Ercan E. and Tonazzini, Anna and Zazula, Damjan and Cigale, Boris and Yoshida, Hiroyuki},
 booktitle = {Artificial {{Intelligence}} in {{Recognition}} and {{Classification}} of {{Astrophysical}} and {{Medical Images}}},
 comments = { The publication does not focus on explainability},
 doi = {10.1007/978-3-540-47518-7_4},
 editor = {Zharkova, Valentina and Jain, Lakhmi C.},
 isbn = {978-3-540-47518-7},
 keywords = {Cellular Neural Network,Compute Tomography Colonography,Independent Component Analysis,Source Separation},
 language = {en},
 pages = {151-338},
 publisher = {{Springer Berlin Heidelberg}},
 series = {Studies in {{Computational Intelligence}}},
 title = {Advanced {{Feature Recognition}} and {{Classification Using Artificial Intelligence Paradigms}}},
 year = {2007}
}

@article{SCIENTIFICABSTRACTS2018,
 comments = { Is not scientific literature},
 doi = {10.1007/s11606-018-4413-y},
 file = {/home/tim/Zotero/storage/E8QM5V3M/2018 - SCIENTIFIC ABSTRACTS.pdf},
 issn = {1525-1497},
 journal = {Journal of General Internal Medicine},
 language = {en},
 month = {April},
 number = {2},
 pages = {83-840},
 title = {{{SCIENTIFIC ABSTRACTS}}},
 volume = {33},
 year = {2018}
}

@article{ScientificProgrammeAbstracts2003,
 comments = { Is not scientific literature, The publication does not focus on explainability},
 doi = {10.1007/BF03323651},
 issn = {1432-1084},
 journal = {European Radiology},
 language = {en},
 month = {February},
 number = {1},
 pages = {93-589},
 title = {Scientific {{Programme}} \textemdash{} {{Abstracts}}},
 volume = {13},
 year = {2003}
}

@inproceedings{Seo:2017:ICN:3109859.3109890,
 acmid = {3109890},
 address = {New York, NY, USA},
 author = {Seo, Sungyong and Huang, Jing and Yang, Hao and Liu, Yan},
 booktitle = {Proceedings of the Eleventh ACM Conference on Recommender Systems},
 comments = {Presents a specific method for enhancing explainability for models, The described method is neither general, nor focused on NLP},
 doi = {10.1145/3109859.3109890},
 isbn = {978-1-4503-4652-8},
 keywords = {attention model, convolutional neural network, deep learning for recommender systems},
 location = {Como, Italy},
 numpages = {9},
 pages = {297--305},
 publisher = {ACM},
 series = {RecSys '17},
 title = {Interpretable Convolutional Neural Networks with Dual Local and Global Attention for Review Rating Prediction},
 url = {http://doi.acm.org/10.1145/3109859.3109890},
 year = {2017}
}

@inproceedings{Sha:2017:IPC:3107411.3107445,
 acmid = {3107445},
 address = {New York, NY, USA},
 author = {Sha, Ying and Wang, May D.},
 booktitle = {Proceedings of the 8th ACM International Conference on Bioinformatics, Computational Biology,and Health Informatics},
 comments = { The described method is neither general, nor focused on NLP},
 doi = {10.1145/3107411.3107445},
 isbn = {978-1-4503-4722-8},
 keywords = {attention, deep learning, electronic health records, health care, interpretability, recurrent neural networks, visualization},
 location = {Boston, Massachusetts, USA},
 numpages = {8},
 pages = {233--240},
 publisher = {ACM},
 series = {ACM-BCB '17},
 title = {Interpretable Predictions of Clinical Outcomes with An Attention-based Recurrent Neural Network},
 url = {http://doi.acm.org/10.1145/3107411.3107445},
 year = {2017}
}

@article{Shao:2013:ICS:2461912.2462003,
 acmid = {2462003},
 address = {New York, NY, USA},
 articleno = {56},
 author = {Shao, Tianjia and Li, Wilmot and Zhou, Kun and Xu, Weiwei and Guo, Baining and Mitra, Niloy J.},
 comments = { The publication does not focus on explainability},
 doi = {10.1145/2461912.2462003},
 issn = {0730-0301},
 issue_date = {July 2013},
 journal = {ACM Trans. Graph.},
 keywords = {NPR, concept sketch, part relations, product design, shape analysis},
 month = {July},
 number = {4},
 numpages = {10},
 pages = {56:1--56:10},
 publisher = {ACM},
 title = {Interpreting Concept Sketches},
 url = {http://doi.acm.org/10.1145/2461912.2462003},
 volume = {32},
 year = {2013}
}

@article{sharpee25thAnnualComputational2016,
 abstract = {Table of contentsA1 Functional advantages of cell-type heterogeneity in neural circuitsTatyana O. SharpeeA2 Mesoscopic modeling of propagating waves in visual cortexAlain DestexheA3 Dynamics and biomarkers of mental disordersMitsuo KawatoF1 Precise recruitment of spiking output at theta frequencies requires dendritic h-channels in multi-compartment models of oriens-lacunosum/moleculare hippocampal interneuronsVladislav Sekuli\'c, Frances K. SkinnerF2 Kernel methods in reconstruction of current sources from extracellular potentials for single cells and the whole brainsDaniel K. W\'ojcik, Chaitanya Chintaluri, Dorottya Cserp\'an, Zolt\'an Somogyv\'ariF3 The synchronized periods depend on intracellular transcriptional repression mechanisms in circadian clocks.Jae Kyoung Kim, Zachary P. Kilpatrick, Matthew R. Bennett, Kresimir Josi\'cO1 Assessing irregularity and coordination of spiking-bursting rhythms in central pattern generatorsIrene Elices, David Arroyo, Rafael Levi, Francisco B. Rodriguez, Pablo VaronaO2 Regulation of top-down processing by cortically-projecting parvalbumin positive neurons in basal forebrainEunjin Hwang, Bowon Kim, Hio-Been Han, Tae Kim, James T. McKenna, Ritchie E. Brown, Robert W. McCarley, Jee Hyun ChoiO3 Modeling auditory stream segregation, build-up and bistabilityJames Rankin, Pamela Osborn Popp, John RinzelO4 Strong competition between tonotopic neural ensembles explains pitch-related dynamics of auditory cortex evoked fieldsAlejandro Tabas, Andr\'e Rupp, Emili Balaguer-BallesterO5 A simple model of retinal response to multi-electrode stimulationMatias I. Maturana, David B. Grayden, Shaun L. Cloherty, Tatiana Kameneva, Michael R. Ibbotson, Hamish MeffinO6 Noise correlations in V4 area correlate with behavioral performance in visual discrimination taskVeronika Koren, Timm Lochmann, Valentin Dragoi, Klaus ObermayerO7 Input-location dependent gain modulation in cerebellar nucleus neuronsMaria Psarrou, Maria Schilstra, Neil Davey, Benjamin Torben-Nielsen, Volker SteuberO8 Analytic solution of cable energy function for cortical axons and dendritesHuiwen Ju, Jiao Yu, Michael L. Hines, Liang Chen, Yuguo YuO9 C. elegans interactome: interactive visualization of Caenorhabditis elegans worm neuronal networkJimin Kim, Will Leahy, Eli ShlizermanO10 Is the model any good? Objective criteria for computational neuroscience model selectionJustas Birgiolas, Richard C. Gerkin, Sharon M. CrookO11 Cooperation and competition of gamma oscillation mechanismsAtthaphon Viriyopase, Raoul-Martin Memmesheimer, Stan GielenO12 A discrete structure of the brain wavesYuri Dabaghian, Justin DeVito, Luca PerottiO13 Direction-specific silencing of the Drosophila gaze stabilization systemAnmo J. Kim, Lisa M. Fenk, Cheng Lyu, Gaby MaimonO14 What does the fruit fly think about values? A model of olfactory associative learningChang Zhao, Yves Widmer, Simon Sprecher,Walter SennO15 Effects of ionic diffusion on power spectra of local field potentials (LFP)Geir Halnes, Tuomo M\"aki-Marttunen, Daniel Keller, Klas H. Pettersen,Ole A. Andreassen, Gaute T. EinevollO16 Large-scale cortical models towards understanding relationship between brain structure abnormalities and cognitive deficitsYasunori YamadaO17 Spatial coarse-graining the brain: origin of minicolumnsMoira L. Steyn-Ross, D. Alistair Steyn-RossO18 Modeling large-scale cortical networks with laminar structureJorge F. Mejias, John D. Murray, Henry Kennedy, Xiao-Jing WangO19 Information filtering by partial synchronous spikes in a neural populationAlexandra Kruscha, Jan Grewe, Jan Benda, Benjamin LindnerO20 Decoding context-dependent olfactory valence in Drosophila Laurent Badel, Kazumi Ohta, Yoshiko Tsuchimoto, Hokto KazamaP1 Neural network as a scale-free network: the role of a hubB. KahngP2 Hemodynamic responses to emotions and decisions using near-infrared spectroscopy optical imagingNicoladie D. TamP3 Phase space analysis of hemodynamic responses to intentional movement directions using functional near-infrared spectroscopy (fNIRS) optical imaging techniqueNicoladie D.Tam, Luca Pollonini, George ZouridakisP4 Modeling jamming avoidance of weakly electric fishJaehyun Soh, DaeEun KimP5 Synergy and redundancy of retinal ganglion cells in predictionMinsu Yoo, S. E. PalmerP6 A neural field model with a third dimension representing cortical depthViviana Culmone, Ingo BojakP7 Network analysis of a probabilistic connectivity model of the Xenopus tadpole spinal cordAndrea Ferrario, Robert Merrison-Hort, Roman BorisyukP8 The recognition dynamics in the brainChang Sub KimP9 Multivariate spike train analysis using a positive definite kernelTaro TezukaP10 Synchronization of burst periods may govern slow brain dynamics during general anesthesiaPangyu JooP11 The ionic basis of heterogeneity affects stochastic synchronyYoung-Ah Rho, Shawn D. Burton, G. Bard Ermentrout, Jaeseung Jeong, Nathaniel N. UrbanP12 Circular statistics of noise in spike trains with a periodic componentPetr MarsalekP14 Representations of directions in EEG-BCI using Gaussian readoutsHoon-Hee Kim, Seok-hyun Moon, Do-won Lee, Sung-beom Lee, Ji-yong Lee, Jaeseung JeongP15 Action selection and reinforcement learning in basal ganglia during reaching movementsYaroslav I. Molkov, Khaldoun Hamade, Wondimu Teka, William H. Barnett, Taegyo Kim, Sergey Markin, Ilya A. RybakP17 Axon guidance: modeling axonal growth in T-Junction assayCsaba Forro, Harald Dermutz, L\'aszl\'o Demk\'o, J\'anos V\"or\"osP19 Transient cell assembly networks encode persistent spatial memoriesYuri Dabaghian, Andrey BabichevP20 Theory of population coupling and applications to describe high order correlations in large populations of interacting neuronsHaiping HuangP21 Design of biologically-realistic simulations for motor controlSergio Verduzco-FloresP22 Towards understanding the functional impact of the behavioural variability of neuronsFilipa Dos Santos, Peter AndrasP23 Different oscillatory dynamics underlying gamma entrainment deficits in schizophreniaChristoph Metzner, Achim Schweikard, Bartosz ZurowskiP24 Memory recall and spike frequency adaptationJames P. Roach, Leonard M. Sander, Michal R. ZochowskiP25 Stability of neural networks and memory consolidation preferentially occur near criticalityQuinton M. Skilling, Nicolette Ognjanovski, Sara J. Aton, Michal ZochowskiP26 Stochastic Oscillation in Self-Organized Critical States of Small Systems: Sensitive Resting State in Neural SystemsSheng-Jun Wang, Guang Ouyang, Jing Guang, Mingsha Zhang, K. Y. Michael Wong, Changsong ZhouP27 Neurofield: a C++ library for fast simulation of 2D neural field modelsPeter A. Robinson, Paula Sanz-Leon, Peter M. Drysdale, Felix Fung, Romesh G. Abeysuriya, Chris J. Rennie, Xuelong ZhaoP28 Action-based grounding: Beyond encoding/decoding in neural codeYoonsuck Choe, Huei-Fang YangP29 Neural computation in a dynamical system with multiple time scalesYuanyuan Mi, Xiaohan Lin, Si WuP30 Maximum entropy models for 3D layouts of orientation selectivityJoscha Liedtke, Manuel Schottdorf, Fred WolfP31 A behavioral assay for probing computations underlying curiosity in rodentsYoriko Yamamura, Jeffery R. WickensP32 Using statistical sampling to balance error function contributions to optimization of conductance-based modelsTimothy Rumbell, Julia Ramsey, Amy Reyes, Danel Dragulji\'c, Patrick R. Hof, Jennifer Luebke, Christina M. WeaverP33 Exploration and implementation of a self-growing and self-organizing neuron network building algorithmHu He, Xu Yang, Hailin Ma, Zhiheng Xu, Yuzhe WangP34 Disrupted resting state brain network in obese subjects: a data-driven graph theory analysisKwangyeol Baek, Laurel S. Morris, Prantik Kundu, Valerie VoonP35 Dynamics of cooperative excitatory and inhibitory plasticityEverton J. Agnes, Tim P. VogelsP36 Frequency-dependent oscillatory signal gating in feed-forward networks of integrate-and-fire neuronsWilliam F. Podlaski, Tim P. VogelsP37 Phenomenological neural model for adaptation of neurons in area ITMartin Giese, Pradeep Kuravi, Rufin VogelsP38 ICGenealogy: towards a common topology of neuronal ion channel function and genealogy in model and experimentAlexander Seeholzer, William Podlaski, Rajnish Ranjan, Tim VogelsP39 Temporal input discrimination from the interaction between dynamic synapses and neural subthreshold oscillationsJoaquin J. Torres, Fabiano Baroni, Roberto Latorre, Pablo VaronaP40 Different roles for transient and sustained activity during active visual processingBart Gips, Eric Lowet, Mark J. Roberts, Peter de Weerd, Ole Jensen, Jan van der EerdenP41 Scale-free functional networks of 2D Ising model are highly robust against structural defects: neuroscience implicationsAbdorreza Goodarzinick, Mohammad D. Niry, Alireza ValizadehP42 High frequency neuron can facilitate propagation of signal in neural networksAref Pariz, Shervin S. Parsi, Alireza ValizadehP43 Investigating the effect of Alzheimer's disease related amyloidopathy on gamma oscillations in the CA1 region of the hippocampusJulia M. Warburton, Lucia Marucci, Francesco Tamagnini, Jon Brown, Krasimira Tsaneva-AtanasovaP44 Long-tailed distributions of inhibitory and excitatory weights in a balanced network with eSTDP and iSTDPFlorence I. Kleberg, Jochen TrieschP45 Simulation of EMG recording from hand muscle due to TMS of motor cortexBahar Moezzi, Nicolangelo Iannella, Natalie Schaworonkow, Lukas Plogmacher, Mitchell R. Goldsworthy, Brenton Hordacre, Mark D. McDonnell, Michael C. Ridding, Jochen TrieschP46 Structure and dynamics of axon network formed in primary cell cultureMartin Zapotocky, Daniel Smit, Coralie Fouquet, Alain TrembleauP47 Efficient signal processing and sampling in random networks that generate variabilitySakyasingha Dasgupta, Isao Nishikawa, Kazuyuki Aihara, Taro ToyoizumiP48 Modeling the effect of riluzole on bursting in respiratory neural networksDaniel T. Robb, Nick Mellen, Natalia ToporikovaP49 Mapping relaxation training using effective connectivity analysisRongxiang Tang, Yi-Yuan TangP50 Modeling neuron oscillation of implicit sequence learningGuangsheng Liang, Seth A. Kiser, James H. Howard, Jr., Yi-Yuan TangP51 The role of cerebellar short-term synaptic plasticity in the pathology and medication of downbeat nystagmusJulia Goncharenko, Neil Davey, Maria Schilstra, Volker SteuberP52 Nonlinear response of noisy neuronsSergej O. Voronenko, Benjamin LindnerP53 Behavioral embedding suggests multiple chaotic dimensions underlie C. elegans locomotionTosif Ahamed, Greg StephensP54 Fast and scalable spike sorting for large and dense multi-electrodes recordingsPierre Yger, Baptiste Lefebvre, Giulia Lia Beatrice Spampinato, Elric Esposito, Marcel Stimberg et Olivier MarreP55 Sufficient sampling rates for fast hand motion trackingHansol Choi, Min-Ho SongP56 Linear readout of object manifoldsSueYeon Chung, Dan D. Lee, Haim SompolinskyP57 Differentiating models of intrinsic bursting and rhythm generation of the respiratory pre-B\"otzinger complex using phase response curvesRyan S. Phillips, Jeffrey SmithP58 The effect of inhibitory cell network interactions during theta rhythms on extracellular field potentials in CA1 hippocampusAlexandra Pierri Chatzikalymniou, Katie Ferguson, Frances K. SkinnerP59 Expansion recoding through sparse sampling in the cerebellar input layer speeds learningN. Alex Cayco Gajic, Claudia Clopath, R. Angus SilverP60 A set of curated cortical models at multiple scales on Open Source BrainPadraig Gleeson, Boris Marin, Sadra Sadeh, Adrian Quintana, Matteo Cantarelli, Salvador Dura-Bernal, William W. Lytton, Andrew Davison, R. Angus SilverP61 A synaptic story of dynamical information encoding in neural adaptationLuozheng Li, Wenhao Zhang, Yuanyuan Mi, Dahui Wang, Si WuP62 Physical modeling of rule-observant rodent behaviorYoungjo Song, Sol Park, Ilhwan Choi, Jaeseung Jeong, Hee-sup ShinP64 Predictive coding in area V4 and prefrontal cortex explains dynamic discrimination of partially occluded shapesHannah Choi, Anitha Pasupathy, Eric Shea-BrownP65 Stability of FORCE learning on spiking and rate-based networksDongsung Huh, Terrence J. SejnowskiP66 Stabilising STDP in striatal neurons for reliable fast state recognition in noisy environmentsSimon M. Vogt, Arvind Kumar, Robert SchmidtP67 Electrodiffusion in one- and two-compartment neuron models for characterizing cellular effects of electrical stimulationStephen Van Wert, Steven J. SchiffP68 STDP improves speech recognition capabilities in spiking recurrent circuits parameterized via differential evolution Markov Chain Monte CarloRichard Veale, Matthias ScheutzP69 Bidirectional transformation between dominant cortical neural activities and phase difference distributionsSang Wan LeeP70 Maturation of sensory networks through homeostatic structural plasticityJ\'ulia Gallinaro, Stefan RotterP71 Corticothalamic dynamics: structure, number of solutions and stability of steady-state solutions in the space of synaptic couplingsPaula Sanz-Leon, Peter A. RobinsonP72 Optogenetic versus electrical stimulation of the parkinsonian basal ganglia. Computational studyLeonid L. Rubchinsky, Chung Ching Cheung, Shivakeshavan Ratnadurai-GiridharanP73 Exact spike-timing distribution reveals higher-order interactions of neuronsSafura Rashid Shomali, Majid Nili Ahmadabadi, Hideaki Shimazaki, S. Nader RasuliP74 Neural mechanism of visual perceptual learning using a multi-layered neural networkXiaochen Zhao, Malte J. RaschP75 Inferring collective spiking dynamics from mostly unobserved systemsJens Wilting, Viola PriesemannP76 How to infer distributions in the brain from subsampled observationsAnna Levina, Viola PriesemannP77 Influences of embedding and estimation strategies on the inferred memory of single spiking neuronsLucas Rudelt, Joseph T. Lizier, Viola PriesemannP78 A nearest-neighbours based estimator for transfer entropy between spike trainsJoseph T. Lizier, Richard E. Spinney, Mikail Rubinov, Michael Wibral, Viola PriesemannP79 Active learning of psychometric functions with multinomial logistic modelsJi Hyun Bak, Jonathan PillowP81 Inferring low-dimensional network dynamics with variational latent Gaussian processYuan Zaho, Il Memming ParkP82 Computational investigation of energy landscapes in the resting state subcortical brain networkJiyoung Kang, Hae-Jeong ParkP83 Local repulsive interaction between retinal ganglion cells can generate a consistent spatial periodicity of orientation mapJaeson Jang, Se-Bum PaikP84 Phase duration of bistable perception reveals intrinsic time scale of perceptual decision under noisy conditionWoochul Choi, Se-Bum PaikP85 Feedforward convergence between retina and primary visual cortex can determine the structure of orientation mapChangju Lee, Jaeson Jang, Se-Bum PaikP86 Computational method classifying neural network activity patterns for imaging dataMin Song, Hyeonsu Lee, Se-Bum PaikP87 Symmetry of spike-timing-dependent-plasticity kernels regulates volatility of memoryYoungjin Park, Woochul Choi, Se-Bum PaikP88 Effects of time-periodic coupling strength on the first-spike latency dynamics of a scale-free network of stochastic Hodgkin-Huxley neuronsErgin Yilmaz, Veli Baysal, Mahmut OzerP89 Spectral properties of spiking responses in V1 and V4 change within the trial and are highly relevant for behavioral performanceVeronika Koren, Klaus ObermayerP90 Methods for building accurate models of individual neuronsDaniel Saska, Thomas NowotnyP91 A full size mathematical model of the early olfactory system of honeybeesHo Ka Chan, Alan Diamond, Thomas NowotnyP92 Stimulation-induced tuning of ongoing oscillations in spiking neural networksChristoph S. Herrmann, Micah M. Murray, Silvio Ionta, Axel Hutt, J\'er\'emie LefebvreP93 Decision-specific sequences of neural activity in balanced random networks driven by structured sensory inputPhilipp Weidel, Renato Duarte, Abigail MorrisonP94 Modulation of tuning induced by abrupt reduction of SST cell activityJung H. Lee, Ramakrishnan Iyer, Stefan MihalasP95 The functional role of VIP cell activation during locomotionJung H. Lee, Ramakrishnan Iyer, Christof Koch, Stefan MihalasP96 Stochastic inference with spiking neural networksMihai A. Petrovici, Luziwei Leng, Oliver Breitwieser, David St\"ockel, Ilja Bytschok, Roman Martel, Johannes Bill, Johannes Schemmel, Karlheinz MeierP97 Modeling orientation-selective electrical stimulation with retinal prosthesesTimothy B. Esler, Anthony N. Burkitt, David B. Grayden, Robert R. Kerr, Bahman Tahayori, Hamish MeffinP98 Ion channel noise can explain firing correlation in auditory nervesBahar Moezzi, Nicolangelo Iannella, Mark D. McDonnellP99 Limits of temporal encoding of thalamocortical inputs in a neocortical microcircuitMax Nolte, Michael W. Reimann, Eilif Muller, Henry MarkramP100 On the representation of arm reaching movements: a computational modelAntonio Parziale, Rosa Senatore, Angelo MarcelliP101 A computational model for investigating the role of cerebellum in acquisition and retention of motor behaviorRosa Senatore, Antonio Parziale, Angelo MarcelliP102 The emergence of semantic categories from a large-scale brain network of semantic knowledgeK. Skiker, M. MaoueneP103 Multiscale modeling of M1 multitarget pharmacotherapy for dystoniaSamuel A. Neymotin, Salvador Dura-Bernal, Alexandra Seidenstein, Peter Lakatos, Terence D. Sanger, William W. LyttonP104 Effect of network size on computational capacitySalvador Dura-Bernal, Rosemary J. Menzies, Campbell McLauchlan, Sacha J. van Albada, David J. Kedziora, Samuel Neymotin, William W. Lytton, Cliff C. KerrP105 NetPyNE: a Python package for NEURON to facilitate development and parallel simulation of biological neuronal networksSalvador Dura-Bernal, Benjamin A. Suter, Samuel A. Neymotin, Cliff C. Kerr, Adrian Quintana, Padraig Gleeson, Gordon M. G. Shepherd, William W. LyttonP107 Inter-areal and inter-regional inhomogeneity in co-axial anisotropy of Cortical Point Spread in human visual areasJuhyoung Ryu, Sang-Hun LeeP108 Two bayesian quanta of uncertainty explain the temporal dynamics of cortical activity in the non-sensory areas during bistable perceptionJoonwon Lee, Sang-Hun LeeP109 Optimal and suboptimal integration of sensory and value information in perceptual decision makingHyang Jung Lee, Sang-Hun LeeP110 A Bayesian algorithm for phoneme Perception and its neural implementationDaeseob Lim, Sang-Hun LeeP111 Complexity of EEG signals is reduced during unconsciousness induced by ketamine and propofolJisung Wang, Heonsoo LeeP112 Self-organized criticality of neural avalanche in a neural model on complex networksNam Jung, Le Anh Quang, Seung Eun Maeng, Tae Ho Lee, Jae Woo LeeP113 Dynamic alterations in connection topology of the hippocampal network during ictal-like epileptiform activity in an in vitro rat modelChang-hyun Park, Sora Ahn, Jangsup Moon, Yun Seo Choi, Juhee Kim, Sang Beom Jun, Seungjun Lee, Hyang Woon LeeP114 Computational model to replicate seizure suppression effect by electrical stimulationSora Ahn, Sumin Jo, Eunji Jun, Suin Yu, Hyang Woon Lee, Sang Beom Jun, Seungjun LeeP115 Identifying excitatory and inhibitory synapses in neuronal networks from spike trains using sorted local transfer entropyFelix Goetze, Pik-Yin LaiP116 Neural network model for obstacle avoidance based on neuromorphic computational model of boundary vector cell and head direction cellSeonghyun Kim, Jeehyun KwagP117 Dynamic gating of spike pattern propagation by Hebbian and anti-Hebbian spike timing-dependent plasticity in excitatory feedforward network modelHyun Jae Jang, Jeehyun KwagP118 Inferring characteristics of input correlations of cells exhibiting up-down state transitions in the rat striatumMarko Filipovi\'c, Ramon Reig, Ad Aertsen, Gilad Silberberg, Arvind KumarP119 Graph properties of the functional connected brain under the influence of Alzheimer's diseaseClaudia Bachmann, Simone Buttler, Heidi Jacobs, Kim Dillen, Gereon R. Fink, Juraj Kukolja, Abigail MorrisonP120 Learning sparse representations in the olfactory bulbDaniel Kepple, Hamza Giaffar, Dima Rinberg, Steven Shea, Alex KoulakovP121 Functional classification of homologous basal-ganglia networksJyotika Bahuguna,Tom Tetzlaff, Abigail Morrison, Arvind Kumar, Jeanette Hellgren KotaleskiP122 Short term memory based on multistabilityTim Kunze, Andre Peterson, Thomas Kn\"oscheP123 A physiologically plausible, computationally efficient model and simulation software for mammalian motor unitsMinjung Kim, Hojeong KimP125 Decoding laser-induced somatosensory information from EEGJi Sung Park, Ji Won Yeon, Sung-Phil KimP126 Phase synchronization of alpha activity for EEG-based personal authenticationJae-Hwan Kang, Chungho Lee, Sung-Phil KimP129 Investigating phase-lags in sEEG data using spatially distributed time delays in a large-scale brain network modelAndreas Spiegler, Spase Petkoski, Matias J. Palva, Viktor K. JirsaP130 Epileptic seizures in the unfolding of a codimension-3 singularityMaria L. Saggio, Silvan F. Siep, Andreas Spiegler, William C. Stacey, Christophe Bernard, Viktor K. JirsaP131 Incremental dimensional exploratory reasoning under multi-dimensional environmentOh-hyeon Choung, Yong JeongP132 A low-cost model of eye movements and memory in personal visual cognitionYong-il Lee, Jaeseung JeongP133 Complex network analysis of structural connectome of autism spectrum disorder patientsSu Hyun Kim, Mir Jeong, Jaeseung JeongP134 Cognitive motives and the neural correlates underlying human social information transmission, gossipJeungmin Lee, Jaehyung Kwon, Jerald D. Kralik, Jaeseung JeongP135 EEG hyperscanning detects neural oscillation for the social interaction during the economic decision-makingJaehwan Jahng, Dong-Uk Hwang, Jaeseung JeongP136 Detecting purchase decision based on hyperfrontality of the EEGJae-Hyung Kwon, Sang-Min Park, Jaeseung JeongP137 Vulnerability-based critical neurons, synapses, and pathways in the Caenorhabditis elegans connectomeSeongkyun Kim, Hyoungkyu Kim, Jerald D. Kralik, Jaeseung JeongP138 Motif analysis reveals functionally asymmetrical neurons in C. elegans Pyeong Soo Kim, Seongkyun Kim, Hyoungkyu Kim, Jaeseung JeongP139 Computational approach to preference-based serial decision dynamics: do temporal discounting and working memory affect it?Sangsup Yoon, Jaehyung Kwon, Sewoong Lim, Jaeseung JeongP141 Social stress induced neural network reconfiguration affects decision making and learning in zebrafishChoongseok Park, Thomas Miller, Katie Clements, Sungwoo Ahn, Eoon Hye Ji, Fadi A. IssaP142 Descriptive, generative, and hybrid approaches for neural connectivity inference from neural activity dataJeongHun Baek, Shigeyuki Oba, Junichiro Yoshimoto, Kenji Doya, Shin IshiiP145 Divergent-convergent synaptic connectivities accelerate coding in multilayered sensory systemsThiago S. Mosqueiro, Martin F. Strube-Bloss, Brian Smith, Ramon HuertaP146 Swinging networksMichal Hadrava, Jaroslav HlinkaP147 Inferring dynamically relevant motifs from oscillatory stimuli: challenges, pitfalls, and solutionsHannah Bos, Moritz HeliasP148 Spatiotemporal mapping of brain network dynamics during cognitive tasks using magnetoencephalography and deep learningCharles M. Welzig, Zachary J. HarperP149 Multiscale complexity analysis for the segmentation of MRI imagesWon Sup Kim, In-Seob Shin, Hyeon-Man Baek, Seung Kee HanP150 A neuro-computational model of emotional attentionRen\'e Richter, Julien Vitay, Frederick Beuth, Fred H. HamkerP151 Multi-site delayed feedback stimulation in parkinsonian networksKelly Toppin, Yixin GuoP152 Bistability in Hodgkin\textendash{}Huxley-type equationsTatiana Kameneva, Hamish Meffin, Anthony N. Burkitt, David B. GraydenP153 Phase changes in postsynaptic spiking due to synaptic connectivity and short term plasticity: mathematical analysis of frequency dependencyMark D. McDonnell, Bruce P. GrahamP154 Quantifying resilience patterns in brain networks: the importance of directionalityPenelope J. Kale, Leonardo L. GolloP155 Dynamics of rate-model networks with separate excitatory and inhibitory populationsMerav Stern, L. F. AbbottP156 A model for multi-stable dynamics in action recognition modulated by integration of silhouette and shading cuesLeonid A. Fedorov, Martin A. GieseP157 Spiking model for the interaction between action recognition and action executionMohammad Hovaidi Ardestani, Martin GieseP158 Surprise-modulated belief update: how to learn within changing environments?Mohammad Javad Faraji, Kerstin Preuschoff, Wulfram GerstnerP159 A fast, stochastic and adaptive model of auditory nerve responses to cochlear implant stimulationMargriet J. van Gendt, Jeroen J. Briaire, Randy K. Kalkman, Johan H. M. FrijnsP160 Quantitative comparison of graph theoretical measures of simulated and empirical functional brain networksWon Hee Lee, Sophia FrangouP161 Determining discriminative properties of fMRI signals in schizophrenia using highly comparative time-series analysisBen D. Fulcher, Patricia H. P. Tran, Alex FornitoP162 Emergence of narrowband LFP oscillations from completely asynchronous activity during seizures and high-frequency oscillationsStephen V. Gliske, William C. Stacey, Eugene Lim, Katherine A. Holman, Christian G. FinkP163 Neuronal diversity in structure and function: cross-validation of anatomical and physiological classification of retinal ganglion cells in the mouseJinseop S. Kim, Shang Mu, Kevin L. Briggman, H. Sebastian Seung, the EyeWirersP164 Analysis and modelling of transient firing rate changes in area MT in response to rapid stimulus feature changesDetlef Wegener, Lisa Bohnenkamp, Udo A. ErnstP165 Step-wise model fitting accounting for high-resolution spatial measurements: construction of a layer V pyramidal cell model with reduced morphologyTuomo M\"aki-Marttunen, Geir Halnes, Anna Devor, Christoph Metzner, Anders M. Dale, Ole A. Andreassen, Gaute T. EinevollP166 Contributions of schizophrenia-associated genes to neuron firing and cardiac pacemaking: a polygenic modeling approachTuomo M\"aki-Marttunen, Glenn T. Lines, Andy Edwards, Aslak Tveito, Anders M. Dale, Gaute T. Einevoll, Ole A. AndreassenP167 Local field potentials in a 4 \texttimes{} 4 mm2 multi-layered network modelEspen Hagen, Johanna Senk, Sacha J. van Albada, Markus DiesmannP168 A spiking network model explains multi-scale properties of cortical dynamicsMaximilian Schmidt, Rembrandt Bakker, Kelly Shen, Gleb Bezgin, Claus-Christian Hilgetag, Markus Diesmann, Sacha Jennifer van AlbadaP169 Using joint weight-delay spike-timing dependent plasticity to find polychronous neuronal groupsHaoqi Sun, Olga Sourina, Guang-Bin Huang, Felix Klanner, Cornelia DenkP170 Tensor decomposition reveals RSNs in simulated resting state fMRIKatharina Glomb, Adri\'an Ponce-Alvarez, Matthieu Gilson, Petra Ritter, Gustavo DecoP171 Getting in the groove: testing a new model-based method for comparing task-evoked vs resting-state activity in fMRI data on music listeningMatthieu Gilson, Maria AG Witek, Eric F. Clarke, Mads Hansen, Mikkel Wallentin, Gustavo Deco, Morten L. Kringelbach, Peter VuustP172 STochastic engine for pathway simulation (STEPS) on massively parallel processorsGuido Klingbeil, Erik De SchutterP173 Toolkit support for complex parallel spatial stochastic reaction\textendash{}diffusion simulation in STEPSWeiliang Chen, Erik De SchutterP174 Modeling the generation and propagation of Purkinje cell dendritic spikes caused by parallel fiber synaptic inputYunliang Zang, Erik De SchutterP175 Dendritic morphology determines how dendrites are organized into functional subunitsSungho Hong, Akira Takashima, Erik De SchutterP176 A model of Ca2+/calmodulin-dependent protein kinase II activity in long term depression at Purkinje cellsCriseida Zamora, Andrew R. Gallimore, Erik De SchutterP177 Reward-modulated learning of population-encoded vectors for insect-like navigation in embodied agentsDennis Goldschmidt, Poramate Manoonpong, Sakyasingha DasguptaP178 Data-driven neural models part II: connectivity patterns of human seizuresPhilippa J. Karoly, Dean R. Freestone, Daniel Soundry, Levin Kuhlmann, Liam Paninski, Mark CookP179 Data-driven neural models part I: state and parameter estimationDean R. Freestone, Philippa J. Karoly, Daniel Soundry, Levin Kuhlmann, Mark CookP180 Spectral and spatial information processing in human auditory streamingJaejin Lee, Yonatan I. Fishman, Yale E. CohenP181 A tuning curve for the global effects of local perturbations in neural activity: Mapping the systems-level susceptibility of the brainLeonardo L. Gollo, James A. Roberts, Luca CocchiP182 Diverse homeostatic responses to visual deprivation mediated by neural ensemblesYann Sweeney, Claudia ClopathP183 Opto-EEG: a novel method for investigating functional connectome in mouse brain based on optogenetics and high density electroencephalographySoohyun Lee, Woo-Sung Jung, Jee Hyun ChoiP184 Biphasic responses of frontal gamma network to repetitive sleep deprivation during REM sleepBowon Kim, Youngsoo Kim, Eunjin Hwang, Jee Hyun ChoiP185 Brain-state correlate and cortical connectivity for frontal gamma oscillations in top-down fashion assessed by auditory steady-state responseYounginha Jung, Eunjin Hwang, Yoon-Kyu Song, Jee Hyun ChoiP186 Neural field model of localized orientation selective activation in V1James Rankin, Fr\'ed\'eric ChavaneP187 An oscillatory network model of Head direction and Grid cells using locomotor inputsKarthik Soman, Vignesh Muralidharan, V. Srinivasa ChakravarthyP188 A computational model of hippocampus inspired by the functional architecture of basal gangliaKarthik Soman, Vignesh Muralidharan, V. Srinivasa ChakravarthyP189 A computational architecture to model the microanatomy of the striatum and its functional propertiesSabyasachi Shivkumar, Vignesh Muralidharan, V. Srinivasa ChakravarthyP190 A scalable cortico-basal ganglia model to understand the neural dynamics of targeted reachingVignesh Muralidharan, Alekhya Mandali, B. Pragathi Priyadharsini, Hima Mehta, V. Srinivasa ChakravarthyP191 Emergence of radial orientation selectivity from synaptic plasticityCatherine E. Davey, David B. Grayden, Anthony N. BurkittP192 How do hidden units shape effective connections between neurons?Braden A. W. Brinkman, Tyler Kekona, Fred Rieke, Eric Shea-Brown, Michael BuiceP193 Characterization of neural firing in the presence of astrocyte-synapse signalingMaurizio De Pitt\`a, Hugues Berry, Nicolas BrunelP194 Metastability of spatiotemporal patterns in a large-scale network model of brain dynamicsJames A. Roberts, Leonardo L. Gollo, Michael BreakspearP195 Comparison of three methods to quantify detection and discrimination capacity estimated from neural population recordingsGary Marsat, Jordan Drew, Phillip D. Chapman, Kevin C. Daly, Samual P. BradleyP196 Quantifying the constraints for independent evoked and spontaneous NMDA receptor mediated synaptic transmission at individual synapsesSat Byul Seo, Jianzhong Su, Ege T. Kavalali, Justin BlackwellP199 Gamma oscillation via adaptive exponential integrate-and-fire neuronsLieJune Shiau, Laure Buhry, Kanishka BasnayakeP200 Visual face representations during memory retrieval compared to perceptionSue-Hyun Lee, Brandon A. Levy, Chris I. BakerP201 Top-down modulation of sequential activity within packets modeled using avalanche dynamicsTimoth\'ee Leleu, Kazuyuki AiharaQ28 An auto-encoder network realizes sparse features under the influence of desynchronized vascular dynamicsRyan T. Philips, Karishma Chhabria, V. Srinivasa Chakravarthy},
 author = {Sharpee, Tatyana O. and Destexhe, Alain and Kawato, Mitsuo and Sekuli\'c, Vladislav and Skinner, Frances K. and W\'ojcik, Daniel K. and Chintaluri, Chaitanya and Cserp\'an, Dorottya and Somogyv\'ari, Zolt\'an and Kim, Jae Kyoung and Kilpatrick, Zachary P. and Bennett, Matthew R. and Josi\'c, Kresimir and Elices, Irene and Arroyo, David and Levi, Rafael and Rodriguez, Francisco B. and Varona, Pablo and Hwang, Eunjin and Kim, Bowon and Han, Hio-Been and Kim, Tae and McKenna, James T. and Brown, Ritchie E. and McCarley, Robert W. and Choi, Jee Hyun and Rankin, James and Popp, Pamela Osborn and Rinzel, John and Tabas, Alejandro and Rupp, Andr\'e and {Balaguer-Ballester}, Emili and Maturana, Matias I. and Grayden, David B. and Cloherty, Shaun L. and Kameneva, Tatiana and Ibbotson, Michael R. and Meffin, Hamish and Koren, Veronika and Lochmann, Timm and Dragoi, Valentin and Obermayer, Klaus and Psarrou, Maria and Schilstra, Maria and Davey, Neil and {Torben-Nielsen}, Benjamin and Steuber, Volker and Ju, Huiwen and Yu, Jiao and Hines, Michael L. and Chen, Liang and Yu, Yuguo and Kim, Jimin and Leahy, Will and Shlizerman, Eli and Birgiolas, Justas and Gerkin, Richard C. and Crook, Sharon M. and Viriyopase, Atthaphon and Memmesheimer, Raoul-Martin and Gielen, Stan and Dabaghian, Yuri and DeVito, Justin and Perotti, Luca and Kim, Anmo J. and Fenk, Lisa M. and Cheng, Cheng and Maimon, Gaby and Zhao, Chang and Widmer, Yves and Sprecher, Simon and Senn, Walter and Halnes, Geir and {M\"aki-Marttunen}, Tuomo and Keller, Daniel and Pettersen, Klas H. and Andreassen, Ole A. and Einevoll, Gaute T. and Yamada, Yasunori and {Steyn-Ross}, Moira L. and {Alistair Steyn-Ross}, D. and Mejias, Jorge F. and Murray, John D. and Kennedy, Henry and Wang, Xiao-Jing and Kruscha, Alexandra and Grewe, Jan and Benda, Jan and Lindner, Benjamin and Badel, Laurent and Ohta, Kazumi and Tsuchimoto, Yoshiko and Kazama, Hokto and Kahng, B. and Tam, Nicoladie D. and Pollonini, Luca and Zouridakis, George and Soh, Jaehyun and Kim, DaeEun and Yoo, Minsu and Palmer, S. E. and Culmone, Viviana and Bojak, Ingo and Ferrario, Andrea and {Merrison-Hort}, Robert and Borisyuk, Roman and Kim, Chang Sub and Tezuka, Taro and Joo, Pangyu and Rho, Young-Ah and Burton, Shawn D. and Bard Ermentrout, G. and Jeong, Jaeseung and Urban, Nathaniel N. and Marsalek, Petr and Kim, Hoon-Hee and Moon, Seok-hyun and Lee, Do-won and Lee, Sung-beom and Lee, Ji-yong and Molkov, Yaroslav I. and Hamade, Khaldoun and Teka, Wondimu and Barnett, William H. and Kim, Taegyo and Markin, Sergey and Rybak, Ilya A. and Forro, Csaba and Dermutz, Harald and Demk\'o, L\'aszl\'o and V\"or\"os, J\'anos and Babichev, Andrey and Huang, Haiping and {Verduzco-Flores}, Sergio and Dos Santos, Filipa and Andras, Peter and Metzner, Christoph and Schweikard, Achim and Zurowski, Bartosz and Roach, James P. and Sander, Leonard M. and Zochowski, Michal R. and Skilling, Quinton M. and Ognjanovski, Nicolette and Aton, Sara J. and Zochowski, Michal and Wang, Sheng-Jun and Ouyang, Guang and Guang, Jing and Zhang, Mingsha and Michael Wong, K. Y. and Zhou, Changsong and Robinson, Peter A. and {Sanz-Leon}, Paula and Drysdale, Peter M. and Fung, Felix and Abeysuriya, Romesh G. and Rennie, Chris J. and Zhao, Xuelong and Choe, Yoonsuck and Yang, Huei-Fang and Mi, Yuanyuan and Lin, Xiaohan and Wu, Si and Liedtke, Joscha and Schottdorf, Manuel and Wolf, Fred and Yamamura, Yoriko and Wickens, Jeffery R. and Rumbell, Timothy and Ramsey, Julia and Reyes, Amy and Dragulji\'c, Danel and Hof, Patrick R. and Luebke, Jennifer and Weaver, Christina M. and He, Hu and Yang, Xu and Ma, Hailin and Xu, Zhiheng and Wang, Yuzhe and Baek, Kwangyeol and Morris, Laurel S. and Kundu, Prantik and Voon, Valerie and Agnes, Everton J. and Vogels, Tim P. and Podlaski, William F. and Giese, Martin and Kuravi, Pradeep and Vogels, Rufin and Seeholzer, Alexander and Podlaski, William and Ranjan, Rajnish and Vogels, Tim and Torres, Joaquin J. and Baroni, Fabiano and Latorre, Roberto and Gips, Bart and Lowet, Eric and Roberts, Mark J. and {de Weerd}, Peter and Jensen, Ole and {van der Eerden}, Jan and Goodarzinick, Abdorreza and Niry, Mohammad D. and Valizadeh, Alireza and Pariz, Aref and Parsi, Shervin S. and Warburton, Julia M. and Marucci, Lucia and Tamagnini, Francesco and Brown, Jon and {Tsaneva-Atanasova}, Krasimira and Kleberg, Florence I. and Triesch, Jochen and Moezzi, Bahar and Iannella, Nicolangelo and Schaworonkow, Natalie and Plogmacher, Lukas and Goldsworthy, Mitchell R. and Hordacre, Brenton and McDonnell, Mark D. and Ridding, Michael C. and Zapotocky, Martin and Smit, Daniel and Fouquet, Coralie and Trembleau, Alain and Dasgupta, Sakyasingha and Nishikawa, Isao and Aihara, Kazuyuki and Toyoizumi, Taro and Robb, Daniel T. and Mellen, Nick and Toporikova, Natalia and Tang, Rongxiang and Tang, Yi-Yuan and Liang, Guangsheng and Kiser, Seth A. and Howard, James H. and Goncharenko, Julia and Voronenko, Sergej O. and Ahamed, Tosif and Stephens, Greg and Yger, Pierre and Lefebvre, Baptiste and Spampinato, Giulia Lia Beatrice and Esposito, Elric and {et Olivier Marre}, Marcel Stimberg and Choi, Hansol and Song, Min-Ho and Chung, SueYeon and Lee, Dan D. and Sompolinsky, Haim and Phillips, Ryan S. and Smith, Jeffrey and Chatzikalymniou, Alexandra Pierri and Ferguson, Katie and Alex Cayco Gajic, N. and Clopath, Claudia and Angus Silver, R. and Gleeson, Padraig and Marin, Boris and Sadeh, Sadra and Quintana, Adrian and Cantarelli, Matteo and {Dura-Bernal}, Salvador and Lytton, William W. and Davison, Andrew and Li, Luozheng and Zhang, Wenhao and Wang, Dahui and Song, Youngjo and Park, Sol and Choi, Ilhwan and Shin, Hee-sup and Choi, Hannah and Pasupathy, Anitha and {Shea-Brown}, Eric and Huh, Dongsung and Sejnowski, Terrence J. and Vogt, Simon M. and Kumar, Arvind and Schmidt, Robert and Van Wert, Stephen and Schiff, Steven J. and Veale, Richard and Scheutz, Matthias and Lee, Sang Wan and Gallinaro, J\'ulia and Rotter, Stefan and Rubchinsky, Leonid L. and Cheung, Chung Ching and {Ratnadurai-Giridharan}, Shivakeshavan and Shomali, Safura Rashid and Ahmadabadi, Majid Nili and Shimazaki, Hideaki and Nader Rasuli, S. and Zhao, Xiaochen and Rasch, Malte J.},
 comments = { The publication does not focus on explainability},
 doi = {10.1186/s12868-016-0283-6},
 file = {/home/tim/Zotero/storage/XF8GJ5F7/Sharpee et al. - 2016 - 25th Annual Computational Neuroscience Meeting CN.pdf},
 issn = {1471-2202},
 journal = {BMC Neuroscience},
 language = {en},
 month = {August},
 number = {1},
 pages = {54},
 shorttitle = {25th {{Annual Computational Neuroscience Meeting}}},
 title = {25th {{Annual Computational Neuroscience Meeting}}: {{CNS}}-2016},
 volume = {17},
 year = {2016}
}

@article{Shin:2016:ITD:2946645.3007060,
 acmid = {3007060},
 author = {Shin, Hoo-Chang and Lu, Le and Kim, Lauren and Seff, Ari and Yao, Jianhua and Summers, Ronald M.},
 comments = { The described method is neither general, nor focused on NLP},
 issn = {1532-4435},
 issue_date = {January 2016},
 journal = {J. Mach. Learn. Res.},
 keywords = {convolutional neural networks, deep learning, medical Imaging, natural language processing, topic models},
 month = {January},
 number = {1},
 numpages = {31},
 pages = {3729--3759},
 publisher = {JMLR.org},
 title = {Interleaved Text/Image Deep Mining on a Large-scale Radiology Database for Automated Image Interpretation},
 url = {http://dl.acm.org/citation.cfm?id=2946645.3007060},
 volume = {17},
 year = {2016}
}

@incollection{shoombuatongRevivalInterpretableQSAR2017,
 abstract = {Quantitative structure-activity relationship (QSAR) has been instrumental in aiding medicinal chemists and physical scientists in understanding how modification of substituents at different positions on a molecular structure exert its influence on the observed biological activity and physicochemical property, respectively. QSAR has received great attention owing to its predictive capability and as such efforts had been directed toward obtaining models with high prediction performance. However, to be useful QSAR models need to be informative and interpretable in which the underlying molecular features that contribute to the increase or decrease of the biological activity are revealed by the model. Thus, the aim of this chapter is to briefly review the general concepts of QSAR modeling, its development and discussions on key issues influencing and contributing to the interpretability of QSAR models.},
 address = {Cham},
 author = {Shoombuatong, Watshara and Prathipati, Philip and Owasirikul, Wiwat and Worachartcheewan, Apilak and Simeon, Saw and Anuwongcharoen, Nuttapat and Wikberg, Jarl E. S. and Nantasenamat, Chanin},
 booktitle = {Advances in {{QSAR Modeling}}: {{Applications}} in {{Pharmaceutical}}, {{Chemical}}, {{Food}}, {{Agricultural}} and {{Environmental Sciences}}},
 comments = { The described method is neither general, nor focused on NLP},
 doi = {10.1007/978-3-319-56850-8_1},
 editor = {Roy, Kunal},
 isbn = {978-3-319-56850-8},
 keywords = {Cheminformatics,Chemogenomics,Data mining,Drug design,Drug discovery,Interpretable,Machine learning,Proteochemometrics,QSAR,QSPR,Quantitative structure-activity relationship,Quantitative structure-property relationship},
 language = {en},
 pages = {3-55},
 publisher = {{Springer International Publishing}},
 series = {Challenges and {{Advances}} in {{Computational Chemistry}} and {{Physics}}},
 title = {Towards the {{Revival}} of {{Interpretable QSAR Models}}},
 year = {2017}
}

@inproceedings{Simmons:2009:LLA:1480945.1480949,
 acmid = {1480949},
 address = {New York, NY, USA},
 author = {Simmons, Robert J. and Pfenning, Frank},
 booktitle = {Proceedings of the 2009 ACM SIGPLAN Workshop on Partial Evaluation and Program Manipulation},
 comments = { The publication does not focus on explainability},
 doi = {10.1145/1480945.1480949},
 isbn = {978-1-60558-327-3},
 keywords = {abstract interpretation, bottom-up linear logic programming, operational semantics},
 location = {Savannah, GA, USA},
 numpages = {12},
 pages = {9--20},
 publisher = {ACM},
 series = {PEPM '09},
 title = {Linear Logical Approximations},
 url = {http://doi.acm.org/10.1145/1480945.1480949},
 year = {2009}
}

@inproceedings{Singh:2019:EES:3289600.3290620,
 acmid = {3290620},
 address = {New York, NY, USA},
 author = {Singh, Jaspreet and Anand, Avishek},
 booktitle = {Proceedings of the Twelfth ACM International Conference on Web Search and Data Mining},
 comments = { The described method is neither general, nor focused on NLP},
 doi = {10.1145/3289600.3290620},
 isbn = {978-1-4503-5940-5},
 keywords = {explainable search, interpretability, neural ranking models},
 location = {Melbourne VIC, Australia},
 numpages = {4},
 pages = {770--773},
 publisher = {ACM},
 series = {WSDM '19},
 title = {EXS: Explainable Search Using Local Model Agnostic Interpretability},
 url = {http://doi.acm.org/10.1145/3289600.3290620},
 year = {2019}
}

@incollection{skienaMachineLearning2017,
 abstract = {For much of my career, I was highly suspicious of the importance of machine learning. I sat through many talks over the years, with grandiose claims and very meager results. But it is clear that the tide has turned. The most interesting work in computer science today revolves around machine learning, both powerful new algorithms and exciting new applications.},
 address = {Cham},
 author = {Skiena, Steven S.},
 booktitle = {The {{Data Science Design Manual}}},
 comments = { The publication does not focus on explainability},
 doi = {10.1007/978-3-319-55444-0_11},
 editor = {Skiena, Steven S.},
 isbn = {978-3-319-55444-0},
 language = {en},
 pages = {351-390},
 publisher = {{Springer International Publishing}},
 series = {Texts in {{Computer Science}}},
 title = {Machine {{Learning}}},
 year = {2017}
}

@inproceedings{Sklar:2018:ETA:3284432.3284470,
 acmid = {3284470},
 address = {New York, NY, USA},
 author = {Sklar, Elizabeth I. and Azhar, Mohammad Q.},
 booktitle = {Proceedings of the 6th International Conference on Human-Agent Interaction},
 comments = { Does not describe the used explainability method, The described method is neither general, nor focused on NLP},
 doi = {10.1145/3284432.3284470},
 isbn = {978-1-4503-5953-5},
 keywords = {computational argumentation, explainable ai, human-robot interaction},
 location = {Southampton, United Kingdom},
 numpages = {9},
 pages = {277--285},
 publisher = {ACM},
 series = {HAI '18},
 title = {Explanation Through Argumentation},
 url = {http://doi.acm.org/10.1145/3284432.3284470},
 year = {2018}
}

@article{SPR20192019,
 comments = { The publication does not focus on explainability},
 doi = {10.1007/s00247-019-04376-7},
 file = {/home/tim/Zotero/storage/TX23AHNA/2019 - SPR 2019.pdf},
 issn = {1432-1998},
 journal = {Pediatric Radiology},
 language = {en},
 month = {April},
 number = {1},
 pages = {1-245},
 title = {{{SPR}} 2019},
 volume = {49},
 year = {2019}
}

@inproceedings{Sridhara:2010:TAG:1858996.1859006,
 acmid = {1859006},
 address = {New York, NY, USA},
 author = {Sridhara, Giriprasad and Hill, Emily and Muppaneni, Divya and Pollock, Lori and Vijay-Shanker, K.},
 booktitle = {Proceedings of the IEEE/ACM International Conference on Automated Software Engineering},
 comments = { The publication does not focus on explainability},
 doi = {10.1145/1858996.1859006},
 isbn = {978-1-4503-0116-9},
 keywords = {comment generation, method summarization, natural language program analysis},
 location = {Antwerp, Belgium},
 numpages = {10},
 pages = {43--52},
 publisher = {ACM},
 series = {ASE '10},
 title = {Towards Automatically Generating Summary Comments for Java Methods},
 url = {http://doi.acm.org/10.1145/1858996.1859006},
 year = {2010}
}

@inproceedings{St.Amant:2003:BEI:604045.604074,
 acmid = {604074},
 address = {New York, NY, USA},
 author = {St. Amant, Robert and Dinardo, Michael D. and Buckner, Nickie},
 booktitle = {Proceedings of the 8th International Conference on Intelligent User Interfaces},
 comments = { The publication does not focus on explainability},
 doi = {10.1145/604045.604074},
 isbn = {1-58113-586-6},
 keywords = {data mountain, efficiency, interpretability, navigation, user interface design},
 location = {Miami, Florida, USA},
 numpages = {8},
 pages = {181--188},
 publisher = {ACM},
 series = {IUI '03},
 title = {Balancing Efficiency and Interpretability in an Interactive Statistical Assistant},
 url = {http://doi.acm.org/10.1145/604045.604074},
 year = {2003}
}

@inproceedings{Tan:2018:IAD:3278721.3278802,
 acmid = {3278802},
 address = {New York, NY, USA},
 author = {Tan, Sarah},
 booktitle = {Proceedings of the 2018 AAAI/ACM Conference on AI, Ethics, and Society},
 comments = { Is not scientific literature},
 doi = {10.1145/3278721.3278802},
 isbn = {978-1-4503-6012-8},
 keywords = {algorithmic fairness, black-box models, interpretability, model distillation, transparency},
 location = {New Orleans, LA, USA},
 numpages = {2},
 pages = {382--383},
 publisher = {ACM},
 series = {AIES '18},
 title = {Interpretable Approaches to Detect Bias in Black-Box Models},
 url = {http://doi.acm.org/10.1145/3278721.3278802},
 year = {2018}
}

@inproceedings{Tang:2018:EVM:3302425.3302476,
 acmid = {3302476},
 address = {New York, NY, USA},
 articleno = {52},
 author = {Tang, Haijing and Wang, Yiru and Yang, Xu},
 booktitle = {Proceedings of the 2018 International Conference on Algorithms, Computing and Artificial Intelligence},
 comments = { The publication does not focus on explainability},
 doi = {10.1145/3302425.3302476},
 isbn = {978-1-4503-6625-0},
 keywords = {Artificial Intelligence, Convolutional Neural Network, Machine Learning, Visualization},
 location = {Sanya, China},
 numpages = {5},
 pages = {52:1--52:5},
 publisher = {ACM},
 series = {ACAI 2018},
 title = {Evaluation of Visualization Methods' Effect on Convolutional Neural Networks Research},
 url = {http://doi.acm.org/10.1145/3302425.3302476},
 year = {2018}
}

@article{tienInternetThingsRealTime2017,
 abstract = {In several earlier papers, the author defined and detailed the concept of a servgood, which can be thought of as a physical good or product enveloped by a services-oriented layer that makes the good smarter or more adaptable and customizable for a particular use. Adding another layer of physical sensors could then enhance its smartness and intelligence, especially if it were to be connected with other servgoods\textemdash{}thus, constituting an Internet of Things (IoT) or servgoods. More importantly, real-time decision making is central to the Internet of Things; it is about decision informatics and embraces the advanced technologies of sensing (i.e., Big Data), processing (i.e., real-time analytics), reacting (i.e., real-time decision-making), and learning (i.e., deep learning). Indeed, real-time decision making (RTDM) is becoming an integral aspect of IoT and artificial intelligence (AI), including its improving abilities at voice and video recognition, speech and predictive synthesis, and language and social-media understanding. These three key and mutually supportive technologies\textemdash{}IoT, RTDM, and AI\textemdash{}are considered herein, including their progress to date.},
 author = {Tien, James M.},
 comments = { The publication does not focus on explainability},
 doi = {10.1007/s40745-017-0112-5},
 issn = {2198-5812},
 journal = {Annals of Data Science},
 keywords = {Artificial intelligence,Goods,Internet of things,Real-time decision making,Servgoods,Services},
 language = {en},
 month = {June},
 number = {2},
 pages = {149-178},
 title = {Internet of {{Things}}, {{Real}}-{{Time Decision Making}}, and {{Artificial Intelligence}}},
 volume = {4},
 year = {2017}
}

@inproceedings{Treanor:2012:MG:2282338.2282347,
 acmid = {2282347},
 address = {New York, NY, USA},
 author = {Treanor, Mike and Schweizer, Bobby and Bogost, Ian and Mateas, Michael},
 booktitle = {Proceedings of the International Conference on the Foundations of Digital Games},
 comments = { The publication does not focus on explainability},
 doi = {10.1145/2282338.2282347},
 isbn = {978-1-4503-1333-9},
 keywords = {game design, game interpretation, procedural rhetoric},
 location = {Raleigh, North Carolina},
 numpages = {8},
 pages = {18--25},
 publisher = {ACM},
 series = {FDG '12},
 title = {The Micro-rhetorics of Game-o-Matic},
 url = {http://doi.acm.org/10.1145/2282338.2282347},
 year = {2012}
}

@incollection{turnerControllingCreations2019,
 abstract = {Turner explains how in order to implement constraints into AI directly, we will need to address both moral and technical questions: Which norms should be chosen? How can these be implemented? Potential basic laws for robots include: a law of identification, requiring that AI makes its status clear; a law of explanation, requiring that at least some parts of AI's reasoning be divulged; a laws on avoiding bias; and a law setting out any limits to areas where AI can operate. Finally, a kill switch law might make it mandatory that AI systems include a mechanism for safely interrupting their processes or operations, either temporarily or permanently.},
 address = {Cham},
 author = {Turner, Jacob},
 booktitle = {Robot {{Rules}} : {{Regulating Artificial Intelligence}}},
 comments = { The publication does not focus on explainability},
 doi = {10.1007/978-3-319-96235-1_8},
 editor = {Turner, Jacob},
 isbn = {978-3-319-96235-1},
 language = {en},
 pages = {319-369},
 publisher = {{Springer International Publishing}},
 title = {Controlling the {{Creations}}},
 year = {2019}
}

@inproceedings{Vartak:2018:MSS:3183713.3196934,
 acmid = {3196934},
 address = {New York, NY, USA},
 author = {Vartak, Manasi and F. da Trindade, Joana M. and Madden, Samuel and Zaharia, Matei},
 booktitle = {Proceedings of the 2018 International Conference on Management of Data},
 comments = { The publication does not focus on explainability},
 doi = {10.1145/3183713.3196934},
 isbn = {978-1-4503-4703-7},
 keywords = {machine learning, model diagnosis, model interpretability, systems for machine learning},
 location = {Houston, TX, USA},
 numpages = {16},
 pages = {1285--1300},
 publisher = {ACM},
 series = {SIGMOD '18},
 title = {MISTIQUE: A System to Store and Query Model Intermediates for Model Diagnosis},
 url = {http://doi.acm.org/10.1145/3183713.3196934},
 year = {2018}
}

@inproceedings{Wang:2016:TCW:2906831.2906852,
 acmid = {2906852},
 address = {Piscataway, NJ, USA},
 author = {Wang, Ning and Pynadath, David V. and Hill, Susan G.},
 booktitle = {The Eleventh ACM/IEEE International Conference on Human Robot Interaction},
 comments = { The described method is neither general, nor focused on NLP},
 isbn = {978-1-4673-8370-7},
 keywords = {explainable a.i., human-robot interaction, pomdp, trust},
 location = {Christchurch, New Zealand},
 numpages = {8},
 pages = {109--116},
 publisher = {IEEE Press},
 series = {HRI '16},
 title = {Trust Calibration Within a Human-Robot Team: Comparing Automatically Generated Explanations},
 url = {http://dl.acm.org/citation.cfm?id=2906831.2906852},
 year = {2016}
}

@inproceedings{Wang:2018:TTE:3178876.3186066,
 acmid = {3186066},
 address = {Republic and Canton of Geneva, Switzerland},
 author = {Wang, Xiang and He, Xiangnan and Feng, Fuli and Nie, Liqiang and Chua, Tat-Seng},
 booktitle = {Proceedings of the 2018 World Wide Web Conference},
 comments = { The described method is neither general, nor focused on NLP},
 doi = {10.1145/3178876.3186066},
 isbn = {978-1-4503-5639-8},
 keywords = {embedding-based model, explainable recommendation, neural attention network, tree-based model},
 location = {Lyon, France},
 numpages = {10},
 pages = {1543--1552},
 publisher = {International World Wide Web Conferences Steering Committee},
 series = {WWW '18},
 title = {TEM: Tree-enhanced Embedding Model for Explainable Recommendation},
 url = {https://doi.org/10.1145/3178876.3186066},
 year = {2018}
}

@inproceedings{Weisz:2019:BTS:3301275.3302290,
 acmid = {3302290},
 address = {New York, NY, USA},
 author = {Weisz, Justin D. and Jain, Mohit and Joshi, Narendra Nath and Johnson, James and Lange, Ingrid},
 booktitle = {Proceedings of the 24th International Conference on Intelligent User Interfaces},
 comments = { The publication does not focus on explainability},
 doi = {10.1145/3301275.3302290},
 isbn = {978-1-4503-6272-6},
 keywords = {conversational agents, explainable AI, mechanical turk},
 location = {Marina del Ray, California},
 numpages = {12},
 pages = {448--459},
 publisher = {ACM},
 series = {IUI '19},
 title = {BigBlueBot: Teaching Strategies for Successful Human-agent Interactions},
 url = {http://doi.acm.org/10.1145/3301275.3302290},
 year = {2019}
}

@article{wengMedicalSubdomainClassification2017,
 abstract = {BackgroundThe medical subdomain of a clinical note, such as cardiology or neurology, is useful content-derived metadata for developing machine learning downstream applications. To classify the medical subdomain of a note accurately, we have constructed a machine learning-based natural language processing (NLP) pipeline and developed medical subdomain classifiers based on the content of the note.MethodsWe constructed the pipeline using the clinical NLP system, clinical Text Analysis and Knowledge Extraction System (cTAKES), the Unified Medical Language System (UMLS) Metathesaurus, Semantic Network, and learning algorithms to extract features from two datasets \textemdash{} clinical notes from Integrating Data for Analysis, Anonymization, and Sharing (iDASH) data repository (n = 431) and Massachusetts General Hospital (MGH) (n = 91,237), and built medical subdomain classifiers with different combinations of data representation methods and supervised learning algorithms. We evaluated the performance of classifiers and their portability across the two datasets.ResultsThe convolutional recurrent neural network with neural word embeddings trained-medical subdomain classifier yielded the best performance measurement on iDASH and MGH datasets with area under receiver operating characteristic curve (AUC) of 0.975 and 0.991, and F1 scores of 0.845 and 0.870, respectively. Considering better clinical interpretability, linear support vector machine-trained medical subdomain classifier using hybrid bag-of-words and clinically relevant UMLS concepts as the feature representation, with term frequency-inverse document frequency (tf-idf)-weighting, outperformed other shallow learning classifiers on iDASH and MGH datasets with AUC of 0.957 and 0.964, and F1 scores of 0.932 and 0.934 respectively. We trained classifiers on one dataset, applied to the other dataset and yielded the threshold of F1 score of 0.7 in classifiers for half of the medical subdomains we studied.ConclusionOur study shows that a supervised learning-based NLP approach is useful to develop medical subdomain classifiers. The deep learning algorithm with distributed word representation yields better performance yet shallow learning algorithms with the word and concept representation achieves comparable performance with better clinical interpretability. Portable classifiers may also be used across datasets from different institutions.},
 author = {Weng, Wei-Hung and Wagholikar, Kavishwar B. and McCray, Alexa T. and Szolovits, Peter and Chueh, Henry C.},
 comments = { The publication does not focus on explainability},
 doi = {10.1186/s12911-017-0556-8},
 file = {/home/tim/Zotero/storage/8NGVVGDF/Weng et al. - 2017 - Medical subdomain classification of clinical notes.pdf},
 issn = {1472-6947},
 journal = {BMC Medical Informatics and Decision Making},
 keywords = {Computer-assisted,Deep Learning,Distributed Representation,Machine Learning,Medical Decision Making,Natural Language Processing,Unified Medical Language System},
 language = {en},
 month = {December},
 number = {1},
 pages = {155},
 title = {Medical Subdomain Classification of Clinical Notes Using a Machine Learning-Based Natural Language Processing Approach},
 volume = {17},
 year = {2017}
}

@inproceedings{Wiegand:2019:IDY:3290607.3312817,
 acmid = {3312817},
 address = {New York, NY, USA},
 articleno = {LBW0163},
 author = {Wiegand, Gesa and Schmidmaier, Matthias and Weber, Thomas and Liu, Yuanting and Hussmann, Heinrich},
 booktitle = {Extended Abstracts of the 2019 CHI Conference on Human Factors in Computing Systems},
 comments = { The publication does not focus on explainability},
 doi = {10.1145/3290607.3312817},
 isbn = {978-1-4503-5971-9},
 keywords = {autonomous driving, explainability, mental model, situation awareness},
 location = {Glasgow, Scotland Uk},
 numpages = {6},
 pages = {LBW0163:1--LBW0163:6},
 publisher = {ACM},
 series = {CHI EA '19},
 title = {I Drive - You Trust: Explaining Driving Behavior Of Autonomous Cars},
 url = {http://doi.acm.org/10.1145/3290607.3312817},
 year = {2019}
}

@incollection{wodeckiArtificialIntelligenceMethods2019,
 abstract = {Artificial intelligence (AI) is a fascinating concept whose origins can be found in the mid-twentieth century. It is an interdisciplinary field, integrating the efforts of logicians, mathematicians, computer scientists, psychologists and, more recently, managers and ethicists. Developing dynamically in the dimension of methods as well as technology, on the one hand, raises many hopes; on the other hand, it raises many fears and controversies (compare e.g. Bostrom 2014), particularly among investors who are interested in ventures with high development potential, yet they are afraid to invest in projects they simply do not understand.},
 address = {Cham},
 author = {Wodecki, Andrzej},
 booktitle = {Artificial {{Intelligence}} in {{Value Creation}}: {{Improving Competitive Advantage}}},
 comments = { The publication does not focus on explainability},
 doi = {10.1007/978-3-319-91596-8_2},
 editor = {Wodecki, Andrzej},
 isbn = {978-3-319-91596-8},
 language = {en},
 pages = {71-132},
 publisher = {{Springer International Publishing}},
 title = {Artificial {{Intelligence Methods}} and {{Techniques}}},
 year = {2019}
}

@inproceedings{Wu:2016:ERR:2872518.2889400,
 acmid = {2889400},
 address = {Republic and Canton of Geneva, Switzerland},
 author = {Wu, Chao-Yuan and Beutel, Alex and Ahmed, Amr and Smola, Alexander J.},
 booktitle = {Proceedings of the 25th International Conference Companion on World Wide Web},
 comments = {Presents a specific method for enhancing explainability for models, The described method is neither general, nor focused on NLP},
 doi = {10.1145/2872518.2889400},
 isbn = {978-1-4503-4144-8},
 keywords = {co-clustering, joint modeling, recommendation systems},
 location = {Montr\&\#233;al, Qu\&\#233;bec, Canada},
 numpages = {2},
 pages = {127--128},
 publisher = {International World Wide Web Conferences Steering Committee},
 series = {WWW '16 Companion},
 title = {Explaining Reviews and Ratings with PACO: Poisson Additive Co-Clustering},
 url = {https://doi.org/10.1145/2872518.2889400},
 year = {2016}
}

@article{Wyner:2017:ESA:3122009.3153004,
 acmid = {3153004},
 author = {Wyner, Abraham J. and Olson, Matthew and Bleich, Justin and Mease, David},
 comments = { The publication does not focus on explainability},
 issn = {1532-4435},
 issue_date = {January 2017},
 journal = {J. Mach. Learn. Res.},
 keywords = {adaboost, classification, overfitting, random forests, tree-ensembles},
 month = {January},
 number = {1},
 numpages = {33},
 pages = {1558--1590},
 publisher = {JMLR.org},
 title = {Explaining the Success of Adaboost and Random Forests As Interpolating Classifiers},
 url = {http://dl.acm.org/citation.cfm?id=3122009.3153004},
 volume = {18},
 year = {2017}
}

@inproceedings{Xiong:2017:ENA:3077136.3080809,
 acmid = {3080809},
 address = {New York, NY, USA},
 author = {Xiong, Chenyan and Dai, Zhuyun and Callan, Jamie and Liu, Zhiyuan and Power, Russell},
 booktitle = {Proceedings of the 40th International ACM SIGIR Conference on Research and Development in Information Retrieval},
 comments = { The publication does not focus on explainability},
 doi = {10.1145/3077136.3080809},
 isbn = {978-1-4503-5022-8},
 keywords = {embedding, kernel pooling, neural ir, ranking, relevance model},
 location = {Shinjuku, Tokyo, Japan},
 numpages = {10},
 pages = {55--64},
 publisher = {ACM},
 series = {SIGIR '17},
 title = {End-to-End Neural Ad-hoc Ranking with Kernel Pooling},
 url = {http://doi.acm.org/10.1145/3077136.3080809},
 year = {2017}
}

@inproceedings{Yang:2018:MNN:3194452.3194473,
 acmid = {3194473},
 address = {New York, NY, USA},
 author = {Yang, Shanliang and Sun, Qi and Zhou, Huyong and Gong, Zhengjie},
 booktitle = {Proceedings of the 2018 International Conference on Computing and Artificial Intelligence},
 comments = { The publication does not focus on explainability},
 doi = {10.1145/3194452.3194473},
 isbn = {978-1-4503-6419-5},
 keywords = {BiLSTM, BiLSTM-CNN, CNN, Neural network, Sentiment recognition, Word embedding},
 location = {Chengdu, China},
 numpages = {7},
 pages = {23--29},
 publisher = {ACM},
 series = {ICCAI 2018},
 title = {A Multi-Layer Neural Network Model Integrating BiLSTM and CNN for Chinese Sentiment Recognition},
 url = {http://doi.acm.org/10.1145/3194452.3194473},
 year = {2018}
}

@inproceedings{Zaheer:2019:UHS:3289600.3291036,
 acmid = {3291036},
 address = {New York, NY, USA},
 author = {Zaheer, Manzil and Ahmed, Amr and Wang, Yuan and Silva, Daniel and Najork, Marc and Wu, Yuchen and Sanan, Shibani and Chatterjee, Surojit},
 booktitle = {Proceedings of the Twelfth ACM International Conference on Web Search and Data Mining},
 comments = { The publication does not focus on explainability},
 doi = {10.1145/3289600.3291036},
 isbn = {978-1-4503-5940-5},
 keywords = {sequence clustering, interpretable recurrent neural network, topic models},
 location = {Melbourne VIC, Australia},
 numpages = {9},
 pages = {186--194},
 publisher = {ACM},
 series = {WSDM '19},
 title = {Uncovering Hidden Structure in Sequence Data via Threading Recurrent Models},
 url = {http://doi.acm.org/10.1145/3289600.3291036},
 year = {2019}
}

@inproceedings{Zantedeschi:2017:EDA:3128572.3140449,
 acmid = {3140449},
 address = {New York, NY, USA},
 author = {Zantedeschi, Valentina and Nicolae, Maria-Irina and Rawat, Ambrish},
 booktitle = {Proceedings of the 10th ACM Workshop on Artificial Intelligence and Security},
 comments = { The publication does not focus on explainability},
 doi = {10.1145/3128572.3140449},
 isbn = {978-1-4503-5202-4},
 keywords = {adversarial learning, deep neural network, defenses, model security},
 location = {Dallas, Texas, USA},
 numpages = {11},
 pages = {39--49},
 publisher = {ACM},
 series = {AISec '17},
 title = {Efficient Defenses Against Adversarial Attacks},
 url = {http://doi.acm.org/10.1145/3128572.3140449},
 year = {2017}
}

@article{zerilliTransparencyAlgorithmicHuman2018,
 abstract = {We are sceptical of concerns over the opacity of algorithmic decision tools. While transparency and explainability are certainly important desiderata in algorithmic governance, we worry that automated decision-making is being held to an unrealistically high standard, possibly owing to an unrealistically high estimate of the degree of transparency attainable from human decision-makers. In this paper, we review evidence demonstrating that much human decision-making is fraught with transparency problems, show in what respects AI fares little worse or better and argue that at least some regulatory proposals for explainable AI could end up setting the bar higher than is necessary or indeed helpful. The demands of practical reason require the justification of action to be pitched at the level of practical reason. Decision tools that support or supplant practical reasoning should not be expected to aim higher than this. We cast this desideratum in terms of Daniel Dennett's theory of the ``intentional stance'' and argue that since the justification of action for human purposes takes the form of intentional stance explanation, the justification of algorithmic decisions should take the same form. In practice, this means that the sorts of explanations for algorithmic decisions that are analogous to intentional stance explanations should be preferred over ones that aim at the architectural innards of a decision tool.},
 author = {Zerilli, John and Knott, Alistair and Maclaurin, James and Gavaghan, Colin},
 comments = { Does not describe the used explainability method, The described method is neither general, nor focused on NLP},
 doi = {10.1007/s13347-018-0330-6},
 issn = {2210-5441},
 journal = {Philosophy \& Technology},
 keywords = {Algorithmic decision-making,Explainable AI,Intentional stance,Transparency},
 language = {en},
 month = {September},
 shorttitle = {Transparency in {{Algorithmic}} and {{Human Decision}}-{{Making}}},
 title = {Transparency in {{Algorithmic}} and {{Human Decision}}-{{Making}}: {{Is There}} a {{Double Standard}}?},
 year = {2018}
}

@inproceedings{Zhang:2018:DAP:3301551.3301588,
 acmid = {3301588},
 address = {New York, NY, USA},
 author = {Zhang, Chiliang and Yang, Zhimou and Ye, Zuochang},
 booktitle = {Proceedings of the 6th International Conference on Information Technology: IoT and Smart City},
 comments = { The described method is neither general, nor focused on NLP},
 doi = {10.1145/3301551.3301588},
 isbn = {978-1-4503-6629-8},
 keywords = {Adversarial Examples, Convolutional Neural Networks, Model Interpretation, Saliency},
 location = {Hong Kong, Hong Kong},
 numpages = {6},
 pages = {25--30},
 publisher = {ACM},
 series = {ICIT 2018},
 title = {Detecting Adversarial Perturbations with Salieny},
 url = {http://doi.acm.org/10.1145/3301551.3301588},
 year = {2018}
}

@inproceedings{Zhang:2018:SWE:3209978.3210193,
 acmid = {3210193},
 address = {New York, NY, USA},
 author = {Zhang, Yongfeng and Zhang, Yi and Zhang, Min},
 booktitle = {The 41st International ACM SIGIR Conference on Research \&\#38; Development in Information Retrieval},
 comments = { The described method is neither general, nor focused on NLP},
 doi = {10.1145/3209978.3210193},
 isbn = {978-1-4503-5657-2},
 keywords = {explainable recommendation, explainable search, information retrieval, recommendation systems},
 location = {Ann Arbor, MI, USA},
 numpages = {3},
 pages = {1411--1413},
 publisher = {ACM},
 series = {SIGIR '18},
 title = {SIGIR 2018 Workshop on ExplainAble Recommendation and Search (EARS 2018)},
 url = {http://doi.acm.org/10.1145/3209978.3210193},
 year = {2018}
}

@article{Zhang:2019:DLM:3309769.3279952,
 acmid = {3279952},
 address = {New York, NY, USA},
 articleno = {2},
 author = {Zhang, Wei and Yao, Ting and Zhu, Shiai and Saddik, Abdulmotaleb El},
 comments = { The publication does not focus on explainability},
 doi = {10.1145/3279952},
 issn = {1551-6857},
 issue_date = {February 2019},
 journal = {ACM Trans. Multimedia Comput. Commun. Appl.},
 keywords = {Multimedia analytics, deep learning, neural networks},
 month = {January},
 number = {1s},
 numpages = {26},
 pages = {2:1--2:26},
 publisher = {ACM},
 title = {Deep Learning\&\#x02013;Based Multimedia Analytics: A Review},
 url = {http://doi.acm.org/10.1145/3279952},
 volume = {15},
 year = {2019}
}

@inproceedings{Zheng:2018:DDL:3232565.3232569,
 acmid = {3232569},
 address = {New York, NY, USA},
 author = {Zheng, Ying and Liu, Ziyu and You, Xinyu and Xu, Yuedong and Jiang, Junchen},
 booktitle = {Proceedings of the 2Nd Asia-Pacific Workshop on Networking},
 comments = { The publication does not focus on explainability},
 doi = {10.1145/3232565.3232569},
 isbn = {978-1-4503-6395-2},
 keywords = {Interpretability, Neural networks, Resource allocation},
 location = {Beijing, China},
 numpages = {7},
 pages = {1--7},
 publisher = {ACM},
 series = {APNet '18},
 title = {Demystifying Deep Learning in Networking},
 url = {http://doi.acm.org/10.1145/3232565.3232569},
 year = {2018}
}

@article{zhuangChallengesOpportunitiesBig2017,
 abstract = {In this paper, we review recent emerging theoretical and technological advances of artificial intelligence (AI) in the big data settings. We conclude that integrating data-driven machine learning with human knowledge (common priors or implicit intuitions) can effectively lead to explainable, robust, and general AI, as follows: from shallow computation to deep neural reasoning; from merely data-driven model to data-driven with structured logic rules models; from task-oriented (domain-specific) intelligence (adherence to explicit instructions) to artificial general intelligence in a general context (the capability to learn from experience). Motivated by such endeavors, the next generation of AI, namely AI 2.0, is positioned to reinvent computing itself, to transform big data into structured knowledge, and to enable better decision-making for our society.},
 author = {Zhuang, Yue-ting and Wu, Fei and Chen, Chun and Pan, Yun-he},
 comments = { The publication does not focus on explainability},
 doi = {10.1631/FITEE.1601883},
 file = {/home/tim/Zotero/storage/CXXGKFY7/Zhuang et al. - 2017 - Challenges and opportunities from big data to kno.pdf},
 issn = {2095-9230},
 journal = {Frontiers of Information Technology \& Electronic Engineering},
 keywords = {Artificial general intelligence,Big data,Cross media,Deep reasoning,Knowledge base population,TP391.4},
 language = {en},
 month = {January},
 number = {1},
 pages = {3-14},
 shorttitle = {Challenges and Opportunities},
 title = {Challenges and Opportunities: From Big Data to Knowledge in {{AI}} 2.0},
 volume = {18},
 year = {2017}
}

