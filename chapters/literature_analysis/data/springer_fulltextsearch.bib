
@incollection{aggarwalMachineLearningShallow2018,
  address = {Cham},
  title = {Machine {{Learning}} with {{Shallow Neural Networks}}},
  isbn = {978-3-319-94463-0},
  abstract = {Conventional machine learning often uses optimization and gradient-descent methods for learning parameterized models. Examples of such models include linear regression, support vector machines, logistic regression, dimensionality reduction, and matrix factorization. Neural networks are also parameterized models that are learned with continuous optimization methods.},
  language = {en},
  booktitle = {Neural {{Networks}} and {{Deep Learning}}: {{A Textbook}}},
  publisher = {{Springer International Publishing}},
  author = {Aggarwal, Charu C.},
  editor = {Aggarwal, Charu C.},
  year = {2018},
  pages = {53-104},
  doi = {10.1007/978-3-319-94463-0_2}
}

@incollection{shoombuatongRevivalInterpretableQSAR2017,
  address = {Cham},
  series = {Challenges and {{Advances}} in {{Computational Chemistry}} and {{Physics}}},
  title = {Towards the {{Revival}} of {{Interpretable QSAR Models}}},
  isbn = {978-3-319-56850-8},
  abstract = {Quantitative structure-activity relationship (QSAR) has been instrumental in aiding medicinal chemists and physical scientists in understanding how modification of substituents at different positions on a molecular structure exert its influence on the observed biological activity and physicochemical property, respectively. QSAR has received great attention owing to its predictive capability and as such efforts had been directed toward obtaining models with high prediction performance. However, to be useful QSAR models need to be informative and interpretable in which the underlying molecular features that contribute to the increase or decrease of the biological activity are revealed by the model. Thus, the aim of this chapter is to briefly review the general concepts of QSAR modeling, its development and discussions on key issues influencing and contributing to the interpretability of QSAR models.},
  language = {en},
  booktitle = {Advances in {{QSAR Modeling}}: {{Applications}} in {{Pharmaceutical}}, {{Chemical}}, {{Food}}, {{Agricultural}} and {{Environmental Sciences}}},
  publisher = {{Springer International Publishing}},
  author = {Shoombuatong, Watshara and Prathipati, Philip and Owasirikul, Wiwat and Worachartcheewan, Apilak and Simeon, Saw and Anuwongcharoen, Nuttapat and Wikberg, Jarl E. S. and Nantasenamat, Chanin},
  editor = {Roy, Kunal},
  year = {2017},
  keywords = {Cheminformatics,Chemogenomics,Data mining,Drug design,Drug discovery,Interpretable,Machine learning,Proteochemometrics,QSAR,QSPR,Quantitative structure-activity relationship,Quantitative structure-property relationship},
  pages = {3-55},
  doi = {10.1007/978-3-319-56850-8_1}
}

@article{NUTSBOLTSBEHAVIORAL2017,
  title = {{{THE}} ``{{NUTS AND BOLTS}}'' {{OF BEHAVIORAL INTERVENTION DEVELOPMENT}}: {{STUDY DESIGNS}}, {{METHODS AND FUNDING OPPORTUNITIES}}},
  volume = {51},
  issn = {1532-4796},
  shorttitle = {{{THE}} ``{{NUTS AND BOLTS}}'' {{OF BEHAVIORAL INTERVENTION DEVELOPMENT}}},
  language = {en},
  number = {1},
  journal = {Annals of Behavioral Medicine},
  doi = {10.1007/s12160-017-9903-3},
  month = mar,
  year = {2017},
  pages = {1-2867}
}

@article{Abstracts2017Society2017,
  title = {Abstracts from the 2017 {{Society}} of {{General Internal Medicine Annual Meeting}}},
  volume = {32},
  issn = {1525-1497},
  language = {en},
  number = {2},
  journal = {Journal of General Internal Medicine},
  doi = {10.1007/s11606-017-4028-8},
  month = apr,
  year = {2017},
  pages = {83-808},
  file = {/home/tim/Zotero/storage/DF6QGEYW/2017 - Abstracts from the 2017 Society of General Interna.pdf;/home/tim/Zotero/storage/PXA8F9U6/2017 - Abstracts from the 2017 Society of General Interna.pdf}
}

@inproceedings{goebelExplainableAINew2018,
  series = {Lecture {{Notes}} in {{Computer Science}}},
  title = {Explainable {{AI}}: {{The New}} 42?},
  isbn = {978-3-319-99740-7},
  shorttitle = {Explainable {{AI}}},
  abstract = {Explainable AI is not a new field. Since at least the early exploitation of C.S. Pierce's abductive reasoning in expert systems of the 1980s, there were reasoning architectures to support an explanation function for complex AI systems, including applications in medical diagnosis, complex multi-component design, and reasoning about the real world. So explainability is at least as old as early AI, and a natural consequence of the design of AI systems. While early expert systems consisted of handcrafted knowledge bases that enabled reasoning over narrowly well-defined domains (e.g., INTERNIST, MYCIN), such systems had no learning capabilities and had only primitive uncertainty handling. But the evolution of formal reasoning architectures to incorporate principled probabilistic reasoning helped address the capture and use of uncertain knowledge.There has been recent and relatively rapid success of AI/machine learning solutions arises from neural network architectures. A new generation of neural methods now scale to exploit the practical applicability of statistical and algebraic learning approaches in arbitrarily high dimensional spaces. But despite their huge successes, largely in problems which can be cast as classification problems, their effectiveness is still limited by their un-debuggability, and their inability to ``explain'' their decisions in a human understandable and reconstructable way. So while AlphaGo or DeepStack can crush the best humans at Go or Poker, neither program has any internal model of its task; its representations defy interpretation by humans, there is no mechanism to explain their actions and behaviour, and furthermore, there is no obvious instructional value ... the high performance systems can not help humans improve.Even when we understand the underlying mathematical scaffolding of current machine learning architectures, it is often impossible to get insight into the internal working of the models; we need explicit modeling and reasoning tools to explain how and why a result was achieved. We also know that a significant challenge for future AI is contextual adaptation, i.e., systems that incrementally help to construct explanatory models for solving real-world problems. Here it would be beneficial not to exclude human expertise, but to augment human intelligence with artificial intelligence.},
  language = {en},
  booktitle = {Machine {{Learning}} and {{Knowledge Extraction}}},
  publisher = {{Springer International Publishing}},
  author = {Goebel, Randy and Chander, Ajay and Holzinger, Katharina and Lecue, Freddy and Akata, Zeynep and Stumpf, Simone and Kieseberg, Peter and Holzinger, Andreas},
  editor = {Holzinger, Andreas and Kieseberg, Peter and Tjoa, A Min and Weippl, Edgar},
  year = {2018},
  keywords = {Artificial intelligence,Explainability,Explainable AI,Machine learning},
  pages = {295-303}
}

@inproceedings{pomarlanUnderstandingNLPNeural2018,
  series = {Lecture {{Notes}} in {{Computer Science}}},
  title = {Understanding {{NLP Neural Networks}} by the {{Texts They Generate}}},
  isbn = {978-3-030-00111-7},
  abstract = {Recurrent neural networks have proven useful in natural language processing. For example, they can be trained to predict, and even generate plausible text with few or no spelling and syntax errors. However, it is not clear what grammar a network has learned, or how it keeps track of the syntactic structure of its input. In this paper, we present a new method to extract a finite state machine from a recurrent neural network. A FSM is in principle a more interpretable representation of a grammar than a neural net would be, however the extracted FSMs for realistic neural networks will also be large. Therefore, we also look at ways to group the states and paths through the extracted FSM so as to get a smaller, easier to understand model of the neural network. To illustrate our methods, we use them to investigate how a neural network learns noun-verb agreement from a simple grammar where relative clauses may appear between noun and verb.},
  language = {en},
  booktitle = {{{KI}} 2018: {{Advances}} in {{Artificial Intelligence}}},
  publisher = {{Springer International Publishing}},
  author = {Pomarlan, Mihai and Bateman, John},
  editor = {Trollmann, Frank and Turhan, Anni-Yasmin},
  year = {2018},
  keywords = {Interpretability,Natural language processing,Recurrent neural networks},
  pages = {284-296}
}

@incollection{kashyapPracticalConceptsMachine2017,
  address = {Berkeley, CA},
  title = {The {{Practical Concepts}} of {{Machine Learning}}},
  isbn = {978-1-4842-2988-0},
  abstract = {This is an important chapter because it discusses the basic and practical concepts of machine learning (ML). I did not take the academic book style to explain these concepts. I have directed my thoughts and energy to provide you with the concepts that are useful during practical decision making. Hence, while explaining the concepts, terminologies, and technical details, I use examples and case studies that are be helpful in extracting relevant insight from the chapter.},
  language = {en},
  booktitle = {Machine {{Learning}} for {{Decision Makers}}: {{Cognitive Computing Fundamentals}} for {{Better Decision Making}}},
  publisher = {{Apress}},
  author = {Kashyap, Patanjali},
  editor = {Kashyap, Patanjali},
  year = {2017},
  pages = {35-90},
  doi = {10.1007/978-1-4842-2988-0_2}
}

@inproceedings{otteSafeInterpretableMachine2013,
  series = {Studies in {{Computational Intelligence}}},
  title = {Safe and {{Interpretable Machine Learning}}: {{A~Methodological Review}}},
  isbn = {978-3-642-32378-2},
  shorttitle = {Safe and {{Interpretable Machine Learning}}},
  abstract = {When learning models from data, the interpretability of the resulting model is often mandatory. For example, safety-related applications for automation and control require that the correctness of the model must be ensured not only for the available data but for all possible input combinations. Thus, understanding what the model has learned and in particular how it will extrapolate to unseen data is a crucial concern. The paper discusses suitable learning methods for classification and regression. For classification problems, we review an approach based on an ensemble of nonlinear low-dimensional submodels, where each submodel is simple enough to be completely verified by domain experts. For regression problems, we review related approaches that try to achieve interpretability by using low-dimensional submodels (for instance, MARS and tree-growing methods). We compare them with symbolic regression, which is a different approach based on genetic algorithms. Finally, a novel approach is proposed for combining a symbolic regression model, which is shown to be easily interpretable, with a Gaussian Process. The combined model has an improved accuracy and provides error bounds in the sense that the deviation from the verified symbolic model is always kept below a defined limit.},
  language = {en},
  booktitle = {Computational {{Intelligence}} in {{Intelligent Data Analysis}}},
  publisher = {{Springer Berlin Heidelberg}},
  author = {Otte, Clemens},
  editor = {Moewes, Christian and N\"urnberger, Andreas},
  year = {2013},
  keywords = {Input Space,Methodological Review,Multivariate Adaptive Regression Spline,Symbolic Model,Symbolic Regression},
  pages = {111-122}
}

@inproceedings{pomarlanMeaningfulClusteringsRecurrent2018,
  series = {Lecture {{Notes}} in {{Computer Science}}},
  title = {Meaningful {{Clusterings}} of {{Recurrent Neural Network Activations}} for {{NLP}}},
  isbn = {978-3-030-05918-7},
  abstract = {Recurrent neural networks have found applications in NLP, but their operation is difficult to interpret. A state automaton that approximates the network would be more interpretable, but for this one needs a method to group network activation states by their behavior. In this paper we propose such a method, and compare it to an existing dimensionality reduction and clustering approach. Our method is better able to group together neural states of similar behavior.},
  language = {en},
  booktitle = {Mining {{Intelligence}} and {{Knowledge Exploration}}},
  publisher = {{Springer International Publishing}},
  author = {Pomarlan, Mihai and Bateman, John},
  editor = {Groza, Adrian and Prasath, Rajendra},
  year = {2018},
  keywords = {Interpretability,Natural language processing,Recurrent neural networks},
  pages = {11-20}
}

@inproceedings{weberInvestigatingTextualCaseBased2018,
  series = {Lecture {{Notes}} in {{Computer Science}}},
  title = {Investigating {{Textual Case}}-{{Based XAI}}},
  isbn = {978-3-030-01081-2},
  abstract = {This paper demonstrates how case-based reasoning (CBR) can be used for an explainable artificial intelligence (XAI) approach to justify solutions produced by an opaque learning method (i.e., target method), particularly in the context of unstructured textual data. Our general hypothesis is twofold: (1) There exists patterns in the relationship between problems and solutions and there should be data or a body of knowledge that describes how problems and solutions relate; and (2) the identification, manipulation, and learning of such patterns through case features can help create and reuse explanations for solutions produced by the target method. When the target method relies on neural network architectures (e.g., deep learning), the resulting latent space (i.e., word embeddings) becomes useful for finding patterns and semantic relatedness in textual data. In the proposed approach, case problems are input-output pairs from the target method, and case solutions are explanations. We exemplify our approach by explaining recommended citations from Citeomatic - a multi-layer neural-network architecture from the Allen Institute for Artificial Intelligence. Citation analysis is the body of knowledge that describes how query documents (i.e., inputs) relate to recommended citations (i.e., outputs). We build cases and similarity assessment to learn features that represent patterns between problems and solutions that can lead to the reuse of corresponding explanations. The illustrative implementation we present becomes an explanation-augmented citation recommender that targets human-computer trust.},
  language = {en},
  booktitle = {Case-{{Based Reasoning Research}} and {{Development}}},
  publisher = {{Springer International Publishing}},
  author = {Weber, Rosina O. and Johs, Adam J. and Li, Jianfei and Huang, Kent},
  editor = {Cox, Michael T. and Funk, Peter and Begum, Shahina},
  year = {2018},
  keywords = {Case-Based reasoning,Citation recommendation,Explainable artificial intelligence,Human-Computer trust,Semantic relatedness,Textual Case-Based reasoning,Word embeddings},
  pages = {431-447}
}

@incollection{doshi-velezConsiderationsEvaluationGeneralization2018,
  address = {Cham},
  series = {The {{Springer Series}} on {{Challenges}} in {{Machine Learning}}},
  title = {Considerations for {{Evaluation}} and {{Generalization}} in {{Interpretable Machine Learning}}},
  isbn = {978-3-319-98131-4},
  abstract = {As machine learning systems become ubiquitous, there has been a surge of interest in interpretable machine learning: systems that provide explanation for their outputs. These explanations are often used to qualitatively assess other criteria such as safety or non-discrimination. However, despite the interest in interpretability, there is little consensus on what interpretable machine learning is and how it should be measured and evaluated. In this paper, we discuss a definitions of interpretability and describe when interpretability is needed (and when it is not). Finally, we talk about a taxonomy for rigorous evaluation, and recommendations for researchers. We will end with discussing open questions and concrete problems for new researchers.},
  language = {en},
  booktitle = {Explainable and {{Interpretable Models}} in {{Computer Vision}} and {{Machine Learning}}},
  publisher = {{Springer International Publishing}},
  author = {{Doshi-Velez}, Finale and Kim, Been},
  editor = {Escalante, Hugo Jair and Escalera, Sergio and Guyon, Isabelle and Bar\'o, Xavier and G\"u{\c c}l\"ut\"urk, Ya{\u g}mur and G\"u{\c c}l\"u, Umut and {van Gerven}, Marcel},
  year = {2018},
  keywords = {Accountability,Interpretability,Machine learning,Transparency},
  pages = {3-17},
  doi = {10.1007/978-3-319-98131-4_1}
}

@article{kuwajimaImprovingTransparencyDeep2019,
  title = {Improving Transparency of Deep Neural Inference Process},
  issn = {2192-6360},
  abstract = {Deep learning techniques are rapidly advanced recently and becoming a necessity component for widespread systems. However, the inference process of deep learning is black box and is not very suitable to safety-critical systems which must exhibit high transparency. In this paper, to address this black-box limitation, we develop a simple analysis method which consists of (1) structural feature analysis: lists of the features contributing to inference process, (2) linguistic feature analysis: lists of the natural language labels describing the visual attributes for each feature contributing to inference process, and (3) consistency analysis: measuring consistency among input data, inference (label), and the result of our structural and linguistic feature analysis. Our analysis is simplified to reflect the actual inference process for high transparency, whereas it does not include any additional black-box mechanisms such as LSTM for highly human readable results. We conduct experiments and discuss the results of our analysis qualitatively and quantitatively and come to believe that our work improves the transparency of neural networks. Evaluated through 12,800 human tasks, 75\% workers answer that input data and result of our feature analysis are consistent, and 70\% workers answer that inference (label) and result of our feature analysis are consistent. In addition to the evaluation of the proposed analysis, we find that our analysis also provides suggestions, or possible next actions such as expanding neural network complexity or collecting training data to improve a neural network.},
  language = {en},
  journal = {Progress in Artificial Intelligence},
  doi = {10.1007/s13748-019-00179-x},
  author = {Kuwajima, Hiroshi and Tanaka, Masayuki and Okutomi, Masatoshi},
  month = apr,
  year = {2019},
  keywords = {Black box,Deep neural network,Explainable AI,Transparency,Visual attribute,Visualization}
}

@article{27thAnnualComputational2018,
  title = {27th {{Annual Computational Neuroscience Meeting}} ({{CNS}}*2018): {{Part One}}},
  volume = {19},
  issn = {1471-2202},
  shorttitle = {27th {{Annual Computational Neuroscience Meeting}} ({{CNS}}*2018)},
  language = {en},
  number = {2},
  journal = {BMC Neuroscience},
  doi = {10.1186/s12868-018-0452-x},
  month = oct,
  year = {2018},
  pages = {64},
  file = {/home/tim/Zotero/storage/I68H3LC3/2018 - 27th Annual Computational Neuroscience Meeting (CN.pdf;/home/tim/Zotero/storage/TJ4V7N93/2018 - 27th Annual Computational Neuroscience Meeting (CN.pdf}
}

@article{bench-caponHistoryAILaw2012,
  title = {A History of {{AI}} and {{Law}} in 50 Papers: 25~Years of the International Conference on {{AI}} and {{Law}}},
  volume = {20},
  issn = {1572-8382},
  shorttitle = {A History of {{AI}} and {{Law}} in 50 Papers},
  abstract = {We provide a retrospective of 25 years of the International Conference on AI and Law, which was first held in 1987. Fifty papers have been selected from the thirteen conferences and each of them is described in a short subsection individually written by one of the 24 authors. These subsections attempt to place the paper discussed in the context of the development of AI and Law, while often offering some personal reactions and reflections. As a whole, the subsections build into a history of the last quarter century of the field, and provide some insights into where it has come from, where it is now, and where it might go.},
  language = {en},
  number = {3},
  journal = {Artificial Intelligence and Law},
  doi = {10.1007/s10506-012-9131-x},
  author = {{Bench-Capon}, Trevor and Araszkiewicz, Micha\l{} and Ashley, Kevin and Atkinson, Katie and Bex, Floris and Borges, Filipe and Bourcier, Daniele and Bourgine, Paul and Conrad, Jack G. and Francesconi, Enrico and Gordon, Thomas F. and Governatori, Guido and Leidner, Jochen L. and Lewis, David D. and Loui, Ronald P. and McCarty, L. Thorne and Prakken, Henry and Schilder, Frank and Schweighofer, Erich and Thompson, Paul and Tyrrell, Alex and Verheij, Bart and Walton, Douglas N. and Wyner, Adam Z.},
  month = sep,
  year = {2012},
  keywords = {Artificial intelligence and law,Legal informatics,Models of legal reasoning},
  pages = {215-319},
  file = {/home/tim/Zotero/storage/9RUMRANY/Bench-Capon et al. - 2012 - A history of AI and Law in 50 papers 25 years of .pdf;/home/tim/Zotero/storage/XXTKI56R/Bench-Capon et al. - 2012 - A history of AI and Law in 50 papers 25 years of .pdf}
}

@incollection{sarkarAnalyzingMovieReviews2018,
  address = {Berkeley, CA},
  title = {Analyzing {{Movie Reviews Sentiment}}},
  isbn = {978-1-4842-3207-1},
  abstract = {In this chapter, we continue with our focus on case-study oriented chapters, where we will focus on specific real-world problems and scenarios and how we can use Machine Learning to solve them. We will cover aspects pertaining to natural language processing (NLP), text analytics, and Machine Learning in this chapter. The problem at hand is sentiment analysis or opinion mining, where we want to analyze some textual documents and predict their sentiment or opinion based on the content of these documents. Sentiment analysis is perhaps one of the most popular applications of natural language processing and text analytics with a vast number of websites, books and tutorials on this subject. Typically sentiment analysis seems to work best on subjective text, where people express opinions, feelings, and their mood. From a real-world industry standpoint, sentiment analysis is widely used to analyze corporate surveys, feedback surveys, social media data, and reviews for movies, places, commodities, and many more. The idea is to analyze and understand the reactions of people toward a specific entity and take insightful actions based on their sentiment.},
  language = {en},
  booktitle = {Practical {{Machine Learning}} with {{Python}}: {{A Problem}}-{{Solver}}'s {{Guide}} to {{Building Real}}-{{World Intelligent Systems}}},
  publisher = {{Apress}},
  author = {Sarkar, Dipanjan and Bali, Raghav and Sharma, Tushar},
  editor = {Sarkar, Dipanjan and Bali, Raghav and Sharma, Tushar},
  year = {2018},
  pages = {331-372},
  doi = {10.1007/978-1-4842-3207-1_7}
}

@inproceedings{huExplainableNeuralComputation2018,
  series = {Lecture {{Notes}} in {{Computer Science}}},
  title = {Explainable {{Neural Computation}} via {{Stack Neural Module Networks}}},
  isbn = {978-3-030-01234-2},
  abstract = {In complex inferential tasks like question answering, machine learning models must confront two challenges: the need to implement a compositional reasoning process, and, in many applications, the need for this reasoning process to be interpretable to assist users in both development and prediction. Existing models designed to produce interpretable traces of their decision-making process typically require these traces to be supervised at training time. In this paper, we present a novel neural modular approach that performs compositional reasoning by automatically inducing a desired sub-task decomposition without relying on strong supervision. Our model allows linking different reasoning tasks though shared modules that handle common routines across tasks. Experiments show that the model is more interpretable to human evaluators compared to other state-of-the-art models: users can better understand the model's underlying reasoning procedure and predict when it will succeed or fail based on observing its intermediate outputs.},
  language = {en},
  booktitle = {Computer {{Vision}} \textendash{} {{ECCV}} 2018},
  publisher = {{Springer International Publishing}},
  author = {Hu, Ronghang and Andreas, Jacob and Darrell, Trevor and Saenko, Kate},
  editor = {Ferrari, Vittorio and Hebert, Martial and Sminchisescu, Cristian and Weiss, Yair},
  year = {2018},
  keywords = {Interpretable reasoning,Neural module networks,Visual question answering},
  pages = {55-71}
}

@incollection{ngomoIntroductionLinkedData2014,
  address = {Cham},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  title = {Introduction to {{Linked Data}} and {{Its Lifecycle}} on the {{Web}}},
  isbn = {978-3-319-10587-1},
  abstract = {With Linked Data, a very pragmatic approach towards achieving the vision of the Semantic Web has gained some traction in the last years. The term Linked Data refers to a set of best practices for publishing and interlinking structured data on the Web. While many standards, methods and technologies developed within by the Semantic Web community are applicable for Linked Data, there are also a number of specific characteristics of Linked Data, which have to be considered. In this article we introduce the main concepts of Linked Data. We present an overview of the Linked Data life-cycle and discuss individual approaches as well as the state-of-the-art with regard to extraction, authoring, linking, enrichment as well as quality of Linked Data. We conclude the chapter with a discussion of issues, limitations and further research and development challenges of Linked Data. This article is an updated version of a similar lecture given at Reasoning Web Summer School 2013.},
  language = {en},
  booktitle = {Reasoning {{Web}}. {{Reasoning}} on the {{Web}} in the {{Big Data Era}}: 10th {{International Summer School}} 2014, {{Athens}}, {{Greece}}, {{September}} 8-13, 2014. {{Proceedings}}},
  publisher = {{Springer International Publishing}},
  author = {Ngomo, Axel-Cyrille Ngonga and Auer, S\"oren and Lehmann, Jens and Zaveri, Amrapali},
  editor = {Koubarakis, Manolis and Stamou, Giorgos and Stoilos, Giorgos and Horrocks, Ian and Kolaitis, Phokion and Lausen, Georg and Weikum, Gerhard},
  year = {2014},
  keywords = {Inductive Logic Programming,Link Data,Link Open Data,Resource Description Framework,SPARQL Query},
  pages = {1-99},
  file = {/home/tim/Zotero/storage/6M2EVAFK/Ngomo et al. - 2014 - Introduction to Linked Data and Its Lifecycle on t.pdf;/home/tim/Zotero/storage/X9CPENNW/Ngomo et al. - 2014 - Introduction to Linked Data and Its Lifecycle on t.pdf},
  doi = {10.1007/978-3-319-10587-1_1}
}

@incollection{browneCriticalChallengesVisual2018,
  address = {Cham},
  series = {Human\textendash{{Computer Interaction Series}}},
  title = {Critical {{Challenges}} for the {{Visual Representation}} of {{Deep Neural Networks}}},
  isbn = {978-3-319-90403-0},
  abstract = {Artificial neural networks have proved successful in a broad range of applications over the last decade. However, there remain significant concerns about their interpretability. Visual representation is one way researchers are attempting to make sense of these models and their behaviour. The representation of neural networks raises questions which cross disciplinary boundaries. This chapter draws on a growing collection of interdisciplinary scholarship regarding neural networks. We present six case studies in the visual representation of neural networks and examine the particular representational challenges posed by these algorithms. Finally we summarise the ideas raised in the case studies as a set of takeaways for researchers engaging in this area.},
  language = {en},
  booktitle = {Human and {{Machine Learning}}: {{Visible}}, {{Explainable}}, {{Trustworthy}} and {{Transparent}}},
  publisher = {{Springer International Publishing}},
  author = {Browne, Kieran and Swift, Ben and Gardner, Henry},
  editor = {Zhou, Jianlong and Chen, Fang},
  year = {2018},
  pages = {119-136},
  doi = {10.1007/978-3-319-90403-0_7}
}

@incollection{kochGroupCognitionCollaborative2018,
  address = {Cham},
  series = {Human\textendash{{Computer Interaction Series}}},
  title = {Group {{Cognition}} and {{Collaborative AI}}},
  isbn = {978-3-319-90403-0},
  abstract = {Significant advances in artificial intelligence suggest that we will be using intelligent agents on a regular basis in the near future. This chapter discusses group cognition as a principle for designing collaborative AI. Group cognition is the ability to relate to other group members' decisions, abilities, and beliefs. It thereby allows participants to adapt their understanding and actions to reach common objectives. Hence, it underpins collaboration. We review two concepts in the context of group cognition that could inform the development of AI and automation in pursuit of natural collaboration with humans: conversational grounding and theory of mind. These concepts are somewhat different from those already discussed in AI research. We outline some new implications for collaborative AI, aimed at extending skills and solution spaces and at improving joint cognitive and creative capacity.},
  language = {en},
  booktitle = {Human and {{Machine Learning}}: {{Visible}}, {{Explainable}}, {{Trustworthy}} and {{Transparent}}},
  publisher = {{Springer International Publishing}},
  author = {Koch, Janin and Oulasvirta, Antti},
  editor = {Zhou, Jianlong and Chen, Fang},
  year = {2018},
  pages = {293-312},
  doi = {10.1007/978-3-319-90403-0_15}
}

@incollection{galitskyDevelopingConversationalNatural2019,
  address = {Cham},
  title = {Developing {{Conversational Natural Language Interface}} to a {{Database}}},
  isbn = {978-3-030-04299-8},
  abstract = {In this Chapter we focus on a problem of a natural language access to a database, well-known and highly desired to be solved. We start with the modern approaches based on deep learning and analyze lessons learned from unusable database access systems. This chapter can serve as a brief introduction to neural networks for learning logic representations. Then a number of hybrid approaches are presented and their strong points are analyzed. Finally, we describe our approach that relies on parsing, thesaurus and disambiguation via chatbot communication mode. The conclusion is that a reliable and flexible database access via NL needs to employ a broad spectrum of linguistic, knowledge representation and learning techniques. We conclude this chapter by surveying the general technology trends related to NL2SQL, observing how AI and ML are seeping into virtually everything and represent a major battleground for technology providers.},
  language = {en},
  booktitle = {Developing {{Enterprise Chatbots}}: {{Learning Linguistic Structures}}},
  publisher = {{Springer International Publishing}},
  author = {Galitsky, Boris},
  editor = {Galitsky, Boris},
  year = {2019},
  pages = {85-120},
  doi = {10.1007/978-3-030-04299-8_4}
}

@article{kotsiantisMachineLearningReview2006,
  title = {Machine Learning: A Review of Classification and Combining Techniques},
  volume = {26},
  issn = {1573-7462},
  shorttitle = {Machine Learning},
  abstract = {Supervised classification is one of the tasks most frequently carried out by so-called Intelligent Systems. Thus, a large number of techniques have been developed based on Artificial Intelligence (Logic-based techniques, Perceptron-based techniques) and Statistics (Bayesian Networks, Instance-based techniques). The goal of supervised learning is to build a concise model of the distribution of class labels in terms of predictor features. The resulting classifier is then used to assign class labels to the testing instances where the values of the predictor features are known, but the value of the class label is unknown. This paper describes various classification algorithms and the recent attempt for improving classification accuracy\textemdash{}ensembles of classifiers.},
  language = {en},
  number = {3},
  journal = {Artificial Intelligence Review},
  doi = {10.1007/s10462-007-9052-3},
  author = {Kotsiantis, S. B. and Zaharakis, I. D. and Pintelas, P. E.},
  month = nov,
  year = {2006},
  keywords = {Classifiers,Data mining techniques,Intelligent data analysis,Learning algorithms},
  pages = {159-190}
}

@article{Abstracts2016Society2016,
  title = {Abstracts from the 2016 {{Society}} of {{General Internal Medicine Annual Meeting}}},
  volume = {31},
  issn = {1525-1497},
  language = {en},
  number = {2},
  journal = {Journal of General Internal Medicine},
  doi = {10.1007/s11606-016-3657-7},
  month = may,
  year = {2016},
  pages = {85-922},
  file = {/home/tim/Zotero/storage/R9S8V92J/2016 - Abstracts from the 2016 Society of General Interna.pdf;/home/tim/Zotero/storage/SSWJIBRH/2016 - Abstracts from the 2016 Society of General Interna.pdf}
}

@article{ScientificProgrammeAbstracts2003,
  title = {Scientific {{Programme}} \textemdash{} {{Abstracts}}},
  volume = {13},
  issn = {1432-1084},
  language = {en},
  number = {1},
  journal = {European Radiology},
  doi = {10.1007/BF03323651},
  month = feb,
  year = {2003},
  pages = {93-589}
}

@article{itoGINNGradientInterpretable2018,
  title = {{{GINN}}: Gradient Interpretable Neural Networks for Visualizing Financial Texts},
  issn = {2364-4168},
  shorttitle = {{{GINN}}},
  abstract = {This study aims to visualize financial documents in such a way that even nonexperts can understand the sentiments contained therein. To achieve this, we propose a novel text visualization method using an interpretable neural network (NN) architecture, called a gradient interpretable NN (GINN). A GINN can visualize a market sentiment score from an entire financial document and the sentiment gradient scores in both word and concept units. Moreover, the GINN can visualize important concepts given in various sentence contexts. Such visualization helps nonexperts easily understand financial documents. We theoretically analyze the validity of the GINN and experimentally demonstrate the validity of text visualization produced by the GINN using real financial texts.},
  language = {en},
  journal = {International Journal of Data Science and Analytics},
  doi = {10.1007/s41060-018-0160-8},
  author = {Ito, Tomoki and Sakaji, Hiroki and Izumi, Kiyoshi and Tsubouchi, Kota and Yamashita, Tatsuo},
  month = dec,
  year = {2018},
  keywords = {Interpretable neural network,Support system,Text mining}
}

@incollection{wodeckiInfluenceArtificialIntelligence2019,
  address = {Cham},
  title = {Influence of {{Artificial Intelligence}} on {{Activities}} and {{Competitiveness}} of an {{Organization}}},
  isbn = {978-3-319-91596-8},
  abstract = {The previous chapter was devoted to the most significant concepts, methods and technologies of artificial intelligence (AI). This gives grounds for the presentation of influence which these systems might have on the contemporary organizations and markets.},
  language = {en},
  booktitle = {Artificial {{Intelligence}} in {{Value Creation}}: {{Improving Competitive Advantage}}},
  publisher = {{Springer International Publishing}},
  author = {Wodecki, Andrzej},
  editor = {Wodecki, Andrzej},
  year = {2019},
  pages = {133-246},
  doi = {10.1007/978-3-319-91596-8_3}
}

@article{zhangVisualInterpretabilityDeep2018,
  title = {Visual Interpretability for Deep Learning: A Survey},
  volume = {19},
  issn = {2095-9230},
  shorttitle = {Visual Interpretability for Deep Learning},
  abstract = {This paper reviews recent studies in understanding neural-network representations and learning neural networks with interpretable/disentangled middle-layer representations. Although deep neural networks have exhibited superior performance in various tasks, interpretability is always Achilles' heel of deep neural networks. At present, deep neural networks obtain high discrimination power at the cost of a low interpretability of their black-box representations. We believe that high model interpretability may help people break several bottlenecks of deep learning, e.g., learning from a few annotations, learning via human\textendash{}computer communications at the semantic level, and semantically debugging network representations. We focus on convolutional neural networks (CNNs), and revisit the visualization of CNN representations, methods of diagnosing representations of pre-trained CNNs, approaches for disentangling pre-trained CNN representations, learning of CNNs with disentangled representations, and middle-to-end learning based on model interpretability. Finally, we discuss prospective trends in explainable artificial intelligence.},
  language = {en},
  number = {1},
  journal = {Frontiers of Information Technology \& Electronic Engineering},
  doi = {10.1631/FITEE.1700808},
  author = {Zhang, Quan-shi and Zhu, Song-chun},
  month = jan,
  year = {2018},
  keywords = {Artificial intelligence,Deep learning,Interpretable model,TP391},
  pages = {27-39},
  file = {/home/tim/Zotero/storage/RDRDKZXC/Zhang and Zhu - 2018 - Visual interpretability for deep learning a surve.pdf}
}

@incollection{dengEpilogueFrontiersNLP2018,
  address = {Singapore},
  title = {Epilogue: {{Frontiers}} of {{NLP}} in the {{Deep Learning Era}}},
  isbn = {978-981-10-5209-5},
  shorttitle = {Epilogue},
  abstract = {In the first part of this epilogue, we summarize the book holistically from two perspectives. The first, task-centric perspective ties together and categories a wide range of NLP techniques discussed in book in terms of general machine learning paradigms. In this way, the majority of sections and chapters of the book can be naturally clustered into four classes: classification, sequence-based prediction, higher-order structured prediction, and sequential decision-making. The second, representation-centric perspective distills insight from holistically analyzed book chapters from cognitive science viewpoints and in terms of two basic types of natural language representations: symbolic and distributed representations. In the second part of the epilogue, we update the most recent progress on deep learning in NLP (mainly during the later part of 2017, not surveyed in earlier chapters). Based on our reviews of these rapid recent advances, we then enrich our earlier writing on the research frontiers of NLP in Chap. 1 by addressing future directions of exploiting compositionality of natural language for generalization, unsupervised and reinforcement learning for NLP and their intricate connections, meta-learning for NLP, and weak-sense and strong-sense interpretability for NLP systems based on deep learning.},
  language = {en},
  booktitle = {Deep {{Learning}} in {{Natural Language Processing}}},
  publisher = {{Springer Singapore}},
  author = {Deng, Li and Liu, Yang},
  editor = {Deng, Li and Liu, Yang},
  year = {2018},
  pages = {309-326},
  doi = {10.1007/978-981-10-5209-5_11}
}

@inproceedings{maragoudakisMiningNaturalLanguage2008,
  series = {Lecture {{Notes}} in {{Computer Science}}},
  title = {Mining {{Natural Language Programming Directives}} with {{Class}}-{{Oriented Bayesian Networks}}},
  isbn = {978-3-540-88192-6},
  abstract = {Learning a programming language is a painstaking process, as it requires knowledge of its syntax, apart from knowing the basic process of representing logical sequences to programming stages. This fact deteriorates the coding process and expels most users from programming. Particularly for novice users or persons with vision problems, learning of how to program and tracing the syntax errors could be improved dramatically by using the most natural of all interfaces, i.e. natural language. Towards this orientation, we suggest a wider framework for allowing programming using natural language. The framework can be easily extended to support different object-oriented programming languages such as C, C++, Visual Basic or Java. Our suggested model is named ``Language Oriented Basic'' and it concerns an intelligent interface that supports code creation, modification and control in Visual Basic. Users can use simple-structured Greek sentences in natural language and the system can output the corresponding syntactic tree. When users declare end of input, the system transforms the syntactic trees to source code. Throughout the whole interaction process, users can check the under-development code in order to verify its correspondence to their expectations. Due to the fact that using natural language can cause a great degree of ambiguity, Bayesian networks and learning from examples have been utilized as an attempt to reason on the most probable programming representation, given a natural language input sentence. In order to enhance the classifier, we propose a novel variation of Bayesian networks that favor the classification process. Experimental results have depicted precision and recall measures in a range of 73\% and 70\% respectively.},
  language = {en},
  booktitle = {Advanced {{Data Mining}} and {{Applications}}},
  publisher = {{Springer Berlin Heidelberg}},
  author = {Maragoudakis, Manolis and Cosmas, Nikolaos and Garbis, Aristogiannis},
  editor = {Tang, Changjie and Ling, Charles X. and Zhou, Xiaofang and Cercone, Nick J. and Li, Xue},
  year = {2008},
  keywords = {Bayesian Classifier,Bayesian Network,Conditional Independence Assumption,Conditional Probability Table,Natural Language},
  pages = {15-26}
}

@article{AnnualCongressEuropean2018,
  title = {Annual {{Congress}} of the {{European Association}} of {{Nuclear Medicine October}} 13 \textendash{} 17, 2018 {{D\"usseldorf}}, {{Germany}}},
  volume = {45},
  issn = {1619-7089},
  language = {en},
  number = {1},
  journal = {European Journal of Nuclear Medicine and Molecular Imaging},
  doi = {10.1007/s00259-018-4148-3},
  month = oct,
  year = {2018},
  pages = {1-844}
}

@article{SPR20192019,
  title = {{{SPR}} 2019},
  volume = {49},
  issn = {1432-1998},
  language = {en},
  number = {1},
  journal = {Pediatric Radiology},
  doi = {10.1007/s00247-019-04376-7},
  month = apr,
  year = {2019},
  pages = {1-245},
  file = {/home/tim/Zotero/storage/TX23AHNA/2019 - SPR 2019.pdf}
}

@incollection{sarkarMachineLearningBasics2018,
  address = {Berkeley, CA},
  title = {Machine {{Learning Basics}}},
  isbn = {978-1-4842-3207-1},
  abstract = {The idea of making intelligent, sentient, and self-aware machines is not something that suddenly came into existence in the last few years. In fact a lot of lore from Greek mythology talks about intelligent machines and inventions having self-awareness and intelligence of their own. The origins and the evolution of the computer have been really revolutionary over a period of several centuries, starting from the basic Abacus and its descendant the slide rule in the 17th Century to the first general purpose computer designed by Charles Babbage in the 1800s. In fact, once computers started evolving with the invention of the Analytical Engine by Babbage and the first computer program, which was written by Ada Lovelace in 1842, people started wondering and contemplating that could there be a time when computers or machines truly become intelligent and start thinking for themselves. In fact, the renowned computer scientist, Alan Turing, was highly influential in the development of theoretical computer science, algorithms, and formal language and addressed concepts like artificial intelligence and Machine Learning as early as the 1950s. This brief insight into the evolution of making machines learn is just to give you an idea of something that has been out there since centuries but has recently started gaining a lot of attention and focus.},
  language = {en},
  booktitle = {Practical {{Machine Learning}} with {{Python}}: {{A Problem}}-{{Solver}}'s {{Guide}} to {{Building Real}}-{{World Intelligent Systems}}},
  publisher = {{Apress}},
  author = {Sarkar, Dipanjan and Bali, Raghav and Sharma, Tushar},
  editor = {Sarkar, Dipanjan and Bali, Raghav and Sharma, Tushar},
  year = {2018},
  pages = {3-65},
  doi = {10.1007/978-1-4842-3207-1_1}
}

@incollection{turnerControllingCreations2019,
  address = {Cham},
  title = {Controlling the {{Creations}}},
  isbn = {978-3-319-96235-1},
  abstract = {Turner explains how in order to implement constraints into AI directly, we will need to address both moral and technical questions: Which norms should be chosen? How can these be implemented? Potential basic laws for robots include: a law of identification, requiring that AI makes its status clear; a law of explanation, requiring that at least some parts of AI's reasoning be divulged; a laws on avoiding bias; and a law setting out any limits to areas where AI can operate. Finally, a kill switch law might make it mandatory that AI systems include a mechanism for safely interrupting their processes or operations, either temporarily or permanently.},
  language = {en},
  booktitle = {Robot {{Rules}} : {{Regulating Artificial Intelligence}}},
  publisher = {{Springer International Publishing}},
  author = {Turner, Jacob},
  editor = {Turner, Jacob},
  year = {2019},
  pages = {319-369},
  doi = {10.1007/978-3-319-96235-1_8}
}

@article{CARS2018Computer2018,
  title = {{{CARS}} 2018\textemdash{{Computer Assisted Radiology}} and {{Surgery Proceedings}} of the 32nd {{International Congress}} and {{Exhibition Berlin}}, {{Germany}}, {{June}} 20\textendash{}23, 2018},
  volume = {13},
  issn = {1861-6429},
  language = {en},
  number = {1},
  journal = {International Journal of Computer Assisted Radiology and Surgery},
  doi = {10.1007/s11548-018-1766-y},
  month = jun,
  year = {2018},
  pages = {1-273},
  file = {/home/tim/Zotero/storage/UDZ8MQ7K/2018 - CARS 2018—Computer Assisted Radiology and Surgery .pdf}
}

@inproceedings{biermannNaturalLanguageProgramming1983,
  series = {{{NATO Advanced Study Institutes Series}}},
  title = {Natural {{Language Programming}}},
  isbn = {978-94-009-7019-9},
  abstract = {A procedural semantics system is described for English imperative sentences in natural language programming. Issues related to the handling of dialog focus, noun group resolution, quantifier processing, and imperative verb execution are discussed. Sequences of imperative sentences may be assembled to build natural language programs and techniques are given for processing such programs. The final sections include a discussion of related research and a brief overview of the field.},
  language = {en},
  booktitle = {Computer {{Program Synthesis Methodologies}}},
  publisher = {{Springer Netherlands}},
  author = {Biermann, Alan W.},
  editor = {Biermann, Alan W. and Guiho, G\'erard},
  year = {1983},
  keywords = {Focus Mechanism,Head Noun,Natural Language,Naval Postgraduate School,Procedural Representation},
  pages = {335-368}
}

@article{ECR2005Scientific2005,
  title = {{{ECR}} 2005 \textendash{} {{Scientific Programme}} \textendash{} {{Abstracts}}},
  volume = {15},
  issn = {1613-3757},
  language = {en},
  number = {1},
  journal = {European Radiology Supplements},
  doi = {10.1007/s10406-005-0100-2},
  month = mar,
  year = {2005},
  keywords = {Public Health,Scientific Programme},
  pages = {1-688}
}

@incollection{ivancevicIntroductionHumanComputational2007,
  address = {Berlin, Heidelberg},
  series = {Studies in {{Computational Intelligence}}},
  title = {Introduction: {{Human}} and {{Computational Mind}}},
  isbn = {978-3-540-71561-0},
  shorttitle = {Introduction},
  language = {en},
  booktitle = {Computational {{Mind}}: {{A Complex Dynamics Perspective}}},
  publisher = {{Springer Berlin Heidelberg}},
  editor = {Ivancevic, Vladimir G. and Ivancevic, Tijana T.},
  year = {2007},
  keywords = {Adaptive Resonance Theory,Cellular Automaton,Horn Clause,Human Mind},
  pages = {1-269},
  doi = {10.1007/978-3-540-71561-0_1}
}

@incollection{panesarMachineLearningAlgorithms2019,
  address = {Berkeley, CA},
  title = {Machine {{Learning Algorithms}}},
  isbn = {978-1-4842-3799-1},
  abstract = {You do not need a background in algebra and statistics to get started in machine learning. However, be under no illusions, mathematics is a huge part of machine learning. Math is key to understanding how the algorithm works and why coding a machine learning project from scratch is a great way to improve your mathematical and statistical skills. Not understanding the underlying principles behind an algorithm can lead to a limited understanding of methods or adopting limited interpretations of algorithms. If nothing else, it is useful to understand the mathematical principles that algorithms are based on and thus understand best which machine learning techniques are most appropriate.},
  language = {en},
  booktitle = {Machine {{Learning}} and {{AI}} for {{Healthcare}}	: {{Big Data}} for {{Improved Health Outcomes}}},
  publisher = {{Apress}},
  author = {Panesar, Arjun},
  editor = {Panesar, Arjun},
  year = {2019},
  pages = {119-188},
  doi = {10.1007/978-1-4842-3799-1_4}
}

@incollection{dengJointIntroductionNatural2018,
  address = {Singapore},
  title = {A {{Joint Introduction}} to {{Natural Language Processing}} and to {{Deep Learning}}},
  isbn = {978-981-10-5209-5},
  abstract = {In this chapter, we set up the fundamental framework for the book. We first provide an introduction to the basics of natural language processing (NLP) as an integral part of artificial intelligence. We then survey the historical development of NLP, spanning over five decades, in terms of three waves. The first two waves arose as rationalism and empiricism, paving ways to the current deep learning wave. The key pillars underlying the deep learning revolution for NLP consist of (1) distributed representations of linguistic entities via embedding, (2) semantic generalization due to the embedding, (3) long-span deep sequence modeling of natural language, (4) hierarchical networks effective for representing linguistic levels from low to high, and (5) end-to-end deep learning methods to jointly solve many NLP tasks. After the survey, several key limitations of current deep learning technology for NLP are analyzed. This analysis leads to five research directions for future advances in NLP.},
  language = {en},
  booktitle = {Deep {{Learning}} in {{Natural Language Processing}}},
  publisher = {{Springer Singapore}},
  author = {Deng, Li and Liu, Yang},
  editor = {Deng, Li and Liu, Yang},
  year = {2018},
  pages = {1-22},
  doi = {10.1007/978-981-10-5209-5_1}
}

@article{25thAnnualConference2018,
  title = {25th {{Annual Conference}} of the {{International Society}} for {{Quality}} of {{Life Research}}},
  volume = {27},
  issn = {1573-2649},
  language = {en},
  number = {1},
  journal = {Quality of Life Research},
  doi = {10.1007/s11136-018-1946-9},
  month = oct,
  year = {2018},
  pages = {1-190}
}

@incollection{aakurInherentExplainabilityPattern2018,
  address = {Cham},
  series = {The {{Springer Series}} on {{Challenges}} in {{Machine Learning}}},
  title = {On the {{Inherent Explainability}} of {{Pattern Theory}}-{{Based Video Event Interpretations}}},
  isbn = {978-3-319-98131-4},
  abstract = {The ability of artificial intelligence systems to offer explanations for its decisions is central to building user confidence and structuring smart human-machine interactions. Expressing the rationale behind such a system's output is an important aspect of human-machine interaction as AI continues to be prominent in general, everyday use-cases. In this paper, we introduce a novel framework integrating Grenander's pattern theory structures to produce inherently explainable, symbolic representations for activity interpretations. These representations provide semantically rich and coherent interpretations of video activity using connected structures of detected (grounded) concepts, such as objects and actions, that are bound by semantics through background concepts not directly observed, i.e. contextualization cues. We use contextualization cues to establish semantic relationships among concepts to infer a deeper interpretation of events than what can be directly sensed. We propose the use of six questions that can be used to gain insight into the models ability to justify its decision and enhance its ability to interact with humans. The six questions are designed to (1) build an understanding of how the model is able to infer interpretations, (2) enable us to walk through its decision-making process, and (3) understand its drawbacks and possibly address them. We demonstrate the viability of this idea on video data using a dialog model that uses interpretations to generate explanations grounded in both video data and semantics.},
  language = {en},
  booktitle = {Explainable and {{Interpretable Models}} in {{Computer Vision}} and {{Machine Learning}}},
  publisher = {{Springer International Publishing}},
  author = {Aakur, Sathyanarayanan N. and {de Souza}, Fillipe D. M. and Sarkar, Sudeep},
  editor = {Escalante, Hugo Jair and Escalera, Sergio and Guyon, Isabelle and Bar\'o, Xavier and G\"u{\c c}l\"ut\"urk, Ya{\u g}mur and G\"u{\c c}l\"u, Umut and {van Gerven}, Marcel},
  year = {2018},
  keywords = {Activity interpretation,ConceptNet,Explainability,Semantics},
  pages = {277-299},
  doi = {10.1007/978-3-319-98131-4_11}
}

@article{grillHealthExploringComplexity2016,
  title = {Health\textemdash{}Exploring Complexity: An Interdisciplinary Systems Approach {{HEC2016}}},
  volume = {31},
  issn = {1573-7284},
  shorttitle = {Health\textemdash{}Exploring Complexity},
  language = {en},
  number = {1},
  journal = {European Journal of Epidemiology},
  doi = {10.1007/s10654-016-0183-1},
  author = {Grill, Eva and M\"uller, Martin and Mansmann, Ulrich},
  month = aug,
  year = {2016},
  pages = {1-239},
  file = {/home/tim/Zotero/storage/PB6D7S2L/Grill et al. - 2016 - Health—exploring complexity an interdisciplinary .pdf}
}

@inproceedings{zhangInterpretableNeuralModel2019,
  series = {Lecture {{Notes}} in {{Computer Science}}},
  title = {An {{Interpretable Neural Model}} with {{Interactive Stepwise Influence}}},
  isbn = {978-3-030-16142-2},
  abstract = {Deep neural networks have achieved promising prediction performance, but are often criticized for the lack of interpretability, which is essential in many real-world applications such as health informatics and political science. Meanwhile, it has been observed that many shallow models, such as linear models or tree-based models, are fairly interpretable though not accurate enough. Motivated by these observations, in this paper, we investigate how to fully take advantage of the interpretability of shallow models in neural networks. To this end, we propose a novel interpretable neural model with Interactive Stepwise Influence (ISI) framework. Specifically, in each iteration of the learning process, ISI interactively trains a shallow model with soft labels computed from a neural network, and the learned shallow model is then used to influence the neural network to gain interpretability. Thus ISI could achieve interpretability in three aspects: importance of features, impact of feature value changes, and adaptability of feature weights in the neural network learning process. Experiments on both synthetic and two real-world datasets demonstrate that ISI could generate reliable interpretation with respect to the three aspects, as well as preserve prediction accuracy by comparing with other state-of-the-art methods.},
  language = {en},
  booktitle = {Advances in {{Knowledge Discovery}} and {{Data Mining}}},
  publisher = {{Springer International Publishing}},
  author = {Zhang, Yin and Liu, Ninghao and Ji, Shuiwang and Caverlee, James and Hu, Xia},
  editor = {Yang, Qiang and Zhou, Zhi-Hua and Gong, Zhiguo and Zhang, Min-Ling and Huang, Sheng-Jun},
  year = {2019},
  keywords = {Interpretation,Neural network,Stepwise Influence},
  pages = {528-540}
}

@article{CARS2017Computer2017,
  title = {{{CARS}} 2017\textemdash{{Computer Assisted Radiology}} and {{Surgery Proceedings}} of the 31st {{International Congress}} and {{Exhibition Barcelona}}, {{Spain}}, {{June}} 20\textendash{}24, 2017},
  volume = {12},
  issn = {1861-6429},
  language = {en},
  number = {1},
  journal = {International Journal of Computer Assisted Radiology and Surgery},
  doi = {10.1007/s11548-017-1588-3},
  month = jun,
  year = {2017},
  pages = {1-286},
  file = {/home/tim/Zotero/storage/9MHAY3SY/2017 - CARS 2017—Computer Assisted Radiology and Surgery .pdf}
}

@article{bharadhwajExplanationsTemporalRecommendations2018,
  title = {Explanations for {{Temporal Recommendations}}},
  volume = {32},
  issn = {1610-1987},
  abstract = {Recommendation systems (RS) are an integral part of artificial intelligence (AI) and have become increasingly important in the growing age of commercialization in AI. Deep learning (DL) techniques for RS provide powerful latent-feature models for effective recommendation but suffer from the major drawback of being non-interpretable. In this paper we describe a framework for explainable temporal recommendations in a DL model. We consider an LSTM based Recurrent Neural Network architecture for recommendation and a neighbourhood based scheme for generating explanations in the model. We demonstrate the effectiveness of our approach through experiments on the Netflix dataset by jointly optimizing for both prediction accuracy and explainability.},
  language = {en},
  number = {4},
  journal = {KI - K\"unstliche Intelligenz},
  doi = {10.1007/s13218-018-0560-x},
  author = {Bharadhwaj, Homanga and Joshi, Shruti},
  month = nov,
  year = {2018},
  keywords = {Explainable AI,Recommendation systems,Recurrent Neural Networks},
  pages = {267-272},
  file = {/home/tim/Zotero/storage/4J8DH8MG/Bharadhwaj and Joshi - 2018 - Explanations for Temporal Recommendations.pdf}
}

@inproceedings{potapenkoInterpretableProbabilisticEmbeddings2018,
  series = {Communications in {{Computer}} and {{Information Science}}},
  title = {Interpretable {{Probabilistic Embeddings}}: {{Bridging}} the {{Gap Between Topic Models}} and {{Neural Networks}}},
  isbn = {978-3-319-71746-3},
  shorttitle = {Interpretable {{Probabilistic Embeddings}}},
  abstract = {We consider probabilistic topic models and more recent word embedding techniques from a perspective of learning hidden semantic representations. Inspired by a striking similarity of the two approaches, we merge them and learn probabilistic embeddings with online EM-algorithm on word co-occurrence data. The resulting embeddings perform on par with Skip-Gram Negative Sampling (SGNS) on word similarity tasks and benefit in the interpretability of the components. Next, we learn probabilistic document embeddings that outperform paragraph2vec on a document similarity task and require less memory and time for training. Finally, we employ multimodal Additive Regularization of Topic Models (ARTM) to obtain a high sparsity and learn embeddings for other modalities, such as timestamps and categories. We observe further improvement of word similarity performance and meaningful inter-modality similarities.},
  language = {en},
  booktitle = {Artificial {{Intelligence}} and {{Natural Language}}},
  publisher = {{Springer International Publishing}},
  author = {Potapenko, Anna and Popov, Artem and Vorontsov, Konstantin},
  editor = {Filchenkov, Andrey and Pivovarova, Lidia and {\v Z}i{\v z}ka, Jan},
  year = {2018},
  pages = {167-180}
}

@article{wengMedicalSubdomainClassification2017,
  title = {Medical Subdomain Classification of Clinical Notes Using a Machine Learning-Based Natural Language Processing Approach},
  volume = {17},
  issn = {1472-6947},
  abstract = {BackgroundThe medical subdomain of a clinical note, such as cardiology or neurology, is useful content-derived metadata for developing machine learning downstream applications. To classify the medical subdomain of a note accurately, we have constructed a machine learning-based natural language processing (NLP) pipeline and developed medical subdomain classifiers based on the content of the note.MethodsWe constructed the pipeline using the clinical NLP system, clinical Text Analysis and Knowledge Extraction System (cTAKES), the Unified Medical Language System (UMLS) Metathesaurus, Semantic Network, and learning algorithms to extract features from two datasets \textemdash{} clinical notes from Integrating Data for Analysis, Anonymization, and Sharing (iDASH) data repository (n = 431) and Massachusetts General Hospital (MGH) (n = 91,237), and built medical subdomain classifiers with different combinations of data representation methods and supervised learning algorithms. We evaluated the performance of classifiers and their portability across the two datasets.ResultsThe convolutional recurrent neural network with neural word embeddings trained-medical subdomain classifier yielded the best performance measurement on iDASH and MGH datasets with area under receiver operating characteristic curve (AUC) of 0.975 and 0.991, and F1 scores of 0.845 and 0.870, respectively. Considering better clinical interpretability, linear support vector machine-trained medical subdomain classifier using hybrid bag-of-words and clinically relevant UMLS concepts as the feature representation, with term frequency-inverse document frequency (tf-idf)-weighting, outperformed other shallow learning classifiers on iDASH and MGH datasets with AUC of 0.957 and 0.964, and F1 scores of 0.932 and 0.934 respectively. We trained classifiers on one dataset, applied to the other dataset and yielded the threshold of F1 score of 0.7 in classifiers for half of the medical subdomains we studied.ConclusionOur study shows that a supervised learning-based NLP approach is useful to develop medical subdomain classifiers. The deep learning algorithm with distributed word representation yields better performance yet shallow learning algorithms with the word and concept representation achieves comparable performance with better clinical interpretability. Portable classifiers may also be used across datasets from different institutions.},
  language = {en},
  number = {1},
  journal = {BMC Medical Informatics and Decision Making},
  doi = {10.1186/s12911-017-0556-8},
  author = {Weng, Wei-Hung and Wagholikar, Kavishwar B. and McCray, Alexa T. and Szolovits, Peter and Chueh, Henry C.},
  month = dec,
  year = {2017},
  keywords = {Computer-assisted,Deep Learning,Distributed Representation,Machine Learning,Medical Decision Making,Natural Language Processing,Unified Medical Language System},
  pages = {155},
  file = {/home/tim/Zotero/storage/8NGVVGDF/Weng et al. - 2017 - Medical subdomain classification of clinical notes.pdf}
}

@inproceedings{silvaComplementaryExplanationsUsing2018,
  series = {Lecture {{Notes}} in {{Computer Science}}},
  title = {Towards {{Complementary Explanations Using Deep Neural Networks}}},
  isbn = {978-3-030-02628-8},
  abstract = {Interpretability is a fundamental property for the acceptance of machine learning models in highly regulated areas. Recently, deep neural networks gained the attention of the scientific community due to their high accuracy in vast classification problems. However, they are still seen as black-box models where it is hard to understand the reasons for the labels that they generate. This paper proposes a deep model with monotonic constraints that generates complementary explanations for its decisions both in terms of style and depth. Furthermore, an objective framework for the evaluation of the explanations is presented. Our method is tested on two biomedical datasets and demonstrates an improvement in relation to traditional models in terms of quality of the explanations generated.},
  language = {en},
  booktitle = {Understanding and {{Interpreting Machine Learning}} in {{Medical Image Computing Applications}}},
  publisher = {{Springer International Publishing}},
  author = {Silva, Wilson and Fernandes, Kelwin and Cardoso, Maria J. and Cardoso, Jaime S.},
  editor = {Stoyanov, Danail and Taylor, Zeike and Kia, Seyed Mostafa and Oguz, Ipek and Reyes, Mauricio and Martel, Anne and {Maier-Hein}, Lena and Marquand, Andre F. and Duchesnay, Edouard and L\"ofstedt, Tommy and Landman, Bennett and Cardoso, M. Jorge and Silva, Carlos A. and Pereira, Sergio and Meier, Raphael},
  year = {2018},
  keywords = {Aesthetics evaluation,Deep neural networks,Dermoscopy,Explanations,Interpretable machine learning},
  pages = {133-140}
}

@incollection{lughoferModelExplanationInterpretation2018,
  address = {Cham},
  series = {Human\textendash{{Computer Interaction Series}}},
  title = {Model {{Explanation}} and {{Interpretation Concepts}} for {{Stimulating Advanced Human}}-{{Machine Interaction}} with ``{{Expert}}-in-the-{{Loop}}''},
  isbn = {978-3-319-90403-0},
  abstract = {We propose two directions for stimulating advanced human-machine interaction in machine learning systems. The first direction acts on a local level by suggesting a reasoning process why certain model decisions/predictions have been made for current sample queries. It may help to better understand how the model behaves and to support humans for providing more consistent and certain feedbacks. A practical example from visual inspection of production items underlines higher human labeling consistency. The second direction acts on a global level by addressing several criteria which are necessary for a good interpretability of the whole model. By meeting the criteria, the likelihood increases (1) of gaining more funded insights into the behavior of the system, and (2) of stimulating advanced expert/operators feedback in form of active manipulations of the model structure. Possibilities how to best integrate different types of advanced feedback in combination with (on-line) data using incremental model updates will be discussed. This leads to a new, hybrid interactive model building paradigm, which is based on subjective knowledge versus objective data and thus integrates the ``expert-in-the-loop'' aspect.},
  language = {en},
  booktitle = {Human and {{Machine Learning}}: {{Visible}}, {{Explainable}}, {{Trustworthy}} and {{Transparent}}},
  publisher = {{Springer International Publishing}},
  author = {Lughofer, Edwin},
  editor = {Zhou, Jianlong and Chen, Fang},
  year = {2018},
  pages = {177-221},
  doi = {10.1007/978-3-319-90403-0_10}
}

@article{moriBalancingTradeoffAccuracy2019,
  title = {Balancing the Trade-off between Accuracy and Interpretability in Software Defect Prediction},
  volume = {24},
  issn = {1573-7616},
  abstract = {ContextClassification techniques of supervised machine learning have been successfully applied to various domains of practice. When building a predictive model, there are two important criteria: predictive accuracy and interpretability, which generally have a trade-off relationship. In particular, interpretability should be accorded greater emphasis in the domains where the incorporation of expert knowledge into a predictive model is required.ObjectiveThe aim of this research is to propose a new classification model, called superposed naive Bayes (SNB), which transforms a naive Bayes ensemble into a simple naive Bayes model by linear approximation.MethodIn order to evaluate the predictive accuracy and interpretability of the proposed method, we conducted a comparative study using well-known classification techniques such as rule-based learners, decision trees, regression models, support vector machines, neural networks, Bayesian learners, and ensemble learners, over 13 real-world public datasets.ResultsA trade-off analysis between the accuracy and interpretability of different classification techniques was performed with a scatter plot comparing relative ranks of accuracy with those of interpretability. The experiment results show that the proposed method (SNB) can produce a balanced output that satisfies both accuracy and interpretability criteria.ConclusionsSNB offers a comprehensible predictive model based on a simple and transparent model structure, which can provide an effective way for balancing the trade-off between accuracy and interpretability.},
  language = {en},
  number = {2},
  journal = {Empirical Software Engineering},
  doi = {10.1007/s10664-018-9638-1},
  author = {Mori, Toshiki and Uchihira, Naoshi},
  month = apr,
  year = {2019},
  keywords = {Ensemble learning,Interpretability,Model approximation,Naive Bayes classifier,Predictive accuracy,Software defect prediction,Trade-off analysis,Weights of evidence},
  pages = {779-825}
}

@inproceedings{oitaReverseEngineeringCreativity2020,
  series = {Lecture {{Notes}} in {{Networks}} and {{Systems}}},
  title = {Reverse {{Engineering Creativity}} into {{Interpretable Neural Networks}}},
  isbn = {978-3-030-12385-7},
  abstract = {In the field of AI the ultimate goal is to achieve generic intelligence, also called ``true AI'', but which depends on the successful enablement of imagination and creativity in artificial agents. To address this problem, this paper presents a novel deep learning framework for creativity, called INNGenuity. Pursuing an interdisciplinary implementation of creativity conditions, INNGenuity aims at the resolution of the various flaws of current AI learning architectures, which stem from the opacity of their models. Inspired by the neuroanatomy of the brain during creative cognition, the proposed framework's hybrid architecture blends both symbolic and connectionist AI, inline with Minsky's ``society of mind''. At its core, semantic gates are designed to facilitate an input/output flow of semantic structures and enable the usage of aligning mechanisms between neural activation clusters and semantic graphs. Having as goal alignment maximization, such a system would enable interpretability through the creation of labeled patterns of computation, and propose unaligned but relevant computation patterns as novel and useful, therefore creative.},
  language = {en},
  booktitle = {Advances in {{Information}} and {{Communication}}},
  publisher = {{Springer International Publishing}},
  author = {Oita, Marilena},
  editor = {Arai, Kohei and Bhatia, Rahul},
  year = {2020},
  keywords = {Creativity,Imagination,Interpretability,Knowledge,Neural architecture,Neural networks,Semantic networks},
  pages = {235-247}
}

@inproceedings{alonsoZadehComputingWords2019,
  series = {Lecture {{Notes}} in {{Computer Science}}},
  title = {From {{Zadeh}}'s {{Computing}} with {{Words Towards eXplainable Artificial Intelligence}}},
  isbn = {978-3-030-12544-8},
  abstract = {The European Commission has identified Artificial Intelligence (AI) as the ``most strategic technology of the 21st century'' [7].},
  language = {en},
  booktitle = {Fuzzy {{Logic}} and {{Applications}}},
  publisher = {{Springer International Publishing}},
  author = {Alonso, Jose M.},
  editor = {Full\'er, Robert and Giove, Silvio and Masulli, Francesco},
  year = {2019},
  keywords = {Cointension,Computing with perceptions,Computing with words,Explainable AI,Fuzzy Logic,Interpretable fuzzy systems},
  pages = {244-248}
}

@incollection{curuksuPrinciplesDataScience2018,
  address = {Cham},
  series = {Management for {{Professionals}}},
  title = {Principles of {{Data Science}}: {{Advanced}}},
  isbn = {978-3-319-70229-2},
  shorttitle = {Principles of {{Data Science}}},
  abstract = {This chapter covers advanced analytics principles and applications. Let us first back up on our objectives and progress so far. In Chap. 6, we defined the key concepts underlying the mathematical science of data analysis. The discussion was structured in two categories: descriptive and inferential statistics. In the context of a data science project, these two categories may be referred to as unsupervised and supervised modeling respectively. These two categories are ubiquitous because the objective of a data science project is always (bear with me please) to better understand some data or else to predict something. Chapter 7 thus again follows this binary structure, although some topics (e.g. computer simulation, Sect. 7.3) may be used to collect and understand data, forecast events, or both.},
  language = {en},
  booktitle = {Data {{Driven}}: {{An Introduction}} to {{Management Consulting}} in the 21st {{Century}}},
  publisher = {{Springer International Publishing}},
  author = {Curuksu, Jeremy David},
  editor = {Curuksu, Jeremy David},
  year = {2018},
  pages = {87-127},
  doi = {10.1007/978-3-319-70229-2_7}
}

@incollection{nissanNarrativesFormalismComputational2014,
  address = {Berlin, Heidelberg},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  title = {Narratives, {{Formalism}}, {{Computational Tools}}, and {{Nonlinearity}}},
  isbn = {978-3-642-45324-3},
  abstract = {We recapitulate four decades of computational processing of narratives. Vladimir Propp's work in the 1920s paved the way to both the structuralists' approach to the folktale and to narratives in general, and the story grammars approach to automate story-processing. In the latter domain, grammar-driven processing was overtaken by goal-driven processing, but there has been a comeback of story grammars, in combination with other devices. Propp's concern was with Russian folktales, and some story-generation programs are relevant indeed for folktale studies: such is the case of the programs TALE-SPIN and Joseph, which reportedly generated fables; MINSTREL generated Arthurian tales. Sometimes, bugs reveal more than proper functioning does, about the actual underlying model. Automated story processing, within artificial intelligence, showed important results since the late 1970s. After slowing down during the 1990s, since the turn of the century the field resurged, especially in the perspective of virtual environments and interactive narratives, also benefiting from the popularity of computer models of the emotions.},
  language = {en},
  booktitle = {Language, {{Culture}}, {{Computation}}. {{Computing}} of the {{Humanities}}, {{Law}}, and {{Narratives}}: {{Essays Dedicated}} to {{Yaacov Choueka}} on the {{Occasion}} of {{His}} 75th {{Birthday}}, {{Part II}}},
  publisher = {{Springer Berlin Heidelberg}},
  author = {Nissan, Ephraim},
  editor = {Dershowitz, Nachum and Nissan, Ephraim},
  year = {2014},
  keywords = {Belief Revision,Computational Linguistics,Computational Tool,Computer Science Department,Natural Language Processing},
  pages = {270-393},
  doi = {10.1007/978-3-642-45324-3_11}
}

@inproceedings{lisboaInterpretabilityMachineLearning2013,
  series = {Lecture {{Notes}} in {{Computer Science}}},
  title = {Interpretability in {{Machine Learning}} \textendash{} {{Principles}} and {{Practice}}},
  isbn = {978-3-319-03200-9},
  abstract = {Theoretical advances in machine learning have been reflected in many research implementations including in safety-critical domains such as medicine. However this has not been reflected in a large number of practical applications used by domain experts. This bottleneck is in a significant part due to lack of interpretability of the non-linear models derived from data. This lecture will review five broad categories of interpretability in machine learning - nomograms, rule induction, fuzzy logic, graphical models \& topographic mapping. Links between the different approaches will be made around the common theme of designing interpretability into the structure of machine learning models, then using the armoury of advanced analytical methods to achieve generic non-linear approximation capabilities.},
  language = {en},
  booktitle = {Fuzzy {{Logic}} and {{Applications}}},
  publisher = {{Springer International Publishing}},
  author = {Lisboa, P. J. G.},
  editor = {Masulli, Francesco and Pasi, Gabriella and Yager, Ronald},
  year = {2013},
  keywords = {Fuzzy Logic,Latent Variable Model,Machine Learning Model,Predictive Inference,Rule Induction},
  pages = {15-21}
}

@incollection{kayaMultimodalPersonalityTrait2018,
  address = {Cham},
  series = {The {{Springer Series}} on {{Challenges}} in {{Machine Learning}}},
  title = {Multimodal {{Personality Trait Analysis}} for {{Explainable Modeling}} of {{Job Interview Decisions}}},
  isbn = {978-3-319-98131-4},
  abstract = {Automatic analysis of job interview screening decisions is useful for establishing the nature of biases that may play a role in such decisions. In particular, assessment of apparent personality gives insights into the first impressions evoked by a candidate. Such analysis tools can be used for training purposes, if they can be configured to provide appropriate and clear feedback. In this chapter, we describe a multimodal system that analyzes a short video of a job candidate, producing apparent personality scores and a prediction about whether the candidate will be invited for a further job interview or not. This system provides a visual and textual explanation about its decision, and was ranked first in the ChaLearn 2017 Job Candidate Screening Competition. We discuss the application scenario and the considerations from a broad perspective.},
  language = {en},
  booktitle = {Explainable and {{Interpretable Models}} in {{Computer Vision}} and {{Machine Learning}}},
  publisher = {{Springer International Publishing}},
  author = {Kaya, Heysem and Salah, Albert Ali},
  editor = {Escalante, Hugo Jair and Escalera, Sergio and Guyon, Isabelle and Bar\'o, Xavier and G\"u{\c c}l\"ut\"urk, Ya{\u g}mur and G\"u{\c c}l\"u, Umut and {van Gerven}, Marcel},
  year = {2018},
  keywords = {Explainable machine learning,Job candidate screening,Multimodal affective computing,Personality trait analysis},
  pages = {255-275},
  doi = {10.1007/978-3-319-98131-4_10}
}

@inproceedings{itoTextVisualizingNeuralNetwork2018,
  series = {Lecture {{Notes}} in {{Computer Science}}},
  title = {Text-{{Visualizing Neural Network Model}}: {{Understanding Online Financial Textual Data}}},
  isbn = {978-3-319-93040-4},
  shorttitle = {Text-{{Visualizing Neural Network Model}}},
  abstract = {This study aims to visualize financial documents to swiftly obtain market sentiment information from these documents and determine the reason for which sentiment decisions are made. This type of visualization is considered helpful for nonexperts to easily understand technical documents such as financial reports. To achieve this, we propose a novel interpretable neural network (NN) architecture called gradient interpretable NN (GINN). GINN can visualize both the market sentiment score from a whole financial document and the sentiment gradient scores in concept units. We experimentally demonstrate the validity of text visualization produced by GINN using a real textual dataset.},
  language = {en},
  booktitle = {Advances in {{Knowledge Discovery}} and {{Data Mining}}},
  publisher = {{Springer International Publishing}},
  author = {Ito, Tomoki and Sakaji, Hiroki and Tsubouchi, Kota and Izumi, Kiyoshi and Yamashita, Tatsuo},
  editor = {Phung, Dinh and Tseng, Vincent S. and Webb, Geoffrey I. and Ho, Bao and Ganji, Mohadeseh and Rashidi, Lida},
  year = {2018},
  keywords = {Interpretable neural network,Support system,Text mining},
  pages = {247-259}
}

@article{AbstractsScientificPapers1999,
  title = {Abstracts {{Scientific Papers Honorary Lectures Categorical Courses Workshops State}}-of-the-{{Art Symposia}}},
  volume = {9},
  issn = {1432-1084},
  language = {en},
  number = {1},
  journal = {European Radiology},
  doi = {10.1007/BF03323585},
  month = mar,
  year = {1999},
  keywords = {Magnetic Resonance Angiography,Magnetic Resonance Imaging,Spiral Compute Tomography,Takayasu Arteritis,Transjugular Intrahepatic Portosystemic Shunt},
  pages = {S1-S362}
}

@incollection{neukartReverseEngineeringMind2017,
  address = {Wiesbaden},
  series = {{{AutoUni}} \textendash{} {{Schriftenreihe}}},
  title = {Reverse Engineering the Mind},
  isbn = {978-3-658-16176-7},
  abstract = {Within this chapter all the requirements for reverse engineering the mind based on the knowledge imparted in the previous chapters will be discussed, and open questions attempted to be solved. A suitable theory of mind that on one side may not be the whole truth from a philosophical point of view, but serves as a valid foundation from an engineering point of view on the other side is introduced. Furthermore, as I indicated more than once, I am of the opinion that both quantum physics as well as self-organization occupy the most important roles in how our brain works and lets us experience conscious content and again, it is required to plunge into the information theoretical approach to quantum physics, quantum computer science.},
  language = {en},
  booktitle = {Reverse {{Engineering}} the {{Mind}}: {{Consciously Acting Machines}} and {{Accelerated Evolution}}},
  publisher = {{Springer Fachmedien Wiesbaden}},
  author = {Neukart, Florian},
  editor = {Neukart, Florian},
  year = {2017},
  keywords = {Artificial Neural Network,Hide Markov Model,Quantum Computer,Reverse Engineering,Semantic Network},
  pages = {237-354},
  doi = {10.1007/978-3-658-16176-7_10}
}

@article{18thISoPAnnual2018,
  title = {18th {{ISoP Annual Meeting}} ``{{Pharmacovigilance}} without Borders'' {{Geneva}}, {{Switzerland}}, 11\textendash{}14 {{November}}, 2018},
  volume = {41},
  issn = {1179-1942},
  language = {en},
  number = {11},
  journal = {Drug Safety},
  doi = {10.1007/s40264-018-0719-2},
  month = nov,
  year = {2018},
  pages = {1103-1273}
}

@article{sharpee25thAnnualComputational2016,
  title = {25th {{Annual Computational Neuroscience Meeting}}: {{CNS}}-2016},
  volume = {17},
  issn = {1471-2202},
  shorttitle = {25th {{Annual Computational Neuroscience Meeting}}},
  abstract = {Table of contentsA1 Functional advantages of cell-type heterogeneity in neural circuitsTatyana O. SharpeeA2 Mesoscopic modeling of propagating waves in visual cortexAlain DestexheA3 Dynamics and biomarkers of mental disordersMitsuo KawatoF1 Precise recruitment of spiking output at theta frequencies requires dendritic h-channels in multi-compartment models of oriens-lacunosum/moleculare hippocampal interneuronsVladislav Sekuli\'c, Frances K. SkinnerF2 Kernel methods in reconstruction of current sources from extracellular potentials for single cells and the whole brainsDaniel K. W\'ojcik, Chaitanya Chintaluri, Dorottya Cserp\'an, Zolt\'an Somogyv\'ariF3 The synchronized periods depend on intracellular transcriptional repression mechanisms in circadian clocks.Jae Kyoung Kim, Zachary P. Kilpatrick, Matthew R. Bennett, Kresimir Josi\'cO1 Assessing irregularity and coordination of spiking-bursting rhythms in central pattern generatorsIrene Elices, David Arroyo, Rafael Levi, Francisco B. Rodriguez, Pablo VaronaO2 Regulation of top-down processing by cortically-projecting parvalbumin positive neurons in basal forebrainEunjin Hwang, Bowon Kim, Hio-Been Han, Tae Kim, James T. McKenna, Ritchie E. Brown, Robert W. McCarley, Jee Hyun ChoiO3 Modeling auditory stream segregation, build-up and bistabilityJames Rankin, Pamela Osborn Popp, John RinzelO4 Strong competition between tonotopic neural ensembles explains pitch-related dynamics of auditory cortex evoked fieldsAlejandro Tabas, Andr\'e Rupp, Emili Balaguer-BallesterO5 A simple model of retinal response to multi-electrode stimulationMatias I. Maturana, David B. Grayden, Shaun L. Cloherty, Tatiana Kameneva, Michael R. Ibbotson, Hamish MeffinO6 Noise correlations in V4 area correlate with behavioral performance in visual discrimination taskVeronika Koren, Timm Lochmann, Valentin Dragoi, Klaus ObermayerO7 Input-location dependent gain modulation in cerebellar nucleus neuronsMaria Psarrou, Maria Schilstra, Neil Davey, Benjamin Torben-Nielsen, Volker SteuberO8 Analytic solution of cable energy function for cortical axons and dendritesHuiwen Ju, Jiao Yu, Michael L. Hines, Liang Chen, Yuguo YuO9 C. elegans interactome: interactive visualization of Caenorhabditis elegans worm neuronal networkJimin Kim, Will Leahy, Eli ShlizermanO10 Is the model any good? Objective criteria for computational neuroscience model selectionJustas Birgiolas, Richard C. Gerkin, Sharon M. CrookO11 Cooperation and competition of gamma oscillation mechanismsAtthaphon Viriyopase, Raoul-Martin Memmesheimer, Stan GielenO12 A discrete structure of the brain wavesYuri Dabaghian, Justin DeVito, Luca PerottiO13 Direction-specific silencing of the Drosophila gaze stabilization systemAnmo J. Kim, Lisa M. Fenk, Cheng Lyu, Gaby MaimonO14 What does the fruit fly think about values? A model of olfactory associative learningChang Zhao, Yves Widmer, Simon Sprecher,Walter SennO15 Effects of ionic diffusion on power spectra of local field potentials (LFP)Geir Halnes, Tuomo M\"aki-Marttunen, Daniel Keller, Klas H. Pettersen,Ole A. Andreassen, Gaute T. EinevollO16 Large-scale cortical models towards understanding relationship between brain structure abnormalities and cognitive deficitsYasunori YamadaO17 Spatial coarse-graining the brain: origin of minicolumnsMoira L. Steyn-Ross, D. Alistair Steyn-RossO18 Modeling large-scale cortical networks with laminar structureJorge F. Mejias, John D. Murray, Henry Kennedy, Xiao-Jing WangO19 Information filtering by partial synchronous spikes in a neural populationAlexandra Kruscha, Jan Grewe, Jan Benda, Benjamin LindnerO20 Decoding context-dependent olfactory valence in Drosophila Laurent Badel, Kazumi Ohta, Yoshiko Tsuchimoto, Hokto KazamaP1 Neural network as a scale-free network: the role of a hubB. KahngP2 Hemodynamic responses to emotions and decisions using near-infrared spectroscopy optical imagingNicoladie D. TamP3 Phase space analysis of hemodynamic responses to intentional movement directions using functional near-infrared spectroscopy (fNIRS) optical imaging techniqueNicoladie D.Tam, Luca Pollonini, George ZouridakisP4 Modeling jamming avoidance of weakly electric fishJaehyun Soh, DaeEun KimP5 Synergy and redundancy of retinal ganglion cells in predictionMinsu Yoo, S. E. PalmerP6 A neural field model with a third dimension representing cortical depthViviana Culmone, Ingo BojakP7 Network analysis of a probabilistic connectivity model of the Xenopus tadpole spinal cordAndrea Ferrario, Robert Merrison-Hort, Roman BorisyukP8 The recognition dynamics in the brainChang Sub KimP9 Multivariate spike train analysis using a positive definite kernelTaro TezukaP10 Synchronization of burst periods may govern slow brain dynamics during general anesthesiaPangyu JooP11 The ionic basis of heterogeneity affects stochastic synchronyYoung-Ah Rho, Shawn D. Burton, G. Bard Ermentrout, Jaeseung Jeong, Nathaniel N. UrbanP12 Circular statistics of noise in spike trains with a periodic componentPetr MarsalekP14 Representations of directions in EEG-BCI using Gaussian readoutsHoon-Hee Kim, Seok-hyun Moon, Do-won Lee, Sung-beom Lee, Ji-yong Lee, Jaeseung JeongP15 Action selection and reinforcement learning in basal ganglia during reaching movementsYaroslav I. Molkov, Khaldoun Hamade, Wondimu Teka, William H. Barnett, Taegyo Kim, Sergey Markin, Ilya A. RybakP17 Axon guidance: modeling axonal growth in T-Junction assayCsaba Forro, Harald Dermutz, L\'aszl\'o Demk\'o, J\'anos V\"or\"osP19 Transient cell assembly networks encode persistent spatial memoriesYuri Dabaghian, Andrey BabichevP20 Theory of population coupling and applications to describe high order correlations in large populations of interacting neuronsHaiping HuangP21 Design of biologically-realistic simulations for motor controlSergio Verduzco-FloresP22 Towards understanding the functional impact of the behavioural variability of neuronsFilipa Dos Santos, Peter AndrasP23 Different oscillatory dynamics underlying gamma entrainment deficits in schizophreniaChristoph Metzner, Achim Schweikard, Bartosz ZurowskiP24 Memory recall and spike frequency adaptationJames P. Roach, Leonard M. Sander, Michal R. ZochowskiP25 Stability of neural networks and memory consolidation preferentially occur near criticalityQuinton M. Skilling, Nicolette Ognjanovski, Sara J. Aton, Michal ZochowskiP26 Stochastic Oscillation in Self-Organized Critical States of Small Systems: Sensitive Resting State in Neural SystemsSheng-Jun Wang, Guang Ouyang, Jing Guang, Mingsha Zhang, K. Y. Michael Wong, Changsong ZhouP27 Neurofield: a C++ library for fast simulation of 2D neural field modelsPeter A. Robinson, Paula Sanz-Leon, Peter M. Drysdale, Felix Fung, Romesh G. Abeysuriya, Chris J. Rennie, Xuelong ZhaoP28 Action-based grounding: Beyond encoding/decoding in neural codeYoonsuck Choe, Huei-Fang YangP29 Neural computation in a dynamical system with multiple time scalesYuanyuan Mi, Xiaohan Lin, Si WuP30 Maximum entropy models for 3D layouts of orientation selectivityJoscha Liedtke, Manuel Schottdorf, Fred WolfP31 A behavioral assay for probing computations underlying curiosity in rodentsYoriko Yamamura, Jeffery R. WickensP32 Using statistical sampling to balance error function contributions to optimization of conductance-based modelsTimothy Rumbell, Julia Ramsey, Amy Reyes, Danel Dragulji\'c, Patrick R. Hof, Jennifer Luebke, Christina M. WeaverP33 Exploration and implementation of a self-growing and self-organizing neuron network building algorithmHu He, Xu Yang, Hailin Ma, Zhiheng Xu, Yuzhe WangP34 Disrupted resting state brain network in obese subjects: a data-driven graph theory analysisKwangyeol Baek, Laurel S. Morris, Prantik Kundu, Valerie VoonP35 Dynamics of cooperative excitatory and inhibitory plasticityEverton J. Agnes, Tim P. VogelsP36 Frequency-dependent oscillatory signal gating in feed-forward networks of integrate-and-fire neuronsWilliam F. Podlaski, Tim P. VogelsP37 Phenomenological neural model for adaptation of neurons in area ITMartin Giese, Pradeep Kuravi, Rufin VogelsP38 ICGenealogy: towards a common topology of neuronal ion channel function and genealogy in model and experimentAlexander Seeholzer, William Podlaski, Rajnish Ranjan, Tim VogelsP39 Temporal input discrimination from the interaction between dynamic synapses and neural subthreshold oscillationsJoaquin J. Torres, Fabiano Baroni, Roberto Latorre, Pablo VaronaP40 Different roles for transient and sustained activity during active visual processingBart Gips, Eric Lowet, Mark J. Roberts, Peter de Weerd, Ole Jensen, Jan van der EerdenP41 Scale-free functional networks of 2D Ising model are highly robust against structural defects: neuroscience implicationsAbdorreza Goodarzinick, Mohammad D. Niry, Alireza ValizadehP42 High frequency neuron can facilitate propagation of signal in neural networksAref Pariz, Shervin S. Parsi, Alireza ValizadehP43 Investigating the effect of Alzheimer's disease related amyloidopathy on gamma oscillations in the CA1 region of the hippocampusJulia M. Warburton, Lucia Marucci, Francesco Tamagnini, Jon Brown, Krasimira Tsaneva-AtanasovaP44 Long-tailed distributions of inhibitory and excitatory weights in a balanced network with eSTDP and iSTDPFlorence I. Kleberg, Jochen TrieschP45 Simulation of EMG recording from hand muscle due to TMS of motor cortexBahar Moezzi, Nicolangelo Iannella, Natalie Schaworonkow, Lukas Plogmacher, Mitchell R. Goldsworthy, Brenton Hordacre, Mark D. McDonnell, Michael C. Ridding, Jochen TrieschP46 Structure and dynamics of axon network formed in primary cell cultureMartin Zapotocky, Daniel Smit, Coralie Fouquet, Alain TrembleauP47 Efficient signal processing and sampling in random networks that generate variabilitySakyasingha Dasgupta, Isao Nishikawa, Kazuyuki Aihara, Taro ToyoizumiP48 Modeling the effect of riluzole on bursting in respiratory neural networksDaniel T. Robb, Nick Mellen, Natalia ToporikovaP49 Mapping relaxation training using effective connectivity analysisRongxiang Tang, Yi-Yuan TangP50 Modeling neuron oscillation of implicit sequence learningGuangsheng Liang, Seth A. Kiser, James H. Howard, Jr., Yi-Yuan TangP51 The role of cerebellar short-term synaptic plasticity in the pathology and medication of downbeat nystagmusJulia Goncharenko, Neil Davey, Maria Schilstra, Volker SteuberP52 Nonlinear response of noisy neuronsSergej O. Voronenko, Benjamin LindnerP53 Behavioral embedding suggests multiple chaotic dimensions underlie C. elegans locomotionTosif Ahamed, Greg StephensP54 Fast and scalable spike sorting for large and dense multi-electrodes recordingsPierre Yger, Baptiste Lefebvre, Giulia Lia Beatrice Spampinato, Elric Esposito, Marcel Stimberg et Olivier MarreP55 Sufficient sampling rates for fast hand motion trackingHansol Choi, Min-Ho SongP56 Linear readout of object manifoldsSueYeon Chung, Dan D. Lee, Haim SompolinskyP57 Differentiating models of intrinsic bursting and rhythm generation of the respiratory pre-B\"otzinger complex using phase response curvesRyan S. Phillips, Jeffrey SmithP58 The effect of inhibitory cell network interactions during theta rhythms on extracellular field potentials in CA1 hippocampusAlexandra Pierri Chatzikalymniou, Katie Ferguson, Frances K. SkinnerP59 Expansion recoding through sparse sampling in the cerebellar input layer speeds learningN. Alex Cayco Gajic, Claudia Clopath, R. Angus SilverP60 A set of curated cortical models at multiple scales on Open Source BrainPadraig Gleeson, Boris Marin, Sadra Sadeh, Adrian Quintana, Matteo Cantarelli, Salvador Dura-Bernal, William W. Lytton, Andrew Davison, R. Angus SilverP61 A synaptic story of dynamical information encoding in neural adaptationLuozheng Li, Wenhao Zhang, Yuanyuan Mi, Dahui Wang, Si WuP62 Physical modeling of rule-observant rodent behaviorYoungjo Song, Sol Park, Ilhwan Choi, Jaeseung Jeong, Hee-sup ShinP64 Predictive coding in area V4 and prefrontal cortex explains dynamic discrimination of partially occluded shapesHannah Choi, Anitha Pasupathy, Eric Shea-BrownP65 Stability of FORCE learning on spiking and rate-based networksDongsung Huh, Terrence J. SejnowskiP66 Stabilising STDP in striatal neurons for reliable fast state recognition in noisy environmentsSimon M. Vogt, Arvind Kumar, Robert SchmidtP67 Electrodiffusion in one- and two-compartment neuron models for characterizing cellular effects of electrical stimulationStephen Van Wert, Steven J. SchiffP68 STDP improves speech recognition capabilities in spiking recurrent circuits parameterized via differential evolution Markov Chain Monte CarloRichard Veale, Matthias ScheutzP69 Bidirectional transformation between dominant cortical neural activities and phase difference distributionsSang Wan LeeP70 Maturation of sensory networks through homeostatic structural plasticityJ\'ulia Gallinaro, Stefan RotterP71 Corticothalamic dynamics: structure, number of solutions and stability of steady-state solutions in the space of synaptic couplingsPaula Sanz-Leon, Peter A. RobinsonP72 Optogenetic versus electrical stimulation of the parkinsonian basal ganglia. Computational studyLeonid L. Rubchinsky, Chung Ching Cheung, Shivakeshavan Ratnadurai-GiridharanP73 Exact spike-timing distribution reveals higher-order interactions of neuronsSafura Rashid Shomali, Majid Nili Ahmadabadi, Hideaki Shimazaki, S. Nader RasuliP74 Neural mechanism of visual perceptual learning using a multi-layered neural networkXiaochen Zhao, Malte J. RaschP75 Inferring collective spiking dynamics from mostly unobserved systemsJens Wilting, Viola PriesemannP76 How to infer distributions in the brain from subsampled observationsAnna Levina, Viola PriesemannP77 Influences of embedding and estimation strategies on the inferred memory of single spiking neuronsLucas Rudelt, Joseph T. Lizier, Viola PriesemannP78 A nearest-neighbours based estimator for transfer entropy between spike trainsJoseph T. Lizier, Richard E. Spinney, Mikail Rubinov, Michael Wibral, Viola PriesemannP79 Active learning of psychometric functions with multinomial logistic modelsJi Hyun Bak, Jonathan PillowP81 Inferring low-dimensional network dynamics with variational latent Gaussian processYuan Zaho, Il Memming ParkP82 Computational investigation of energy landscapes in the resting state subcortical brain networkJiyoung Kang, Hae-Jeong ParkP83 Local repulsive interaction between retinal ganglion cells can generate a consistent spatial periodicity of orientation mapJaeson Jang, Se-Bum PaikP84 Phase duration of bistable perception reveals intrinsic time scale of perceptual decision under noisy conditionWoochul Choi, Se-Bum PaikP85 Feedforward convergence between retina and primary visual cortex can determine the structure of orientation mapChangju Lee, Jaeson Jang, Se-Bum PaikP86 Computational method classifying neural network activity patterns for imaging dataMin Song, Hyeonsu Lee, Se-Bum PaikP87 Symmetry of spike-timing-dependent-plasticity kernels regulates volatility of memoryYoungjin Park, Woochul Choi, Se-Bum PaikP88 Effects of time-periodic coupling strength on the first-spike latency dynamics of a scale-free network of stochastic Hodgkin-Huxley neuronsErgin Yilmaz, Veli Baysal, Mahmut OzerP89 Spectral properties of spiking responses in V1 and V4 change within the trial and are highly relevant for behavioral performanceVeronika Koren, Klaus ObermayerP90 Methods for building accurate models of individual neuronsDaniel Saska, Thomas NowotnyP91 A full size mathematical model of the early olfactory system of honeybeesHo Ka Chan, Alan Diamond, Thomas NowotnyP92 Stimulation-induced tuning of ongoing oscillations in spiking neural networksChristoph S. Herrmann, Micah M. Murray, Silvio Ionta, Axel Hutt, J\'er\'emie LefebvreP93 Decision-specific sequences of neural activity in balanced random networks driven by structured sensory inputPhilipp Weidel, Renato Duarte, Abigail MorrisonP94 Modulation of tuning induced by abrupt reduction of SST cell activityJung H. Lee, Ramakrishnan Iyer, Stefan MihalasP95 The functional role of VIP cell activation during locomotionJung H. Lee, Ramakrishnan Iyer, Christof Koch, Stefan MihalasP96 Stochastic inference with spiking neural networksMihai A. Petrovici, Luziwei Leng, Oliver Breitwieser, David St\"ockel, Ilja Bytschok, Roman Martel, Johannes Bill, Johannes Schemmel, Karlheinz MeierP97 Modeling orientation-selective electrical stimulation with retinal prosthesesTimothy B. Esler, Anthony N. Burkitt, David B. Grayden, Robert R. Kerr, Bahman Tahayori, Hamish MeffinP98 Ion channel noise can explain firing correlation in auditory nervesBahar Moezzi, Nicolangelo Iannella, Mark D. McDonnellP99 Limits of temporal encoding of thalamocortical inputs in a neocortical microcircuitMax Nolte, Michael W. Reimann, Eilif Muller, Henry MarkramP100 On the representation of arm reaching movements: a computational modelAntonio Parziale, Rosa Senatore, Angelo MarcelliP101 A computational model for investigating the role of cerebellum in acquisition and retention of motor behaviorRosa Senatore, Antonio Parziale, Angelo MarcelliP102 The emergence of semantic categories from a large-scale brain network of semantic knowledgeK. Skiker, M. MaoueneP103 Multiscale modeling of M1 multitarget pharmacotherapy for dystoniaSamuel A. Neymotin, Salvador Dura-Bernal, Alexandra Seidenstein, Peter Lakatos, Terence D. Sanger, William W. LyttonP104 Effect of network size on computational capacitySalvador Dura-Bernal, Rosemary J. Menzies, Campbell McLauchlan, Sacha J. van Albada, David J. Kedziora, Samuel Neymotin, William W. Lytton, Cliff C. KerrP105 NetPyNE: a Python package for NEURON to facilitate development and parallel simulation of biological neuronal networksSalvador Dura-Bernal, Benjamin A. Suter, Samuel A. Neymotin, Cliff C. Kerr, Adrian Quintana, Padraig Gleeson, Gordon M. G. Shepherd, William W. LyttonP107 Inter-areal and inter-regional inhomogeneity in co-axial anisotropy of Cortical Point Spread in human visual areasJuhyoung Ryu, Sang-Hun LeeP108 Two bayesian quanta of uncertainty explain the temporal dynamics of cortical activity in the non-sensory areas during bistable perceptionJoonwon Lee, Sang-Hun LeeP109 Optimal and suboptimal integration of sensory and value information in perceptual decision makingHyang Jung Lee, Sang-Hun LeeP110 A Bayesian algorithm for phoneme Perception and its neural implementationDaeseob Lim, Sang-Hun LeeP111 Complexity of EEG signals is reduced during unconsciousness induced by ketamine and propofolJisung Wang, Heonsoo LeeP112 Self-organized criticality of neural avalanche in a neural model on complex networksNam Jung, Le Anh Quang, Seung Eun Maeng, Tae Ho Lee, Jae Woo LeeP113 Dynamic alterations in connection topology of the hippocampal network during ictal-like epileptiform activity in an in vitro rat modelChang-hyun Park, Sora Ahn, Jangsup Moon, Yun Seo Choi, Juhee Kim, Sang Beom Jun, Seungjun Lee, Hyang Woon LeeP114 Computational model to replicate seizure suppression effect by electrical stimulationSora Ahn, Sumin Jo, Eunji Jun, Suin Yu, Hyang Woon Lee, Sang Beom Jun, Seungjun LeeP115 Identifying excitatory and inhibitory synapses in neuronal networks from spike trains using sorted local transfer entropyFelix Goetze, Pik-Yin LaiP116 Neural network model for obstacle avoidance based on neuromorphic computational model of boundary vector cell and head direction cellSeonghyun Kim, Jeehyun KwagP117 Dynamic gating of spike pattern propagation by Hebbian and anti-Hebbian spike timing-dependent plasticity in excitatory feedforward network modelHyun Jae Jang, Jeehyun KwagP118 Inferring characteristics of input correlations of cells exhibiting up-down state transitions in the rat striatumMarko Filipovi\'c, Ramon Reig, Ad Aertsen, Gilad Silberberg, Arvind KumarP119 Graph properties of the functional connected brain under the influence of Alzheimer's diseaseClaudia Bachmann, Simone Buttler, Heidi Jacobs, Kim Dillen, Gereon R. Fink, Juraj Kukolja, Abigail MorrisonP120 Learning sparse representations in the olfactory bulbDaniel Kepple, Hamza Giaffar, Dima Rinberg, Steven Shea, Alex KoulakovP121 Functional classification of homologous basal-ganglia networksJyotika Bahuguna,Tom Tetzlaff, Abigail Morrison, Arvind Kumar, Jeanette Hellgren KotaleskiP122 Short term memory based on multistabilityTim Kunze, Andre Peterson, Thomas Kn\"oscheP123 A physiologically plausible, computationally efficient model and simulation software for mammalian motor unitsMinjung Kim, Hojeong KimP125 Decoding laser-induced somatosensory information from EEGJi Sung Park, Ji Won Yeon, Sung-Phil KimP126 Phase synchronization of alpha activity for EEG-based personal authenticationJae-Hwan Kang, Chungho Lee, Sung-Phil KimP129 Investigating phase-lags in sEEG data using spatially distributed time delays in a large-scale brain network modelAndreas Spiegler, Spase Petkoski, Matias J. Palva, Viktor K. JirsaP130 Epileptic seizures in the unfolding of a codimension-3 singularityMaria L. Saggio, Silvan F. Siep, Andreas Spiegler, William C. Stacey, Christophe Bernard, Viktor K. JirsaP131 Incremental dimensional exploratory reasoning under multi-dimensional environmentOh-hyeon Choung, Yong JeongP132 A low-cost model of eye movements and memory in personal visual cognitionYong-il Lee, Jaeseung JeongP133 Complex network analysis of structural connectome of autism spectrum disorder patientsSu Hyun Kim, Mir Jeong, Jaeseung JeongP134 Cognitive motives and the neural correlates underlying human social information transmission, gossipJeungmin Lee, Jaehyung Kwon, Jerald D. Kralik, Jaeseung JeongP135 EEG hyperscanning detects neural oscillation for the social interaction during the economic decision-makingJaehwan Jahng, Dong-Uk Hwang, Jaeseung JeongP136 Detecting purchase decision based on hyperfrontality of the EEGJae-Hyung Kwon, Sang-Min Park, Jaeseung JeongP137 Vulnerability-based critical neurons, synapses, and pathways in the Caenorhabditis elegans connectomeSeongkyun Kim, Hyoungkyu Kim, Jerald D. Kralik, Jaeseung JeongP138 Motif analysis reveals functionally asymmetrical neurons in C. elegans Pyeong Soo Kim, Seongkyun Kim, Hyoungkyu Kim, Jaeseung JeongP139 Computational approach to preference-based serial decision dynamics: do temporal discounting and working memory affect it?Sangsup Yoon, Jaehyung Kwon, Sewoong Lim, Jaeseung JeongP141 Social stress induced neural network reconfiguration affects decision making and learning in zebrafishChoongseok Park, Thomas Miller, Katie Clements, Sungwoo Ahn, Eoon Hye Ji, Fadi A. IssaP142 Descriptive, generative, and hybrid approaches for neural connectivity inference from neural activity dataJeongHun Baek, Shigeyuki Oba, Junichiro Yoshimoto, Kenji Doya, Shin IshiiP145 Divergent-convergent synaptic connectivities accelerate coding in multilayered sensory systemsThiago S. Mosqueiro, Martin F. Strube-Bloss, Brian Smith, Ramon HuertaP146 Swinging networksMichal Hadrava, Jaroslav HlinkaP147 Inferring dynamically relevant motifs from oscillatory stimuli: challenges, pitfalls, and solutionsHannah Bos, Moritz HeliasP148 Spatiotemporal mapping of brain network dynamics during cognitive tasks using magnetoencephalography and deep learningCharles M. Welzig, Zachary J. HarperP149 Multiscale complexity analysis for the segmentation of MRI imagesWon Sup Kim, In-Seob Shin, Hyeon-Man Baek, Seung Kee HanP150 A neuro-computational model of emotional attentionRen\'e Richter, Julien Vitay, Frederick Beuth, Fred H. HamkerP151 Multi-site delayed feedback stimulation in parkinsonian networksKelly Toppin, Yixin GuoP152 Bistability in Hodgkin\textendash{}Huxley-type equationsTatiana Kameneva, Hamish Meffin, Anthony N. Burkitt, David B. GraydenP153 Phase changes in postsynaptic spiking due to synaptic connectivity and short term plasticity: mathematical analysis of frequency dependencyMark D. McDonnell, Bruce P. GrahamP154 Quantifying resilience patterns in brain networks: the importance of directionalityPenelope J. Kale, Leonardo L. GolloP155 Dynamics of rate-model networks with separate excitatory and inhibitory populationsMerav Stern, L. F. AbbottP156 A model for multi-stable dynamics in action recognition modulated by integration of silhouette and shading cuesLeonid A. Fedorov, Martin A. GieseP157 Spiking model for the interaction between action recognition and action executionMohammad Hovaidi Ardestani, Martin GieseP158 Surprise-modulated belief update: how to learn within changing environments?Mohammad Javad Faraji, Kerstin Preuschoff, Wulfram GerstnerP159 A fast, stochastic and adaptive model of auditory nerve responses to cochlear implant stimulationMargriet J. van Gendt, Jeroen J. Briaire, Randy K. Kalkman, Johan H. M. FrijnsP160 Quantitative comparison of graph theoretical measures of simulated and empirical functional brain networksWon Hee Lee, Sophia FrangouP161 Determining discriminative properties of fMRI signals in schizophrenia using highly comparative time-series analysisBen D. Fulcher, Patricia H. P. Tran, Alex FornitoP162 Emergence of narrowband LFP oscillations from completely asynchronous activity during seizures and high-frequency oscillationsStephen V. Gliske, William C. Stacey, Eugene Lim, Katherine A. Holman, Christian G. FinkP163 Neuronal diversity in structure and function: cross-validation of anatomical and physiological classification of retinal ganglion cells in the mouseJinseop S. Kim, Shang Mu, Kevin L. Briggman, H. Sebastian Seung, the EyeWirersP164 Analysis and modelling of transient firing rate changes in area MT in response to rapid stimulus feature changesDetlef Wegener, Lisa Bohnenkamp, Udo A. ErnstP165 Step-wise model fitting accounting for high-resolution spatial measurements: construction of a layer V pyramidal cell model with reduced morphologyTuomo M\"aki-Marttunen, Geir Halnes, Anna Devor, Christoph Metzner, Anders M. Dale, Ole A. Andreassen, Gaute T. EinevollP166 Contributions of schizophrenia-associated genes to neuron firing and cardiac pacemaking: a polygenic modeling approachTuomo M\"aki-Marttunen, Glenn T. Lines, Andy Edwards, Aslak Tveito, Anders M. Dale, Gaute T. Einevoll, Ole A. AndreassenP167 Local field potentials in a 4 \texttimes{} 4 mm2 multi-layered network modelEspen Hagen, Johanna Senk, Sacha J. van Albada, Markus DiesmannP168 A spiking network model explains multi-scale properties of cortical dynamicsMaximilian Schmidt, Rembrandt Bakker, Kelly Shen, Gleb Bezgin, Claus-Christian Hilgetag, Markus Diesmann, Sacha Jennifer van AlbadaP169 Using joint weight-delay spike-timing dependent plasticity to find polychronous neuronal groupsHaoqi Sun, Olga Sourina, Guang-Bin Huang, Felix Klanner, Cornelia DenkP170 Tensor decomposition reveals RSNs in simulated resting state fMRIKatharina Glomb, Adri\'an Ponce-Alvarez, Matthieu Gilson, Petra Ritter, Gustavo DecoP171 Getting in the groove: testing a new model-based method for comparing task-evoked vs resting-state activity in fMRI data on music listeningMatthieu Gilson, Maria AG Witek, Eric F. Clarke, Mads Hansen, Mikkel Wallentin, Gustavo Deco, Morten L. Kringelbach, Peter VuustP172 STochastic engine for pathway simulation (STEPS) on massively parallel processorsGuido Klingbeil, Erik De SchutterP173 Toolkit support for complex parallel spatial stochastic reaction\textendash{}diffusion simulation in STEPSWeiliang Chen, Erik De SchutterP174 Modeling the generation and propagation of Purkinje cell dendritic spikes caused by parallel fiber synaptic inputYunliang Zang, Erik De SchutterP175 Dendritic morphology determines how dendrites are organized into functional subunitsSungho Hong, Akira Takashima, Erik De SchutterP176 A model of Ca2+/calmodulin-dependent protein kinase II activity in long term depression at Purkinje cellsCriseida Zamora, Andrew R. Gallimore, Erik De SchutterP177 Reward-modulated learning of population-encoded vectors for insect-like navigation in embodied agentsDennis Goldschmidt, Poramate Manoonpong, Sakyasingha DasguptaP178 Data-driven neural models part II: connectivity patterns of human seizuresPhilippa J. Karoly, Dean R. Freestone, Daniel Soundry, Levin Kuhlmann, Liam Paninski, Mark CookP179 Data-driven neural models part I: state and parameter estimationDean R. Freestone, Philippa J. Karoly, Daniel Soundry, Levin Kuhlmann, Mark CookP180 Spectral and spatial information processing in human auditory streamingJaejin Lee, Yonatan I. Fishman, Yale E. CohenP181 A tuning curve for the global effects of local perturbations in neural activity: Mapping the systems-level susceptibility of the brainLeonardo L. Gollo, James A. Roberts, Luca CocchiP182 Diverse homeostatic responses to visual deprivation mediated by neural ensemblesYann Sweeney, Claudia ClopathP183 Opto-EEG: a novel method for investigating functional connectome in mouse brain based on optogenetics and high density electroencephalographySoohyun Lee, Woo-Sung Jung, Jee Hyun ChoiP184 Biphasic responses of frontal gamma network to repetitive sleep deprivation during REM sleepBowon Kim, Youngsoo Kim, Eunjin Hwang, Jee Hyun ChoiP185 Brain-state correlate and cortical connectivity for frontal gamma oscillations in top-down fashion assessed by auditory steady-state responseYounginha Jung, Eunjin Hwang, Yoon-Kyu Song, Jee Hyun ChoiP186 Neural field model of localized orientation selective activation in V1James Rankin, Fr\'ed\'eric ChavaneP187 An oscillatory network model of Head direction and Grid cells using locomotor inputsKarthik Soman, Vignesh Muralidharan, V. Srinivasa ChakravarthyP188 A computational model of hippocampus inspired by the functional architecture of basal gangliaKarthik Soman, Vignesh Muralidharan, V. Srinivasa ChakravarthyP189 A computational architecture to model the microanatomy of the striatum and its functional propertiesSabyasachi Shivkumar, Vignesh Muralidharan, V. Srinivasa ChakravarthyP190 A scalable cortico-basal ganglia model to understand the neural dynamics of targeted reachingVignesh Muralidharan, Alekhya Mandali, B. Pragathi Priyadharsini, Hima Mehta, V. Srinivasa ChakravarthyP191 Emergence of radial orientation selectivity from synaptic plasticityCatherine E. Davey, David B. Grayden, Anthony N. BurkittP192 How do hidden units shape effective connections between neurons?Braden A. W. Brinkman, Tyler Kekona, Fred Rieke, Eric Shea-Brown, Michael BuiceP193 Characterization of neural firing in the presence of astrocyte-synapse signalingMaurizio De Pitt\`a, Hugues Berry, Nicolas BrunelP194 Metastability of spatiotemporal patterns in a large-scale network model of brain dynamicsJames A. Roberts, Leonardo L. Gollo, Michael BreakspearP195 Comparison of three methods to quantify detection and discrimination capacity estimated from neural population recordingsGary Marsat, Jordan Drew, Phillip D. Chapman, Kevin C. Daly, Samual P. BradleyP196 Quantifying the constraints for independent evoked and spontaneous NMDA receptor mediated synaptic transmission at individual synapsesSat Byul Seo, Jianzhong Su, Ege T. Kavalali, Justin BlackwellP199 Gamma oscillation via adaptive exponential integrate-and-fire neuronsLieJune Shiau, Laure Buhry, Kanishka BasnayakeP200 Visual face representations during memory retrieval compared to perceptionSue-Hyun Lee, Brandon A. Levy, Chris I. BakerP201 Top-down modulation of sequential activity within packets modeled using avalanche dynamicsTimoth\'ee Leleu, Kazuyuki AiharaQ28 An auto-encoder network realizes sparse features under the influence of desynchronized vascular dynamicsRyan T. Philips, Karishma Chhabria, V. Srinivasa Chakravarthy},
  language = {en},
  number = {1},
  journal = {BMC Neuroscience},
  doi = {10.1186/s12868-016-0283-6},
  author = {Sharpee, Tatyana O. and Destexhe, Alain and Kawato, Mitsuo and Sekuli\'c, Vladislav and Skinner, Frances K. and W\'ojcik, Daniel K. and Chintaluri, Chaitanya and Cserp\'an, Dorottya and Somogyv\'ari, Zolt\'an and Kim, Jae Kyoung and Kilpatrick, Zachary P. and Bennett, Matthew R. and Josi\'c, Kresimir and Elices, Irene and Arroyo, David and Levi, Rafael and Rodriguez, Francisco B. and Varona, Pablo and Hwang, Eunjin and Kim, Bowon and Han, Hio-Been and Kim, Tae and McKenna, James T. and Brown, Ritchie E. and McCarley, Robert W. and Choi, Jee Hyun and Rankin, James and Popp, Pamela Osborn and Rinzel, John and Tabas, Alejandro and Rupp, Andr\'e and {Balaguer-Ballester}, Emili and Maturana, Matias I. and Grayden, David B. and Cloherty, Shaun L. and Kameneva, Tatiana and Ibbotson, Michael R. and Meffin, Hamish and Koren, Veronika and Lochmann, Timm and Dragoi, Valentin and Obermayer, Klaus and Psarrou, Maria and Schilstra, Maria and Davey, Neil and {Torben-Nielsen}, Benjamin and Steuber, Volker and Ju, Huiwen and Yu, Jiao and Hines, Michael L. and Chen, Liang and Yu, Yuguo and Kim, Jimin and Leahy, Will and Shlizerman, Eli and Birgiolas, Justas and Gerkin, Richard C. and Crook, Sharon M. and Viriyopase, Atthaphon and Memmesheimer, Raoul-Martin and Gielen, Stan and Dabaghian, Yuri and DeVito, Justin and Perotti, Luca and Kim, Anmo J. and Fenk, Lisa M. and Cheng, Cheng and Maimon, Gaby and Zhao, Chang and Widmer, Yves and Sprecher, Simon and Senn, Walter and Halnes, Geir and {M\"aki-Marttunen}, Tuomo and Keller, Daniel and Pettersen, Klas H. and Andreassen, Ole A. and Einevoll, Gaute T. and Yamada, Yasunori and {Steyn-Ross}, Moira L. and {Alistair Steyn-Ross}, D. and Mejias, Jorge F. and Murray, John D. and Kennedy, Henry and Wang, Xiao-Jing and Kruscha, Alexandra and Grewe, Jan and Benda, Jan and Lindner, Benjamin and Badel, Laurent and Ohta, Kazumi and Tsuchimoto, Yoshiko and Kazama, Hokto and Kahng, B. and Tam, Nicoladie D. and Pollonini, Luca and Zouridakis, George and Soh, Jaehyun and Kim, DaeEun and Yoo, Minsu and Palmer, S. E. and Culmone, Viviana and Bojak, Ingo and Ferrario, Andrea and {Merrison-Hort}, Robert and Borisyuk, Roman and Kim, Chang Sub and Tezuka, Taro and Joo, Pangyu and Rho, Young-Ah and Burton, Shawn D. and Bard Ermentrout, G. and Jeong, Jaeseung and Urban, Nathaniel N. and Marsalek, Petr and Kim, Hoon-Hee and Moon, Seok-hyun and Lee, Do-won and Lee, Sung-beom and Lee, Ji-yong and Molkov, Yaroslav I. and Hamade, Khaldoun and Teka, Wondimu and Barnett, William H. and Kim, Taegyo and Markin, Sergey and Rybak, Ilya A. and Forro, Csaba and Dermutz, Harald and Demk\'o, L\'aszl\'o and V\"or\"os, J\'anos and Babichev, Andrey and Huang, Haiping and {Verduzco-Flores}, Sergio and Dos Santos, Filipa and Andras, Peter and Metzner, Christoph and Schweikard, Achim and Zurowski, Bartosz and Roach, James P. and Sander, Leonard M. and Zochowski, Michal R. and Skilling, Quinton M. and Ognjanovski, Nicolette and Aton, Sara J. and Zochowski, Michal and Wang, Sheng-Jun and Ouyang, Guang and Guang, Jing and Zhang, Mingsha and Michael Wong, K. Y. and Zhou, Changsong and Robinson, Peter A. and {Sanz-Leon}, Paula and Drysdale, Peter M. and Fung, Felix and Abeysuriya, Romesh G. and Rennie, Chris J. and Zhao, Xuelong and Choe, Yoonsuck and Yang, Huei-Fang and Mi, Yuanyuan and Lin, Xiaohan and Wu, Si and Liedtke, Joscha and Schottdorf, Manuel and Wolf, Fred and Yamamura, Yoriko and Wickens, Jeffery R. and Rumbell, Timothy and Ramsey, Julia and Reyes, Amy and Dragulji\'c, Danel and Hof, Patrick R. and Luebke, Jennifer and Weaver, Christina M. and He, Hu and Yang, Xu and Ma, Hailin and Xu, Zhiheng and Wang, Yuzhe and Baek, Kwangyeol and Morris, Laurel S. and Kundu, Prantik and Voon, Valerie and Agnes, Everton J. and Vogels, Tim P. and Podlaski, William F. and Giese, Martin and Kuravi, Pradeep and Vogels, Rufin and Seeholzer, Alexander and Podlaski, William and Ranjan, Rajnish and Vogels, Tim and Torres, Joaquin J. and Baroni, Fabiano and Latorre, Roberto and Gips, Bart and Lowet, Eric and Roberts, Mark J. and {de Weerd}, Peter and Jensen, Ole and {van der Eerden}, Jan and Goodarzinick, Abdorreza and Niry, Mohammad D. and Valizadeh, Alireza and Pariz, Aref and Parsi, Shervin S. and Warburton, Julia M. and Marucci, Lucia and Tamagnini, Francesco and Brown, Jon and {Tsaneva-Atanasova}, Krasimira and Kleberg, Florence I. and Triesch, Jochen and Moezzi, Bahar and Iannella, Nicolangelo and Schaworonkow, Natalie and Plogmacher, Lukas and Goldsworthy, Mitchell R. and Hordacre, Brenton and McDonnell, Mark D. and Ridding, Michael C. and Zapotocky, Martin and Smit, Daniel and Fouquet, Coralie and Trembleau, Alain and Dasgupta, Sakyasingha and Nishikawa, Isao and Aihara, Kazuyuki and Toyoizumi, Taro and Robb, Daniel T. and Mellen, Nick and Toporikova, Natalia and Tang, Rongxiang and Tang, Yi-Yuan and Liang, Guangsheng and Kiser, Seth A. and Howard, James H. and Goncharenko, Julia and Voronenko, Sergej O. and Ahamed, Tosif and Stephens, Greg and Yger, Pierre and Lefebvre, Baptiste and Spampinato, Giulia Lia Beatrice and Esposito, Elric and {et Olivier Marre}, Marcel Stimberg and Choi, Hansol and Song, Min-Ho and Chung, SueYeon and Lee, Dan D. and Sompolinsky, Haim and Phillips, Ryan S. and Smith, Jeffrey and Chatzikalymniou, Alexandra Pierri and Ferguson, Katie and Alex Cayco Gajic, N. and Clopath, Claudia and Angus Silver, R. and Gleeson, Padraig and Marin, Boris and Sadeh, Sadra and Quintana, Adrian and Cantarelli, Matteo and {Dura-Bernal}, Salvador and Lytton, William W. and Davison, Andrew and Li, Luozheng and Zhang, Wenhao and Wang, Dahui and Song, Youngjo and Park, Sol and Choi, Ilhwan and Shin, Hee-sup and Choi, Hannah and Pasupathy, Anitha and {Shea-Brown}, Eric and Huh, Dongsung and Sejnowski, Terrence J. and Vogt, Simon M. and Kumar, Arvind and Schmidt, Robert and Van Wert, Stephen and Schiff, Steven J. and Veale, Richard and Scheutz, Matthias and Lee, Sang Wan and Gallinaro, J\'ulia and Rotter, Stefan and Rubchinsky, Leonid L. and Cheung, Chung Ching and {Ratnadurai-Giridharan}, Shivakeshavan and Shomali, Safura Rashid and Ahmadabadi, Majid Nili and Shimazaki, Hideaki and Nader Rasuli, S. and Zhao, Xiaochen and Rasch, Malte J.},
  month = aug,
  year = {2016},
  pages = {54},
  file = {/home/tim/Zotero/storage/XF8GJ5F7/Sharpee et al. - 2016 - 25th Annual Computational Neuroscience Meeting CN.pdf}
}

@article{schubbachJudgingMachinesPhilosophical2019,
  title = {Judging Machines: Philosophical Aspects of Deep Learning},
  issn = {1573-0964},
  shorttitle = {Judging Machines},
  abstract = {Although machine learning has been successful in recent years and is increasingly being deployed in the sciences, enterprises or administrations, it has rarely been discussed in philosophy beyond the philosophy of mathematics and machine learning. The present contribution addresses the resulting lack of conceptual tools for an epistemological discussion of machine learning by conceiving of deep learning networks as `judging machines' and using the Kantian analysis of judgments for specifying the type of judgment they are capable of. At the center of the argument is the fact that the functionality of deep learning networks is established by training and cannot be explained and justified by reference to a predefined rule-based procedure. Instead, the computational process of a deep learning network is barely explainable and needs further justification, as is shown in reference to the current research literature. Thus, it requires a new form of justification, that is to be specified with the help of Kant's epistemology.},
  language = {en},
  journal = {Synthese},
  doi = {10.1007/s11229-019-02167-z},
  author = {Schubbach, Arno},
  month = mar,
  year = {2019},
  keywords = {Algorithm,Artificial intelligence,Computation,Deep learning,Explanation,Judgment,Justification,Kant,Machine learning}
}

@incollection{wodeckiArtificialIntelligenceMethods2019,
  address = {Cham},
  title = {Artificial {{Intelligence Methods}} and {{Techniques}}},
  isbn = {978-3-319-91596-8},
  abstract = {Artificial intelligence (AI) is a fascinating concept whose origins can be found in the mid-twentieth century. It is an interdisciplinary field, integrating the efforts of logicians, mathematicians, computer scientists, psychologists and, more recently, managers and ethicists. Developing dynamically in the dimension of methods as well as technology, on the one hand, raises many hopes; on the other hand, it raises many fears and controversies (compare e.g. Bostrom 2014), particularly among investors who are interested in ventures with high development potential, yet they are afraid to invest in projects they simply do not understand.},
  language = {en},
  booktitle = {Artificial {{Intelligence}} in {{Value Creation}}: {{Improving Competitive Advantage}}},
  publisher = {{Springer International Publishing}},
  author = {Wodecki, Andrzej},
  editor = {Wodecki, Andrzej},
  year = {2019},
  pages = {71-132},
  doi = {10.1007/978-3-319-91596-8_2}
}

@incollection{jinSimultaneousGenerationAccurate2006,
  address = {Berlin, Heidelberg},
  series = {Studies in {{Computational Intelligence}}},
  title = {Simultaneous {{Generation}} of {{Accurate}} and {{Interpretable Neural Network Classifiers}}},
  isbn = {978-3-540-33019-6},
  abstract = {Generating machine learning models is inherently a multi-objective optimization problem. Two most common objectives are accuracy and interpretability, which are very likely conflicting with each other. While in most cases we are interested only in the model accuracy, interpretability of the model becomes the major concern if the model is used for data mining or if the model is applied to critical applications. In this chapter, we present a method for simultaneously generating accurate and interpretable neural network models for classification using an evolutionary multi-objective optimization algorithm. Lifetime learning is embedded to fine-tune the weights in the evolution that mutates the structure and weights of the neural networks. The efficiency of Baldwin effect and Lamarckian evolution are compared. It is found that the Lamarckian evolution outperforms the Baldwin effect in evolutionary multi-objective optimization of neural networks. Simulation results on two benchmark problems demonstrate that the evolutionary multi-objective approach is able to generate both accurate and understandable neural network models, which can be used for different purpose.},
  language = {en},
  booktitle = {Multi-{{Objective Machine Learning}}},
  publisher = {{Springer Berlin Heidelberg}},
  author = {Jin, Yaochu and Sendhoff, Bernhard and K\"orner, Edgar},
  editor = {Jin, Yaochu},
  year = {2006},
  keywords = {Hide Neuron,Mean Square Error,Multiobjective Optimization,Neural Network,Pareto Front},
  pages = {291-312},
  doi = {10.1007/3-540-33019-4_13}
}

@inproceedings{berzinsInnovationsNaturalLanguage2008,
  series = {Lecture {{Notes}} in {{Computer Science}}},
  title = {Innovations in {{Natural Language Document Processing}} for {{Requirements Engineering}}},
  isbn = {978-3-540-89778-1},
  abstract = {This paper evaluates the potential contributions of natural language processing to requirements engineering. We present a selective history of the relationship between requirements engineering (RE) and natural-language processing (NLP), and briefly summarize relevant recent trends in NLP. The paper outlines basic issues in RE and how they relate to interactions between a NLP front end and system-development processes. We suggest some improvements to NLP that may be possible in the context of RE and conclude with an assessment of what should be done to improve likelihood of practical impact in this direction.},
  language = {en},
  booktitle = {Innovations for {{Requirement Analysis}}. {{From Stakeholders}}' {{Needs}} to {{Formal Designs}}},
  publisher = {{Springer Berlin Heidelberg}},
  author = {Berzins, Valdis and Martell, Craig and {Luqi} and Adams, Paige},
  editor = {Paech, Barbara and Martell, Craig},
  year = {2008},
  keywords = {Ambiguity,Domain-Specific Methods,Gaps,Natural Language,Requirements},
  pages = {125-146}
}

@inproceedings{bratkoMachineLearningAccuracy1997,
  series = {International {{Centre}} for {{Mechanical Sciences}}},
  title = {Machine {{Learning}}: {{Between Accuracy}} and {{Interpretability}}},
  isbn = {978-3-7091-2668-4},
  shorttitle = {Machine {{Learning}}},
  abstract = {Predictive accuracy is the usual measure of success of Machine Learning (ML) applications. However, experience from many ML applications in difficult, domains indicates the importance of interpretability of induced descriptions. Often in such domains, predictive accuracy is hardly of interest to the user. Instead, the users' interest now lies in the interpretion of the induced descriptions and not, in their use for prediction. In such cases, ML is essentially used as a tool for exploring the domain, to generate new, potentially useful ideas about the domain, and thus improve the user's understanding of the domain. The important questions are how to make domain-specific background knowledge usable by the learning system, and how to interpret the results in the light of this background expertise. These questions are discussed and illustrated by relevant example applications of ML, including: medical diagnosis, ecological modelling, and interpreting discrete event simulations. The observations in these applications show that predictive accuracy, the usual measure of success in ML, should be accompanied by a. criterion of interpretability of induced descriptions. The formalisation of interpretability is however a completely new challenge for ML.},
  language = {en},
  booktitle = {Learning, {{Networks}} and {{Statistics}}},
  publisher = {{Springer Vienna}},
  author = {Bratko, I.},
  editor = {Della Riccia, Giacomo and Lenz, Hans-Joachim and Kruse, Rudolf},
  year = {1997},
  keywords = {Discrete Event Simulation,Ecological Modelling,Machine Learn,Predictive Accuracy,Regression Tree},
  pages = {163-177}
}

@incollection{miradiKnowledgeDiscoveryData2009,
  address = {Berlin, Heidelberg},
  series = {Studies in {{Computational Intelligence}}},
  title = {Knowledge {{Discovery}} and {{Data Mining Using Artificial Intelligence}} to {{Unravel Porous Asphalt Concrete}} in the {{Netherlands}}},
  isbn = {978-3-642-04586-8},
  abstract = {The main goal of this study was to discover knowledge from data about Porous Asphalt Concrete (PAC) roads to achieve a better understanding of the behavior of them and via this understanding improve pavement quality and enhance its lifespan. The knowledge discovery process includes five steps, being understanding the problem, understanding the data, data preparation, data mining (modeling), and the interpretation/evaluation of the results of the models. At the moment, almost 75\% of the Dutch motorways network has a PAC top layer. The main damage of PAC is raveling, which is when the top layer of the road loses stones. The SHRP-NL databases provided ten years of material property data from PAC roads. The data for climate and traffic were obtained from databases of the Royal Dutch Meteorological Institute (KNMI) and the Ministry of Transport and Water Management, respectively. Due to the low number of data points (74 data points), an extensive variable selection was performed using eight different methods to determine the four or five most influential input variables and consequently reduce the input dimension. These methods were decision trees, genetic polynomial, artificial neural network, rough set theory, correlation based variable selection with bidirectional and genetic search, wrappers of neural network with genetic search, and relief ranking filter. The modeling step resulted in 8 intelligent models which were developed using two prediction techniques, being artificial neural networks and support vector machines and two rule-based techniques, being decision trees and rough set theory. Taking the low number of data points into account, the prediction models showed a good performance (R2 = 0.95). The rule based models were transparent and easy to interpret but performed less.},
  language = {en},
  booktitle = {Intelligent and {{Soft Computing}} in {{Infrastructure Systems Engineering}}: {{Recent Advances}}},
  publisher = {{Springer Berlin Heidelberg}},
  author = {Miradi, Maryam and Molenaar, Andre A. A. and {van de Ven}, Martin F. C.},
  editor = {Gopalakrishnan, Kasthurirangan and Ceylan, Halil and {Attoh-Okine}, Nii O.},
  year = {2009},
  keywords = {Artificial Neural Network,Data Mining,Knowledge Discovery,Support Vector Machine,Test Section},
  pages = {107-176},
  doi = {10.1007/978-3-642-04586-8_5}
}

@article{zhuangChallengesOpportunitiesBig2017,
  title = {Challenges and Opportunities: From Big Data to Knowledge in {{AI}} 2.0},
  volume = {18},
  issn = {2095-9230},
  shorttitle = {Challenges and Opportunities},
  abstract = {In this paper, we review recent emerging theoretical and technological advances of artificial intelligence (AI) in the big data settings. We conclude that integrating data-driven machine learning with human knowledge (common priors or implicit intuitions) can effectively lead to explainable, robust, and general AI, as follows: from shallow computation to deep neural reasoning; from merely data-driven model to data-driven with structured logic rules models; from task-oriented (domain-specific) intelligence (adherence to explicit instructions) to artificial general intelligence in a general context (the capability to learn from experience). Motivated by such endeavors, the next generation of AI, namely AI 2.0, is positioned to reinvent computing itself, to transform big data into structured knowledge, and to enable better decision-making for our society.},
  language = {en},
  number = {1},
  journal = {Frontiers of Information Technology \& Electronic Engineering},
  doi = {10.1631/FITEE.1601883},
  author = {Zhuang, Yue-ting and Wu, Fei and Chen, Chun and Pan, Yun-he},
  month = jan,
  year = {2017},
  keywords = {Artificial general intelligence,Big data,Cross media,Deep reasoning,Knowledge base population,TP391.4},
  pages = {3-14},
  file = {/home/tim/Zotero/storage/CXXGKFY7/Zhuang et al. - 2017 - Challenges and opportunities from big data to kno.pdf}
}

@inproceedings{zhouMeasuringInterpretabilityDifferent2018,
  series = {Lecture {{Notes}} in {{Computer Science}}},
  title = {Measuring {{Interpretability}} for {{Different Types}} of {{Machine Learning Models}}},
  isbn = {978-3-030-04503-6},
  abstract = {The interpretability of a machine learning model plays a significant role in practical applications, thus it is necessary to develop a method to compare the interpretability for different models so as to select the most appropriate one. However, model interpretability, a highly subjective concept, is difficult to be accurately measured, not to mention the interpretability comparison of different models. To this end, we develop an interpretability evaluation model to compute model interpretability and compare interpretability for different models. Specifically, first we we present a general form of model interpretability. Second, a questionnaire survey system is developed to collect information about users' understanding of a machine learning model. Next, three structure features are selected to investigate the relationship between interpretability and structural complexity. After this, an interpretability label is build based on the questionnaire survey result and a linear regression model is developed to evaluate the relationship between the structural features and model interpretability. The experiment results demonstrate that our interpretability evaluation model is valid and reliable to evaluate the interpretability of different models.},
  language = {en},
  booktitle = {Trends and {{Applications}} in {{Knowledge Discovery}} and {{Data Mining}}},
  publisher = {{Springer International Publishing}},
  author = {Zhou, Qing and Liao, Fenglu and Mou, Chao and Wang, Ping},
  editor = {Ganji, Mohadeseh and Rashidi, Lida and Fung, Benjamin C. M. and Wang, Can},
  year = {2018},
  keywords = {Interpretability evaluation model,Machine learning models,Model interpretability,Structural complexity},
  pages = {295-308}
}

@inproceedings{fabra-boludaModellingMachineLearning2018,
  series = {Studies in {{Applied Philosophy}}, {{Epistemology}} and {{Rational Ethics}}},
  title = {Modelling {{Machine Learning Models}}},
  isbn = {978-3-319-96448-5},
  abstract = {Machine learning (ML) models make decisions for governments, companies, and individuals. Accordingly, there is the increasing concern of not having a rich explanatory and predictive account of the behaviour of these ML models relative to the users' interests (goals) and (pre-)conceptions (ontologies). We argue that the recent research trends in finding better characterisations of what a ML model does are leading to the view of ML models as complex behavioural systems. A good explanation for a model should depend on how well it describes the behaviour of the model in simpler, more comprehensible, or more understandable terms according to a given context. Consequently, we claim that a more contextual abstraction is necessary (as is done in system theory and psychology), which is very much like building a subjective mind modelling problem. We bring some research evidence of how this partial and subjective modelling of machine learning models can take place, suggesting that more machine learning is the answer.},
  language = {en},
  booktitle = {Philosophy and {{Theory}} of {{Artificial Intelligence}} 2017},
  publisher = {{Springer International Publishing}},
  author = {{Fabra-Boluda}, Ra\"ul and Ferri, C\`esar and {Hern\'andez-Orallo}, Jos\'e and {Mart\'inez-Plumed}, Fernando and {Ram\'irez-Quintana}, M. Jos\'e},
  editor = {M\"uller, Vincent C.},
  year = {2018},
  pages = {175-186}
}

@article{guhaInterpretationInterpretabilityQuantitative2008,
  title = {On the Interpretation and Interpretability of Quantitative Structure\textendash{}Activity Relationship Models},
  volume = {22},
  issn = {1573-4951},
  abstract = {The goal of a quantitative structure\textendash{}activity relationship (QSAR) model is to encode the relationship between molecular structure and biological activity or physical property. Based on this encoding, such models can be used for predictive purposes. Assuming the use of relevant and meaningful descriptors, and a statistically significant model, extraction of the encoded structure\textendash{}activity relationships (SARs) can provide insight into what makes a molecule active or inactive. Such analyses by QSAR models are useful in a number of scenarios, such as suggesting structural modifications to enhance activity, explanation of outliers and exploratory analysis of novel SARs. In this paper we discuss the need for interpretation and an overview of the factors that affect interpretability of QSAR models. We then describe interpretation protocols for different types of models, highlighting the different types of interpretations, ranging from very broad, global, trends to very specific, case-by-case, descriptions of the SAR, using examples from the training set. Finally, we discuss a number of case studies where workers have provide some form of interpretation of a QSAR model.},
  language = {en},
  number = {12},
  journal = {Journal of Computer-Aided Molecular Design},
  doi = {10.1007/s10822-008-9240-5},
  author = {Guha, Rajarshi},
  month = dec,
  year = {2008},
  keywords = {Interpretation,Linear regression,Neural network,Partial least squares (PLS),Quantitative structure–activity relationship (QSAR)},
  pages = {857-871}
}

@article{butz12thBiannualConference2014,
  title = {12th {{Biannual}} Conference of the {{German}} Cognitive Science Society ({{Gesellschaft}} F\"ur {{Kognitionswissenschaft}})},
  volume = {15},
  issn = {1612-4790},
  language = {en},
  number = {1},
  journal = {Cognitive Processing},
  doi = {10.1007/s10339-014-0632-2},
  author = {Butz, Martin V.},
  month = sep,
  year = {2014},
  keywords = {Head Noun,Lateralized Readiness Potential,Mental Rotation,Relative Clause,SNARC Effect},
  pages = {1-158}
}

@article{CARS2016Computer2016,
  title = {{{CARS}} 2016\textemdash{{Computer Assisted Radiology}} and {{Surgery Proceedings}} of the 30th {{International Congress}} and {{Exhibition Heidelberg}}, {{Germany}}, {{June}} 21\textendash{}25, 2016},
  volume = {11},
  issn = {1861-6429},
  language = {en},
  number = {1},
  journal = {International Journal of Computer Assisted Radiology and Surgery},
  doi = {10.1007/s11548-016-1412-5},
  month = jun,
  year = {2016},
  pages = {1-286}
}

@incollection{liuInterpretabilityComputationalModels2016,
  address = {Cham},
  series = {Studies in {{Computational Intelligence}}},
  title = {Interpretability of {{Computational Models}} for {{Sentiment Analysis}}},
  isbn = {978-3-319-30319-2},
  abstract = {Sentiment analysis, which is also known as opinion mining, has been an increasingly popular research area focusing on sentiment classification/regression. In many studies, computational models have been considered as effective and efficient tools for sentiment analysis . Computational models could be built by using expert knowledge or learning from data. From this viewpoint, the design of computational models could be categorized into expert based design and data based design. Due to the vast and rapid increase in data, the latter approach of design has become increasingly more popular for building computational models. A data based design typically follows machine learning approaches, each of which involves a particular strategy of learning. Therefore, the resulting computational models are usually represented in different forms. For example, neural network learning results in models in the form of multi-layer perceptron network whereas decision tree learning results in a rule set in the form of decision tree. On the basis of above description, interpretability has become a main problem that arises with computational models. This chapter explores the significance of interpretability for computational models as well as analyzes the factors that impact on interpretability. This chapter also introduces several ways to evaluate and improve the interpretability for computational models which are used as sentiment analysis systems. In particular, rule based systems , a special type of computational models, are used as an example for illustration with respects to evaluation and improvements through the use of computational intelligence methodologies.},
  language = {en},
  booktitle = {Sentiment {{Analysis}} and {{Ontology Engineering}}: {{An Environment}} of {{Computational Intelligence}}},
  publisher = {{Springer International Publishing}},
  author = {Liu, Han and Cocea, Mihaela and Gegov, Alexander},
  editor = {Pedrycz, Witold and Chen, Shyi-Ming},
  year = {2016},
  keywords = {Computational intelligence,Fuzzy computational models,Interpretability analysis,Interpretability evaluation,Machine learning,Rule based networks,Rule based systems,Sentiment prediction},
  pages = {199-220},
  doi = {10.1007/978-3-319-30319-2_9}
}

@incollection{pace-siggeWhereCorpusLinguistics2018,
  address = {Cham},
  title = {Where {{Corpus Linguistics}} and {{Artificial Intelligence}} ({{AI}}) {{Meet}}},
  isbn = {978-3-319-90719-2},
  abstract = {This chapter will provide a platform to showcase the more recent developments that have grown out of the early laid groundwork. The latest theories in the field of linguistics will be presented, based on empirical data taken from naturally occurring language. In particular, the lexical priming theory will be introduced as a way to explain structures of language that corpus linguists have uncovered. Furthermore, the chapter will discuss the development of increasingly sophisticated algorithms that also deal with the use of language. Here, the focus will be on key achievements in the 1980s by IBM which created a solid foundation for applications that are now widely used in mobile and desktop devices\textemdash{}namely ``assistants'' like Amazon's Echo, Apple's SIRI or Google's (and Android's) Google Go.},
  language = {en},
  booktitle = {Spreading {{Activation}}, {{Lexical Priming}} and the {{Semantic Web}}: {{Early Psycholinguistic Theories}}, {{Corpus Linguistics}} and {{AI Applications}}},
  publisher = {{Springer International Publishing}},
  author = {{Pace-Sigge}, Michael},
  editor = {{Pace-Sigge}, Michael},
  year = {2018},
  keywords = {Digital translators,Hoey,Lexical priming,LSTM,N-gram model,Norvig,Quillian},
  pages = {29-82},
  doi = {10.1007/978-3-319-90719-2_3}
}

@incollection{liaoMiningHumanInterpretable2006,
  address = {Boston, MA},
  series = {Massive {{Computing}}},
  title = {Mining {{Human Interpretable Knowledge}} with {{Fuzzy Modeling Methods}}: {{An Overview}}},
  isbn = {978-0-387-34296-2},
  shorttitle = {Mining {{Human Interpretable Knowledge}} with {{Fuzzy Modeling Methods}}},
  abstract = {This chapter focuses on one particular class of data mining methodologies that expresses the mined knowledge in the form of fuzzy If-Then rules or fuzzy decision trees that can be easily understood by a human. Past studies on generating fuzzy If-Then rules (mostly from exemplar crisp data and a few from exemplar fuzzy data) are grouped into six major categories: grid partitioning, fuzzy clustering, genetic algorithms, neural networks, hybrid methods, and others. The representative method in each category is detailed. The latest improvements and advancements in each category are also reviewed. Similarly, past studies on generating fuzzy decision trees (from exemplar nominal and/or numeric data as well as from exemplar fuzzy data) are surveyed. The essence of each method is presented. Moreover, we discuss selected studies that address most of the necessary conditions for a fuzzy model to be interpretable and highlight areas for future studies. To give an idea of where fuzzy modeling methods have been applied, major application areas are also summarized.},
  language = {en},
  booktitle = {Data {{Mining}} and {{Knowledge Discovery Approaches Based}} on {{Rule Induction Techniques}}},
  publisher = {{Springer US}},
  author = {Liao, T. Warren},
  editor = {Triantaphyllou, Evangelos and Felici, Giovanni},
  year = {2006},
  keywords = {Data mining,Fuzzy clustering,Fuzzy decision trees,Fuzzy If-Then rules,Fuzzy modeling,Fuzzy-neural networks,Genetic algorithms,Neural networks},
  pages = {495-550},
  doi = {10.1007/0-387-34296-6_15}
}

@incollection{kimExplainableDeepDriving2018,
  address = {Cham},
  series = {The {{Springer Series}} on {{Challenges}} in {{Machine Learning}}},
  title = {Explainable {{Deep Driving}} by {{Visualizing Causal Attention}}},
  isbn = {978-3-319-98131-4},
  abstract = {Deep neural perception and control networks are likely to be a key component of self-driving vehicles. These models need to be explainable\textemdash{}they should provide easy-to-interpret rationales for their behavior\textemdash{}so that passengers, insurance companies, law enforcement, developers etc., can understand what triggered a particular behavior. Here, we explore the use of visual explanations. These explanations take the form of real-time highlighted regions of an image that causally influence the network's output (steering control). Our approach is two-stage. In the first stage, we use a visual attention model to train a convolutional network end-to-end from images to steering angle. The attention model highlights image regions that potentially influence the network's output. Some of these are true influences, but some are spurious. We then apply a causal filtering step to determine which input regions actually influence the output. This produces more succinct visual explanations and more accurately exposes the network's behavior. We demonstrate the effectiveness of our model on three datasets totaling 16 h of driving. We first show that training with attention does not degrade the performance of the end-to-end network. Then we show that the network highlights interpretable features that are used by humans while driving, and causal filtering achieves a useful reduction in explanation complexity by removing features which do not significantly affect the output.},
  language = {en},
  booktitle = {Explainable and {{Interpretable Models}} in {{Computer Vision}} and {{Machine Learning}}},
  publisher = {{Springer International Publishing}},
  author = {Kim, Jinkyu and Canny, John},
  editor = {Escalante, Hugo Jair and Escalera, Sergio and Guyon, Isabelle and Bar\'o, Xavier and G\"u{\c c}l\"ut\"urk, Ya{\u g}mur and G\"u{\c c}l\"u, Umut and {van Gerven}, Marcel},
  year = {2018},
  keywords = {Explainable AI,Self-driving vehicles,Visual attention},
  pages = {173-193},
  doi = {10.1007/978-3-319-98131-4_8}
}

@article{qureshiEVEExplainableVector2018,
  title = {{{EVE}}: Explainable Vector Based Embedding Technique Using {{Wikipedia}}},
  issn = {1573-7675},
  shorttitle = {{{EVE}}},
  abstract = {We present an unsupervised explainable vector embedding technique, called EVE, which is built upon the structure of Wikipedia. The proposed model defines the dimensions of a semantic vector representing a concept using human-readable labels, thereby it is readily interpretable. Specifically, each vector is constructed using the Wikipedia category graph structure together with the Wikipedia article link structure. To test the effectiveness of the proposed model, we consider its usefulness in three fundamental tasks: 1) intruder detection\textemdash{}to evaluate its ability to identify a non-coherent vector from a list of coherent vectors, 2) ability to cluster\textemdash{}to evaluate its tendency to group related vectors together while keeping unrelated vectors in separate clusters, and 3) sorting relevant items first\textemdash{}to evaluate its ability to rank vectors (items) relevant to the query in the top order of the result. For each task, we also propose a strategy to generate a task-specific human-interpretable explanation from the model. These demonstrate the overall effectiveness of the explainable embeddings generated by EVE. Finally, we compare EVE with the Word2Vec, FastText, and GloVe embedding techniques across the three tasks, and report improvements over the state-of-the-art.},
  language = {en},
  journal = {Journal of Intelligent Information Systems},
  doi = {10.1007/s10844-018-0511-x},
  author = {Qureshi, M. Atif and Greene, Derek},
  month = jun,
  year = {2018},
  keywords = {Distributional semantics,Unsupervised learning,Wikipedia},
  file = {/home/tim/Zotero/storage/9BHZ5UXW/Qureshi and Greene - 2018 - EVE explainable vector based embedding technique .pdf}
}

@incollection{schetininAdvancedFeatureRecognition2007,
  address = {Berlin, Heidelberg},
  series = {Studies in {{Computational Intelligence}}},
  title = {Advanced {{Feature Recognition}} and {{Classification Using Artificial Intelligence Paradigms}}},
  isbn = {978-3-540-47518-7},
  language = {en},
  booktitle = {Artificial {{Intelligence}} in {{Recognition}} and {{Classification}} of {{Astrophysical}} and {{Medical Images}}},
  publisher = {{Springer Berlin Heidelberg}},
  author = {Schetinin, V. and Zharkova, Valentina and Brazhnikov, A. and Zharkov, S. I. and Salerno, Emanuele and Bedini, Luigi and Kuruoglu, Ercan E. and Tonazzini, Anna and Zazula, Damjan and Cigale, Boris and Yoshida, Hiroyuki},
  editor = {Zharkova, Valentina and Jain, Lakhmi C.},
  year = {2007},
  keywords = {Cellular Neural Network,Compute Tomography Colonography,Independent Component Analysis,Source Separation},
  pages = {151-338},
  doi = {10.1007/978-3-540-47518-7_4}
}

@inproceedings{carringtonMeasuresModelInterpretability2018,
  series = {Lecture {{Notes}} in {{Computer Science}}},
  title = {Measures of {{Model Interpretability}} for {{Model Selection}}},
  isbn = {978-3-319-99740-7},
  abstract = {The literature lacks definitions for quantitative measures of model interpretability for automatic model selection to achieve high accuracy and interpretability, hence we define inherent model interpretability. We extend the work of Lipton et al. and Liu et al. from qualitative and subjective concepts of model interpretability to objective criteria and quantitative measures. We also develop another new measure called simplicity of sensitivity and illustrate prior, initial and posterior measurement. Measures are tested and validated with some measures recommended for use. It is demonstrated that high accuracy and high interpretability are jointly achievable with little to no sacrifice in either.},
  language = {en},
  booktitle = {Machine {{Learning}} and {{Knowledge Extraction}}},
  publisher = {{Springer International Publishing}},
  author = {Carrington, Andr\'e and Fieguth, Paul and Chen, Helen},
  editor = {Holzinger, Andreas and Kieseberg, Peter and Tjoa, A Min and Weippl, Edgar},
  year = {2018},
  keywords = {Kernels,Model interpretability,Model transparency,Support vector machines},
  pages = {329-349}
}

@incollection{hoschkeSelforganizingSensingSystem2008,
  address = {London},
  series = {Advanced {{Information}} and {{Knowledge Processing}}},
  title = {A {{Self}}-Organizing {{Sensing System}} for {{Structural Health Monitoring}} of {{Aerospace Vehicles}}},
  isbn = {978-1-84628-982-8},
  language = {en},
  booktitle = {Advances in {{Applied Self}}-Organizing {{Systems}}},
  publisher = {{Springer London}},
  author = {Hoschke, N. and Lewis, C. J. and Price, D. C. and Scott, D. A. and Gerasimov, V. and Wang, P.},
  editor = {Prokopenko, Mikhail},
  year = {2008},
  keywords = {Cellular Automaton,Genetic Programming,Mobile Agent,Multiagent System},
  pages = {51-76},
  doi = {10.1007/978-1-84628-982-8_4}
}

@article{tienInternetThingsRealTime2017,
  title = {Internet of {{Things}}, {{Real}}-{{Time Decision Making}}, and {{Artificial Intelligence}}},
  volume = {4},
  issn = {2198-5812},
  abstract = {In several earlier papers, the author defined and detailed the concept of a servgood, which can be thought of as a physical good or product enveloped by a services-oriented layer that makes the good smarter or more adaptable and customizable for a particular use. Adding another layer of physical sensors could then enhance its smartness and intelligence, especially if it were to be connected with other servgoods\textemdash{}thus, constituting an Internet of Things (IoT) or servgoods. More importantly, real-time decision making is central to the Internet of Things; it is about decision informatics and embraces the advanced technologies of sensing (i.e., Big Data), processing (i.e., real-time analytics), reacting (i.e., real-time decision-making), and learning (i.e., deep learning). Indeed, real-time decision making (RTDM) is becoming an integral aspect of IoT and artificial intelligence (AI), including its improving abilities at voice and video recognition, speech and predictive synthesis, and language and social-media understanding. These three key and mutually supportive technologies\textemdash{}IoT, RTDM, and AI\textemdash{}are considered herein, including their progress to date.},
  language = {en},
  number = {2},
  journal = {Annals of Data Science},
  doi = {10.1007/s40745-017-0112-5},
  author = {Tien, James M.},
  month = jun,
  year = {2017},
  keywords = {Artificial intelligence,Goods,Internet of things,Real-time decision making,Servgoods,Services},
  pages = {149-178}
}

@article{balachandranInterpretableReconfigurableClustering2012,
  title = {Interpretable and Reconfigurable Clustering of Document Datasets by Deriving Word-Based Rules},
  volume = {32},
  issn = {0219-3116},
  abstract = {Clusters of text documents output by clustering algorithms are often hard to interpret. We describe motivating real-world scenarios that necessitate reconfigurability and high interpretability of clusters and outline the problem of generating clusterings with interpretable and reconfigurable cluster models. We develop two clustering algorithms toward the outlined goal of building interpretable and reconfigurable cluster models. They generate clusters with associated rules that are composed of conditions on word occurrences or nonoccurrences. The proposed approaches vary in the complexity of the format of the rules; RGC employs disjunctions and conjunctions in rule generation whereas RGC-D rules are simple disjunctions of conditions signifying presence of various words. In both the cases, each cluster is comprised of precisely the set of documents that satisfy the corresponding rule. Rules of the latter kind are easy to interpret, whereas the former leads to more accurate clustering. We show that our approaches outperform the unsupervised decision tree approach for rule-generating clustering and also an approach we provide for generating interpretable models for general clusterings, both by significant margins. We empirically show that the purity and f-measure losses to achieve interpretability can be as little as 3 and 5\%, respectively using the algorithms presented herein.},
  language = {en},
  number = {3},
  journal = {Knowledge and Information Systems},
  doi = {10.1007/s10115-011-0446-9},
  author = {Balachandran, Vipin and {Deepak P} and Khemani, Deepak},
  month = sep,
  year = {2012},
  keywords = {Data clustering,Interpretability,Text clustering},
  pages = {475-503},
  file = {/home/tim/Zotero/storage/N4JXINRM/Balachandran et al. - 2012 - Interpretable and reconfigurable clustering of doc.pdf}
}

@incollection{azizMachineLearningAI2019,
  address = {Cham},
  series = {Palgrave {{Studies}} in {{Digital Business}} \& {{Enabling Technologies}}},
  title = {Machine {{Learning}} and {{AI}} for {{Risk Management}}},
  isbn = {978-3-030-02330-0},
  abstract = {We explore how machine learning and artificial intelligence (AI) solutions are transforming risk management. A non-technical overview is first given of the main machine learning and AI techniques of benefit to risk management. Then a review is provided, using current practice and empirical evidence, of the application of these techniques to the risk management fields of credit risk, market risk, operational risk, and compliance (`RegTech'). We conclude with some thoughts on current limitations and views on how the field is likely to develop in the short- to medium-term. Overall, we present an optimistic picture of the role of machine learning and AI in risk management, but note some practical limitations around suitable data management policies, transparency, and lack of necessary skillsets within firms.},
  language = {en},
  booktitle = {Disrupting {{Finance}}: {{FinTech}} and {{Strategy}} in the 21st {{Century}}},
  publisher = {{Springer International Publishing}},
  author = {Aziz, Saqib and Dowling, Michael},
  editor = {Lynn, Theo and Mooney, John G. and Rosati, Pierangelo and Cummins, Mark},
  year = {2019},
  keywords = {AI,Credit risk,Machine learning,Market risk,Operational risk,RegTech,Risk management},
  pages = {33-50},
  file = {/home/tim/Zotero/storage/EY8T5IEC/Aziz and Dowling - 2019 - Machine Learning and AI for Risk Management.pdf},
  doi = {10.1007/978-3-030-02330-0_3}
}

@incollection{luceBasicsArtificialIntelligence2019,
  address = {Berkeley, CA},
  title = {Basics of {{Artificial Intelligence}}},
  isbn = {978-1-4842-3931-5},
  abstract = {Fashion not only provides functional purpose, but captures mysterious and elusive aspects of being human. Fashion expresses and invokes human emotion and creativity. How we look and sometimes even how we feel is intertwined in this industry. Fashion has always been forward looking, grabbing onto new technologies as they arise. Artificial intelligence is no exception, and it's moving as quickly as fashion does.},
  language = {en},
  booktitle = {Artificial {{Intelligence}} for {{Fashion}}: {{How AI}} Is {{Revolutionizing}} the {{Fashion Industry}}},
  publisher = {{Apress}},
  author = {Luce, Leanne},
  editor = {Luce, Leanne},
  year = {2019},
  pages = {3-18},
  doi = {10.1007/978-1-4842-3931-5_1}
}

@incollection{skienaMachineLearning2017,
  address = {Cham},
  series = {Texts in {{Computer Science}}},
  title = {Machine {{Learning}}},
  isbn = {978-3-319-55444-0},
  abstract = {For much of my career, I was highly suspicious of the importance of machine learning. I sat through many talks over the years, with grandiose claims and very meager results. But it is clear that the tide has turned. The most interesting work in computer science today revolves around machine learning, both powerful new algorithms and exciting new applications.},
  language = {en},
  booktitle = {The {{Data Science Design Manual}}},
  publisher = {{Springer International Publishing}},
  author = {Skiena, Steven S.},
  editor = {Skiena, Steven S.},
  year = {2017},
  pages = {351-390},
  doi = {10.1007/978-3-319-55444-0_11}
}

@inproceedings{laugelComparisonBasedInverseClassification2018,
  series = {Communications in {{Computer}} and {{Information Science}}},
  title = {Comparison-{{Based Inverse Classification}} for {{Interpretability}} in {{Machine Learning}}},
  isbn = {978-3-319-91473-2},
  abstract = {In the context of post-hoc interpretability, this paper addresses the task of explaining the prediction of a classifier, considering the case where no information is available, neither on the classifier itself, nor on the processed data (neither the training nor the test data). It proposes an inverse classification approach whose principle consists in determining the minimal changes needed to alter a prediction: in an instance-based framework, given a data point whose classification must be explained, the proposed method consists in identifying a close neighbor classified differently, where the closeness definition integrates a sparsity constraint. This principle is implemented using observation generation in the Growing Spheres algorithm. Experimental results on two datasets illustrate the relevance of the proposed approach that can be used to gain knowledge about the classifier.},
  language = {en},
  booktitle = {Information {{Processing}} and {{Management}} of {{Uncertainty}} in {{Knowledge}}-{{Based Systems}}. {{Theory}} and {{Foundations}}},
  publisher = {{Springer International Publishing}},
  author = {Laugel, Thibault and Lesot, Marie-Jeanne and Marsala, Christophe and Renard, Xavier and Detyniecki, Marcin},
  editor = {Medina, Jes\'us and {Ojeda-Aciego}, Manuel and Verdegay, Jos\'e Luis and Pelta, David A. and Cabrera, Inma P. and {Bouchon-Meunier}, Bernadette and Yager, Ronald R.},
  year = {2018},
  keywords = {Comparison-based,Inverse classification,Local explanation,Post-hoc interpretability},
  pages = {100-111}
}

@inproceedings{holzingerCurrentAdvancesTrends2018,
  series = {Lecture {{Notes}} in {{Computer Science}}},
  title = {Current {{Advances}}, {{Trends}} and {{Challenges}} of {{Machine Learning}} and {{Knowledge Extraction}}: {{From Machine Learning}} to {{Explainable AI}}},
  isbn = {978-3-319-99740-7},
  shorttitle = {Current {{Advances}}, {{Trends}} and {{Challenges}} of {{Machine Learning}} and {{Knowledge Extraction}}},
  abstract = {In this short editorial we present some thoughts on present and future trends in Artificial Intelligence (AI) generally, and Machine Learning (ML) specifically. Due to the huge ongoing success in machine learning, particularly in statistical learning from big data, there is rising interest of academia, industry and the public in this field. Industry is investing heavily in AI, and spin-offs and start-ups are emerging on an unprecedented rate. The European Union is allocating a lot of additional funding into AI research grants, and various institutions are calling for a joint European AI research institute. Even universities are taking AI/ML into their curricula and strategic plans. Finally, even the people on the street talk about it, and if grandma knows what her grandson is doing in his new start-up, then the time is ripe: We are reaching a new AI spring. However, as fantastic current approaches seem to be, there are still huge problems to be solved: the best performing models lack transparency, hence are considered to be black boxes. The general and worldwide trends in privacy, data protection, safety and security make such black box solutions difficult to use in practice. Specifically in Europe, where the new General Data Protection Regulation (GDPR) came into effect on May, 28, 2018 which affects everybody (right of explanation). Consequently, a previous niche field for many years, explainable AI, explodes in importance. For the future, we envision a fruitful marriage between classic logical approaches (ontologies) with statistical approaches which may lead to context-adaptive systems (stochastic ontologies) that might work similar as the human brain.},
  language = {en},
  booktitle = {Machine {{Learning}} and {{Knowledge Extraction}}},
  publisher = {{Springer International Publishing}},
  author = {Holzinger, Andreas and Kieseberg, Peter and Weippl, Edgar and Tjoa, A. Min},
  editor = {Holzinger, Andreas and Kieseberg, Peter and Tjoa, A Min and Weippl, Edgar},
  year = {2018},
  keywords = {Artificial intelligence,Explainable AI,Knowledge extraction,Machine learning,Privacy},
  pages = {1-8}
}

@article{zerilliTransparencyAlgorithmicHuman2018,
  title = {Transparency in {{Algorithmic}} and {{Human Decision}}-{{Making}}: {{Is There}} a {{Double Standard}}?},
  issn = {2210-5441},
  shorttitle = {Transparency in {{Algorithmic}} and {{Human Decision}}-{{Making}}},
  abstract = {We are sceptical of concerns over the opacity of algorithmic decision tools. While transparency and explainability are certainly important desiderata in algorithmic governance, we worry that automated decision-making is being held to an unrealistically high standard, possibly owing to an unrealistically high estimate of the degree of transparency attainable from human decision-makers. In this paper, we review evidence demonstrating that much human decision-making is fraught with transparency problems, show in what respects AI fares little worse or better and argue that at least some regulatory proposals for explainable AI could end up setting the bar higher than is necessary or indeed helpful. The demands of practical reason require the justification of action to be pitched at the level of practical reason. Decision tools that support or supplant practical reasoning should not be expected to aim higher than this. We cast this desideratum in terms of Daniel Dennett's theory of the ``intentional stance'' and argue that since the justification of action for human purposes takes the form of intentional stance explanation, the justification of algorithmic decisions should take the same form. In practice, this means that the sorts of explanations for algorithmic decisions that are analogous to intentional stance explanations should be preferred over ones that aim at the architectural innards of a decision tool.},
  language = {en},
  journal = {Philosophy \& Technology},
  doi = {10.1007/s13347-018-0330-6},
  author = {Zerilli, John and Knott, Alistair and Maclaurin, James and Gavaghan, Colin},
  month = sep,
  year = {2018},
  keywords = {Algorithmic decision-making,Explainable AI,Intentional stance,Transparency}
}

@incollection{holzingerLectureMultimediaData2014,
  address = {Cham},
  title = {Lecture 6 {{Multimedia Data Mining}} and {{Knowledge Discovery}}},
  isbn = {978-3-319-04528-3},
  abstract = {At the end of this sixth lecture you:},
  language = {en},
  booktitle = {Biomedical {{Informatics}}: {{Discovering Knowledge}} in {{Big Data}}},
  publisher = {{Springer International Publishing}},
  author = {Holzinger, Andreas},
  editor = {Holzinger, Andreas},
  year = {2014},
  pages = {251-298},
  doi = {10.1007/978-3-319-04528-3_6}
}

@inproceedings{holzingerMachineLearningKnowledge2017,
  series = {Lecture {{Notes}} in {{Computer Science}}},
  title = {Machine {{Learning}} and {{Knowledge Extraction}} in {{Digital Pathology Needs}} an {{Integrative Approach}}},
  isbn = {978-3-319-69775-8},
  abstract = {During the last decade pathology has benefited from the rapid progress of image digitizing technologies, which led to the development of scanners, capable to produce so-called Whole Slide images (WSI) which can be explored by a pathologist on a computer screen comparable to the conventional microscope and can be used for diagnostics, research, archiving and also education and training. Digital pathology is not just the transformation of the classical microscopic analysis of histological slides by pathologists to just a digital visualization. It is a disruptive innovation that will dramatically change medical work-flows in the coming years and help to foster personalized medicine. Really powerful gets a pathologist if she/he is augmented by machine learning, e.g. by support vector machines, random forests and deep learning. The ultimate benefit of digital pathology is to enable to learn, to extract knowledge and to make predictions from a combination of heterogenous data, i.e. the histological image, the patient history and the *omics data. These challenges call for integrated/integrative machine learning approach fostering transparency, trust, acceptance and the ability to explain step-by-step why a decision has been made.},
  language = {en},
  booktitle = {Towards {{Integrative Machine Learning}} and {{Knowledge Extraction}}},
  publisher = {{Springer International Publishing}},
  author = {Holzinger, Andreas and Malle, Bernd and Kieseberg, Peter and Roth, Peter M. and M\"uller, Heimo and Reihs, Robert and Zatloukal, Kurt},
  editor = {Holzinger, Andreas and Goebel, Randy and Ferri, Massimo and Palade, Vasile},
  year = {2017},
  keywords = {Data integration,Deep learning,Digital pathology,Integrative machine learning,Transfer learning},
  pages = {13-50}
}

@incollection{elmiedanyArtificialIntelligence2019,
  address = {Cham},
  title = {Artificial {{Intelligence}}},
  isbn = {978-3-319-98213-7},
  abstract = {Artificial intelligence can be defined as computer systems which have been designed to interact with the world through abilities (e.g. visual perception and speech recognition) and intelligent behaviours (e.g. evaluating the available information and then taking the most sensible action to achieve a defined aim) that we would think of as principally humans. Initially, research has focused on letting software do things better, in which computers have always been doing better, such as the analysis of large datasets. However, the use of artificial intelligence in our day-to-day life has increased exponentially. Data forms the basis for the development of artificial intelligent software systems that will not only collect information but is able to learn, understand and interpret information, adapt its behaviour, plan, conclude, solve problems, think abstract, come up with ideas and understand and interpret language. Thanks to AI, a smart phone can detect cancer and a smart watch can detect a stroke. Machine learning is infiltrating and optimizing nearly every aspect of medicine from the way 911 emergency services are dispatched to assisting doctors during surgery. People can even quit smoking or kick opiate addiction with the help of AI. AI scientists are currently developing new approaches in machine learning, computer modelling and probability statistics to improve decision-making processes and are using decision theory and neuroscience to drive the progress of more effective healthcare and education as well as economics. This chapter will discuss the science of AI and explore the importance of big data and AI strategies. It will expand to discuss AI and medicine as well as medical education. It will conclude with discussion of AI and education as well as the future of artificial intelligence.},
  language = {en},
  booktitle = {Rheumatology {{Teaching}}: {{The Art}} and {{Science}} of {{Medical Education}}},
  publisher = {{Springer International Publishing}},
  author = {El Miedany, Yasser},
  editor = {El Miedany, Yasser},
  year = {2019},
  keywords = {Artificial intelligence,Big data,Medical education,Science of artificial intelligence,Virtual reality in education},
  pages = {347-378},
  doi = {10.1007/978-3-319-98213-7_18}
}

@inproceedings{brideDependableExplainableMachine2018,
  series = {Lecture {{Notes}} in {{Computer Science}}},
  title = {Towards {{Dependable}} and {{Explainable Machine Learning Using Automated Reasoning}}},
  isbn = {978-3-030-02450-5},
  abstract = {The ability to learn from past experience and improve in the future, as well as the ability to reason about the context of problems and extrapolate information from what is known, are two important aspects of Artificial Intelligence. In this paper, we introduce a novel automated reasoning based approach that can extract valuable insights from classification and prediction models obtained via machine learning. A major benefit of the proposed approach is that the user can understand the reason behind the decision-making of machine learning models. This is often as important as good performance. Our technique can also be used to reinforce user-specified requirements in the model as well as to improve the classification and prediction.},
  language = {en},
  booktitle = {Formal {{Methods}} and {{Software Engineering}}},
  publisher = {{Springer International Publishing}},
  author = {Bride, Hadrien and Dong, Jie and Dong, Jin Song and H\'ou, Zh\'e},
  editor = {Sun, Jing and Sun, Meng},
  year = {2018},
  pages = {412-416}
}

@article{yankovskayaTradeoffSearchMethods2017,
  title = {Tradeoff Search Methods between Interpretability and Accuracy of the Identification Fuzzy Systems Based on Rules},
  volume = {27},
  issn = {1555-6212},
  abstract = {This paper starts a brief historical overview of occurrence and development of fuzzy systems and their applications. Integration methods are proposed to construct a fuzzy system using other AI methods, achieving synergy effect. Accuracy and interpretability are selected as main properties of rule-based fuzzy systems. The tradeoff between interpretability and accuracy is considered to be the actual problem. The purpose of this paper is the in-depth study of the methods and tools to achieve a tradeoff for accuracy and interpretability in rule-based fuzzy systems and to describe our interpretability indexes. A comparison of the existing ways of interpretability estimation has been made We also propose the new way to construct heuristic interpretability indexes as a quantitative measure of interpretability. In the main part of this paper we describe previously used approaches, the current state and original authors' methods for achieving tradeoff between accuracy and complexity.},
  language = {en},
  number = {2},
  journal = {Pattern Recognition and Image Analysis},
  doi = {10.1134/S1054661817020134},
  author = {Yankovskaya, A. E. and Gorbunov, I. V. and Hodashinsky, I. A.},
  month = apr,
  year = {2017},
  keywords = {accuracy,fuzzy modelling,fuzzy system,interpretability,interpretability-accuracy tradeoff,machine learning,metaheuristic,pattern recognition,synergy},
  pages = {243-265}
}

@article{nguyenMachineLearningDeep2019,
  title = {Machine {{Learning}} and {{Deep Learning}} Frameworks and Libraries for Large-Scale Data Mining: A Survey},
  issn = {1573-7462},
  shorttitle = {Machine {{Learning}} and {{Deep Learning}} Frameworks and Libraries for Large-Scale Data Mining},
  abstract = {The combined impact of new computing resources and techniques with an increasing avalanche of large datasets, is transforming many research areas and may lead to technological breakthroughs that can be used by billions of people. In the recent years, Machine Learning and especially its subfield Deep Learning have seen impressive advances. Techniques developed within these two fields are now able to analyze and learn from huge amounts of real world examples in a disparate formats. While the number of Machine Learning algorithms is extensive and growing, their implementations through frameworks and libraries is also extensive and growing too. The software development in this field is fast paced with a large number of open-source software coming from the academy, industry, start-ups or wider open-source communities. This survey presents a recent time-slide comprehensive overview with comparisons as well as trends in development and usage of cutting-edge Artificial Intelligence software. It also provides an overview of massive parallelism support that is capable of scaling computation effectively and efficiently in the era of Big Data.},
  language = {en},
  journal = {Artificial Intelligence Review},
  doi = {10.1007/s10462-018-09679-z},
  author = {Nguyen, Giang and Dlugolinsky, Stefan and Bob\'ak, Martin and Tran, Viet and L\'opez Garc\'ia, \'Alvaro and Heredia, Ignacio and Mal\'ik, Peter and Hluch\'y, Ladislav},
  month = jan,
  year = {2019},
  keywords = {Artificial Intelligence software,Deep Learning,Graphics processing unit (GPU),Intensive computing,Large-scale data mining,Machine Learning,Parallel processing},
  file = {/home/tim/Zotero/storage/U6RYW6DN/Nguyen et al. - 2019 - Machine Learning and Deep Learning frameworks and .pdf}
}

@article{Posters2009,
  title = {Posters},
  volume = {13},
  issn = {1760-4788},
  language = {en},
  number = {1},
  journal = {JNHA - The Journal of Nutrition, Health and Aging},
  doi = {10.1007/s12603-009-0095-9},
  month = jun,
  year = {2009},
  pages = {210-723}
}

@article{SCIENTIFICABSTRACTS2018,
  title = {{{SCIENTIFIC ABSTRACTS}}},
  volume = {33},
  issn = {1525-1497},
  language = {en},
  number = {2},
  journal = {Journal of General Internal Medicine},
  doi = {10.1007/s11606-018-4413-y},
  month = apr,
  year = {2018},
  pages = {83-840},
  file = {/home/tim/Zotero/storage/E8QM5V3M/2018 - SCIENTIFIC ABSTRACTS.pdf}
}

@incollection{AbstractsDocumentsThis1997,
  address = {Boston, MA},
  title = {Abstracts of {{Documents}} in {{This Supplement}}},
  isbn = {978-1-4615-5971-9},
  language = {en},
  booktitle = {Political {{Science Abstracts}}: 1996 {{Annual Supplement}};{{Volume}} 1},
  publisher = {{Springer US}},
  year = {1997},
  pages = {1-817},
  doi = {10.1007/978-1-4615-5971-9_1}
}

@article{EANM152015,
  title = {{{EANM}}'15},
  volume = {42},
  issn = {1619-7089},
  language = {en},
  number = {1},
  journal = {European Journal of Nuclear Medicine and Molecular Imaging},
  doi = {10.1007/s00259-015-3198-z},
  month = oct,
  year = {2015},
  pages = {1-924}
}

@incollection{aggarwalModelBasedCollaborativeFiltering2016,
  address = {Cham},
  title = {Model-{{Based Collaborative Filtering}}},
  isbn = {978-3-319-29659-3},
  abstract = {The neighborhood-based methods of the previous chapter can be viewed as generalizations of k-nearest neighbor classifiers, which are commonly used in machine learning.},
  language = {en},
  booktitle = {Recommender {{Systems}}: {{The Textbook}}},
  publisher = {{Springer International Publishing}},
  author = {Aggarwal, Charu C.},
  editor = {Aggarwal, Charu C.},
  year = {2016},
  pages = {71-138},
  doi = {10.1007/978-3-319-29659-3_3}
}

@article{Abstracts36thAnnual2013,
  title = {Abstracts from the 36th {{Annual Meeting}} of the {{Society}} of {{General Internal Medicine}}},
  volume = {28},
  issn = {1525-1497},
  language = {en},
  number = {1},
  journal = {Journal of General Internal Medicine},
  doi = {10.1007/s11606-013-2436-y},
  month = jun,
  year = {2013},
  pages = {1-489},
  file = {/home/tim/Zotero/storage/NP4WH8EI/2013 - Abstracts from the 36th Annual Meeting of the Soci.pdf}
}


