% ---------------------------------------------------
% ----- Conclusion of the template
% ----- for Bachelor-, Master thesis and class papers
% ---------------------------------------------------
%  Created by C. Müller-Birn on 2012-08-17, CC-BY-SA 3.0.
%  Freie Universität Berlin, Institute of Computer Science, Human Centered Computing. 
%
\chapter{Conclusion}
\label{chap:conclusion}

As stated in the Introduction, this thesis was conducted in order to study what kind of interpretability techniques for NLP exist and how they could support a non-technical expert in understanding the output from the system.

An exploratory workshops with the researchers from project IKON laid the groundwork for this thesis by defining key questions and a theoretical model of how interpretative processes may form in non-technical experts. The proposed theory puts the context of a interpretative context and connects high-level explanation strategies to concrete explanations via algorithmic interpretability techniques.

The first step was a systematic literature mapping study according to Petersen et al. \cite{petersenSystematicMappingStudies} which enabled me to confirm the findings of Lipton \cite{liptonMythosModelInterpretability2016a} and Miller \cite{millerExplanationArtificialIntelligence2017} in the domain of NLP.
Furthermore the results from the literature mapping study suggest that most of the current research focuses on supervised methods, such as neural networks, and these models are mainly made interpretable through local instance explanations. A proper definition of interpretability or an analysis of how a method influences interpretability lacks in a majority of publications.

Based on these findings I was now able to take each component of the general topic extraction pipeline in \autoref{pic:general_topic_extraction_pipeline} and propose and implement a contending method. Each method was evaluated according to standard measures in order to ensure proper performance.

Having the choice between two models for each step still not enabled me to implement any method from the sourced literature. Therefore I developed three techniques which follow the strategies found in the literature and are tailored to the use case of IKON. 
The first technique (Top Words) explains projects or clusters locally by supplying the user with the most influential words connected a project or a cluster.
The second technique (Cluster Topography) allows the user to make global deductions concerning the fitness of each project in its assigned cluster. In order to do this a similarity measure is calculated in the latent topic space and is visualized in 2D by interpolating a relief on the corresponding scatter plot.
The last implemented technique solves the long-standing problem of clutter in scatter graphs in this use case. Since the distances in 2D have only limited expressiveness due to the performed dimensionality reductions the scatter plot is mapped onto a grid structure. This allows to add additional metadata more easily. Additionally this technique synergizes well with the cluster topography since cluttered relief changes are also expanded and are more easily to grasp.

Using the top words and coherence scores I measured the performance of the  quantitatively and made a model selection based on these computed scores. Ultimately, the previously existing topic modeling pipeline appeared to be superior to the newly developed techniques.
A cognitive walkthrough simulating a researcher performing an exploratory interaction unveiled a number of usability issues, but also showed how the implemented techniques support the user in making inferences about the output of the topic modeling pipeline.  In contrast to what was expected I found out that the output of these interpretability techniques can be reinterpreted hinting at the possibility that one technique may support multiple strategies. As a consequence, context-less or context-light usability techniques, as cognitive walkthroughs, may not be well suited to study the impact of interpretability techniques on the interpretation of non-technical experts since the concrete materialization of the explanation technique depends heavily on the context.

\section{Outlook}   
As discussed in \autoref{chap:literature_analysis} and visible in the results of the literature mapping study, there are a number of additional explanation strategies which could be applied to the augmented topic modeling pipeline.

Although the performance of Agglomerative Clustering didn't seem to satisfy the needs of the application, the idea of explaining a model by an induced taxonomy is still very interesting \cite{Liu:2018:INE:3219819.3220001}. Factoring in that the majority of the staff at the museum are trained biologists and taxonomies are widely used in this scientific discipline, these structures may be a very useful metaphor to present information to these non-technical experts.

Furthermore during the work on this thesis another potential question, additional to the ones defined in \autoref{tab:overview_viz_questions}, arose:
\begin{center}
	What kind of potential projects exist in the space between projects?
\end{center}
One of the already used techniques could be used to deliver potential answers . If the current LDA reduction gets replaced by a special kind of autoencoding, called variational autoencoding (VAE), it should be possible to generate meaningful vectors in the latent topic space and via the previously discussed methods also top words for these potential projects. 

Asides from additional interpretability strategies and further model tuning, the whole system needs to be subjected to complete and rigorous user test with non-technical experts from the museum. The cognitive walkthrough included in this thesis does deliver a few insights into the usability of the application and the interaction with the topic modeling pipeline, but only a test in the situational context of the environment of the museum can convey reliable information concerning the interpretability of the used algorithms and the inferences the users are able to make using the system.

Accordingly, and based in part on the work of this thesis, the researchers in project IKON are currently developing qualitative research methods to study the contextual interpretability of the topic modeling pipeline. This may show how reinterpretation of interpretability techniques, and possible refinement of the developed interpretability techniques of this thesis, may be taken up in future work.
