% ---------------------------------------------------
% ----- Main document of the template
% ----- for Bachelor-, Master thesis and class papers
% ---------------------------------------------------
%  Created by Claudia Müller-Birn on 2012-08-17. (updated on 2013-04-03)
%  Freie Universität Berlin, Institute of Computer Science, Human Centered Computing (HCC). 
%
\documentclass[pdftex,a4paper,12pt]{scrartcl}   
%
%---------------------------------------------------
%----- Packages
%---------------------------------------------------
%
\usepackage{pgfgantt}
\usepackage[T1]{fontenc} 
\usepackage[utf8]{inputenc}
%\usepackage[ngerman]{babel} 
\usepackage[english]{babel}  
\usepackage{ae} 
\usepackage{bibgerm}    

\usepackage{fancyref} 
\usepackage{fancyhdr} % Define simple headings 
\usepackage{xcolor}
\usepackage{url}
%
%\usepackage[pdftex]{graphicx}  
\usepackage{hyperref} % turn all your internal references into hyperlinks
%\usepackage[pdfstartview=FitH,pdftitle={<<Titel der Arbeit>>}, pdfauthor={<<Autor>>}, pdfkeywords={<<Schlüsselwörter>>}, pdfsubject={<<Titel der Arbeit>>}, colorlinks=true, linkcolor=black, citecolor=black, urlcolor=black, hypertexnames=false, bookmarksnumbered=true, bookmarksopen=true, pdfborder = {0 0 0}]{hyperref}
% 
% a new command is defined that allows to include an empty page when needed
\definecolor{tim}{rgb}  {0.6, 0.1, 0.4}
\newcommand{\tk}[1]{\textcolor{tim}{[\textbf{TK:} #1]}}
\newcommand{\blankpage}{
\newpage
\thispagestyle{empty}
\mbox{}
\newpage
}
%
%---------------------------------------------------
%----- PDF and document setup
%---------------------------------------------------
%
\hypersetup{
	pdftitle={Comparing Interpretability Techniques for Unsupervised Topic Modeling},  % please, add the title of your thesis
    pdfauthor={Tim Korjakow},   % please, add your name
    pdfsubject={<<Bachelor thesis>, Institute of Computer Science, Freie Universität Berlin>}, % please, select the type of this document
    pdfstartview={FitH},    % fits the width of the page to the window
    pdfnewwindow=true, 		% links in new window
    colorlinks=false,  		% false: boxed links; true: colored links
    linkcolor=red,          % color of internal links
    citecolor=green,        % color of links to bibliography
    filecolor=magenta,      % color of file links
    urlcolor=cyan           % color of external links
}
%
%---------------------------------------------------      
%----- Settings for word separation  
%---------------------------------------------------      
% Help for separation (from package babel, section 22)):
% In german package the following hints are additionally available:
% "- = an explicit hyphen sign, allowing hyphenation in the rest of the word
% "| = disable ligature at this position. (e.g., Schaf"|fell)
% "~ = for a compound word mark without a breakpoint (e.g., bergauf und "~ab)
% "= = for a compound word mark with a breakpoint, allowing hyphenation in the composing words
% "" = like "-, but producing no hyphen sign (e.g., und/""oder)
%
% Describe separation hints here:
\hyphenation{
% Pro-to-koll-in-stan-zen
% Ma-na-ge-ment  Netz-werk-ele-men-ten
% Netz-werk Netz-werk-re-ser-vie-rung
% Netz-werk-adap-ter Fein-ju-stier-ung
% Da-ten-strom-spe-zi-fi-ka-tion Pa-ket-rumpf
% Kon-troll-in-stanz
}

%---------------------------------------------------      
%----- Settings for title page 
%---------------------------------------------------

\begin{titlepage}

\title{
{\small Bachelor thesis, Institute of Computer Science, Freie Universität Berlin}\\
{\small Human-Centered Computing (HCC), AG NBI}\\
[6ex]
{\LARGE Comparing Interpretability Techniques for Unsupervised Topic Modeling}\\
{\normalsize-- Exposé --}}

\author{
{\emph{\normalsize Tim Korjakow}}\\
{\normalsize tim.korjakow@campus.tu-berlin.de}\\\\
{\normalsize Supervisor: Jesse Josua Benjamin } \\
{\normalsize First examiner: Prof. Claudia Müller-Birn} \\
{\normalsize Second examiner: Prof. Klaus-Robert Müller } \\
}

\date{\normalsize Berlin, \today}

\end{titlepage}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% The content part of the documentent starts here! %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}

\maketitle 

\thispagestyle{empty}  % eliminate page number on the title page

\blankpage

%---------------------------------------------------      
%----- Content part  
%---------------------------------------------------

\setcounter{page}{1} % page number is set to "1" otherwise it would be "3"

\section{Motivation of the thesis} 

Research on Explainable Artificial Intelligence, often called XAI, is currently wildly distributed and characterized by several competing ideas and approaches from a vast number of fields including computer science, mathematics, social sciences and philosophy. Additionally to that development stands the fact that most of humanity's knowledge is encoded in texts. Therefore there is an urgent need to research these methods in the context of NLP.

Project IKON, which aims to develop a data-driven application for the discovery of knowledge transfer potentials between research projects and society at a major natural history research institution, serves as an optimal use case to analyze and apply this development. The core of this application is a cluster visualization which links research projects by their semantic similarity and is supplemented by links to infrastructures (e.g., collections or labs) and knowledge transfer activities (e.g., collections or labs). This cluster view is driven by a Topic Modelling Pipeline with a Singular Value Decomposition at its heart. It is thought that this method shares a limited amount of expressiveness with different other linear methods due to its purely linear nature \cite{arrasWhatRelevantText2017}. Furthermore building the pipeline brought up serious concerns and uncertainty concerning the meaningfulness of approaches such as parameter manipulation or choosing between algorithms for dimensionality reduction \cite{benjaminTransparencyMediationMeaning2018} in our use case. Interviews with domain experts and future users of the application reflected our uncertainty and revealed problems with the interpretation of results produced by the pipeline.

Therefore the integral problem in Project IKON is: Which parts of the pipeline need explainability, what kind of models can be used for these parts and what kind of artifacts can be extracted in order to support the process of identifying potentials for knowledge transfer at the research institution?

\section{Related work}

With the surge of the application of machine learning (ML) systems in our daily life there is an increasing demand to make operation and results of these systems interpretable for people with different backgrounds (ML experts, non-technical experts etc.). Contrary to these efforts, interpretability as term has become an ill-defined objective \cite{liptonMythosModelInterpretability2016}  for research and development in ML algorithms since there is no widely agreed upon definition of it. This leads to a very fragmented nature of the field. 

Miller et al. \cite{millerExplainableAIBeware2017} support this point by conducting a literature study and uncovering that interpretability research is rarely influenced by insights from the humanities, especially connected fields as explainability or causality research.

This thesis builds upon these concepts  and tries to transfer their critical insights into the sub field of natural language processing - an often overlooked discipline in the context of interpretability research.

\section{Goal setting and procedure} 
As formulated in the introduction, the main problem for project IKON is missing knowledge about the interpretability of the existing model. This thesis should therefore examine existing interpretability techniques, their applicability to the existing model or a contending one and subsequently a decision for one of them by systematically and iteratively sourcing feedback from the principal researchers of project IKON. The chosen model will be implemented and augmented by a number of interpretability techniques. The results will be assessed with the help of an exemplary, qualitative user test with an expert user from the natural history museum. This goal setting directly leads to the following list of steps:

\begin{enumerate}
	\item Since we as developers are not sure what kind of techniques to enhance explainability for unsupervised NLP models exist, a thorough and reproducible literature analysis on the status of XAI research in the field of NLP according to Petersen et al. \cite{petersenSystematicMappingStudies2008} is going to be conducted. This should result in a number of papers which are, according to the process, good representatives of the literature base and therefore also of current research efforts. 
	
	A quantitative analysis of these papers should summarize occurring XAI methods and categorize them according to the proposed categories of Hohman et. al. \cite{hohmanGamutDesignProbe2019}.
	
	\item The currently existing topic extraction pipeline can be clustered into the following four components: document embedding, dimensionality reduction into a topic space, clustering and another dimensionality reduction into 2D. Based on the results of the previous step for each component either a directly applicable method (e.g. a clustering algorithm) from a paper or a model which supports most collected methods (e.g. a neural network for document embedding) is chosen and implemented. Since the new pipeline should perform at least as good as the old one, each component will be quantitatively accessed according to applicable measures e.g. (\cite{roderExploringSpaceTopic2015a}). This is necessary to ensure that one is actually interpreting existing and captured semantic relations and not random artifacts generated by the various methods.
	
	\item In order to access how the implemented methods may support a non-technical expert in interpreting the results of the pipeline, a cognitive walkthrough from the point of view of a researcher from the national natural history museum will be conducted. Since ensuring robustness in such qualitative tests is always a concern, information from previous interviews with domain experts from the museum will be used to derive meaningful tasks.
\end{enumerate}

\section{Implementation}

One of the main technical challenges and parts of the implementational work will be the augmentation of the current topic modelling pipeline by a document embedding technique. Since the performance of the model greatly depends on this step, it is crucial to have well learned vector representations of the document base. Currently there is a corpus of circa 114000 scientific documents available in order to train the model. If that is not enough to gain expressive document embeddings, one may include pretrained word embeddings via e.g. BERT \cite{devlinBERTPretrainingDeep2018} to introduce external information into the model and enhance the semantic coherence of the learned embeddings. This path should be taken with caution since it is connected to an hardly determinable amount of complexity. Research in the field of transfer learning for document embeddings is still in its infancy.

In order to adhere to the current research and industry standards, the implementation of this thesis is going to be done in Python. Specifically, all the data preprocessing will be done with \href{https://spacy.io/}{spaCy} and all models will be  implemented either in \href{https://radimrehurek.com/gensim/}{Gensim} or \href{https://keras.io/}{Keras}. Based on the chosen model which is going to be augmented with explainability mechanisms further packages and technologies may be selected.

\section{Time calculation}

\begin{ganttchart}[
	hgrid,
	vgrid={*{6}{draw=none}, dotted},
	x unit=0.115cm,
	expand chart=\textwidth,
	time slot format=isodate,
	%   time slot unit=day,
	calendar week text = {\currentweek{}},
	milestone left shift =-1,
	milestone right shift =2,
	chart element start border=right,
	% Jens's nice update
	link bulge = 1.3,
	link/.style={-to, rounded corners = 3pt}
	%%
	]{2019-05-06}{2019-08-31}
	\gantttitlecalendar{year, month=name, week} \\
	\ganttbar{Literature analysis}{2019-05-06}{2019-05-26} \\
	\ganttlinkedmilestone{Selection of models and techniques}{2019-05-26} \\
	\ganttbar{Implementation}{2019-05-26}{2019-06-16} \\
	\ganttbar{User test}{2019-06-16}{2019-06-30} \\
	\ganttbar{Writing}{2019-05-06}{2019-05-13} \ganttlinkedbar{}{2019-06-01}{2019-07-30} \\
	\ganttlinkedmilestone{Handing in thesis}{2019-07-30} \\
	\ganttbar{}{2019-08-03}{2019-08-30}
	\ganttmilestone{Optional defense of thesis}{2019-08-30}
\end{ganttchart}


%---------------------------------------------------
%----- Bibliography
%---------------------------------------------------
\newpage
\phantomsection
\addcontentsline{toc}{chapter}{Literatur}   % headline
\bibliographystyle{alpha}  % citation style
\bibliography{../references/proposal} % bib file


\end{document}